{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival clustered linear regression\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "training_features_df_file='./data/processed/02.1-scaled_encoded_training_features_df.parquet'\n",
    "training_labels_df_file='./data/processed/02.1-scaled_encoded_training_labels_df.parquet'\n",
    "\n",
    "model_file='./models/03.1-linear_regression.pkl'\n",
    "classifier_model_file='./models/03.2-EFS_classifier_model.pkl'\n",
    "cluster_regression_models_file='./models/03.2-cluster_regression_models.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "features_df=pd.read_parquet(training_features_df_file)\n",
    "labels_df=pd.read_parquet(training_labels_df_file)\n",
    "\n",
    "# Remove id column from training features\n",
    "features_df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "print(f'Features: {features_df.shape}')\n",
    "print(f'Labels: {labels_df.shape}')\n",
    "\n",
    "plt.title('EFS time distribution')\n",
    "plt.hist(labels_df['efs_time'], density=True, bins=30, color='black')\n",
    "plt.xlabel('ln(EFS time)')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make naive linear regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the baseline linear regression model\n",
    "with open(model_file, 'rb') as input_file:\n",
    "    regression_model=pickle.load(input_file)\n",
    "\n",
    "# Make predictions for the whole training set\n",
    "predictions=regression_model.predict(features_df)\n",
    "\n",
    "predictions_df=pd.DataFrame.from_dict({\n",
    "    'EFS time': labels_df['efs_time'],\n",
    "    'Predicted EFS time': predictions\n",
    "})\n",
    "\n",
    "rmse=root_mean_squared_error(labels_df['efs_time'],predictions)\n",
    "results={'Naive linear regression': rmse}\n",
    "print(f'Naive linear regression RMSE: {rmse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot results by EFS label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['Predicted EFS time']=predictions\n",
    "predictions_df['EFS time']=labels_df['efs_time']\n",
    "predictions_df['EFS']=labels_df['efs']\n",
    "\n",
    "efs_neg=predictions_df[predictions_df['EFS'] == 0]\n",
    "efs_pos=predictions_df[predictions_df['EFS'] == 1]\n",
    "\n",
    "# Plot the results\n",
    "plt.title('EFS binary label')\n",
    "plt.scatter(efs_neg['EFS time'], efs_neg['Predicted EFS time'], s=0.2, label='EFS negative', c='black')\n",
    "plt.scatter(efs_pos['EFS time'], efs_pos['Predicted EFS time'], s=0.2, label='EFS positive', c='firebrick')\n",
    "plt.xlabel('True EFS time')\n",
    "plt.ylabel('Predicted EFS time')\n",
    "plt.legend(loc='best', markerscale=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learn EFS binary label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_one_classifier=GradientBoostingClassifier(max_depth=20, random_state=315)\n",
    "result=round_one_classifier.fit(features_df, labels_df['efs'])\n",
    "\n",
    "with open(classifier_model_file, 'wb') as output_file:\n",
    "    pickle.dump(round_one_classifier, output_file)\n",
    "\n",
    "predictions_df['Round 1 learned cluster']=round_one_classifier.predict(features_df)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, testing_features, training_labels, testing_labels=train_test_split(\n",
    "    features_df, \n",
    "    labels_df['efs'],\n",
    "    test_size=0.33,\n",
    "    random_state=315\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Hyperaparameter tune gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model=GradientBoostingClassifier(random_state=315)\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cross_validation=KFold(n_splits=7, shuffle=True, random_state=315)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "distributions={\n",
    "    'learning_rate': stats.uniform(loc=0.00001, scale=0.00999),\n",
    "    'n_estimators': list(range(10, 500)),\n",
    "    'max_depth': list(range(5, 20)),\n",
    "    'min_samples_split': list(range(2, 100)),\n",
    "    'min_samples_leaf': list(range(1, 100)),\n",
    "    'subsample': stats.uniform(loc=0.5, scale=0.5)\n",
    "}\n",
    "\n",
    "# Set-up the search\n",
    "search=RandomizedSearchCV(\n",
    "    model,\n",
    "    distributions,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=cross_validation,\n",
    "    n_iter=100,\n",
    "    random_state=315,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "search_results=search.fit(training_features, training_labels)\n",
    "print(f'Best hyperparameters: {search_results.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Evaluate test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_one_classifier=GradientBoostingClassifier(**search_results.best_params_, random_state=315)\n",
    "result=round_one_classifier.fit(training_features, training_labels)\n",
    "predictions=round_one_classifier.predict(testing_features)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision=precision_score(testing_labels, predictions)\n",
    "recall=recall_score(testing_labels, predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm=confusion_matrix(testing_labels, predictions, normalize='true')\n",
    "cm_disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['EFS negative', 'EFS positive'])\n",
    "_=cm_disp.plot()\n",
    "\n",
    "plt.title('Test set classifier performance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Train and label whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_one_classifier=GradientBoostingClassifier(**search_results.best_params_, random_state=315)\n",
    "result=round_one_classifier.fit(features_df, labels_df['efs'])\n",
    "\n",
    "with open(classifier_model_file, 'wb') as output_file:\n",
    "    pickle.dump(round_one_classifier, output_file)\n",
    "\n",
    "predictions_df['Round 1 learned cluster']=round_one_classifier.predict(features_df)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,2, figsize=(8,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Round 1 clustering')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "\n",
    "# Split the data by learned cluster\n",
    "cluster_zero=predictions_df[predictions_df['Round 1 learned cluster'] == 0]\n",
    "cluster_one=predictions_df[predictions_df['Round 1 learned cluster'] == 1]\n",
    "\n",
    "axs[0].scatter(cluster_zero['EFS time'], cluster_zero['Predicted EFS time'], s=0.2, label='EFS negative', c='black')\n",
    "axs[0].scatter(cluster_one['EFS time'], cluster_one['Predicted EFS time'], s=0.2, label='EFS positive', c='firebrick')\n",
    "\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "axs[0].legend(loc='best', markerscale=10)\n",
    "\n",
    "axs[1].set_title('EFS classifier performance')\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision=precision_score(predictions_df['EFS'], predictions_df['Round 1 learned cluster'])\n",
    "recall=recall_score(predictions_df['EFS'], predictions_df['Round 1 learned cluster'])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm=confusion_matrix(predictions_df['EFS'], predictions_df['Round 1 learned cluster'], normalize='true')\n",
    "cm_disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['EFS negative', 'EFS positive'])\n",
    "_=cm_disp.plot(ax=axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regression in clusters\n",
    "\n",
    "### 5.1. Split data by learned cluster assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['Round 1 learned cluster']=predictions_df['Round 1 learned cluster']\n",
    "\n",
    "clustered_features={\n",
    "    'Cluster zero': features_df[features_df['Round 1 learned cluster'] == 0].copy(),\n",
    "    'Cluster one': features_df[features_df['Round 1 learned cluster'] == 1].copy()\n",
    "}\n",
    "\n",
    "labels_df['Round 1 learned cluster']=predictions_df['Round 1 learned cluster']\n",
    "\n",
    "clustered_labels={\n",
    "    'Cluster zero': labels_df[labels_df['Round 1 learned cluster'] == 0].copy(),\n",
    "    'Cluster one': labels_df[labels_df['Round 1 learned cluster'] == 1].copy()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Cluster regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_one_regression_models={\n",
    "    'Cluster zero': LinearRegression(),\n",
    "    'Cluster one': LinearRegression()\n",
    "}\n",
    "\n",
    "predictions={}\n",
    "\n",
    "for cluster in clustered_features.keys():\n",
    "\n",
    "    if cluster == 'Cluster zero':\n",
    "        features=np.array(clustered_features[cluster])**2\n",
    "\n",
    "    elif cluster == 'Cluster one':\n",
    "        features=clustered_features[cluster]\n",
    "\n",
    "    round_one_regression_models[cluster].fit(features, clustered_labels[cluster]['efs_time'])\n",
    "    predictions[cluster]=round_one_regression_models[cluster].predict(features)\n",
    "\n",
    "with open(cluster_regression_models_file, 'wb') as output_file:\n",
    "    pickle.dump(round_one_regression_models, output_file)\n",
    "\n",
    "joined_predictions=[]\n",
    "joined_labels=[]\n",
    "\n",
    "for cluster in clustered_features.keys():\n",
    "    joined_predictions.extend(predictions[cluster])\n",
    "    joined_labels.extend(clustered_labels[cluster]['efs_time'])\n",
    "    \n",
    "rmse=root_mean_squared_error(joined_labels, joined_predictions)\n",
    "results['Round 1 clustered regression']=rmse\n",
    "\n",
    "plt.title('Actual vs predicted EFS time')\n",
    "\n",
    "colors=['black', 'firebrick']\n",
    "\n",
    "for cluster, color in zip(clustered_features.keys(), colors):\n",
    "    plt.scatter(clustered_labels[cluster]['efs_time'], predictions[cluster], s=0.2, c=color, label=cluster)\n",
    "\n",
    "plt.xlabel('True EFS time')\n",
    "plt.ylabel('Predicted EFS time')\n",
    "plt.legend(loc='best', markerscale=10)\n",
    "plt.show()\n",
    "\n",
    "for key, value in results.items():\n",
    "    print(f'{key} RMSE: {value:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_labels=np.array(joined_labels)\n",
    "joined_predictions=np.array(joined_predictions)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,3, figsize=(10,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Linear regression model performance')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "axs[0].scatter(joined_labels, joined_predictions, color='black', s=0.2)\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "\n",
    "axs[1].set_title('EFS residual as a function of fitted value')\n",
    "axs[1].scatter(\n",
    "    joined_predictions, \n",
    "    joined_labels - joined_predictions,\n",
    "    color='black',\n",
    "    s=0.2\n",
    ")\n",
    "axs[1].set_xlabel('EFS time')\n",
    "axs[1].set_ylabel('true - predicted EFS time')\n",
    "\n",
    "axs[2].set_title('Normal quantile plot')\n",
    "stats.probplot(joined_labels - joined_predictions, plot=axs[2])\n",
    "axs[2].get_lines()[0].set_markeredgecolor('black')\n",
    "axs[2].get_lines()[0].set_markerfacecolor('black')\n",
    "axs[2].set_xlabel('Normal quantiles')\n",
    "axs[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
