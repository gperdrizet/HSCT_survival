{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival: gradient boosting decision tree ensemble model\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "import configuration as config\n",
    "import functions.helper as helper_funcs\n",
    "\n",
    "# Data files\n",
    "raw_training_data_file=f'{config.DATA_PATH}/raw/train.csv'\n",
    "raw_testing_data_file=f'{config.DATA_PATH}/raw/train.csv'\n",
    "\n",
    "# Model files\n",
    "naive_model_file=f'{config.MODELS_PATH}/05.2-XGBoost_naive.pkl'\n",
    "tuned_model_file=f'{config.MODELS_PATH}/05.2-XGBoost_tuned.pkl'\n",
    "\n",
    "retune_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(raw_training_data_file, index_col='ID')\n",
    "\n",
    "plt.title('EFS time distribution')\n",
    "plt.hist(df['efs_time'], density=True, bins=30, color='black')\n",
    "plt.xlabel('EFS time')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "print(f'Training features: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save race group\n",
    "race_group=df['race_group']\n",
    "\n",
    "# Encode\n",
    "df=pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Clean up column names\n",
    "df.columns=df.columns.str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "\n",
    "# Add back race_group\n",
    "df['race_group']=race_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing=train_test_split(df, test_size=0.33, random_state=315)\n",
    "\n",
    "training_df=pd.DataFrame(training, columns=df.columns)\n",
    "testing_df=pd.DataFrame(testing, columns=df.columns)\n",
    "\n",
    "training_race_group=training_df['race_group']\n",
    "testing_race_group=testing_df['race_group']\n",
    "\n",
    "training_df.drop('race_group', axis=1, inplace=True)\n",
    "testing_df.drop('race_group', axis=1, inplace=True)\n",
    "\n",
    "training_labels_df=training_df[['efs', 'efs_time']]\n",
    "training_features_df=training_df.drop(['efs', 'efs_time'], axis=1)\n",
    "\n",
    "testing_labels_df=testing_df[['efs', 'efs_time']]\n",
    "testing_features_df=testing_df.drop(['efs', 'efs_time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "xgb_params={\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-validate naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation splitter\n",
    "k_fold=KFold(n_splits=30, shuffle=True, random_state=42)\n",
    "\n",
    "# Collector for scores\n",
    "scores=[]\n",
    "\n",
    "# Loop on cross-validation folds\n",
    "for i, (training_idx, validation_idx) in enumerate(k_fold.split(training_df)):\n",
    "\n",
    "    # Get the features for this fold\n",
    "    training_features=training_df.iloc[training_idx].drop(['efs', 'efs_time'], axis=1)\n",
    "    validation_features=training_df.iloc[validation_idx].drop(['efs', 'efs_time'], axis=1)\n",
    "\n",
    "    # Get the labels\n",
    "    training_labels=training_df.iloc[training_idx]['efs_time']\n",
    "    validation_labels=training_df.iloc[validation_idx]['efs_time']\n",
    "\n",
    "    # Convert to DMaxtrix for XGBoost training\n",
    "    dtraining=xgb.DMatrix(training_features, label=training_labels)\n",
    "    dvalidation=xgb.DMatrix(validation_features, label=validation_labels)\n",
    "\n",
    "    naive_model=xgb.train(\n",
    "        xgb_params,\n",
    "        dtraining,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtraining, 'training'), (dvalidation, 'validation')],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=0\n",
    "    )\n",
    "\n",
    "    predictions=naive_model.predict(dvalidation)\n",
    "    scores.append(root_mean_squared_error(validation_labels, predictions))\n",
    "\n",
    "cross_val_scores={'Naive model': scores}\n",
    "print(f'\\nCross-validation RMSE: {np.array(scores).mean():.3f} +/- {np.array(scores).std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit and evaluate naive model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert testing features & labels and convert to DMaxtrix for XGBoost training\n",
    "testing_features=testing_df.drop(['efs', 'efs_time'], axis=1)\n",
    "testing_labels=testing_df['efs_time']\n",
    "dtesting=xgb.DMatrix(testing_features, label=testing_labels)\n",
    "\n",
    "naive_model=xgb.train(\n",
    "    xgb_params,\n",
    "    dtraining,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtraining, 'training')],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "# Make predictions for the whole test set\n",
    "predicted_efs_time=naive_model.predict(dtesting)\n",
    "\n",
    "# Get and save the RMSE for later\n",
    "rmse=root_mean_squared_error(testing_labels_df['efs_time'], predicted_efs_time)\n",
    "rmse_results={'Naive model': rmse}\n",
    "\n",
    "# Get and save the concordance index for later\n",
    "cindex=concordance_index(\n",
    "    testing_labels_df['efs_time'],\n",
    "    predicted_efs_time,\n",
    "    testing_labels_df['efs']\n",
    ")\n",
    "\n",
    "cindex_results={'Naive model': cindex}\n",
    "\n",
    "# Get and save stratified concordance index for later\n",
    "results_df=pd.DataFrame({'ID': testing_df.index, 'prediction': predicted_efs_time})\n",
    "results_df['race_group']=testing_race_group\n",
    "results_df['efs_time']=testing_labels_df['efs_time']\n",
    "results_df['efs']=testing_labels_df['efs']\n",
    "solution=results_df.drop(['ID', 'prediction'], axis=1)\n",
    "submission=results_df.drop(['race_group','efs_time','efs'], axis=1)\n",
    "score=helper_funcs.competition_score(solution, submission)\n",
    "stratified_cindex_results={'Naive model': score}\n",
    "\n",
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,3, figsize=(10,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Naive gradient regression model test set performance')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "axs[0].scatter(testing_labels_df['efs_time'], predicted_efs_time, color='black', s=0.2)\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "\n",
    "axs[1].set_title('EFS residual as a function of fitted value')\n",
    "axs[1].scatter(predicted_efs_time, testing_labels_df['efs_time'] - predicted_efs_time, color='black', s=0.2)\n",
    "axs[1].set_xlabel('EFS time')\n",
    "axs[1].set_ylabel('true - predicted EFS time')\n",
    "\n",
    "axs[2].set_title('Normal quantile plot')\n",
    "stats.probplot(testing_labels_df['efs_time'] - predicted_efs_time, plot=axs[2])\n",
    "axs[2].get_lines()[0].set_markeredgecolor('black')\n",
    "axs[2].get_lines()[0].set_markerfacecolor('black')\n",
    "axs[2].set_xlabel('Normal quantiles')\n",
    "axs[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "with open(naive_model_file, 'wb') as output_file:\n",
    "    pickle.dump(naive_model, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter tuning\n",
    "\n",
    "Current search space runs at about a minute per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train or load model as desired\n",
    "if retune_model == True:\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model=xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        random_state=315\n",
    "    )\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cross_validation=KFold(n_splits=7, shuffle=True, random_state=315)\n",
    "\n",
    "    # Define the hyperparameter search space\n",
    "    distributions={\n",
    "        'learning_rate': stats.uniform(loc=0.0001, scale=0.0999),\n",
    "        'n_estimators': list(range(5, 100)),\n",
    "        'max_depth': list(range(5, 50)),\n",
    "        'num_parallel_tree': list(range(1, 5)),\n",
    "        'gamma': stats.uniform(loc=0.0001, scale=0.9999),\n",
    "        'subsample': stats.uniform(loc=0.5, scale=0.4)\n",
    "    }\n",
    "\n",
    "    # Set-up the search\n",
    "    search=RandomizedSearchCV(\n",
    "        model,\n",
    "        distributions,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=1,\n",
    "        cv=cross_validation,\n",
    "        n_iter=500,\n",
    "        random_state=315,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    results=search.fit(\n",
    "        training_features_df,\n",
    "        training_labels_df['efs_time'],\n",
    "    )\n",
    "    \n",
    "    print(f'Best hyperparameters: {results.best_params_}')\n",
    "\n",
    "    # Instantiate the model with the tuned hyperparameters\n",
    "    tuned_model=xgb.XGBRegressor(\n",
    "        **results.best_params_,\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        random_state=315\n",
    "    )\n",
    "    \n",
    "    tuned_model.fit(\n",
    "        training_features_df,\n",
    "        training_labels_df['efs_time'],\n",
    "    )\n",
    "\n",
    "    with open(tuned_model_file, 'wb') as output_file:\n",
    "        pickle.dump(tuned_model, output_file)\n",
    "    \n",
    "elif retune_model == False:\n",
    "    with open(tuned_model_file, 'rb') as input_file:\n",
    "        tuned_model=pickle.load(input_file)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-validate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation to estimate out-of-sample performance\n",
    "scores=helper_funcs.cross_val(\n",
    "    tuned_model,\n",
    "    training_features_df,\n",
    "    training_labels_df['efs_time'],\n",
    "    folds=30\n",
    ")\n",
    "\n",
    "cross_val_scores['Tuned model']=scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit and evaluate tuned model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training set\n",
    "predicted_efs_time=tuned_model.predict(testing_features_df)\n",
    "\n",
    "# Save the RMSE for later\n",
    "rmse_results['Tuned model']=root_mean_squared_error(testing_labels_df['efs_time'], predicted_efs_time)\n",
    "\n",
    "# Save the concordance index for later\n",
    "cindex_results['Tuned model']=concordance_index(\n",
    "    testing_labels_df['efs_time'],\n",
    "    predicted_efs_time,\n",
    "    testing_labels_df['efs']\n",
    ")\n",
    "\n",
    "# Get and save stratified concordance index for later\n",
    "results_df=pd.DataFrame({'ID': testing_df.index, 'prediction': predicted_efs_time})\n",
    "results_df['race_group']=testing_race_group\n",
    "results_df['efs_time']=testing_labels_df['efs_time']\n",
    "results_df['efs']=testing_labels_df['efs']\n",
    "solution=results_df.drop(['ID', 'prediction'], axis=1)\n",
    "submission=results_df.drop(['race_group','efs_time','efs'], axis=1)\n",
    "stratified_cindex_results['Tuned model']=helper_funcs.competition_score(solution, submission)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,3, figsize=(10,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Tuned gradient boosting regression model performance')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "axs[0].scatter(testing_labels_df['efs_time'], predicted_efs_time, color='black', s=0.2)\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "\n",
    "axs[1].set_title('EFS residual as a function of fitted value')\n",
    "axs[1].scatter(predicted_efs_time, testing_labels_df['efs_time'] - predicted_efs_time, color='black', s=0.2)\n",
    "axs[1].set_xlabel('EFS time')\n",
    "axs[1].set_ylabel('true - predicted EFS time')\n",
    "\n",
    "axs[2].set_title('Normal quantile plot')\n",
    "stats.probplot(testing_labels_df['efs_time'] - predicted_efs_time, plot=axs[2])\n",
    "axs[2].get_lines()[0].set_markeredgecolor('black')\n",
    "axs[2].get_lines()[0].set_markerfacecolor('black')\n",
    "axs[2].set_xlabel('Normal quantiles')\n",
    "axs[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model comparison\n",
    "\n",
    "### 9.1. Cross-validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect scores\n",
    "joined_scores=[]\n",
    "\n",
    "for scores in cross_val_scores.values():\n",
    "    joined_scores.extend(scores)\n",
    "\n",
    "_, bins=np.histogram(joined_scores)\n",
    "\n",
    "plt.title('Cross-validation performance comparison')\n",
    "\n",
    "for model, scores in cross_val_scores.items():\n",
    "    plt.hist(scores, bins=bins, alpha=0.7, label=model)\n",
    "    \n",
    "plt.xlabel('Validation RMSE')\n",
    "plt.ylabel('Samples')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Test set performance\n",
    "\n",
    "#### 9.2.1 RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, score in rmse_results.items():\n",
    "    print(f'{model} RMSE: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.2. Concordance index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, score in cindex_results.items():\n",
    "    print(f'{model} concordance index: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.3. Stratified concordance index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, score in stratified_cindex_results.items():\n",
    "    print(f'{model} stratified concordance index: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
