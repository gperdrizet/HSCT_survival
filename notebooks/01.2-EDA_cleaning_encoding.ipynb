{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival: data cleaning and encoding\n",
    "\n",
    "## 1. Notebook set-up\n",
    "\n",
    "### 1.1. Imports & options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyPI imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "\n",
    "# Internal imports\n",
    "import configuration as config\n",
    "import functions.encoding as encode_funcs\n",
    "import functions.helper as helper_funcs\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run options\n",
    "rebuild_datasets=True\n",
    "\n",
    "# Some cleaning/encoding options\n",
    "knn_neighbors=5\n",
    "one_hot_drop, collinearity='first', 'no-multicollinearity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base data input file: ID column set as index, missing string placeholders converted to nan\n",
    "# ordinal categorical features translated to numerical categorical where possible\n",
    "translated_features_file=f'{config.PROCESSED_DATA}/01.1-features_translated.pkl'\n",
    "\n",
    "# Feature data type definition file\n",
    "feature_types_dict_file=f'{config.PROCESSED_DATA}/01.1-feature_type_dict.pkl'\n",
    "\n",
    "# Nominal and ordinal features ordinal encoded.\n",
    "# NAN values encoded as 'missing' for categorical features\n",
    "# and KNN imputed for numerical features.\n",
    "ordinal_all_nan_encoded_data_df_file=f'{config.PROCESSED_DATA}/02.1-{collinearity}_ordinal_all_nan_encoded_data_df.pkl'\n",
    "\n",
    "# Nominal and ordinal features ordinal encoded encoded.\n",
    "# NANs filled in by KNN imputation for all features.\n",
    "ordinal_all_nan_imputed_data_df_file=f'{config.PROCESSED_DATA}/02.1-{collinearity}_ordinal_all_nan_imputed_data_df.pkl'\n",
    "\n",
    "# Nominal features one hot encoded, ordinal features ordinal encoded. \n",
    "# Data with with NAN values encoded as missing for categorical features \n",
    "# and KNN imputed for numerical features.\n",
    "one_hot_ordinal_nan_encoded_data_df_file=f'{config.PROCESSED_DATA}/02.1-{collinearity}_one_hot_ordinal_nan_encoded_data_df.pkl'\n",
    "\n",
    "# Nominal features one hot encoded, ordinal features ordinal encoded.\n",
    "# NANs filled in by KNN imputation for all features.\n",
    "one_hot_ordinal_nan_imputed_data_df_file=f'{config.PROCESSED_DATA}/02.1-{collinearity}_one_hot_ordinal_nan_imputed_data_df.pkl'\n",
    "\n",
    "# All ordinal and nominal features target encoded on EFS\n",
    "binary_target_encoded_data_file=f'{config.PROCESSED_DATA}/02.1-binary_target_encoded_data_df.pkl'\n",
    "\n",
    "# All ordinal and nominal features target encoded on EFS time\n",
    "continuous_target_encoded_data_file=f'{config.PROCESSED_DATA}/02.1-continuous_target_encoded_data_df.pkl'\n",
    "\n",
    "# Save dataset definitions\n",
    "datasets={\n",
    "    'Nominal one-hot/ordinal encoded, NANs encoded':one_hot_ordinal_nan_encoded_data_df_file,\n",
    "    'Nominal one-hot/ordinal encoded, NANs imputed':one_hot_ordinal_nan_imputed_data_df_file,\n",
    "    'All ordinal encoded, NAN encoded':ordinal_all_nan_encoded_data_df_file,\n",
    "    'All ordinal encoded, NAN imputed':ordinal_all_nan_imputed_data_df_file,\n",
    "    'Binary target encoded':binary_target_encoded_data_file,\n",
    "    'Continuous target encoded':continuous_target_encoded_data_file\n",
    "}\n",
    "\n",
    "# Dataset definition file\n",
    "datasets_file=f'{config.PROCESSED_DATA}/02.1-dataset_definitions.pkl'\n",
    "\n",
    "# Save the dataset metadata\n",
    "with open(datasets_file, 'wb') as output_file:\n",
    "    pickle.dump(datasets, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input data\n",
    "\n",
    "### 2.1. Feature type definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature types:\n",
      "\n",
      "Interval\n",
      "['donor_age', 'age_at_hct']\n",
      "\n",
      "Ordinal\n",
      "['hla_match_c_high', 'hla_high_res_8', 'hla_low_res_6', 'hla_high_res_6', 'hla_high_res_10', 'hla_match_dqb1_high', 'hla_nmdp_6', 'hla_match_c_low', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'year_hct', 'hla_match_a_high', 'hla_match_b_low', 'hla_match_a_low', 'hla_match_b_high', 'comorbidity_score', 'karnofsky_score', 'hla_low_res_8', 'hla_match_drb1_high', 'hla_low_res_10', 'dri_score', 'cyto_score', 'cmv_status', 'cyto_score_detail']\n",
      "\n",
      "Nominal\n",
      "['psych_disturb', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'tce_imm_match', 'rituximab', 'prod_type', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n",
      "\n",
      "Labels\n",
      "['efs', 'efs_time']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the feature data type definitions\n",
    "with open(feature_types_dict_file, 'rb') as input_file:\n",
    "    feature_types_dict=pickle.load(input_file)\n",
    "\n",
    "print('Feature types:\\n')\n",
    "\n",
    "for feature_type, features in feature_types_dict.items():\n",
    "    print(f'{feature_type}\\n{features}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rebuild_datasets == True:\n",
    "    \n",
    "    # Load the dataset\n",
    "    data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "    # Train test split\n",
    "    master_training_df, master_testing_df=train_test_split(data_df, test_size=0.3, random_state=315)\n",
    "\n",
    "    # Save the un-encoded race group so we can use it in C-index scoring later\n",
    "    training_race_group=master_training_df['race_group']\n",
    "    testing_race_group=master_testing_df['race_group']\n",
    "\n",
    "    # Save and remove the IDs\n",
    "    training_ids=master_training_df.index\n",
    "    master_training_df.reset_index(drop=True, inplace=True)\n",
    "    testing_ids=master_testing_df.index\n",
    "    master_testing_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Remove the labels\n",
    "    master_training_labels_df=master_training_df[['efs', 'efs_time']].copy()\n",
    "    master_training_features_df=master_training_df.drop(['efs', 'efs_time'], axis=1)\n",
    "    master_testing_labels_df=master_testing_df[['efs', 'efs_time']].copy()\n",
    "    master_testing_features_df=master_testing_df.drop(['efs', 'efs_time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoding and NAN handling schemes\n",
    "\n",
    "### 3.1. One-hot encode nominal features with missing value string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot encoding input data: (20160, 57)\n",
      "Feature data: (20160, 31)\n",
      "One-hot encoded feature data: (8640, 114)\n",
      "\n",
      "Ordinal encoding input data: (20160, 57)\n",
      "Feature data: (20160, 24)\n",
      "Ordinal encoded feature data: (20160, 24)\n",
      "Imputed, ordinal encoded feature data: (20160, 24)\n",
      "\n",
      "Imputation input data: (20160, 22)\n",
      "Imputed numerical data: (20160, 2)\n",
      "Re-combined data: (20160, 140)\n",
      "\n",
      "Data dictionary contains:\n",
      " Training features: <class 'pandas.core.frame.DataFrame'>\n",
      " Training labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Training IDs: <class 'list'>\n",
      " Training race group: <class 'list'>\n",
      " Testing features: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing IDs: <class 'list'>\n",
      " Testing race group: <class 'list'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20160 entries, 0 to 20159\n",
      "Data columns (total 140 columns):\n",
      " #    Column                                                Non-Null Count  Dtype  \n",
      "---   ------                                                --------------  -----  \n",
      " 0    psych_disturb_Yes                                     20160 non-null  int32  \n",
      " 1    psych_disturb_missing                                 20160 non-null  int32  \n",
      " 2    diabetes_Yes                                          20160 non-null  int32  \n",
      " 3    diabetes_missing                                      20160 non-null  int32  \n",
      " 4    tbi_status_>cGy                                       20160 non-null  int32  \n",
      " 5    tbi_status_Cy                                         20160 non-null  int32  \n",
      " 6    tbi_status_None                                       20160 non-null  int32  \n",
      " 7    tbi_status_frac                                       20160 non-null  int32  \n",
      " 8    tbi_status_missing                                    20160 non-null  int32  \n",
      " 9    tbi_status_single                                     20160 non-null  int32  \n",
      " 10   tbi_status_unknown                                    20160 non-null  int32  \n",
      " 11   arrhythmia_Yes                                        20160 non-null  int32  \n",
      " 12   arrhythmia_missing                                    20160 non-null  int32  \n",
      " 13   graft_type_Marrow                                     20160 non-null  int32  \n",
      " 14   vent_hist_Yes                                         20160 non-null  int32  \n",
      " 15   vent_hist_missing                                     20160 non-null  int32  \n",
      " 16   renal_issue_Yes                                       20160 non-null  int32  \n",
      " 17   renal_issue_missing                                   20160 non-null  int32  \n",
      " 18   pulm_severe_Yes                                       20160 non-null  int32  \n",
      " 19   pulm_severe_missing                                   20160 non-null  int32  \n",
      " 20   prim_disease_hct_ALEU                                 20160 non-null  int32  \n",
      " 21   prim_disease_hct_ALL                                  20160 non-null  int32  \n",
      " 22   prim_disease_hct_AML                                  20160 non-null  int32  \n",
      " 23   prim_disease_hct_CML                                  20160 non-null  int32  \n",
      " 24   prim_disease_hct_HD                                   20160 non-null  int32  \n",
      " 25   prim_disease_hct_HIS                                  20160 non-null  int32  \n",
      " 26   prim_disease_hct_IEA                                  20160 non-null  int32  \n",
      " 27   prim_disease_hct_IIS                                  20160 non-null  int32  \n",
      " 28   prim_disease_hct_IMD                                  20160 non-null  int32  \n",
      " 29   prim_disease_hct_IPA                                  20160 non-null  int32  \n",
      " 30   prim_disease_hct_LEU                                  20160 non-null  int32  \n",
      " 31   prim_disease_hct_MDS                                  20160 non-null  int32  \n",
      " 32   prim_disease_hct_MPN                                  20160 non-null  int32  \n",
      " 33   prim_disease_hct_NHL                                  20160 non-null  int32  \n",
      " 34   prim_disease_hct_PCD                                  20160 non-null  int32  \n",
      " 35   prim_disease_hct_SAA                                  20160 non-null  int32  \n",
      " 36   prim_disease_hct_SOL                                  20160 non-null  int32  \n",
      " 37   tce_imm_match_G/G                                     20160 non-null  int32  \n",
      " 38   tce_imm_match_H/B                                     20160 non-null  int32  \n",
      " 39   tce_imm_match_H/H                                     20160 non-null  int32  \n",
      " 40   tce_imm_match_P/B                                     20160 non-null  int32  \n",
      " 41   tce_imm_match_P/G                                     20160 non-null  int32  \n",
      " 42   tce_imm_match_P/H                                     20160 non-null  int32  \n",
      " 43   tce_imm_match_P/P                                     20160 non-null  int32  \n",
      " 44   tce_imm_match_missing                                 20160 non-null  int32  \n",
      " 45   rituximab_Yes                                         20160 non-null  int32  \n",
      " 46   rituximab_missing                                     20160 non-null  int32  \n",
      " 47   prod_type_PB                                          20160 non-null  int32  \n",
      " 48   conditioning_intensity_NMA                            20160 non-null  int32  \n",
      " 49   conditioning_intensity_None                           20160 non-null  int32  \n",
      " 50   conditioning_intensity_RIC                            20160 non-null  int32  \n",
      " 51   conditioning_intensity_missing                        20160 non-null  int32  \n",
      " 52   ethnicity_-His+Lat                                    20160 non-null  int32  \n",
      " 53   ethnicity_Non-US                                      20160 non-null  int32  \n",
      " 54   ethnicity_missing                                     20160 non-null  int32  \n",
      " 55   obesity_Yes                                           20160 non-null  int32  \n",
      " 56   obesity_missing                                       20160 non-null  int32  \n",
      " 57   mrd_hct_Positive                                      20160 non-null  int32  \n",
      " 58   mrd_hct_missing                                       20160 non-null  int32  \n",
      " 59   in_vivo_tcd_Yes                                       20160 non-null  int32  \n",
      " 60   in_vivo_tcd_missing                                   20160 non-null  int32  \n",
      " 61   tce_match_HvG non-per                                 20160 non-null  int32  \n",
      " 62   tce_match_Match                                       20160 non-null  int32  \n",
      " 63   tce_match_Per                                         20160 non-null  int32  \n",
      " 64   tce_match_missing                                     20160 non-null  int32  \n",
      " 65   hepatic_severe_Yes                                    20160 non-null  int32  \n",
      " 66   hepatic_severe_missing                                20160 non-null  int32  \n",
      " 67   prior_tumor_Yes                                       20160 non-null  int32  \n",
      " 68   prior_tumor_missing                                   20160 non-null  int32  \n",
      " 69   peptic_ulcer_Yes                                      20160 non-null  int32  \n",
      " 70   peptic_ulcer_missing                                  20160 non-null  int32  \n",
      " 71   gvhd_proph_CDsel+                                     20160 non-null  int32  \n",
      " 72   gvhd_proph_CSA                                        20160 non-null  int32  \n",
      " 73   gvhd_proph_CSA+                                       20160 non-null  int32  \n",
      " 74   gvhd_proph_CSA+MMF                                    20160 non-null  int32  \n",
      " 75   gvhd_proph_CSA+MTX+                                   20160 non-null  int32  \n",
      " 76   gvhd_proph_Cyclop                                     20160 non-null  int32  \n",
      " 77   gvhd_proph_Cyclop+                                    20160 non-null  int32  \n",
      " 78   gvhd_proph_FK                                         20160 non-null  int32  \n",
      " 79   gvhd_proph_FK+MMF                                     20160 non-null  int32  \n",
      " 80   gvhd_proph_FK+MTX                                     20160 non-null  int32  \n",
      " 81   gvhd_proph_GVHD                                       20160 non-null  int32  \n",
      " 82   gvhd_proph_None                                       20160 non-null  int32  \n",
      " 83   gvhd_proph_ParQ                                       20160 non-null  int32  \n",
      " 84   gvhd_proph_T-DEP                                      20160 non-null  int32  \n",
      " 85   gvhd_proph_T-DEP+                                     20160 non-null  int32  \n",
      " 86   gvhd_proph_missing                                    20160 non-null  int32  \n",
      " 87   gvhd_proph_infrequent_sklearn                         20160 non-null  int32  \n",
      " 88   rheum_issue_Yes                                       20160 non-null  int32  \n",
      " 89   rheum_issue_missing                                   20160 non-null  int32  \n",
      " 90   sex_match_F-M                                         20160 non-null  int32  \n",
      " 91   sex_match_M-F                                         20160 non-null  int32  \n",
      " 92   sex_match_M-M                                         20160 non-null  int32  \n",
      " 93   sex_match_missing                                     20160 non-null  int32  \n",
      " 94   race_group_Asian                                      20160 non-null  int32  \n",
      " 95   race_group_Black or African-American                  20160 non-null  int32  \n",
      " 96   race_group_More than one race                         20160 non-null  int32  \n",
      " 97   race_group_Native Hawaiian or other Pacific Islander  20160 non-null  int32  \n",
      " 98   race_group_White                                      20160 non-null  int32  \n",
      " 99   hepatic_mild_Yes                                      20160 non-null  int32  \n",
      " 100  hepatic_mild_missing                                  20160 non-null  int32  \n",
      " 101  tce_div_match_HvG no                                  20160 non-null  int32  \n",
      " 102  tce_div_match_No                                      20160 non-null  int32  \n",
      " 103  tce_div_match_Yes                                     20160 non-null  int32  \n",
      " 104  tce_div_match_missing                                 20160 non-null  int32  \n",
      " 105  donor_related_No                                      20160 non-null  int32  \n",
      " 106  donor_related_Yes                                     20160 non-null  int32  \n",
      " 107  donor_related_missing                                 20160 non-null  int32  \n",
      " 108  melphalan_dose_Yes                                    20160 non-null  int32  \n",
      " 109  melphalan_dose_missing                                20160 non-null  int32  \n",
      " 110  cardiac_Yes                                           20160 non-null  int32  \n",
      " 111  cardiac_missing                                       20160 non-null  int32  \n",
      " 112  pulm_moderate_Yes                                     20160 non-null  int32  \n",
      " 113  pulm_moderate_missing                                 20160 non-null  int32  \n",
      " 114  hla_match_c_high                                      20160 non-null  int32  \n",
      " 115  hla_high_res_8                                        20160 non-null  int32  \n",
      " 116  hla_low_res_6                                         20160 non-null  int32  \n",
      " 117  hla_high_res_6                                        20160 non-null  int32  \n",
      " 118  hla_high_res_10                                       20160 non-null  int32  \n",
      " 119  hla_match_dqb1_high                                   20160 non-null  int32  \n",
      " 120  hla_nmdp_6                                            20160 non-null  int32  \n",
      " 121  hla_match_c_low                                       20160 non-null  int32  \n",
      " 122  hla_match_drb1_low                                    20160 non-null  int32  \n",
      " 123  hla_match_dqb1_low                                    20160 non-null  int32  \n",
      " 124  year_hct                                              20160 non-null  int32  \n",
      " 125  hla_match_a_high                                      20160 non-null  int32  \n",
      " 126  hla_match_b_low                                       20160 non-null  int32  \n",
      " 127  hla_match_a_low                                       20160 non-null  int32  \n",
      " 128  hla_match_b_high                                      20160 non-null  int32  \n",
      " 129  comorbidity_score                                     20160 non-null  int32  \n",
      " 130  karnofsky_score                                       20160 non-null  int32  \n",
      " 131  hla_low_res_8                                         20160 non-null  int32  \n",
      " 132  hla_match_drb1_high                                   20160 non-null  int32  \n",
      " 133  hla_low_res_10                                        20160 non-null  int32  \n",
      " 134  dri_score                                             20160 non-null  int32  \n",
      " 135  cyto_score                                            20160 non-null  int32  \n",
      " 136  cmv_status                                            20160 non-null  int32  \n",
      " 137  cyto_score_detail                                     20160 non-null  int32  \n",
      " 138  donor_age                                             20160 non-null  float64\n",
      " 139  age_at_hct                                            20160 non-null  float64\n",
      "dtypes: float64(2), int32(138)\n",
      "memory usage: 10.9 MB\n"
     ]
    }
   ],
   "source": [
    "if rebuild_datasets == True:\n",
    "    \n",
    "    # Make a copy of the master input testing and training features\n",
    "    training_df=master_training_features_df.copy()\n",
    "    testing_df=master_testing_features_df.copy()\n",
    "\n",
    "    # Encode the nominal features\n",
    "    nominal_training_df, nominal_testing_df=encode_funcs.one_hot_nan_encoded(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Nominal'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Encode the ordinal features\n",
    "    ordinal_training_df, ordinal_testing_df=encode_funcs.ordinal_encode_nan_imputed(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Ordinal'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Clean NANs in the interval features\n",
    "    interval_training_df, interval_testing_df=encode_funcs.impute_numerical_features(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Interval'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Join the data back together\n",
    "    training_df=pd.concat([nominal_training_df, ordinal_training_df, interval_training_df], axis=1)\n",
    "    testing_df=pd.concat([nominal_testing_df, ordinal_testing_df, interval_testing_df], axis=1)\n",
    "    print(f'Re-combined data: {training_df.shape}\\n')\n",
    "\n",
    "    # Assemble dataset dictionary\n",
    "    dataset={\n",
    "        'Training features': training_df,\n",
    "        'Training labels': master_training_labels_df,\n",
    "        'Training IDs': list(training_ids.values),\n",
    "        'Training race group': list(training_race_group.values),\n",
    "        'Testing features': testing_df,\n",
    "        'Testing labels': master_testing_labels_df,\n",
    "        'Testing IDs': list(testing_ids.values),\n",
    "        'Testing race group': list(testing_race_group.values),\n",
    "    }\n",
    "\n",
    "    print('Data dictionary contains:')\n",
    "    for key, value in dataset.items():\n",
    "        print(f' {key}: {type(value)}')\n",
    "\n",
    "    # Save\n",
    "    with open(one_hot_ordinal_nan_encoded_data_df_file, 'wb') as output_file:\n",
    "        pickle.dump(dataset, output_file)\n",
    "\n",
    "    # Inspect\n",
    "    print()\n",
    "    training_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. One-hot encode nominal features with missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot encoding input data: (20160, 57)\n",
      "Feature data: (20160, 31)\n",
      "On-hot encoded, imputed feature data: (20160, 114)\n",
      "\n",
      "Ordinal encoding input data: (20160, 57)\n",
      "Feature data: (20160, 24)\n",
      "Ordinal encoded feature data: (20160, 24)\n",
      "Imputed, ordinal encoded feature data: (20160, 24)\n",
      "\n",
      "Imputation input data: (20160, 22)\n",
      "Imputed numerical data: (20160, 2)\n",
      "Re-combined data: (20160, 140)\n",
      "\n",
      "Data dictionary contains:\n",
      " Training features: <class 'pandas.core.frame.DataFrame'>\n",
      " Training labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Training IDs: <class 'list'>\n",
      " Training race group: <class 'list'>\n",
      " Testing features: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing IDs: <class 'list'>\n",
      " Testing race group: <class 'list'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20160 entries, 0 to 20159\n",
      "Data columns (total 140 columns):\n",
      " #    Column                         Non-Null Count  Dtype  \n",
      "---   ------                         --------------  -----  \n",
      " 0    psych_disturb_1.0              20160 non-null  int32  \n",
      " 1    psych_disturb_2.0              20160 non-null  int32  \n",
      " 2    diabetes_1.0                   20160 non-null  int32  \n",
      " 3    diabetes_2.0                   20160 non-null  int32  \n",
      " 4    tbi_status_1.0                 20160 non-null  int32  \n",
      " 5    tbi_status_2.0                 20160 non-null  int32  \n",
      " 6    tbi_status_3.0                 20160 non-null  int32  \n",
      " 7    tbi_status_4.0                 20160 non-null  int32  \n",
      " 8    tbi_status_5.0                 20160 non-null  int32  \n",
      " 9    tbi_status_6.0                 20160 non-null  int32  \n",
      " 10   tbi_status_7.0                 20160 non-null  int32  \n",
      " 11   arrhythmia_1.0                 20160 non-null  int32  \n",
      " 12   arrhythmia_2.0                 20160 non-null  int32  \n",
      " 13   graft_type_1.0                 20160 non-null  int32  \n",
      " 14   vent_hist_1.0                  20160 non-null  int32  \n",
      " 15   vent_hist_2.0                  20160 non-null  int32  \n",
      " 16   renal_issue_1.0                20160 non-null  int32  \n",
      " 17   renal_issue_2.0                20160 non-null  int32  \n",
      " 18   pulm_severe_1.0                20160 non-null  int32  \n",
      " 19   pulm_severe_2.0                20160 non-null  int32  \n",
      " 20   prim_disease_hct_1.0           20160 non-null  int32  \n",
      " 21   prim_disease_hct_2.0           20160 non-null  int32  \n",
      " 22   prim_disease_hct_3.0           20160 non-null  int32  \n",
      " 23   prim_disease_hct_4.0           20160 non-null  int32  \n",
      " 24   prim_disease_hct_5.0           20160 non-null  int32  \n",
      " 25   prim_disease_hct_6.0           20160 non-null  int32  \n",
      " 26   prim_disease_hct_7.0           20160 non-null  int32  \n",
      " 27   prim_disease_hct_8.0           20160 non-null  int32  \n",
      " 28   prim_disease_hct_9.0           20160 non-null  int32  \n",
      " 29   prim_disease_hct_10.0          20160 non-null  int32  \n",
      " 30   prim_disease_hct_11.0          20160 non-null  int32  \n",
      " 31   prim_disease_hct_12.0          20160 non-null  int32  \n",
      " 32   prim_disease_hct_13.0          20160 non-null  int32  \n",
      " 33   prim_disease_hct_14.0          20160 non-null  int32  \n",
      " 34   prim_disease_hct_15.0          20160 non-null  int32  \n",
      " 35   prim_disease_hct_16.0          20160 non-null  int32  \n",
      " 36   prim_disease_hct_17.0          20160 non-null  int32  \n",
      " 37   tce_imm_match_1.0              20160 non-null  int32  \n",
      " 38   tce_imm_match_2.0              20160 non-null  int32  \n",
      " 39   tce_imm_match_3.0              20160 non-null  int32  \n",
      " 40   tce_imm_match_4.0              20160 non-null  int32  \n",
      " 41   tce_imm_match_5.0              20160 non-null  int32  \n",
      " 42   tce_imm_match_6.0              20160 non-null  int32  \n",
      " 43   tce_imm_match_7.0              20160 non-null  int32  \n",
      " 44   tce_imm_match_8.0              20160 non-null  int32  \n",
      " 45   rituximab_1.0                  20160 non-null  int32  \n",
      " 46   rituximab_2.0                  20160 non-null  int32  \n",
      " 47   prod_type_1.0                  20160 non-null  int32  \n",
      " 48   conditioning_intensity_1.0     20160 non-null  int32  \n",
      " 49   conditioning_intensity_2.0     20160 non-null  int32  \n",
      " 50   conditioning_intensity_3.0     20160 non-null  int32  \n",
      " 51   conditioning_intensity_4.0     20160 non-null  int32  \n",
      " 52   ethnicity_1.0                  20160 non-null  int32  \n",
      " 53   ethnicity_2.0                  20160 non-null  int32  \n",
      " 54   ethnicity_3.0                  20160 non-null  int32  \n",
      " 55   obesity_1.0                    20160 non-null  int32  \n",
      " 56   obesity_2.0                    20160 non-null  int32  \n",
      " 57   mrd_hct_1.0                    20160 non-null  int32  \n",
      " 58   mrd_hct_2.0                    20160 non-null  int32  \n",
      " 59   in_vivo_tcd_1.0                20160 non-null  int32  \n",
      " 60   in_vivo_tcd_2.0                20160 non-null  int32  \n",
      " 61   tce_match_1.0                  20160 non-null  int32  \n",
      " 62   tce_match_2.0                  20160 non-null  int32  \n",
      " 63   tce_match_3.0                  20160 non-null  int32  \n",
      " 64   tce_match_4.0                  20160 non-null  int32  \n",
      " 65   hepatic_severe_1.0             20160 non-null  int32  \n",
      " 66   hepatic_severe_2.0             20160 non-null  int32  \n",
      " 67   prior_tumor_1.0                20160 non-null  int32  \n",
      " 68   prior_tumor_2.0                20160 non-null  int32  \n",
      " 69   peptic_ulcer_1.0               20160 non-null  int32  \n",
      " 70   peptic_ulcer_2.0               20160 non-null  int32  \n",
      " 71   gvhd_proph_1.0                 20160 non-null  int32  \n",
      " 72   gvhd_proph_2.0                 20160 non-null  int32  \n",
      " 73   gvhd_proph_3.0                 20160 non-null  int32  \n",
      " 74   gvhd_proph_4.0                 20160 non-null  int32  \n",
      " 75   gvhd_proph_5.0                 20160 non-null  int32  \n",
      " 76   gvhd_proph_6.0                 20160 non-null  int32  \n",
      " 77   gvhd_proph_7.0                 20160 non-null  int32  \n",
      " 78   gvhd_proph_8.0                 20160 non-null  int32  \n",
      " 79   gvhd_proph_10.0                20160 non-null  int32  \n",
      " 80   gvhd_proph_11.0                20160 non-null  int32  \n",
      " 81   gvhd_proph_12.0                20160 non-null  int32  \n",
      " 82   gvhd_proph_13.0                20160 non-null  int32  \n",
      " 83   gvhd_proph_14.0                20160 non-null  int32  \n",
      " 84   gvhd_proph_15.0                20160 non-null  int32  \n",
      " 85   gvhd_proph_16.0                20160 non-null  int32  \n",
      " 86   gvhd_proph_17.0                20160 non-null  int32  \n",
      " 87   gvhd_proph_infrequent_sklearn  20160 non-null  int32  \n",
      " 88   rheum_issue_1.0                20160 non-null  int32  \n",
      " 89   rheum_issue_2.0                20160 non-null  int32  \n",
      " 90   sex_match_1.0                  20160 non-null  int32  \n",
      " 91   sex_match_2.0                  20160 non-null  int32  \n",
      " 92   sex_match_3.0                  20160 non-null  int32  \n",
      " 93   sex_match_4.0                  20160 non-null  int32  \n",
      " 94   race_group_1.0                 20160 non-null  int32  \n",
      " 95   race_group_2.0                 20160 non-null  int32  \n",
      " 96   race_group_3.0                 20160 non-null  int32  \n",
      " 97   race_group_4.0                 20160 non-null  int32  \n",
      " 98   race_group_5.0                 20160 non-null  int32  \n",
      " 99   hepatic_mild_1.0               20160 non-null  int32  \n",
      " 100  hepatic_mild_2.0               20160 non-null  int32  \n",
      " 101  tce_div_match_1.0              20160 non-null  int32  \n",
      " 102  tce_div_match_2.0              20160 non-null  int32  \n",
      " 103  tce_div_match_3.0              20160 non-null  int32  \n",
      " 104  tce_div_match_4.0              20160 non-null  int32  \n",
      " 105  donor_related_1.0              20160 non-null  int32  \n",
      " 106  donor_related_2.0              20160 non-null  int32  \n",
      " 107  donor_related_3.0              20160 non-null  int32  \n",
      " 108  melphalan_dose_1.0             20160 non-null  int32  \n",
      " 109  melphalan_dose_2.0             20160 non-null  int32  \n",
      " 110  cardiac_1.0                    20160 non-null  int32  \n",
      " 111  cardiac_2.0                    20160 non-null  int32  \n",
      " 112  pulm_moderate_1.0              20160 non-null  int32  \n",
      " 113  pulm_moderate_2.0              20160 non-null  int32  \n",
      " 114  hla_match_c_high               20160 non-null  int32  \n",
      " 115  hla_high_res_8                 20160 non-null  int32  \n",
      " 116  hla_low_res_6                  20160 non-null  int32  \n",
      " 117  hla_high_res_6                 20160 non-null  int32  \n",
      " 118  hla_high_res_10                20160 non-null  int32  \n",
      " 119  hla_match_dqb1_high            20160 non-null  int32  \n",
      " 120  hla_nmdp_6                     20160 non-null  int32  \n",
      " 121  hla_match_c_low                20160 non-null  int32  \n",
      " 122  hla_match_drb1_low             20160 non-null  int32  \n",
      " 123  hla_match_dqb1_low             20160 non-null  int32  \n",
      " 124  year_hct                       20160 non-null  int32  \n",
      " 125  hla_match_a_high               20160 non-null  int32  \n",
      " 126  hla_match_b_low                20160 non-null  int32  \n",
      " 127  hla_match_a_low                20160 non-null  int32  \n",
      " 128  hla_match_b_high               20160 non-null  int32  \n",
      " 129  comorbidity_score              20160 non-null  int32  \n",
      " 130  karnofsky_score                20160 non-null  int32  \n",
      " 131  hla_low_res_8                  20160 non-null  int32  \n",
      " 132  hla_match_drb1_high            20160 non-null  int32  \n",
      " 133  hla_low_res_10                 20160 non-null  int32  \n",
      " 134  dri_score                      20160 non-null  int32  \n",
      " 135  cyto_score                     20160 non-null  int32  \n",
      " 136  cmv_status                     20160 non-null  int32  \n",
      " 137  cyto_score_detail              20160 non-null  int32  \n",
      " 138  donor_age                      20160 non-null  float64\n",
      " 139  age_at_hct                     20160 non-null  float64\n",
      "dtypes: float64(2), int32(138)\n",
      "memory usage: 10.9 MB\n"
     ]
    }
   ],
   "source": [
    "if rebuild_datasets == True:\n",
    "\n",
    "    # Make a copy of the master input testing and training features\n",
    "    training_df=master_training_features_df.copy()\n",
    "    testing_df=master_testing_features_df.copy()\n",
    "\n",
    "    # Encode the nominal features\n",
    "    nominal_training_df, nominal_testing_df=encode_funcs.one_hot_encode_nan_imputed(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Nominal'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Encode the ordinal features\n",
    "    ordinal_training_df, ordinal_testing_df=encode_funcs.ordinal_encode_nan_imputed(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Ordinal'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Clean NANs in the interval features\n",
    "    interval_training_df, interval_testing_df=encode_funcs.impute_numerical_features(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Interval'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Join the data back together\n",
    "    training_df=pd.concat([nominal_training_df, ordinal_training_df, interval_training_df], axis=1)\n",
    "    testing_df=pd.concat([nominal_testing_df, ordinal_testing_df, interval_testing_df], axis=1)\n",
    "    print(f'Re-combined data: {training_df.shape}\\n')\n",
    "\n",
    "    # Assemble dataset dictionary\n",
    "    dataset={\n",
    "        'Training features': training_df,\n",
    "        'Training labels': master_training_labels_df,\n",
    "        'Training IDs': list(training_ids.values),\n",
    "        'Training race group': list(training_race_group.values),\n",
    "        'Testing features': testing_df,\n",
    "        'Testing labels': master_testing_labels_df,\n",
    "        'Testing IDs': list(testing_ids.values),\n",
    "        'Testing race group': list(testing_race_group.values),\n",
    "    }\n",
    "\n",
    "    print('Data dictionary contains:')\n",
    "    for key, value in dataset.items():\n",
    "        print(f' {key}: {type(value)}')\n",
    "\n",
    "    # Save\n",
    "    with open(one_hot_ordinal_nan_imputed_data_df_file, 'wb') as output_file:\n",
    "        pickle.dump(dataset, output_file)\n",
    "\n",
    "    # Inspect\n",
    "    print()\n",
    "    training_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Ordinal encode nominal and ordinal features with 'missing' level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinal encoding input data: (20160, 57)\n",
      "Feature data: (20160, 55)\n",
      "Ordinal encoded feature data: (20160, 55)\n",
      "\n",
      "Imputation input data: (20160, 22)\n",
      "Imputed numerical data: (20160, 2)\n",
      "Re-combined data: (20160, 57)\n",
      "\n",
      "Data dictionary contains:\n",
      " Training features: <class 'pandas.core.frame.DataFrame'>\n",
      " Training labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Training IDs: <class 'list'>\n",
      " Training race group: <class 'list'>\n",
      " Testing features: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing IDs: <class 'list'>\n",
      " Testing race group: <class 'list'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20160 entries, 0 to 20159\n",
      "Data columns (total 57 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   psych_disturb           20160 non-null  int32  \n",
      " 1   diabetes                20160 non-null  int32  \n",
      " 2   tbi_status              20160 non-null  int32  \n",
      " 3   arrhythmia              20160 non-null  int32  \n",
      " 4   graft_type              20160 non-null  int32  \n",
      " 5   vent_hist               20160 non-null  int32  \n",
      " 6   renal_issue             20160 non-null  int32  \n",
      " 7   pulm_severe             20160 non-null  int32  \n",
      " 8   prim_disease_hct        20160 non-null  int32  \n",
      " 9   tce_imm_match           20160 non-null  int32  \n",
      " 10  rituximab               20160 non-null  int32  \n",
      " 11  prod_type               20160 non-null  int32  \n",
      " 12  conditioning_intensity  20160 non-null  int32  \n",
      " 13  ethnicity               20160 non-null  int32  \n",
      " 14  obesity                 20160 non-null  int32  \n",
      " 15  mrd_hct                 20160 non-null  int32  \n",
      " 16  in_vivo_tcd             20160 non-null  int32  \n",
      " 17  tce_match               20160 non-null  int32  \n",
      " 18  hepatic_severe          20160 non-null  int32  \n",
      " 19  prior_tumor             20160 non-null  int32  \n",
      " 20  peptic_ulcer            20160 non-null  int32  \n",
      " 21  gvhd_proph              20160 non-null  int32  \n",
      " 22  rheum_issue             20160 non-null  int32  \n",
      " 23  sex_match               20160 non-null  int32  \n",
      " 24  race_group              20160 non-null  int32  \n",
      " 25  hepatic_mild            20160 non-null  int32  \n",
      " 26  tce_div_match           20160 non-null  int32  \n",
      " 27  donor_related           20160 non-null  int32  \n",
      " 28  melphalan_dose          20160 non-null  int32  \n",
      " 29  cardiac                 20160 non-null  int32  \n",
      " 30  pulm_moderate           20160 non-null  int32  \n",
      " 31  hla_match_c_high        20160 non-null  int32  \n",
      " 32  hla_high_res_8          20160 non-null  int32  \n",
      " 33  hla_low_res_6           20160 non-null  int32  \n",
      " 34  hla_high_res_6          20160 non-null  int32  \n",
      " 35  hla_high_res_10         20160 non-null  int32  \n",
      " 36  hla_match_dqb1_high     20160 non-null  int32  \n",
      " 37  hla_nmdp_6              20160 non-null  int32  \n",
      " 38  hla_match_c_low         20160 non-null  int32  \n",
      " 39  hla_match_drb1_low      20160 non-null  int32  \n",
      " 40  hla_match_dqb1_low      20160 non-null  int32  \n",
      " 41  year_hct                20160 non-null  int32  \n",
      " 42  hla_match_a_high        20160 non-null  int32  \n",
      " 43  hla_match_b_low         20160 non-null  int32  \n",
      " 44  hla_match_a_low         20160 non-null  int32  \n",
      " 45  hla_match_b_high        20160 non-null  int32  \n",
      " 46  comorbidity_score       20160 non-null  int32  \n",
      " 47  karnofsky_score         20160 non-null  int32  \n",
      " 48  hla_low_res_8           20160 non-null  int32  \n",
      " 49  hla_match_drb1_high     20160 non-null  int32  \n",
      " 50  hla_low_res_10          20160 non-null  int32  \n",
      " 51  dri_score               20160 non-null  int32  \n",
      " 52  cyto_score              20160 non-null  int32  \n",
      " 53  cmv_status              20160 non-null  int32  \n",
      " 54  cyto_score_detail       20160 non-null  int32  \n",
      " 55  donor_age               20160 non-null  float64\n",
      " 56  age_at_hct              20160 non-null  float64\n",
      "dtypes: float64(2), int32(55)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "if rebuild_datasets == True:\n",
    "    \n",
    "    # Make a copy of the master input testing and training features\n",
    "    training_df=master_training_features_df.copy()\n",
    "    testing_df=master_testing_features_df.copy()\n",
    "\n",
    "    # Encode the nominal & ordinal features\n",
    "    categorical_training_df, categorical_testing_df=encode_funcs.ordinal_encode_nan_encoded(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Nominal'] + feature_types_dict['Ordinal'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Clean NANs in the interval features\n",
    "    interval_training_df, interval_testing_df=encode_funcs.impute_numerical_features(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Interval'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Join the data back together\n",
    "    training_df=pd.concat([categorical_training_df, interval_training_df], axis=1)\n",
    "    testing_df=pd.concat([categorical_testing_df, interval_testing_df], axis=1)\n",
    "    print(f'Re-combined data: {training_df.shape}\\n')\n",
    "\n",
    "    # Assemble dataset dictionary\n",
    "    dataset={\n",
    "        'Training features': training_df,\n",
    "        'Training labels': master_training_labels_df,\n",
    "        'Training IDs': list(training_ids.values),\n",
    "        'Training race group': list(training_race_group.values),\n",
    "        'Testing features': testing_df,\n",
    "        'Testing labels': master_testing_labels_df,\n",
    "        'Testing IDs': list(testing_ids.values),\n",
    "        'Testing race group': list(testing_race_group.values),\n",
    "    }\n",
    "\n",
    "    print('Data dictionary contains:')\n",
    "    for key, value in dataset.items():\n",
    "        print(f' {key}: {type(value)}')\n",
    "\n",
    "    # Save\n",
    "    with open(ordinal_all_nan_encoded_data_df_file, 'wb') as output_file:\n",
    "        pickle.dump(dataset, output_file)\n",
    "\n",
    "    # Inspect\n",
    "    print()\n",
    "    training_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Ordinal encode nominal and ordinal features with NAN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinal encoding input data: (20160, 57)\n",
      "Feature data: (20160, 55)\n",
      "Ordinal encoded feature data: (20160, 55)\n",
      "Imputed, ordinal encoded feature data: (20160, 55)\n",
      "\n",
      "Imputation input data: (20160, 22)\n",
      "Imputed numerical data: (20160, 2)\n",
      "Re-combined data: (20160, 57)\n",
      "\n",
      "Data dictionary contains:\n",
      " Training features: <class 'pandas.core.frame.DataFrame'>\n",
      " Training labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Training IDs: <class 'list'>\n",
      " Training race group: <class 'list'>\n",
      " Testing features: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing IDs: <class 'list'>\n",
      " Testing race group: <class 'list'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20160 entries, 0 to 20159\n",
      "Data columns (total 57 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   psych_disturb           20160 non-null  int32  \n",
      " 1   diabetes                20160 non-null  int32  \n",
      " 2   tbi_status              20160 non-null  int32  \n",
      " 3   arrhythmia              20160 non-null  int32  \n",
      " 4   graft_type              20160 non-null  int32  \n",
      " 5   vent_hist               20160 non-null  int32  \n",
      " 6   renal_issue             20160 non-null  int32  \n",
      " 7   pulm_severe             20160 non-null  int32  \n",
      " 8   prim_disease_hct        20160 non-null  int32  \n",
      " 9   tce_imm_match           20160 non-null  int32  \n",
      " 10  rituximab               20160 non-null  int32  \n",
      " 11  prod_type               20160 non-null  int32  \n",
      " 12  conditioning_intensity  20160 non-null  int32  \n",
      " 13  ethnicity               20160 non-null  int32  \n",
      " 14  obesity                 20160 non-null  int32  \n",
      " 15  mrd_hct                 20160 non-null  int32  \n",
      " 16  in_vivo_tcd             20160 non-null  int32  \n",
      " 17  tce_match               20160 non-null  int32  \n",
      " 18  hepatic_severe          20160 non-null  int32  \n",
      " 19  prior_tumor             20160 non-null  int32  \n",
      " 20  peptic_ulcer            20160 non-null  int32  \n",
      " 21  gvhd_proph              20160 non-null  int32  \n",
      " 22  rheum_issue             20160 non-null  int32  \n",
      " 23  sex_match               20160 non-null  int32  \n",
      " 24  race_group              20160 non-null  int32  \n",
      " 25  hepatic_mild            20160 non-null  int32  \n",
      " 26  tce_div_match           20160 non-null  int32  \n",
      " 27  donor_related           20160 non-null  int32  \n",
      " 28  melphalan_dose          20160 non-null  int32  \n",
      " 29  cardiac                 20160 non-null  int32  \n",
      " 30  pulm_moderate           20160 non-null  int32  \n",
      " 31  hla_match_c_high        20160 non-null  int32  \n",
      " 32  hla_high_res_8          20160 non-null  int32  \n",
      " 33  hla_low_res_6           20160 non-null  int32  \n",
      " 34  hla_high_res_6          20160 non-null  int32  \n",
      " 35  hla_high_res_10         20160 non-null  int32  \n",
      " 36  hla_match_dqb1_high     20160 non-null  int32  \n",
      " 37  hla_nmdp_6              20160 non-null  int32  \n",
      " 38  hla_match_c_low         20160 non-null  int32  \n",
      " 39  hla_match_drb1_low      20160 non-null  int32  \n",
      " 40  hla_match_dqb1_low      20160 non-null  int32  \n",
      " 41  year_hct                20160 non-null  int32  \n",
      " 42  hla_match_a_high        20160 non-null  int32  \n",
      " 43  hla_match_b_low         20160 non-null  int32  \n",
      " 44  hla_match_a_low         20160 non-null  int32  \n",
      " 45  hla_match_b_high        20160 non-null  int32  \n",
      " 46  comorbidity_score       20160 non-null  int32  \n",
      " 47  karnofsky_score         20160 non-null  int32  \n",
      " 48  hla_low_res_8           20160 non-null  int32  \n",
      " 49  hla_match_drb1_high     20160 non-null  int32  \n",
      " 50  hla_low_res_10          20160 non-null  int32  \n",
      " 51  dri_score               20160 non-null  int32  \n",
      " 52  cyto_score              20160 non-null  int32  \n",
      " 53  cmv_status              20160 non-null  int32  \n",
      " 54  cyto_score_detail       20160 non-null  int32  \n",
      " 55  donor_age               20160 non-null  float64\n",
      " 56  age_at_hct              20160 non-null  float64\n",
      "dtypes: float64(2), int32(55)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "if rebuild_datasets == True:\n",
    "\n",
    "    # Make a copy of the master input testing and training features\n",
    "    training_df=master_training_features_df.copy()\n",
    "    testing_df=master_testing_features_df.copy()\n",
    "\n",
    "    # Encode the nominal & ordinal features\n",
    "    categorical_training_df, categorical_testing_df=encode_funcs.ordinal_encode_nan_imputed(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Nominal'] + feature_types_dict['Ordinal'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Clean NANs in the interval features\n",
    "    interval_training_df, interval_testing_df=encode_funcs.impute_numerical_features(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Interval'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Join the data back together\n",
    "    training_df=pd.concat([categorical_training_df, interval_training_df], axis=1)\n",
    "    testing_df=pd.concat([categorical_testing_df, interval_testing_df], axis=1)\n",
    "    print(f'Re-combined data: {training_df.shape}\\n')\n",
    "\n",
    "    # Assemble dataset dictionary\n",
    "    dataset={\n",
    "        'Training features': training_df,\n",
    "        'Training labels': master_training_labels_df,\n",
    "        'Training IDs': list(training_ids.values),\n",
    "        'Training race group': list(training_race_group.values),\n",
    "        'Testing features': testing_df,\n",
    "        'Testing labels': master_testing_labels_df,\n",
    "        'Testing IDs': list(testing_ids.values),\n",
    "        'Testing race group': list(testing_race_group.values),\n",
    "    }\n",
    "\n",
    "    print('Data dictionary contains:')\n",
    "    for key, value in dataset.items():\n",
    "        print(f' {key}: {type(value)}')\n",
    "\n",
    "    # Save\n",
    "    with open(ordinal_all_nan_imputed_data_df_file, 'wb') as output_file:\n",
    "        pickle.dump(dataset, output_file)\n",
    "\n",
    "    # Inspect\n",
    "    print()\n",
    "    training_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Binary target encode everything on efs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputation input data: (20160, 22)\n",
      "Imputed numerical data: (20160, 2)\n",
      "Re-combined data: (20160, 57)\n",
      "\n",
      "Data dictionary contains:\n",
      " Training features: <class 'pandas.core.frame.DataFrame'>\n",
      " Training labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Training IDs: <class 'list'>\n",
      " Training race group: <class 'list'>\n",
      " Testing features: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing IDs: <class 'list'>\n",
      " Testing race group: <class 'list'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20160 entries, 0 to 20159\n",
      "Data columns (total 57 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   psych_disturb           20160 non-null  float64\n",
      " 1   diabetes                20160 non-null  float64\n",
      " 2   tbi_status              20160 non-null  float64\n",
      " 3   arrhythmia              20160 non-null  float64\n",
      " 4   graft_type              20160 non-null  float64\n",
      " 5   vent_hist               20160 non-null  float64\n",
      " 6   renal_issue             20160 non-null  float64\n",
      " 7   pulm_severe             20160 non-null  float64\n",
      " 8   prim_disease_hct        20160 non-null  float64\n",
      " 9   tce_imm_match           20160 non-null  float64\n",
      " 10  rituximab               20160 non-null  float64\n",
      " 11  prod_type               20160 non-null  float64\n",
      " 12  conditioning_intensity  20160 non-null  float64\n",
      " 13  ethnicity               20160 non-null  float64\n",
      " 14  obesity                 20160 non-null  float64\n",
      " 15  mrd_hct                 20160 non-null  float64\n",
      " 16  in_vivo_tcd             20160 non-null  float64\n",
      " 17  tce_match               20160 non-null  float64\n",
      " 18  hepatic_severe          20160 non-null  float64\n",
      " 19  prior_tumor             20160 non-null  float64\n",
      " 20  peptic_ulcer            20160 non-null  float64\n",
      " 21  gvhd_proph              20160 non-null  float64\n",
      " 22  rheum_issue             20160 non-null  float64\n",
      " 23  sex_match               20160 non-null  float64\n",
      " 24  race_group              20160 non-null  float64\n",
      " 25  hepatic_mild            20160 non-null  float64\n",
      " 26  tce_div_match           20160 non-null  float64\n",
      " 27  donor_related           20160 non-null  float64\n",
      " 28  melphalan_dose          20160 non-null  float64\n",
      " 29  cardiac                 20160 non-null  float64\n",
      " 30  pulm_moderate           20160 non-null  float64\n",
      " 31  hla_match_c_high        20160 non-null  float64\n",
      " 32  hla_high_res_8          20160 non-null  float64\n",
      " 33  hla_low_res_6           20160 non-null  float64\n",
      " 34  hla_high_res_6          20160 non-null  float64\n",
      " 35  hla_high_res_10         20160 non-null  float64\n",
      " 36  hla_match_dqb1_high     20160 non-null  float64\n",
      " 37  hla_nmdp_6              20160 non-null  float64\n",
      " 38  hla_match_c_low         20160 non-null  float64\n",
      " 39  hla_match_drb1_low      20160 non-null  float64\n",
      " 40  hla_match_dqb1_low      20160 non-null  float64\n",
      " 41  year_hct                20160 non-null  float64\n",
      " 42  hla_match_a_high        20160 non-null  float64\n",
      " 43  hla_match_b_low         20160 non-null  float64\n",
      " 44  hla_match_a_low         20160 non-null  float64\n",
      " 45  hla_match_b_high        20160 non-null  float64\n",
      " 46  comorbidity_score       20160 non-null  float64\n",
      " 47  karnofsky_score         20160 non-null  float64\n",
      " 48  hla_low_res_8           20160 non-null  float64\n",
      " 49  hla_match_drb1_high     20160 non-null  float64\n",
      " 50  hla_low_res_10          20160 non-null  float64\n",
      " 51  dri_score               20160 non-null  float64\n",
      " 52  cyto_score              20160 non-null  float64\n",
      " 53  cmv_status              20160 non-null  float64\n",
      " 54  cyto_score_detail       20160 non-null  float64\n",
      " 55  donor_age               20160 non-null  float64\n",
      " 56  age_at_hct              20160 non-null  float64\n",
      "dtypes: float64(57)\n",
      "memory usage: 8.8 MB\n"
     ]
    }
   ],
   "source": [
    "if rebuild_datasets == True:\n",
    "\n",
    "    # Make a copy of the master input testing and training features\n",
    "    training_df=master_training_features_df.copy()\n",
    "    testing_df=master_testing_features_df.copy()\n",
    "\n",
    "    # Get categorical features\n",
    "    categorical_training_df=training_df[feature_types_dict['Nominal'] + feature_types_dict['Ordinal']]\n",
    "    categorical_testing_df=testing_df[feature_types_dict['Nominal'] + feature_types_dict['Ordinal']]\n",
    "    \n",
    "    # Encode the nominal & ordinal features\n",
    "    encoder=TargetEncoder()\n",
    "    encoder.fit(categorical_training_df, master_training_labels_df['efs'])\n",
    "    encoded_categorical_training_features=encoder.transform(categorical_training_df)\n",
    "    encoded_categorical_testing_features=encoder.transform(categorical_testing_df)\n",
    "\n",
    "    # Save the encoder\n",
    "    with open(f'{config.MODELS_PATH}/01.2-binary_target_encoder.pkl', 'wb') as output_file:\n",
    "        pickle.dump(encoder, output_file)\n",
    "\n",
    "    # Rebuild the dataframes\n",
    "    encoded_categorical_training_features_df=pd.DataFrame(\n",
    "        encoded_categorical_training_features,\n",
    "        columns=feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    "    )\n",
    "\n",
    "    encoded_categorical_testing_features_df=pd.DataFrame(\n",
    "        encoded_categorical_testing_features,\n",
    "        columns=feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    "    )\n",
    "\n",
    "    # Clean NANs in the interval features\n",
    "    interval_training_df, interval_testing_df=encode_funcs.impute_numerical_features(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Interval'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Join the data back together\n",
    "    training_df=pd.concat([encoded_categorical_training_features_df, interval_training_df], axis=1)\n",
    "    testing_df=pd.concat([encoded_categorical_testing_features_df, interval_testing_df], axis=1)\n",
    "    print(f'Re-combined data: {training_df.shape}\\n')\n",
    "\n",
    "    # Assemble dataset dictionary\n",
    "    dataset={\n",
    "        'Training features': training_df,\n",
    "        'Training labels': master_training_labels_df,\n",
    "        'Training IDs': list(training_ids.values),\n",
    "        'Training race group': list(training_race_group.values),\n",
    "        'Testing features': testing_df,\n",
    "        'Testing labels': master_testing_labels_df,\n",
    "        'Testing IDs': list(testing_ids.values),\n",
    "        'Testing race group': list(testing_race_group.values),\n",
    "    }\n",
    "\n",
    "    print('Data dictionary contains:')\n",
    "    for key, value in dataset.items():\n",
    "        print(f' {key}: {type(value)}')\n",
    "\n",
    "    # Save\n",
    "    with open(binary_target_encoded_data_file, 'wb') as output_file:\n",
    "        pickle.dump(dataset, output_file)\n",
    "\n",
    "    # Inspect\n",
    "    print()\n",
    "    training_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Continuous target encode everything on efs_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputation input data: (20160, 22)\n",
      "Imputed numerical data: (20160, 2)\n",
      "Re-combined data: (20160, 57)\n",
      "\n",
      "Data dictionary contains:\n",
      " Training features: <class 'pandas.core.frame.DataFrame'>\n",
      " Training labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Training IDs: <class 'list'>\n",
      " Training race group: <class 'list'>\n",
      " Testing features: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing labels: <class 'pandas.core.frame.DataFrame'>\n",
      " Testing IDs: <class 'list'>\n",
      " Testing race group: <class 'list'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20160 entries, 0 to 20159\n",
      "Data columns (total 57 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   psych_disturb           20160 non-null  float64\n",
      " 1   diabetes                20160 non-null  float64\n",
      " 2   tbi_status              20160 non-null  float64\n",
      " 3   arrhythmia              20160 non-null  float64\n",
      " 4   graft_type              20160 non-null  float64\n",
      " 5   vent_hist               20160 non-null  float64\n",
      " 6   renal_issue             20160 non-null  float64\n",
      " 7   pulm_severe             20160 non-null  float64\n",
      " 8   prim_disease_hct        20160 non-null  float64\n",
      " 9   tce_imm_match           20160 non-null  float64\n",
      " 10  rituximab               20160 non-null  float64\n",
      " 11  prod_type               20160 non-null  float64\n",
      " 12  conditioning_intensity  20160 non-null  float64\n",
      " 13  ethnicity               20160 non-null  float64\n",
      " 14  obesity                 20160 non-null  float64\n",
      " 15  mrd_hct                 20160 non-null  float64\n",
      " 16  in_vivo_tcd             20160 non-null  float64\n",
      " 17  tce_match               20160 non-null  float64\n",
      " 18  hepatic_severe          20160 non-null  float64\n",
      " 19  prior_tumor             20160 non-null  float64\n",
      " 20  peptic_ulcer            20160 non-null  float64\n",
      " 21  gvhd_proph              20160 non-null  float64\n",
      " 22  rheum_issue             20160 non-null  float64\n",
      " 23  sex_match               20160 non-null  float64\n",
      " 24  race_group              20160 non-null  float64\n",
      " 25  hepatic_mild            20160 non-null  float64\n",
      " 26  tce_div_match           20160 non-null  float64\n",
      " 27  donor_related           20160 non-null  float64\n",
      " 28  melphalan_dose          20160 non-null  float64\n",
      " 29  cardiac                 20160 non-null  float64\n",
      " 30  pulm_moderate           20160 non-null  float64\n",
      " 31  hla_match_c_high        20160 non-null  float64\n",
      " 32  hla_high_res_8          20160 non-null  float64\n",
      " 33  hla_low_res_6           20160 non-null  float64\n",
      " 34  hla_high_res_6          20160 non-null  float64\n",
      " 35  hla_high_res_10         20160 non-null  float64\n",
      " 36  hla_match_dqb1_high     20160 non-null  float64\n",
      " 37  hla_nmdp_6              20160 non-null  float64\n",
      " 38  hla_match_c_low         20160 non-null  float64\n",
      " 39  hla_match_drb1_low      20160 non-null  float64\n",
      " 40  hla_match_dqb1_low      20160 non-null  float64\n",
      " 41  year_hct                20160 non-null  float64\n",
      " 42  hla_match_a_high        20160 non-null  float64\n",
      " 43  hla_match_b_low         20160 non-null  float64\n",
      " 44  hla_match_a_low         20160 non-null  float64\n",
      " 45  hla_match_b_high        20160 non-null  float64\n",
      " 46  comorbidity_score       20160 non-null  float64\n",
      " 47  karnofsky_score         20160 non-null  float64\n",
      " 48  hla_low_res_8           20160 non-null  float64\n",
      " 49  hla_match_drb1_high     20160 non-null  float64\n",
      " 50  hla_low_res_10          20160 non-null  float64\n",
      " 51  dri_score               20160 non-null  float64\n",
      " 52  cyto_score              20160 non-null  float64\n",
      " 53  cmv_status              20160 non-null  float64\n",
      " 54  cyto_score_detail       20160 non-null  float64\n",
      " 55  donor_age               20160 non-null  float64\n",
      " 56  age_at_hct              20160 non-null  float64\n",
      "dtypes: float64(57)\n",
      "memory usage: 8.8 MB\n"
     ]
    }
   ],
   "source": [
    "if rebuild_datasets == True:\n",
    "\n",
    "    # Make a copy of the master input testing and training features\n",
    "    training_df=master_training_features_df.copy()\n",
    "    testing_df=master_testing_features_df.copy()\n",
    "\n",
    "    # Get categorical features\n",
    "    categorical_training_df=training_df[feature_types_dict['Nominal'] + feature_types_dict['Ordinal']]\n",
    "    categorical_testing_df=testing_df[feature_types_dict['Nominal'] + feature_types_dict['Ordinal']]\n",
    "    \n",
    "    # Encode the nominal & ordinal features\n",
    "    encoder=TargetEncoder()\n",
    "    encoder.fit(categorical_training_df, master_training_labels_df['efs_time'])\n",
    "    encoded_categorical_training_features=encoder.transform(categorical_training_df)\n",
    "    encoded_categorical_testing_features=encoder.transform(categorical_testing_df)\n",
    "\n",
    "    # Save the encoder\n",
    "    with open(f'{config.MODELS_PATH}/01.2-binary_target_encoder.pkl', 'wb') as output_file:\n",
    "        pickle.dump(encoder, output_file)\n",
    "\n",
    "    # Rebuild the dataframes\n",
    "    encoded_categorical_training_features_df=pd.DataFrame(\n",
    "        encoded_categorical_training_features,\n",
    "        columns=feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    "    )\n",
    "\n",
    "    encoded_categorical_testing_features_df=pd.DataFrame(\n",
    "        encoded_categorical_testing_features,\n",
    "        columns=feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    "    )\n",
    "\n",
    "    # Clean NANs in the interval features\n",
    "    interval_training_df, interval_testing_df=encode_funcs.impute_numerical_features(\n",
    "        training_df=training_df,\n",
    "        testing_df=testing_df,\n",
    "        features=feature_types_dict['Interval'],\n",
    "        models_path=config.MODELS_PATH\n",
    "    )\n",
    "\n",
    "    # Join the data back together\n",
    "    training_df=pd.concat([encoded_categorical_training_features_df, interval_training_df], axis=1)\n",
    "    testing_df=pd.concat([encoded_categorical_testing_features_df, interval_testing_df], axis=1)\n",
    "    print(f'Re-combined data: {training_df.shape}\\n')\n",
    "\n",
    "    # Assemble dataset dictionary\n",
    "    dataset={\n",
    "        'Training features': training_df,\n",
    "        'Training labels': master_training_labels_df,\n",
    "        'Training IDs': list(training_ids.values),\n",
    "        'Training race group': list(training_race_group.values),\n",
    "        'Testing features': testing_df,\n",
    "        'Testing labels': master_testing_labels_df,\n",
    "        'Testing IDs': list(testing_ids.values),\n",
    "        'Testing race group': list(testing_race_group.values),\n",
    "    }\n",
    "\n",
    "    print('Data dictionary contains:')\n",
    "    for key, value in dataset.items():\n",
    "        print(f' {key}: {type(value)}')\n",
    "\n",
    "    # Save\n",
    "    with open(continuous_target_encoded_data_file, 'wb') as output_file:\n",
    "        pickle.dump(dataset, output_file)\n",
    "\n",
    "    # Inspect\n",
    "    print()\n",
    "    training_df.info(verbose=True, show_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
