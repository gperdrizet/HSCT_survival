{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival: data cleaning and encoding\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import configuration as config\n",
    "import functions.encoding as encode_funcs\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "# Some cleaning/encoding options\n",
    "knn_neighbors=5\n",
    "one_hot_drop, collinearity='first', 'no-multicollinearity'\n",
    "\n",
    "# Base data input file: ID column set as index, missing string placeholders converted to nan\n",
    "# ordinal categorical features translated to numerical categorical where possible\n",
    "translated_features_file=f'{config.DATA_PATH}/processed/01.1-features_translated.pkl'\n",
    "\n",
    "# Feature data type definition file\n",
    "feature_types_dict_file=f'{config.DATA_PATH}/processed/01.1-feature_type_dict.pkl'\n",
    "\n",
    "# Nominal and ordinal features ordinal encoded.\n",
    "# NAN values encoded as 'missing' for categorical features\n",
    "# and KNN imputed for numerical features.\n",
    "ordinal_all_nan_encoded_data_df_file=f'{config.DATA_PATH}/processed/02.1-{collinearity}_ordinal_all_nan_encoded_data_df.parquet'\n",
    "\n",
    "# Nominal and ordinal features ordinal encoded encoded.\n",
    "# NANs filled in by KNN imputation for all features.\n",
    "ordinal_all_nan_imputed_data_df_file=f'{config.DATA_PATH}/processed/02.1-{collinearity}_ordinal_all_nan_imputed_data_df.parquet'\n",
    "\n",
    "# Nominal features one hot encoded, ordinal features ordinal encoded. \n",
    "# Data with with NAN values encoded as missing for categorical features \n",
    "# and KNN imputed for numerical features.\n",
    "one_hot_ordinal_nan_encoded_data_df_file=f'{config.DATA_PATH}/processed/02.1-{collinearity}_one_hot_ordinal_nan_encoded_data_df.parquet'\n",
    "\n",
    "# Nominal features one hot encoded, ordinal features ordinal encoded.\n",
    "# NANs filled in by KNN imputation for all features.\n",
    "one_hot_ordinal_nan_imputed_data_df_file=f'{config.DATA_PATH}/processed/02.1-{collinearity}_one_hot_ordinal_nan_imputed_data_df.parquet'\n",
    "\n",
    "# All ordinal and nominal features target encoded on EFS\n",
    "binary_target_encoded_data_file=f'{config.DATA_PATH}/processed/02.1-binary_target_encoded_data_df'\n",
    "\n",
    "# All ordinal and nominal features target encoded on EFS time\n",
    "continuous_target_encoded_data_file=f'{config.DATA_PATH}/processed/02.1-binary_target_encoded_data_df'\n",
    "\n",
    "# Save dataset definitions\n",
    "datasets={\n",
    "    'Nominal one-hot/ordinal encoded, NANs encoded':one_hot_ordinal_nan_encoded_data_df_file,\n",
    "    'Nominal one-hot/ordinal encoded, NANs imputed':one_hot_ordinal_nan_imputed_data_df_file,\n",
    "    'All ordinal encoded, NAN encoded':ordinal_all_nan_encoded_data_df_file,\n",
    "    'All ordinal encoded, NAN imputed':ordinal_all_nan_imputed_data_df_file,\n",
    "    'Binary target encoded':binary_target_encoded_data_file,\n",
    "    'Continuous target encoded':continuous_target_encoded_data_file\n",
    "}\n",
    "\n",
    "# Dataset definition file\n",
    "datasets_file=f'{config.DATA_PATH}/processed/02.1-dataset_definitions.pkl'\n",
    "\n",
    "# Save the dataset metadata\n",
    "with open(datasets_file, 'wb') as output_file:\n",
    "    pickle.dump(datasets, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input data\n",
    "\n",
    "### 1.1. Feature type definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature types:\n",
      "\n",
      "Interval\n",
      "['donor_age', 'age_at_hct']\n",
      "\n",
      "Ordinal\n",
      "['hla_match_c_high', 'hla_high_res_8', 'hla_low_res_6', 'hla_high_res_6', 'hla_high_res_10', 'hla_match_dqb1_high', 'hla_nmdp_6', 'hla_match_c_low', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'year_hct', 'hla_match_a_high', 'hla_match_b_low', 'hla_match_a_low', 'hla_match_b_high', 'comorbidity_score', 'karnofsky_score', 'hla_low_res_8', 'hla_match_drb1_high', 'hla_low_res_10', 'dri_score', 'cyto_score', 'cmv_status', 'cyto_score_detail']\n",
      "\n",
      "Nominal\n",
      "['psych_disturb', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'tce_imm_match', 'rituximab', 'prod_type', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n",
      "\n",
      "Labels\n",
      "['efs', 'efs_time']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the feature data type definitions\n",
    "with open(feature_types_dict_file, 'rb') as input_file:\n",
    "    feature_types_dict=pickle.load(input_file)\n",
    "\n",
    "print('Feature types:\\n')\n",
    "\n",
    "for feature_type, features in feature_types_dict.items():\n",
    "    print(f'{feature_type}\\n{features}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "# Remove and preserve the labels\n",
    "labels_df=data_df[['efs','efs_time']]\n",
    "data_df.drop(['efs','efs_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save the unencoded 'race_group' feature\n",
    "race_group=data_df['race_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoding and NAN handling schemes\n",
    "\n",
    "### 2.1. One-hot encode nominal features with missing value string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "# Remove and preserve the labels\n",
    "labels_df=data_df[['efs','efs_time']]\n",
    "data_df.drop(['efs','efs_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save the unencoded 'race_group' feature\n",
    "race_group=data_df['race_group']\n",
    "\n",
    "# Encode the nominal features\n",
    "encoded_nominal_features_df=encode_funcs.one_hot_nan_encoded(\n",
    "    data_df,\n",
    "    feature_types_dict['Nominal']\n",
    ")\n",
    "\n",
    "# Encode the ordinal features\n",
    "encoded_ordinal_features_df=encode_funcs.ordinal_encode_nan_imputed(\n",
    "    data_df,\n",
    "    feature_types_dict['Ordinal']\n",
    ")\n",
    "\n",
    "# Clean NANs in the interval features\n",
    "cleaned_interval_features_df=encode_funcs.impute_numerical_features(\n",
    "    data_df,\n",
    "    feature_types_dict['Interval']\n",
    ")\n",
    "\n",
    "# Join the data back together\n",
    "result_df=pd.concat([encoded_nominal_features_df, encoded_ordinal_features_df, cleaned_interval_features_df], axis=1)\n",
    "print(f'Re-combined data: {result_df.shape}')\n",
    "\n",
    "# Add back the labels\n",
    "result_df=pd.concat([result_df, labels_df], axis=1)\n",
    "print(f'Labeled re-combined data: {data_df.shape}\\n')\n",
    "\n",
    "# Add back un-encoded race group\n",
    "result_df['race_group']=race_group\n",
    "\n",
    "# Save\n",
    "result_df.to_parquet(one_hot_ordinal_nan_encoded_data_df_file)\n",
    "\n",
    "# Inspect\n",
    "result_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. One-hot encode nominal features with missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot encoding input data: (28800, 57)\n",
      "Feature data: (28800, 31)\n",
      "On-hot encoded, imputed feature data: (28800, 114)\n",
      "\n",
      "Ordinal encoding input data: (28800, 57)\n",
      "Feature data: (28800, 24)\n",
      "Ordinal encoded feature data: (28800, 24)\n",
      "Imputed, ordinal encoded feature data: (28800, 24)\n",
      "\n",
      "Imputation input data: (28800, 22)\n",
      "Imputed numerical data: (28800, 2)\n",
      "\n",
      "Re-combined data: (28800, 140)\n",
      "Labeled re-combined data: (28800, 57)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 28800 entries, 0 to 28799\n",
      "Data columns (total 143 columns):\n",
      " #    Column                         Non-Null Count  Dtype  \n",
      "---   ------                         --------------  -----  \n",
      " 0    psych_disturb_1.0              28800 non-null  int32  \n",
      " 1    psych_disturb_2.0              28800 non-null  int32  \n",
      " 2    diabetes_1.0                   28800 non-null  int32  \n",
      " 3    diabetes_2.0                   28800 non-null  int32  \n",
      " 4    tbi_status_1.0                 28800 non-null  int32  \n",
      " 5    tbi_status_2.0                 28800 non-null  int32  \n",
      " 6    tbi_status_3.0                 28800 non-null  int32  \n",
      " 7    tbi_status_4.0                 28800 non-null  int32  \n",
      " 8    tbi_status_5.0                 28800 non-null  int32  \n",
      " 9    tbi_status_6.0                 28800 non-null  int32  \n",
      " 10   tbi_status_7.0                 28800 non-null  int32  \n",
      " 11   arrhythmia_1.0                 28800 non-null  int32  \n",
      " 12   arrhythmia_2.0                 28800 non-null  int32  \n",
      " 13   graft_type_1.0                 28800 non-null  int32  \n",
      " 14   vent_hist_1.0                  28800 non-null  int32  \n",
      " 15   vent_hist_2.0                  28800 non-null  int32  \n",
      " 16   renal_issue_1.0                28800 non-null  int32  \n",
      " 17   renal_issue_2.0                28800 non-null  int32  \n",
      " 18   pulm_severe_1.0                28800 non-null  int32  \n",
      " 19   pulm_severe_2.0                28800 non-null  int32  \n",
      " 20   prim_disease_hct_1.0           28800 non-null  int32  \n",
      " 21   prim_disease_hct_2.0           28800 non-null  int32  \n",
      " 22   prim_disease_hct_3.0           28800 non-null  int32  \n",
      " 23   prim_disease_hct_4.0           28800 non-null  int32  \n",
      " 24   prim_disease_hct_5.0           28800 non-null  int32  \n",
      " 25   prim_disease_hct_6.0           28800 non-null  int32  \n",
      " 26   prim_disease_hct_7.0           28800 non-null  int32  \n",
      " 27   prim_disease_hct_8.0           28800 non-null  int32  \n",
      " 28   prim_disease_hct_9.0           28800 non-null  int32  \n",
      " 29   prim_disease_hct_10.0          28800 non-null  int32  \n",
      " 30   prim_disease_hct_11.0          28800 non-null  int32  \n",
      " 31   prim_disease_hct_12.0          28800 non-null  int32  \n",
      " 32   prim_disease_hct_13.0          28800 non-null  int32  \n",
      " 33   prim_disease_hct_14.0          28800 non-null  int32  \n",
      " 34   prim_disease_hct_15.0          28800 non-null  int32  \n",
      " 35   prim_disease_hct_16.0          28800 non-null  int32  \n",
      " 36   prim_disease_hct_17.0          28800 non-null  int32  \n",
      " 37   tce_imm_match_1.0              28800 non-null  int32  \n",
      " 38   tce_imm_match_2.0              28800 non-null  int32  \n",
      " 39   tce_imm_match_3.0              28800 non-null  int32  \n",
      " 40   tce_imm_match_4.0              28800 non-null  int32  \n",
      " 41   tce_imm_match_5.0              28800 non-null  int32  \n",
      " 42   tce_imm_match_6.0              28800 non-null  int32  \n",
      " 43   tce_imm_match_7.0              28800 non-null  int32  \n",
      " 44   tce_imm_match_8.0              28800 non-null  int32  \n",
      " 45   rituximab_1.0                  28800 non-null  int32  \n",
      " 46   rituximab_2.0                  28800 non-null  int32  \n",
      " 47   prod_type_1.0                  28800 non-null  int32  \n",
      " 48   conditioning_intensity_1.0     28800 non-null  int32  \n",
      " 49   conditioning_intensity_2.0     28800 non-null  int32  \n",
      " 50   conditioning_intensity_3.0     28800 non-null  int32  \n",
      " 51   conditioning_intensity_4.0     28800 non-null  int32  \n",
      " 52   ethnicity_1.0                  28800 non-null  int32  \n",
      " 53   ethnicity_2.0                  28800 non-null  int32  \n",
      " 54   ethnicity_3.0                  28800 non-null  int32  \n",
      " 55   obesity_1.0                    28800 non-null  int32  \n",
      " 56   obesity_2.0                    28800 non-null  int32  \n",
      " 57   mrd_hct_1.0                    28800 non-null  int32  \n",
      " 58   mrd_hct_2.0                    28800 non-null  int32  \n",
      " 59   in_vivo_tcd_1.0                28800 non-null  int32  \n",
      " 60   in_vivo_tcd_2.0                28800 non-null  int32  \n",
      " 61   tce_match_1.0                  28800 non-null  int32  \n",
      " 62   tce_match_2.0                  28800 non-null  int32  \n",
      " 63   tce_match_3.0                  28800 non-null  int32  \n",
      " 64   tce_match_4.0                  28800 non-null  int32  \n",
      " 65   hepatic_severe_1.0             28800 non-null  int32  \n",
      " 66   hepatic_severe_2.0             28800 non-null  int32  \n",
      " 67   prior_tumor_1.0                28800 non-null  int32  \n",
      " 68   prior_tumor_2.0                28800 non-null  int32  \n",
      " 69   peptic_ulcer_1.0               28800 non-null  int32  \n",
      " 70   peptic_ulcer_2.0               28800 non-null  int32  \n",
      " 71   gvhd_proph_1.0                 28800 non-null  int32  \n",
      " 72   gvhd_proph_2.0                 28800 non-null  int32  \n",
      " 73   gvhd_proph_3.0                 28800 non-null  int32  \n",
      " 74   gvhd_proph_4.0                 28800 non-null  int32  \n",
      " 75   gvhd_proph_5.0                 28800 non-null  int32  \n",
      " 76   gvhd_proph_6.0                 28800 non-null  int32  \n",
      " 77   gvhd_proph_7.0                 28800 non-null  int32  \n",
      " 78   gvhd_proph_8.0                 28800 non-null  int32  \n",
      " 79   gvhd_proph_10.0                28800 non-null  int32  \n",
      " 80   gvhd_proph_11.0                28800 non-null  int32  \n",
      " 81   gvhd_proph_12.0                28800 non-null  int32  \n",
      " 82   gvhd_proph_13.0                28800 non-null  int32  \n",
      " 83   gvhd_proph_14.0                28800 non-null  int32  \n",
      " 84   gvhd_proph_15.0                28800 non-null  int32  \n",
      " 85   gvhd_proph_16.0                28800 non-null  int32  \n",
      " 86   gvhd_proph_17.0                28800 non-null  int32  \n",
      " 87   gvhd_proph_infrequent_sklearn  28800 non-null  int32  \n",
      " 88   rheum_issue_1.0                28800 non-null  int32  \n",
      " 89   rheum_issue_2.0                28800 non-null  int32  \n",
      " 90   sex_match_1.0                  28800 non-null  int32  \n",
      " 91   sex_match_2.0                  28800 non-null  int32  \n",
      " 92   sex_match_3.0                  28800 non-null  int32  \n",
      " 93   sex_match_4.0                  28800 non-null  int32  \n",
      " 94   race_group_1.0                 28800 non-null  int32  \n",
      " 95   race_group_2.0                 28800 non-null  int32  \n",
      " 96   race_group_3.0                 28800 non-null  int32  \n",
      " 97   race_group_4.0                 28800 non-null  int32  \n",
      " 98   race_group_5.0                 28800 non-null  int32  \n",
      " 99   hepatic_mild_1.0               28800 non-null  int32  \n",
      " 100  hepatic_mild_2.0               28800 non-null  int32  \n",
      " 101  tce_div_match_1.0              28800 non-null  int32  \n",
      " 102  tce_div_match_2.0              28800 non-null  int32  \n",
      " 103  tce_div_match_3.0              28800 non-null  int32  \n",
      " 104  tce_div_match_4.0              28800 non-null  int32  \n",
      " 105  donor_related_1.0              28800 non-null  int32  \n",
      " 106  donor_related_2.0              28800 non-null  int32  \n",
      " 107  donor_related_3.0              28800 non-null  int32  \n",
      " 108  melphalan_dose_1.0             28800 non-null  int32  \n",
      " 109  melphalan_dose_2.0             28800 non-null  int32  \n",
      " 110  cardiac_1.0                    28800 non-null  int32  \n",
      " 111  cardiac_2.0                    28800 non-null  int32  \n",
      " 112  pulm_moderate_1.0              28800 non-null  int32  \n",
      " 113  pulm_moderate_2.0              28800 non-null  int32  \n",
      " 114  hla_match_c_high               28800 non-null  int32  \n",
      " 115  hla_high_res_8                 28800 non-null  int32  \n",
      " 116  hla_low_res_6                  28800 non-null  int32  \n",
      " 117  hla_high_res_6                 28800 non-null  int32  \n",
      " 118  hla_high_res_10                28800 non-null  int32  \n",
      " 119  hla_match_dqb1_high            28800 non-null  int32  \n",
      " 120  hla_nmdp_6                     28800 non-null  int32  \n",
      " 121  hla_match_c_low                28800 non-null  int32  \n",
      " 122  hla_match_drb1_low             28800 non-null  int32  \n",
      " 123  hla_match_dqb1_low             28800 non-null  int32  \n",
      " 124  year_hct                       28800 non-null  int32  \n",
      " 125  hla_match_a_high               28800 non-null  int32  \n",
      " 126  hla_match_b_low                28800 non-null  int32  \n",
      " 127  hla_match_a_low                28800 non-null  int32  \n",
      " 128  hla_match_b_high               28800 non-null  int32  \n",
      " 129  comorbidity_score              28800 non-null  int32  \n",
      " 130  karnofsky_score                28800 non-null  int32  \n",
      " 131  hla_low_res_8                  28800 non-null  int32  \n",
      " 132  hla_match_drb1_high            28800 non-null  int32  \n",
      " 133  hla_low_res_10                 28800 non-null  int32  \n",
      " 134  dri_score                      28800 non-null  int32  \n",
      " 135  cyto_score                     28800 non-null  int32  \n",
      " 136  cmv_status                     28800 non-null  int32  \n",
      " 137  cyto_score_detail              28800 non-null  int32  \n",
      " 138  donor_age                      28800 non-null  float64\n",
      " 139  age_at_hct                     28800 non-null  float64\n",
      " 140  efs                            28800 non-null  float64\n",
      " 141  efs_time                       28800 non-null  float64\n",
      " 142  race_group                     28800 non-null  object \n",
      "dtypes: float64(4), int32(138), object(1)\n",
      "memory usage: 16.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "# Remove and preserve the labels\n",
    "labels_df=data_df[['efs','efs_time']]\n",
    "data_df.drop(['efs','efs_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save the unencoded 'race_group' feature\n",
    "race_group=data_df['race_group']\n",
    "\n",
    "# Encode the nominal features\n",
    "encoded_nominal_features_df=encode_funcs.one_hot_encode_nan_imputed(\n",
    "    data_df,\n",
    "    feature_types_dict['Nominal']\n",
    ")\n",
    "\n",
    "# Encode the ordinal features\n",
    "encoded_ordinal_features_df=encode_funcs.ordinal_encode_nan_imputed(\n",
    "    data_df,\n",
    "    feature_types_dict['Ordinal']\n",
    ")\n",
    "\n",
    "# Clean NANs in the interval features\n",
    "cleaned_interval_features_df=encode_funcs.impute_numerical_features(\n",
    "    data_df,\n",
    "    feature_types_dict['Interval']\n",
    ")\n",
    "\n",
    "# Join the data back together\n",
    "result_df=pd.concat([encoded_nominal_features_df, encoded_ordinal_features_df, cleaned_interval_features_df], axis=1)\n",
    "print(f'\\nRe-combined data: {result_df.shape}')\n",
    "\n",
    "# Add back the labels\n",
    "result_df=pd.concat([result_df, labels_df], axis=1)\n",
    "print(f'Labeled re-combined data: {data_df.shape}\\n')\n",
    "\n",
    "# Add back un-encoded race group\n",
    "result_df['race_group']=race_group\n",
    "\n",
    "# Save\n",
    "result_df.to_parquet(one_hot_ordinal_nan_imputed_data_df_file)\n",
    "\n",
    "# Inspect\n",
    "result_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Label encode nominal and ordinal features with 'missing' level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinal encoding input data: (28800, 57)\n",
      "Feature data: (28800, 55)\n",
      "Ordinal encoded feature data: (28800, 55)\n",
      "\n",
      "Imputation input data: (28800, 22)\n",
      "Imputed numerical data: (28800, 2)\n",
      "Re-combined data: (28800, 57)\n",
      "Labeled re-combined data: (28800, 57)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 28800 entries, 0 to 28799\n",
      "Data columns (total 59 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   psych_disturb           28800 non-null  int32  \n",
      " 1   diabetes                28800 non-null  int32  \n",
      " 2   tbi_status              28800 non-null  int32  \n",
      " 3   arrhythmia              28800 non-null  int32  \n",
      " 4   graft_type              28800 non-null  int32  \n",
      " 5   vent_hist               28800 non-null  int32  \n",
      " 6   renal_issue             28800 non-null  int32  \n",
      " 7   pulm_severe             28800 non-null  int32  \n",
      " 8   prim_disease_hct        28800 non-null  int32  \n",
      " 9   tce_imm_match           28800 non-null  int32  \n",
      " 10  rituximab               28800 non-null  int32  \n",
      " 11  prod_type               28800 non-null  int32  \n",
      " 12  conditioning_intensity  28800 non-null  int32  \n",
      " 13  ethnicity               28800 non-null  int32  \n",
      " 14  obesity                 28800 non-null  int32  \n",
      " 15  mrd_hct                 28800 non-null  int32  \n",
      " 16  in_vivo_tcd             28800 non-null  int32  \n",
      " 17  tce_match               28800 non-null  int32  \n",
      " 18  hepatic_severe          28800 non-null  int32  \n",
      " 19  prior_tumor             28800 non-null  int32  \n",
      " 20  peptic_ulcer            28800 non-null  int32  \n",
      " 21  gvhd_proph              28800 non-null  int32  \n",
      " 22  rheum_issue             28800 non-null  int32  \n",
      " 23  sex_match               28800 non-null  int32  \n",
      " 24  race_group              28800 non-null  object \n",
      " 25  hepatic_mild            28800 non-null  int32  \n",
      " 26  tce_div_match           28800 non-null  int32  \n",
      " 27  donor_related           28800 non-null  int32  \n",
      " 28  melphalan_dose          28800 non-null  int32  \n",
      " 29  cardiac                 28800 non-null  int32  \n",
      " 30  pulm_moderate           28800 non-null  int32  \n",
      " 31  hla_match_c_high        28800 non-null  int32  \n",
      " 32  hla_high_res_8          28800 non-null  int32  \n",
      " 33  hla_low_res_6           28800 non-null  int32  \n",
      " 34  hla_high_res_6          28800 non-null  int32  \n",
      " 35  hla_high_res_10         28800 non-null  int32  \n",
      " 36  hla_match_dqb1_high     28800 non-null  int32  \n",
      " 37  hla_nmdp_6              28800 non-null  int32  \n",
      " 38  hla_match_c_low         28800 non-null  int32  \n",
      " 39  hla_match_drb1_low      28800 non-null  int32  \n",
      " 40  hla_match_dqb1_low      28800 non-null  int32  \n",
      " 41  year_hct                28800 non-null  int32  \n",
      " 42  hla_match_a_high        28800 non-null  int32  \n",
      " 43  hla_match_b_low         28800 non-null  int32  \n",
      " 44  hla_match_a_low         28800 non-null  int32  \n",
      " 45  hla_match_b_high        28800 non-null  int32  \n",
      " 46  comorbidity_score       28800 non-null  int32  \n",
      " 47  karnofsky_score         28800 non-null  int32  \n",
      " 48  hla_low_res_8           28800 non-null  int32  \n",
      " 49  hla_match_drb1_high     28800 non-null  int32  \n",
      " 50  hla_low_res_10          28800 non-null  int32  \n",
      " 51  dri_score               28800 non-null  int32  \n",
      " 52  cyto_score              28800 non-null  int32  \n",
      " 53  cmv_status              28800 non-null  int32  \n",
      " 54  cyto_score_detail       28800 non-null  int32  \n",
      " 55  donor_age               28800 non-null  float64\n",
      " 56  age_at_hct              28800 non-null  float64\n",
      " 57  efs                     28800 non-null  float64\n",
      " 58  efs_time                28800 non-null  float64\n",
      "dtypes: float64(4), int32(54), object(1)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "# Remove and preserve the labels\n",
    "labels_df=data_df[['efs','efs_time']]\n",
    "data_df.drop(['efs','efs_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save the unencoded 'race_group' feature\n",
    "race_group=data_df['race_group']\n",
    "\n",
    "# Encode the nominal & ordinal features\n",
    "encoded_categorical_features_df=encode_funcs.ordinal_encode_nan_encoded(\n",
    "    data_df,\n",
    "    feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    ")\n",
    "\n",
    "# Clean NANs in the interval features\n",
    "cleaned_interval_features_df=encode_funcs.impute_numerical_features(\n",
    "    data_df,\n",
    "    feature_types_dict['Interval']\n",
    ")\n",
    "\n",
    "# Join the data back together\n",
    "result_df=pd.concat([encoded_categorical_features_df, cleaned_interval_features_df], axis=1)\n",
    "print(f'Re-combined data: {result_df.shape}')\n",
    "\n",
    "# Add back the labels\n",
    "result_df=pd.concat([result_df, labels_df], axis=1)\n",
    "print(f'Labeled re-combined data: {data_df.shape}\\n')\n",
    "\n",
    "# Add back un-encoded race group\n",
    "result_df['race_group']=race_group\n",
    "\n",
    "# Save\n",
    "result_df.to_parquet(ordinal_all_nan_encoded_data_df_file)\n",
    "\n",
    "# Inspect\n",
    "result_df.info(verbose=True, show_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Label encode nominal and ordinal features with NAN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinal encoding input data: (28800, 57)\n",
      "Feature data: (28800, 55)\n",
      "Ordinal encoded feature data: (28800, 55)\n",
      "Imputed, ordinal encoded feature data: (28800, 55)\n",
      "\n",
      "Imputation input data: (28800, 22)\n",
      "Imputed numerical data: (28800, 2)\n",
      "Re-combined data: (28800, 57)\n",
      "Labeled re-combined data: (28800, 57)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 28800 entries, 0 to 28799\n",
      "Data columns (total 59 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   psych_disturb           28800 non-null  int32  \n",
      " 1   diabetes                28800 non-null  int32  \n",
      " 2   tbi_status              28800 non-null  int32  \n",
      " 3   arrhythmia              28800 non-null  int32  \n",
      " 4   graft_type              28800 non-null  int32  \n",
      " 5   vent_hist               28800 non-null  int32  \n",
      " 6   renal_issue             28800 non-null  int32  \n",
      " 7   pulm_severe             28800 non-null  int32  \n",
      " 8   prim_disease_hct        28800 non-null  int32  \n",
      " 9   tce_imm_match           28800 non-null  int32  \n",
      " 10  rituximab               28800 non-null  int32  \n",
      " 11  prod_type               28800 non-null  int32  \n",
      " 12  conditioning_intensity  28800 non-null  int32  \n",
      " 13  ethnicity               28800 non-null  int32  \n",
      " 14  obesity                 28800 non-null  int32  \n",
      " 15  mrd_hct                 28800 non-null  int32  \n",
      " 16  in_vivo_tcd             28800 non-null  int32  \n",
      " 17  tce_match               28800 non-null  int32  \n",
      " 18  hepatic_severe          28800 non-null  int32  \n",
      " 19  prior_tumor             28800 non-null  int32  \n",
      " 20  peptic_ulcer            28800 non-null  int32  \n",
      " 21  gvhd_proph              28800 non-null  int32  \n",
      " 22  rheum_issue             28800 non-null  int32  \n",
      " 23  sex_match               28800 non-null  int32  \n",
      " 24  race_group              28800 non-null  object \n",
      " 25  hepatic_mild            28800 non-null  int32  \n",
      " 26  tce_div_match           28800 non-null  int32  \n",
      " 27  donor_related           28800 non-null  int32  \n",
      " 28  melphalan_dose          28800 non-null  int32  \n",
      " 29  cardiac                 28800 non-null  int32  \n",
      " 30  pulm_moderate           28800 non-null  int32  \n",
      " 31  hla_match_c_high        28800 non-null  int32  \n",
      " 32  hla_high_res_8          28800 non-null  int32  \n",
      " 33  hla_low_res_6           28800 non-null  int32  \n",
      " 34  hla_high_res_6          28800 non-null  int32  \n",
      " 35  hla_high_res_10         28800 non-null  int32  \n",
      " 36  hla_match_dqb1_high     28800 non-null  int32  \n",
      " 37  hla_nmdp_6              28800 non-null  int32  \n",
      " 38  hla_match_c_low         28800 non-null  int32  \n",
      " 39  hla_match_drb1_low      28800 non-null  int32  \n",
      " 40  hla_match_dqb1_low      28800 non-null  int32  \n",
      " 41  year_hct                28800 non-null  int32  \n",
      " 42  hla_match_a_high        28800 non-null  int32  \n",
      " 43  hla_match_b_low         28800 non-null  int32  \n",
      " 44  hla_match_a_low         28800 non-null  int32  \n",
      " 45  hla_match_b_high        28800 non-null  int32  \n",
      " 46  comorbidity_score       28800 non-null  int32  \n",
      " 47  karnofsky_score         28800 non-null  int32  \n",
      " 48  hla_low_res_8           28800 non-null  int32  \n",
      " 49  hla_match_drb1_high     28800 non-null  int32  \n",
      " 50  hla_low_res_10          28800 non-null  int32  \n",
      " 51  dri_score               28800 non-null  int32  \n",
      " 52  cyto_score              28800 non-null  int32  \n",
      " 53  cmv_status              28800 non-null  int32  \n",
      " 54  cyto_score_detail       28800 non-null  int32  \n",
      " 55  donor_age               28800 non-null  float64\n",
      " 56  age_at_hct              28800 non-null  float64\n",
      " 57  efs                     28800 non-null  float64\n",
      " 58  efs_time                28800 non-null  float64\n",
      "dtypes: float64(4), int32(54), object(1)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "# Remove and preserve the labels\n",
    "labels_df=data_df[['efs','efs_time']]\n",
    "data_df.drop(['efs','efs_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save the unencoded 'race_group' feature\n",
    "race_group=data_df['race_group']\n",
    "\n",
    "# Encode the nominal & ordinal features\n",
    "encoded_categorical_features_df=encode_funcs.ordinal_encode_nan_imputed(\n",
    "    data_df,\n",
    "    feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    ")\n",
    "\n",
    "# Clean NANs in the interval features\n",
    "cleaned_interval_features_df=encode_funcs.impute_numerical_features(\n",
    "    data_df,\n",
    "    feature_types_dict['Interval']\n",
    ")\n",
    "\n",
    "# Join the data back together\n",
    "result_df=pd.concat([encoded_categorical_features_df, cleaned_interval_features_df], axis=1)\n",
    "print(f'Re-combined data: {result_df.shape}')\n",
    "\n",
    "# Add back the labels\n",
    "result_df=pd.concat([result_df, labels_df], axis=1)\n",
    "print(f'Labeled re-combined data: {data_df.shape}\\n')\n",
    "\n",
    "# Add back un-encoded race group\n",
    "result_df['race_group']=race_group\n",
    "\n",
    "# Save\n",
    "result_df.to_parquet(ordinal_all_nan_imputed_data_df_file)\n",
    "\n",
    "# Inspect\n",
    "result_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Binary target encode everything on efs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputation input data: (28800, 22)\n",
      "Imputed numerical data: (28800, 2)\n",
      "Re-combined data: (28800, 57)\n",
      "Labeled re-combined data: (28800, 57)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28800 entries, 0 to 28799\n",
      "Data columns (total 59 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   psych_disturb           28800 non-null  float64\n",
      " 1   diabetes                28800 non-null  float64\n",
      " 2   tbi_status              28800 non-null  float64\n",
      " 3   arrhythmia              28800 non-null  float64\n",
      " 4   graft_type              28800 non-null  float64\n",
      " 5   vent_hist               28800 non-null  float64\n",
      " 6   renal_issue             28800 non-null  float64\n",
      " 7   pulm_severe             28800 non-null  float64\n",
      " 8   prim_disease_hct        28800 non-null  float64\n",
      " 9   tce_imm_match           28800 non-null  float64\n",
      " 10  rituximab               28800 non-null  float64\n",
      " 11  prod_type               28800 non-null  float64\n",
      " 12  conditioning_intensity  28800 non-null  float64\n",
      " 13  ethnicity               28800 non-null  float64\n",
      " 14  obesity                 28800 non-null  float64\n",
      " 15  mrd_hct                 28800 non-null  float64\n",
      " 16  in_vivo_tcd             28800 non-null  float64\n",
      " 17  tce_match               28800 non-null  float64\n",
      " 18  hepatic_severe          28800 non-null  float64\n",
      " 19  prior_tumor             28800 non-null  float64\n",
      " 20  peptic_ulcer            28800 non-null  float64\n",
      " 21  gvhd_proph              28800 non-null  float64\n",
      " 22  rheum_issue             28800 non-null  float64\n",
      " 23  sex_match               28800 non-null  float64\n",
      " 24  race_group              28800 non-null  object \n",
      " 25  hepatic_mild            28800 non-null  float64\n",
      " 26  tce_div_match           28800 non-null  float64\n",
      " 27  donor_related           28800 non-null  float64\n",
      " 28  melphalan_dose          28800 non-null  float64\n",
      " 29  cardiac                 28800 non-null  float64\n",
      " 30  pulm_moderate           28800 non-null  float64\n",
      " 31  hla_match_c_high        28800 non-null  float64\n",
      " 32  hla_high_res_8          28800 non-null  float64\n",
      " 33  hla_low_res_6           28800 non-null  float64\n",
      " 34  hla_high_res_6          28800 non-null  float64\n",
      " 35  hla_high_res_10         28800 non-null  float64\n",
      " 36  hla_match_dqb1_high     28800 non-null  float64\n",
      " 37  hla_nmdp_6              28800 non-null  float64\n",
      " 38  hla_match_c_low         28800 non-null  float64\n",
      " 39  hla_match_drb1_low      28800 non-null  float64\n",
      " 40  hla_match_dqb1_low      28800 non-null  float64\n",
      " 41  year_hct                28800 non-null  float64\n",
      " 42  hla_match_a_high        28800 non-null  float64\n",
      " 43  hla_match_b_low         28800 non-null  float64\n",
      " 44  hla_match_a_low         28800 non-null  float64\n",
      " 45  hla_match_b_high        28800 non-null  float64\n",
      " 46  comorbidity_score       28800 non-null  float64\n",
      " 47  karnofsky_score         28800 non-null  float64\n",
      " 48  hla_low_res_8           28800 non-null  float64\n",
      " 49  hla_match_drb1_high     28800 non-null  float64\n",
      " 50  hla_low_res_10          28800 non-null  float64\n",
      " 51  dri_score               28800 non-null  float64\n",
      " 52  cyto_score              28800 non-null  float64\n",
      " 53  cmv_status              28800 non-null  float64\n",
      " 54  cyto_score_detail       28800 non-null  float64\n",
      " 55  donor_age               28800 non-null  float64\n",
      " 56  age_at_hct              28800 non-null  float64\n",
      " 57  efs                     28800 non-null  float64\n",
      " 58  efs_time                28800 non-null  float64\n",
      "dtypes: float64(58), object(1)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "# Remove and preserve the labels\n",
    "labels_df=data_df[['efs','efs_time']]\n",
    "data_df.drop(['efs','efs_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save the unencoded 'race_group' feature\n",
    "race_group=data_df['race_group']\n",
    "\n",
    "# Encode the nominal & ordinal features\n",
    "encoder=TargetEncoder()\n",
    "encoded_categorical_features=encoder.fit_transform(data_df[feature_types_dict['Nominal'] + feature_types_dict['Ordinal']], labels_df['efs'])\n",
    "\n",
    "encoded_categorical_features_df=pd.DataFrame(\n",
    "    encoded_categorical_features,\n",
    "    columns=feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    ")\n",
    "\n",
    "# Clean NANs in the interval features\n",
    "cleaned_interval_features_df=encode_funcs.impute_numerical_features(\n",
    "    data_df,\n",
    "    feature_types_dict['Interval']\n",
    ")\n",
    "\n",
    "# Join the data back together\n",
    "result_df=pd.concat([encoded_categorical_features_df, cleaned_interval_features_df], axis=1)\n",
    "print(f'Re-combined data: {result_df.shape}')\n",
    "\n",
    "# Add back the labels\n",
    "result_df=pd.concat([result_df, labels_df], axis=1)\n",
    "print(f'Labeled re-combined data: {data_df.shape}\\n')\n",
    "\n",
    "# Add back un-encoded race group\n",
    "result_df['race_group']=race_group\n",
    "\n",
    "# Save\n",
    "result_df.to_parquet(binary_target_encoded_data_file)\n",
    "\n",
    "# Inspect\n",
    "result_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Continuous target encode everything on efs_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(translated_features_file)\n",
    "\n",
    "# Remove and preserve the labels\n",
    "labels_df=data_df[['efs','efs_time']]\n",
    "data_df.drop(['efs','efs_time'], axis=1, inplace=True)\n",
    "\n",
    "# Save the unencoded 'race_group' feature\n",
    "race_group=data_df['race_group']\n",
    "\n",
    "# Encode the nominal & ordinal features\n",
    "encoder=TargetEncoder()\n",
    "encoded_categorical_features=encoder.fit_transform(data_df[feature_types_dict['Nominal'] + feature_types_dict['Ordinal']], labels_df['efs_time'])\n",
    "\n",
    "encoded_categorical_features_df=pd.DataFrame(\n",
    "    encoded_categorical_features,\n",
    "    columns=feature_types_dict['Nominal'] + feature_types_dict['Ordinal']\n",
    ")\n",
    "\n",
    "# Clean NANs in the interval features\n",
    "cleaned_interval_features_df=encode_funcs.impute_numerical_features(\n",
    "    data_df,\n",
    "    feature_types_dict['Interval']\n",
    ")\n",
    "\n",
    "# Join the data back together\n",
    "result_df=pd.concat([encoded_categorical_features_df, cleaned_interval_features_df], axis=1)\n",
    "print(f'Re-combined data: {result_df.shape}')\n",
    "\n",
    "# Add back the labels\n",
    "result_df=pd.concat([result_df, labels_df], axis=1)\n",
    "print(f'Labeled re-combined data: {data_df.shape}\\n')\n",
    "\n",
    "# Add back un-encoded race group\n",
    "result_df['race_group']=race_group\n",
    "\n",
    "# Save\n",
    "result_df.to_parquet(continuous_target_encoded_data_file)\n",
    "\n",
    "# Inspect\n",
    "result_df.info(verbose=True, show_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
