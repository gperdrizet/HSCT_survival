{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival: gradient boosting decision tree model\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "import configuration as config\n",
    "import functions.helper as helper_funcs\n",
    "\n",
    "# Data files\n",
    "training_features_df_file=f'{config.DATA_PATH}/processed/02.1-scaled_encoded_training_features_df.parquet'\n",
    "training_labels_df_file=f'{config.DATA_PATH}/processed/02.1-scaled_encoded_training_labels_df.parquet'\n",
    "raw_training_features_file=f'{config.DATA_PATH}/raw/train.csv'\n",
    "testing_features_df_file=f'{config.DATA_PATH}/processed/02.1-scaled_encoded_testing_features_df.parquet'\n",
    "\n",
    "# Model files\n",
    "naive_model_file=f'{config.MODELS_PATH}/05.1-sklearn_gradient_boosting_naive.pkl'\n",
    "tuned_model_file=f'{config.MODELS_PATH}/05.1-sklearn_gradient_boosting_tuned.pkl'\n",
    "\n",
    "retune_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df=pd.read_parquet(training_features_df_file)\n",
    "labels_df=pd.read_parquet(training_labels_df_file)\n",
    "\n",
    "df=pd.concat([features_df.reset_index(drop=True),labels_df.reset_index(drop=True)],axis=1)\n",
    "\n",
    "raw_training_df=pd.read_csv(raw_training_features_file)\n",
    "df['race_group']=raw_training_df['race_group']\n",
    "\n",
    "plt.title('EFS time distribution')\n",
    "plt.hist(df['efs_time'], density=True, bins=30, color='black')\n",
    "plt.xlabel('EFS time')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "print(f'Training features: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing=train_test_split(df, test_size=0.33, random_state=315)\n",
    "\n",
    "training_df=pd.DataFrame(training, columns=df.columns)\n",
    "testing_df=pd.DataFrame(testing, columns=df.columns)\n",
    "\n",
    "training_labels_df=training_df[['efs', 'efs_time']]\n",
    "training_features_df=training_df.drop(['efs', 'efs_time'], axis=1)\n",
    "\n",
    "testing_labels_df=testing_df[['efs', 'efs_time']]\n",
    "testing_features_df=testing_df.drop(['efs', 'efs_time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model=GradientBoostingRegressor(random_state=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-validate naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation to estimate out-of-sample performance\n",
    "scores=helper_funcs.cross_val(\n",
    "    naive_model,\n",
    "    training_features_df.drop(['ID','race_group'], axis=1),\n",
    "    training_labels_df['efs_time'],\n",
    "    folds=30\n",
    ")\n",
    "\n",
    "cross_val_scores={'Naive model': scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit and evaluate naive model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "naive_model.fit(\n",
    "    training_features_df.drop(['ID','race_group'], axis=1),\n",
    "    training_labels_df['efs_time']\n",
    ")\n",
    "\n",
    "# Make predictions for the whole test set\n",
    "predicted_efs_time=naive_model.predict(testing_features_df.drop(['ID','race_group'], axis=1))\n",
    "\n",
    "# Get and save the RMSE for later\n",
    "rmse=root_mean_squared_error(testing_labels_df['efs_time'], predicted_efs_time)\n",
    "rmse_results={'Naive model': rmse}\n",
    "\n",
    "# Get and save the concordance index for later\n",
    "cindex=concordance_index(\n",
    "    testing_labels_df['efs_time'],\n",
    "    predicted_efs_time,\n",
    "    testing_labels_df['efs']\n",
    ")\n",
    "\n",
    "cindex_results={'Naive model': cindex}\n",
    "\n",
    "# Get and save stratified concordance index for later\n",
    "submission=pd.DataFrame({'ID': testing_df['ID'], 'prediction': predicted_efs_time})\n",
    "score=helper_funcs.competition_score(testing_df, submission)\n",
    "stratified_cindex_results={'Naive model': score}\n",
    "\n",
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,3, figsize=(10,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Naive gradient regression model test set performance')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "axs[0].scatter(testing_labels_df['efs_time'], predicted_efs_time, color='black', s=0.2)\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "\n",
    "axs[1].set_title('EFS residual as a function of fitted value')\n",
    "axs[1].scatter(predicted_efs_time, testing_labels_df['efs_time'] - predicted_efs_time, color='black', s=0.2)\n",
    "axs[1].set_xlabel('EFS time')\n",
    "axs[1].set_ylabel('true - predicted EFS time')\n",
    "\n",
    "axs[2].set_title('Normal quantile plot')\n",
    "stats.probplot(testing_labels_df['efs_time'] - predicted_efs_time, plot=axs[2])\n",
    "axs[2].get_lines()[0].set_markeredgecolor('black')\n",
    "axs[2].get_lines()[0].set_markerfacecolor('black')\n",
    "axs[2].set_xlabel('Normal quantiles')\n",
    "axs[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "with open(naive_model_file, 'wb') as output_file:\n",
    "    pickle.dump(naive_model, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load model as desired\n",
    "if retune_model == True:\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model=GradientBoostingRegressor(random_state=315)\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cross_validation=KFold(n_splits=7, shuffle=True, random_state=315)\n",
    "\n",
    "    # Define the hyperparameter search space\n",
    "    distributions={\n",
    "        'learning_rate': stats.uniform(loc=0.0001, scale=0.0999),\n",
    "        'n_estimators': list(range(5, 100)),\n",
    "        'max_depth': list(range(5, 50)),\n",
    "        'min_samples_split': list(range(2, 50)),\n",
    "        'min_samples_leaf': list(range(1, 50)),\n",
    "        'subsample': stats.uniform(loc=0.5, scale=0.4)\n",
    "    }\n",
    "\n",
    "    # Set-up the search\n",
    "    search=RandomizedSearchCV(\n",
    "        model,\n",
    "        distributions,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        cv=cross_validation,\n",
    "        n_iter=200,\n",
    "        random_state=315,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    results=search.fit(\n",
    "        training_features_df.drop(['ID','race_group'], axis=1),\n",
    "        training_labels_df['efs_time']\n",
    "    )\n",
    "    \n",
    "    print(f'Best hyperparameters: {results.best_params_}')\n",
    "\n",
    "    # Instantiate the model with the tuned hyperparameters\n",
    "    tuned_model=GradientBoostingRegressor(**results.best_params_, random_state=315)\n",
    "\n",
    "    tuned_model.fit(\n",
    "        training_features_df.drop(['ID','race_group'], axis=1),\n",
    "        training_labels_df['efs_time']\n",
    "    )\n",
    "\n",
    "    with open(tuned_model_file, 'wb') as output_file:\n",
    "        pickle.dump(tuned_model, output_file)\n",
    "    \n",
    "elif retune_model == False:\n",
    "    with open(tuned_model_file, 'rb') as input_file:\n",
    "        tuned_model=pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-validate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation to estimate out-of-sample performance\n",
    "scores=helper_funcs.cross_val(\n",
    "    tuned_model,\n",
    "    training_features_df.drop(['ID','race_group'], axis=1),\n",
    "    training_labels_df['efs_time'],\n",
    "    folds=30\n",
    ")\n",
    "\n",
    "cross_val_scores['Tuned model']=scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit and evaluate tuned model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training set\n",
    "predicted_efs_time=tuned_model.predict(testing_features_df.drop(['ID','race_group'], axis=1))\n",
    "\n",
    "# Save the RMSE for later\n",
    "rmse_results['Tuned model']=root_mean_squared_error(testing_labels_df['efs_time'], predicted_efs_time)\n",
    "\n",
    "# Save the concordance index for later\n",
    "cindex_results['Tuned model']=concordance_index(\n",
    "    testing_labels_df['efs_time'],\n",
    "    predicted_efs_time,\n",
    "    testing_labels_df['efs']\n",
    ")\n",
    "\n",
    "# Get and save stratified concordance index for later\n",
    "submission=pd.DataFrame({'ID': testing_df['ID'], 'prediction': predicted_efs_time})\n",
    "stratified_cindex_results['Tuned model']=helper_funcs.competition_score(testing_df, submission)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,3, figsize=(10,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Tuned gradient boosting regression model performance')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "axs[0].scatter(testing_labels_df['efs_time'], predicted_efs_time, color='black', s=0.2)\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "\n",
    "axs[1].set_title('EFS residual as a function of fitted value')\n",
    "axs[1].scatter(predicted_efs_time, testing_labels_df['efs_time'] - predicted_efs_time, color='black', s=0.2)\n",
    "axs[1].set_xlabel('EFS time')\n",
    "axs[1].set_ylabel('true - predicted EFS time')\n",
    "\n",
    "axs[2].set_title('Normal quantile plot')\n",
    "stats.probplot(testing_labels_df['efs_time'] - predicted_efs_time, plot=axs[2])\n",
    "axs[2].get_lines()[0].set_markeredgecolor('black')\n",
    "axs[2].get_lines()[0].set_markerfacecolor('black')\n",
    "axs[2].set_xlabel('Normal quantiles')\n",
    "axs[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model comparison\n",
    "\n",
    "### 9.1. Cross-validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect scores\n",
    "joined_scores=[]\n",
    "\n",
    "for scores in cross_val_scores.values():\n",
    "    joined_scores.extend(scores)\n",
    "\n",
    "_, bins=np.histogram(joined_scores)\n",
    "\n",
    "plt.title('Cross-validation performance comparison')\n",
    "\n",
    "for model, scores in cross_val_scores.items():\n",
    "    plt.hist(scores, bins=bins, alpha=0.7, label=model)\n",
    "    \n",
    "plt.xlabel('Validation RMSE')\n",
    "plt.ylabel('Samples')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Test set performance\n",
    "\n",
    "#### 9.2.1 RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, score in rmse_results.items():\n",
    "    print(f'{model} RMSE: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.2. Concordance index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, score in cindex_results.items():\n",
    "    print(f'{model} concordance index: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.3. Stratified concordance index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, score in stratified_cindex_results.items():\n",
    "    print(f'{model} stratified concordance index: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features_df=pd.read_parquet(testing_features_df_file)\n",
    "ids=testing_features_df['ID']\n",
    "testing_features_df.drop('ID', axis=1, inplace=True)\n",
    "predicted_efs_time=tuned_model.predict(testing_features_df)\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(predicted_efs_time.reshape(-1, 1))\n",
    "predicted_efs_time=scaler.transform(predicted_efs_time.reshape(-1, 1))\n",
    "\n",
    "predictions_df=pd.DataFrame.from_dict({'ID': ids, 'prediction': predicted_efs_time.flatten()})\n",
    "predictions_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
