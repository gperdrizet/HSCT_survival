{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival: clustering\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "import configuration as config\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "data_df_file=f'{config.DATA_PATH}/processed/02.1-no-multicollinearity_encoded_all_imputed_data_df.parquet'\n",
    "feature_types_dict_file=f'{config.DATA_PATH}/processed/01.1-feature_type_dict.pkl'\n",
    "retrain_tree=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAEiCAYAAAAyFTwvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYhlJREFUeJzt3XdUFNfbB/DvUnbpXVhQBEQFCypiRGxIREGxoETFGEXUWILGFiUkFtQkxN5iTYGYgC2JxhJRRLFERAURsaJBMcqCUQEFpd73D387r0NdloWlPJ9z5hz2zp2Z5+6yl4c7M3cEjDEGQgghhBBSbSrKDoAQQgghpKGiRIoQQgghRE6USBFCCCGEyIkSKUIIIYQQOVEiRQghhBAiJ0qkCCGEEELkRIkUIYQQQoicKJEihBBCCJETJVKEEEIIIXKiRIpU2y+//AJ7e3uoq6vDwMBA2eHUS8HBwRAIBLV6DGtra0ycOFHu7esiRkIUgfqcqtWXPufBgwcQCARYs2ZNlftrLH0QJVK1KCwsDAKBoMLl4sWLyg4RFy5cQHBwMLKysmSqf/v2bUycOBG2trb4/vvvsXPnztoNkNRIXl4egoODERMTo+xQSB2gPoeQuqem7ACaguXLl8PGxqZMeevWrZUQDd+FCxewbNkyTJw4Uab/9GJiYlBSUoKNGzfWi/jrq0WLFuHzzz9XdhjIy8vDsmXLAAD9+vXjrasvMRLFoz6n6WmI3+eGGHN5KJGqA4MGDUK3bt2UHYZCZGZmAkCVHSBjDG/evIGmpmYdRFX7cnNzoa2tLXN9NTU1qKnV769XQ4iRyIf6nIavMfY5pSkr5uq+t1WhU3tKVlhYCCMjI/j7+5dZl5OTAw0NDXz22WdcWX5+PpYuXYrWrVtDJBLB0tISCxcuRH5+Pm9bgUCAmTNn4uDBg+jYsSNEIhE6dOiAyMhIrk5wcDAWLFgAALCxseGG/x88eFBurNbW1li6dCkAoFmzZhAIBAgODubWDRkyBMePH0e3bt2gqamJHTt2AACysrIwZ84cWFpaQiQSoXXr1li5ciVKSkp4+y8pKcGGDRvQoUMHaGhowMzMDNOmTcOLFy+qfB8lEgn8/f3RokULiEQimJubY/jw4by2vBtv6Xa9e95fenrkzJkz+OSTT2BqaooWLVrgt99+48pL27FjBwQCAZKTk7n39t1z/x07doSbm1uZ7UpKStC8eXN88MEHXNmaNWvQs2dPGBsbQ1NTE05OTvjtt9+qfA9Ke/DgAZo1awYAWLZsGff5St+D8q5PkP7e7N+/H+3bt4empiZcXFxw/fp1rp2tW7eGhoYG+vXrV+7vSlxcHDw9PaGvrw8tLS24urri77//rnb8pHZQn/P/qM95S1F9Tmnr16+HlZUVNDU14erqysUqVVkfVNnvEQA8fPgQn3zyCezs7KCpqQljY2OMGjWqzO9SRe/t6dOnIRAIcODAgTJxR0REQCAQIDY2VqZ2Nqz0tYHKzs7Gf//9xysTCAQwNjaGuro6RowYgT/++AM7duyAUCjk6hw8eBD5+fnw9fUF8PYLMGzYMJw/fx5Tp05Fu3btcP36daxfvx53797FwYMHecc4f/48/vjjD3zyySfQ1dXFpk2b4OPjg7S0NBgbG2PkyJG4e/cudu/ejfXr18PExAQAuD++pW3YsAG7du3CgQMHsG3bNujo6KBTp07c+jt37mDs2LGYNm0aPv74Y9jZ2SEvLw+urq54/Pgxpk2bhpYtW+LChQsICgpCeno6NmzYwG0/bdo0hIWFwd/fH59++ilSU1Px3Xff4erVq/j777+hrq5e4Xvs4+ODGzduYNasWbC2tkZmZiaioqKQlpYGa2trWT6mMj755BM0a9YMS5YsQW5uLry8vKCjo4N9+/bB1dWVV3fv3r3o0KEDOnbsWO6+xowZg+DgYEgkEojFYq78/PnzePLkCfcZA8DGjRsxbNgwjBs3DgUFBdizZw9GjRqFI0eOwMvLS+b4mzVrhm3btmHGjBkYMWIERo4cCQC8z6w8586dw6FDhxAQEAAACAkJwZAhQ7Bw4UJs3boVn3zyCV68eIFVq1Zh0qRJOHXqFLftqVOnMGjQIDg5OWHp0qVQUVFBaGgo3n//fZw7dw7du3eXOX4iP+pzqM9RRp/zrl27duHly5cICAjAmzdvsHHjRrz//vu4fv06zMzMKt22qt8jALh8+TIuXLgAX19ftGjRAg8ePMC2bdvQr18/3Lx5E1paWrx9ln5v+/XrB0tLS4SHh2PEiBG8uuHh4bC1tYWLi4tsjWWk1oSGhjIA5S4ikYird/z4cQaAHT58mLf94MGDWatWrbjXv/zyC1NRUWHnzp3j1du+fTsDwP7++2+uDAATCoXs3r17XNm1a9cYALZ582aubPXq1QwAS01NlalNS5cuZQDY06dPeeVWVlYMAIuMjOSVr1ixgmlra7O7d+/yyj///HOmqqrK0tLSGGOMnTt3jgFg4eHhvHqRkZHllr/rxYsXDABbvXp1pbEDYEuXLi1TbmVlxfz8/LjX0s+td+/erKioiFd37NixzNTUlFeenp7OVFRU2PLly7ky6fskdefOnTLvPWOMffLJJ0xHR4fl5eVxZe/+zBhjBQUFrGPHjuz999+vNO7yPH36tMJ2l46RMcb9br77+7Bjxw4GgInFYpaTk8OVBwUF8X53SkpKWJs2bZiHhwcrKSnhtcfGxoYNGDCg0lhJzVGfQ32OlLL6nNTUVAaAaWpqsn///Zcrj4uLYwDY3LlzK4yZMdl/j0rHzBhjsbGxDADbtWsXV1bZexsUFMREIhHLysriyjIzM5mamlq5n1tF6NReHdiyZQuioqJ4y7Fjx7j177//PkxMTLB3716u7MWLF4iKisKYMWO4sv3796Ndu3awt7fHf//9xy3vv/8+AOD06dO847q7u8PW1pZ73alTJ+jp6eGff/6plXba2NjAw8ODV7Z//3706dMHhoaGvJjd3d1RXFyMs2fPcvX09fUxYMAAXj0nJyfo6OiUadu7NDU1IRQKERMTI9OQvKw+/vhjqKqq8srGjBmDzMxM3l1wv/32G0pKSnifVWlt27ZFly5deJ9xcXExfvvtNwwdOpR3Xce7P7948QLZ2dno06cPEhISFNCqqvXv35/3H7WzszOAt/+B6+rqlimX/j4lJiYiJSUFH374IZ49e8Z9hrm5uejfvz/Onj1b5tQKqR3U51Cfo+w+x9vbG82bN+ded+/eHc7Ozvjrr7+q3FaW36N3Yy4sLMSzZ8/QunVrGBgYlBt3ee/thAkTkJ+fzzuNuXfvXhQVFeGjjz6SraGgU3t1onv37pVe+KmmpgYfHx9EREQgPz8fIpEIf/zxBwoLC3lflJSUFNy6davCYXDpRZlSLVu2LFPH0NBQoV/8d5V3l1BKSgqSkpKqjDklJQXZ2dkwNTWttF55RCIRVq5cifnz58PMzAw9evTAkCFDMGHCBN6QdnWV1x7ptT979+5F//79Abz94nXp0gVt27atdH9jxozBF198gcePH6N58+aIiYlBZmZmmc7wyJEj+Oqrr5CYmMi7DqWu5lsp/Xujr68PALC0tCy3XPr7lJKSAgDw8/OrcN/Z2dkwNDRUWKykfNTnUJ8DKLfPadOmTZmytm3bYt++fVVuK8vv0evXrxESEoLQ0FA8fvwYbwez3srOzi6zfXnvrb29Pd577z2Eh4dj8uTJAN6e1uvRo0e17hClRKqe8PX1xY4dO3Ds2DF4e3tj3759sLe3R+fOnbk6JSUlcHBwwLp168rdR+k/dKWzb6l3f+EUqby7ZUpKSjBgwAAsXLiw3G2kHUFJSQlMTU0RHh5ebr2KOkWpOXPmYOjQoTh48CCOHz+OxYsXIyQkBKdOnYKjo2Ol2xYXF5dbXl57RCIRvL29ceDAAWzduhUZGRn4+++/8c0331R6DOBtpxYUFIT9+/djzpw52LdvH/T19eHp6cnVOXfuHIYNG4a+ffti69atMDc3h7q6OkJDQxEREVHlMRShot+bqn6fpKNNq1evRpcuXcqtq6OjU/MAiUJQn0N9DlA/+pzSZPk9mjVrFkJDQzFnzhy4uLhAX18fAoEAvr6+5Y58V3Q354QJEzB79mz8+++/yM/Px8WLF/Hdd99VK15KpOqJvn37wtzcHHv37kXv3r1x6tQpfPnll7w6tra2uHbtGvr376+w0YnaHuWwtbXFq1ev4O7uXmW9kydPolevXnLfvmxra4v58+dj/vz5SElJQZcuXbB27Vr8+uuvAN7+R1N6EsCCggKkp6dX6zhjxozBzz//jOjoaNy6dQuMsUqH2KVsbGzQvXt37N27FzNnzsQff/wBb29viEQirs7vv/8ODQ0NHD9+nFceGhparRil6nLWYOlQvJ6eXpWfN1E+6nOozwEU3+dISUeo33X37l25L8Qv7bfffoOfnx/Wrl3Llb1580bmiV6lfH19MW/ePOzevRuvX7+Gurq6TO/tu+gaqXpCRUUFH3zwAQ4fPoxffvkFRUVFZT7M0aNH4/Hjx/j+++/LbP/69Wvk5uZW+7jSuTSq+8snq9GjRyM2NhbHjx8vsy4rKwtFRUVcveLiYqxYsaJMvaKiokrjy8vLw5s3b3hltra20NXV5Q1T29ractdHSO3cubPC/w4r4u7uDiMjI+zduxd79+5F9+7dyx02Ls+YMWNw8eJF/PTTT/jvv//KfMaqqqoQCAS8mB48eFDm7ihZSe9cqa3P911OTk6wtbXFmjVr8OrVqzLrnz59WusxENlRn0N9DqD4Pkfq4MGDePz4Mff60qVLiIuLw6BBg2q0XylVVdUyI52bN2+u9ntrYmKCQYMG4ddff0V4eDg8PT25u0llRSNSdeDYsWO4fft2mfKePXuiVatW3OsxY8Zg8+bNWLp0KRwcHNCuXTte/fHjx2Pfvn2YPn06Tp8+jV69eqG4uBi3b9/Gvn37uPlUqsPJyQkA8OWXX8LX1xfq6uoYOnSowiYrW7BgAQ4dOoQhQ4Zg4sSJcHJyQm5uLq5fv47ffvsNDx48gImJCVxdXTFt2jSEhIQgMTERAwcOhLq6OlJSUrB//35s3LiRN+/Ju+7evYv+/ftj9OjRaN++PdTU1HDgwAFkZGTwbvGdMmUKpk+fDh8fHwwYMADXrl3D8ePHq/2lUVdXx8iRI7Fnzx7k5ubK9EwpqdGjR+Ozzz7DZ599BiMjozL/NXt5eWHdunXw9PTEhx9+iMzMTGzZsgWtW7dGUlJSteIE3g5nt2/fHnv37kXbtm1hZGSEjh07VnjLdE2oqKjghx9+wKBBg9ChQwf4+/ujefPmePz4MU6fPg09PT0cPnxY4cclZVGfQ32OVF33OVKtW7dG7969MWPGDOTn52PDhg0wNjau8JRrdQ0ZMgS//PIL9PX10b59e8TGxuLkyZPc9AjVMWHCBO6zLi+xrpLM9/eRaqvsVmQALDQ0lFe/pKSEWVpaMgDsq6++KnefBQUFbOXKlaxDhw5MJBIxQ0ND5uTkxJYtW8ays7O5egBYQEBAme3Lu311xYoVrHnz5kxFRaXK25IruxXZy8ur3G1evnzJgoKCWOvWrZlQKGQmJiasZ8+ebM2aNaygoIBXd+fOnczJyYlpamoyXV1d5uDgwBYuXMiePHlSYUz//fcfCwgIYPb29kxbW5vp6+szZ2dntm/fPl694uJiFhgYyExMTJiWlhbz8PBg9+7dq/BW5MuXL1d4zKioKAaACQQC9ujRowrfp/L06tWLAWBTpkwpd/2PP/7I2rRpw0QiEbO3t2ehoaHl7k+WW5EZY+zChQvMycmJCYVC3u3YFd16XPr3Rno7c+lbvU+fPs0AsP379/PKr169ykaOHMmMjY2ZSCRiVlZWbPTo0Sw6OrrKWEnNUJ/zFvU5fHXZ57zbX6xdu5ZZWloykUjE+vTpw65du1ZlzLL+Hr148YL5+/szExMTpqOjwzw8PNjt27flem/z8/OZoaEh09fXZ69fv660feUR/C9wQgghhJAmp6ioCBYWFhg6dCh+/PHHam9P10gRQgghpMk6ePAgnj59igkTJsi1PY1IEUIIIaTJiYuLQ1JSElasWAETExO5JyClESlCCCGENDnSZ5Gamppi165dcu+HRqQIIYQQQuREI1KEEEIIIXJSaiJ19uxZDB06FBYWFhAIBGUmAGOMYcmSJTA3N4empibc3d3LzJb6/PlzjBs3Dnp6ejAwMMDkyZPLTAaYlJSEPn36QENDA5aWlli1alWZWPbv3w97e3toaGjAwcFBpgcrEkIIIaRpU+qEnLm5uejcuTMmTZqEkSNHllm/atUqbNq0CT///DNsbGywePFieHh44ObNm9DQ0AAAjBs3Dunp6YiKikJhYSH8/f0xdepU7hlBOTk5GDhwINzd3bF9+3Zcv34dkyZNgoGBAaZOnQoAuHDhAsaOHYuQkBAMGTIEERER8Pb2RkJCgswTF5aUlODJkyfQ1dWt08dyENJQMcbw8uVLWFhYQEWFBscVjfokQmRXo/6o2jNP1RIA7MCBA9zrkpISJhaLeZMAZmVlMZFIxHbv3s0YY+zmzZtlJto6duwYEwgE7PHjx4wxxrZu3coMDQ1Zfn4+VycwMJDZ2dlxr0ePHl1mYjdnZ2c2bdo0meN/9OhRpRPh0UILLeUv5U0uSGqO+iRaaKn+Ik9/VG8fEZOamgqJRMKbzl5fXx/Ozs6IjY2Fr68vYmNjYWBgwHtEgbu7O1RUVBAXF4cRI0YgNjYWffv2hVAo5Op4eHhg5cqVePHiBQwNDREbG4t58+bxju/h4VHps4by8/N5z1Ri/7tm/9GjR9DT06tp8wlp9HJycmBpaQldXV1lh9IoSd9X6pMIqVpN+qN6m0hJJBIAgJmZGa/czMyMWyeRSGBqaspbr6amBiMjI16d0g93lO5TIpHA0NAQEomk0uOUJyQkBMuWLStTrqenR50WIdVAp51qh/R9pT6JENnJ0x/RhQlyCgoKQnZ2Nrc8evRI2SERQgghpI7V20RKLBYDADIyMnjlGRkZ3DqxWIzMzEze+qKiIjx//pxXp7x9vHuMiupI15dHJBJx/+nRf3yEEEJI01RvEykbGxuIxWJER0dzZTk5OYiLi4OLiwsAwMXFBVlZWYiPj+fqnDp1CiUlJXB2dubqnD17FoWFhVydqKgo2NnZwdDQkKvz7nGkdaTHIYQQQggpj1KvkXr16hXu3bvHvU5NTUViYiKMjIzQsmVLzJkzB1999RXatGnDTX9gYWEBb29vAEC7du3g6emJjz/+GNu3b0dhYSFmzpwJX19fWFhYAAA+/PBDLFu2DJMnT0ZgYCCSk5OxceNGrF+/njvu7Nmz4erqirVr18LLywt79uzBlStXsHPnzjp9P4jyFBcX85JtUnPq6upQVVVVdhiEEFKrlJpIXblyBW5ubtxr6Z1zfn5+CAsLw8KFC5Gbm4upU6ciKysLvXv3RmRkJDeHFACEh4dj5syZ6N+/P1RUVODj44NNmzZx6/X19XHixAkEBATAyckJJiYmWLJkCTeHFAD07NkTERERWLRoEb744gu0adMGBw8elHkOKdJwMcYgkUiQlZWl7FAaJQMDA4jFYrqgnBDSaNGz9hQkJycH+vr6yM7OpuulGpD09HRkZWXB1NQUWlpa9AdfQRhjyMvLQ2ZmJgwMDGBubl6mDn1nahe9v4TIribfl3o7/QEhta24uJhLooyNjZUdTqOjqakJAMjMzISpqSmd5iOENEqUSNUDh21ty5QNvX9fCZE0LdJrorS0tJQcSeMlfW8LCwspkSKkmmiEXHFq8+Rbvb1rj5C6Qp1V7aH3lhDS2FEiRQgh/3P27FkMHToUFhYWEAgEZR4TNXHiRAgEAt7i6enJq/P8+XOMGzcOenp6MDAwwOTJk/Hq1StenaSkJPTp0wcaGhqwtLTEqlWrysSyf/9+2NvbQ0NDAw4ODvjrr78U3l5CSM1RIkUIIf+Tm5uLzp07Y8uWLRXW8fT0RHp6Orfs3r2bt37cuHG4ceMGoqKicOTIEZw9e5Z3l3BOTg4GDhwIKysrxMfHY/Xq1QgODuZNt3LhwgWMHTsWkydPxtWrV+Ht7Q1vb28kJycrvtGEkBqhRIqQcpQedajNpbrKGxUpPTJibW1dZn2LFi249QcOHECPHj2gr68PXV1ddOjQAXPmzKn0uLKMtDR0gwYNwldffYURI0ZUWEckEkEsFnOLdGJfALh16xYiIyPxww8/wNnZGb1798bmzZuxZ88ePHnyBMDbKVsKCgrw008/oUOHDvD19cWnn36KdevWcfvZuHEjPD09sWDBArRr1w4rVqxA165d8d1339Ve4wkhcqFEipAGqPSoSHkjI8uXL+etv3r1KgAgOjoaY8aMgY+PDy5duoT4+Hh8/fXXVU5IWtVIS1MRExMDU1NT2NnZYcaMGXj27Bm3LjY2FgYGBujWrRtX5u7uDhUVFcTFxXF1+vbtC6FQyNXx8PDAnTt38OLFC66Ou7s777geHh6IjY2tzaYRQuRAd+0R0gBJR0Uqo6urW26dw4cPo1evXliwYAFX1rZtW+6JAeWRjrRcvnyZSxI2b96MwYMHY82aNdyTBBo7T09PjBw5EjY2Nrh//z6++OILDBo0CLGxsVBVVYVEIoGpqSlvGzU1NRgZGUEikQAAJBIJbGxseHXMzMy4dYaGhpBIJFzZu3Wk+yhPfn4+8vPzudc5OTk1aishRDY0IkVIEyMWi3Hjxo1qXW8jy0hLU+Dr64thw4bBwcEB3t7eOHLkCC5fvoyYmBhlh4aQkBDo6+tzi6WlpbJDIqRJoESKkAboyJEj0NHR4S3ffPMNr05gYCBvvfTRSbNmzcJ7770HBwcHWFtbw9fXFz/99BNvNKM0WUZamqJWrVrBxMSEe2aoWCxGZmYmr05RURGeP3/OjQ6KxWJkZGTw6khfV1WnslHIoKAgZGdnc8ujR49q1jhCiEzo1B4hDZCbmxu2bdvGKzMyMuK9XrBgASZOnMi9NjExAQBoa2vj6NGjuH//Pk6fPo2LFy9i/vz52LhxI2JjY2mC0mr4999/8ezZM+4ROC4uLsjKykJ8fDycnJwAAKdOnUJJSQmcnZ25Ol9++SUKCwuhrq4OAIiKioKdnR134bqLiwuio6N5NwBERUXBxcWlwlhEIhFEIlFtNJMQUglKpAhpgLS1tdG6detK65iYmFRax9bWFra2tpgyZQq+/PJLtG3bFnv37oW/v3+ZurKMtDQGr1694kaXACA1NRWJiYkwMjKCkZERli1bBh8fH4jFYty/fx8LFy5E69at4eHhAQBo164dPD098fHHH2P79u0oLCzEzJkz4evry11H9uGHH2LZsmWYPHkyAgMDkZycjI0bN2L9+vXccWfPng1XV1esXbsWXl5e2LNnD65cucKbIoEQUj/QqT1CCKytraGlpYXc3Nxy17870iJVeqSlMbhy5QocHR3h6OgIAJg3bx4cHR2xZMkSqKqqIikpCcOGDUPbtm0xefJkODk54dy5c7yRoPDwcNjb26N///4YPHgwevfuzUuA9PX1ceLECaSmpsLJyQnz58/HkiVLeHdA9uzZExEREdi5cyc6d+6M3377DQcPHkTHjh3r7s0ghMiERqQIaYDy8/PLXJukpqbGnb6rTHBwMPLy8jB48GBYWVkhKysLmzZtQmFhIQYMGFDuNrKMtDQG/fr1q/SZXMePH69yH0ZGRoiIiKi0TqdOnXDu3LlK64waNQqjRo2q8niEEOWiRIqQBigyMpK7LkfKzs4Ot2/frnJbV1dXbNmyBRMmTEBGRgYMDQ3h6OiIEydOwM7OrsLtwsPDMXPmTPTv3x8qKirw8fHhLmAnhJCmihIpQspRm08Kr6mwsDCEhYVVWufBgwcVrnNzc4Obm1u1jyvLSAshhDQ1dI0UIYQQQoicKJEihBBCCJETJVKEEEIIIXKiRIoQQgghRE6USBFCCCGEyIkSKUIIIYQQOVEiRQghhBAiJ0qkCCGEEELkRIkUIYQQQoicKJEihBBCCJETPSKGkHIctrWts2MNvX+/WvUnTpyIn3/+uUy5h4cHIiMjAQDW1tZ4+PAhb33z5s3x77//AgAOHDiAlStX4tatWygpKUHLli0xYMAAbNiwocLjfv311zh69CgSExMhFAqRlZVVrbgJIaQxokSKkAbI09MToaGhvDKRSMR7vXz5cnz88cfca1VVVQBAdHQ0xowZg6+//hrDhg2DQCDAzZs3ERUVVekxCwoKMGrUKLi4uODHH39UUEsIIaRho0SKkAZIJBJBLBZXWkdXV7fcOocPH0avXr2wYMECrqxt27bw9vaudH/Lli0DgCofmEwIIU1Jvb5Gqri4GIsXL4aNjQ00NTVha2uLFStWgDHG1WGMYcmSJTA3N4empibc3d2RkpLC28/z588xbtw46OnpwcDAAJMnT8arV694dZKSktCnTx9oaGjA0tISq1atqpM2ElLXxGIxbty4geTkZGWHQuoBgUBAi4IW0jTV60Rq5cqV2LZtG7777jvcunULK1euxKpVq7B582auzqpVq7Bp0yZs374dcXFx0NbWhoeHB968ecPVGTduHG7cuIGoqCgcOXIEZ8+exdSpU7n1OTk5GDhwIKysrBAfH4/Vq1cjODgYO3furNP2EiKrI0eOQEdHh7d88803vDqBgYG89Zs2bQIAzJo1C++99x4cHBxgbW0NX19f/PTTT8jPz1dGUwghpEGr16f2Lly4gOHDh8PLywvA2wtod+/ejUuXLgF4Oxq1YcMGLFq0CMOHDwcA7Nq1C2ZmZjh48CB8fX1x69YtREZG4vLly+jWrRsAYPPmzRg8eDDWrFkDCwsLhIeHo6CgAD/99BOEQiE6dOiAxMRErFu3jpdwEVJfuLm5Ydu2bbwyIyMj3usFCxZg4sSJ3GsTExMAgLa2No4ePYr79+/j9OnTuHjxIubPn4+NGzciNjYWWlpatR4/IYQ0FvV6RKpnz56Ijo7G3bt3AQDXrl3D+fPnMWjQIABAamoqJBIJ3N3duW309fXh7OyM2NhYAEBsbCwMDAy4JAoA3N3doaKigri4OK5O3759IRQKuToeHh64c+cOXrx4UevtJKS6tLW10bp1a95SOpEyMTHhrTcwMOCtt7W1xZQpU/DDDz8gISEBN2/exN69e+uwFYQQ0vDV6xGpzz//HDk5ObC3t4eqqiqKi4vx9ddfY9y4cQAAiUQCADAzM+NtZ2Zmxq2TSCQwNTXlrVdTU4ORkRGvjo2NTZl9SNcZGhqWiS0/P593KiQnJ6cmTSVEqaytraGlpYXc3Fxlh0IIIQ1KvU6k9u3bh/DwcERERHCn2+bMmQMLCwv4+fkpNbaQkBDuLiZC6lp+fj73j4CUmpoad/quMsHBwcjLy8PgwYNhZWWFrKwsbNq0CYWFhRgwYECF26WlpeH58+dIS0tDcXExEhMTAQCtW7eGjo5OjdpDCCENVb0+tbdgwQJ8/vnn8PX1hYODA8aPH4+5c+ciJCQEALhbuzMyMnjbZWRkcOvEYjEyMzN564uKivD8+XNenfL28e4xSgsKCkJ2dja3PHr0qIatJUR2kZGRMDc35y29e/eWaVtXV1f8888/mDBhAuzt7TFo0CBIJBKcOHECdnZ2FW63ZMkSODo6YunSpXj16hUcHR3h6OiIK1euKKpZSnf27FkMHToUFhYWEAgEOHjwILeusLAQgYGBcHBwgLa2NiwsLDBhwgQ8efKEtw9ra+syd3N9++23vDqy3CW8f/9+2NvbQ0NDAw4ODvjrr79qpc2EkJqp1yNSeXl5UFHh53qqqqooKSkBANjY2EAsFiM6OhpdunQB8PYUW1xcHGbMmAEAcHFxQVZWFuLj4+Hk5AQAOHXqFEpKSuDs7MzV+fLLL1FYWAh1dXUAQFRUFOzs7Mo9rQe8ncen9ASIpPGo7mzjdSksLKzKuZwePHhQ4To3Nze4ubnVynEbutzcXHTu3BmTJk3CyJEjeevy8vKQkJCAxYsXo3Pnznjx4gVmz56NYcOGlUkmS0+Gqqury/0svUvY3d0d27dvx/Xr1zFp0iQYGBhwN7dcuHABY8eORUhICIYMGYKIiAh4e3sjISEBHTt2rMV3gBBSbawe8/PzY82bN2dHjhxhqamp7I8//mAmJiZs4cKFXJ1vv/2WGRgYsD///JMlJSWx4cOHMxsbG/b69WuujqenJ3N0dGRxcXHs/PnzrE2bNmzs2LHc+qysLGZmZsbGjx/PkpOT2Z49e5iWlhbbsWOHzLFmZ2czACw7O7va7TzUqlWZhdS+169fs5s3b/J+V4hiVfYe1+Q7UxcAsAMHDlRa59KlSwwAe/jwIVdmZWXF1q9fX+E2W7duZYaGhiw/P58rCwwMZHZ2dtzr0aNHMy8vL952zs7ObNq0aTLHL+v7C4AWBS2Kpuz2NKalKjXpj+r1qb3Nmzfjgw8+wCeffIJ27drhs88+w7Rp07BixQquzsKFCzFr1ixMnToV7733Hl69eoXIyEhoaGhwdcLDw2Fvb4/+/ftj8ODB6N27N2+OKH19fZw4cQKpqalwcnLC/PnzsWTJEpr6gBBSqezsbAgEgjJ3RH777bcwNjaGo6MjVq9ejaKiIm6dLHcJx8bG8u5GltaR3o1cnvz8fOTk5PAWQkjtq9en9nR1dbFhw4ZKH6QqEAiwfPlyLF++vMI6RkZGiIiIqPRYnTp1wrlz5+QNlRDSxLx58waBgYEYO3Ys9PT0uPJPP/0UXbt2hZGRES5cuICgoCCkp6dj3bp1AGS7S1gikVR6N3J56AYYQpSjXidShBBSHxUWFmL06NFgjJWZGHXevHncz506dYJQKMS0adMQEhJSq9dVBgUF8Y6dk5MDS0vLWjseIeQtSqQIIaQapEnUw4cPcerUKd5oVHmcnZ1RVFSEBw8ewM7OTqa7hCuqU9mDqukGGEKUo15fI0VIXZDeBUoUr7G9t9IkKiUlBSdPnoSxsXGV2yQmJkJFRYWbGNjFxQVnz55FYWEhV6f0XcIuLi6Ijo7m7ScqKgouLi4KbA0hRBFoRIo0WUKhECoqKnjy5AmaNWsGoVBIT3BXEMYYCgoK8PTpU6ioqPAurK7PXr16hXv37nGvU1NTkZiYCCMjI5ibm+ODDz5AQkICjhw5guLiYu6aJSMjIwiFQsTGxiIuLg5ubm7Q1dVFbGws5s6di48++ohLkj788EMsW7YMkydPRmBgIJKTk7Fx40asX7+eO+7s2bPh6uqKtWvXwsvLC3v27MGVK1foQeqE1EOC/91iSWooJycH+vr6yM7OrnKov7TDtrZlyurzPEaNSUFBAdLT05GXl6fsUBolLS0tmJubl5tI1eQ7U1tiYmLKnWPLz88PwcHBZS4Slzp9+jT69euHhIQEfPLJJ7h9+zby8/NhY2OD8ePHY968ebzTbklJSQgICMDly5dhYmKCWbNmITAwkLfP/fv3Y9GiRXjw4AHatGmDVatWYfDgwTK3Rdb3l/55UBxF/zmlz0ZxqvpsatIfUSKlIJRINVyMMRQVFaG4uFjZoTQqqqqqUFNTq/CPQX1MpBoTSqTqHiVS9VdtJlJ0ao80eQKBAOrq6tys9oQQQois6GJzQgghhBA5USJFCCGEECInSqQIIYQQQuREiRQhhBBCiJwokSKEEEIIkRMlUoQQQgghcqJEihBCCCFETpRIEUIIIYTISSGJVHFxMRITE/HixQtF7I4QQgghpEGQK5GaM2cOfvzxRwBvkyhXV1d07doVlpaWiImJUWR8hBBCCCH1llyJ1G+//YbOnTsDAA4fPozU1FTcvn0bc+fOxZdffqnQAAkhhBBC6iu5Eqn//vsPYrEYAPDXX39h1KhRaNu2LSZNmoTr168rNEBCCCGEkPpKrkTKzMwMN2/eRHFxMSIjIzFgwAAAQF5eHlRVVRUaICGEEEJIfaUmz0b+/v4YPXo0zM3NIRAI4O7uDgCIi4uDvb29QgMkhBBCCKmv5EqkgoOD0bFjRzx69AijRo2CSCQCAKiqquLzzz9XaICEEEIIIfWVXInUrl27MGbMGC6Bkho7diz27NmjkMAIIYQQQuo7ua6R8vf3R3Z2dpnyly9fwt/fv8ZBEUIIIYQ0BHIlUowxCASCMuX//vsv9PX1axwUIYQQQkhDUK1Te46OjhAIBBAIBOjfvz/U1P5/8+LiYqSmpsLT01PhQRJCCCGE1EfVGpHy9vbG8OHDwRiDh4cHhg8fzi2+vr7YsWMHfv3119qKlRBCatXZs2cxdOhQWFhYQCAQ4ODBg7z1jDEsWbIE5ubm0NTUhLu7O1JSUnh1nj9/jnHjxkFPTw8GBgaYPHkyXr16xauTlJSEPn36QENDA5aWlli1alWZWPbv3w97e3toaGjAwcEBf/31l8LbSwipuWqNSC1duhQAYG1tjTFjxkBDQ6NWgiKEEGXIzc1F586dMWnSJIwcObLM+lWrVmHTpk34+eefYWNjg8WLF8PDwwM3b97k+sNx48YhPT0dUVFRKCwshL+/P6ZOnYqIiAgAQE5ODgYOHAh3d3ds374d169fx6RJk2BgYICpU6cCAC5cuICxY8ciJCQEQ4YMQUREBLy9vZGQkICOHTvW3RtCCKkaq4H8/Hz26NEj9vDhQ97SFGVnZzMALDs7u9rbHmrVqsxCSGNXk+9MXQDADhw4wL0uKSlhYrGYrV69mivLyspiIpGI7d69mzHG2M2bNxkAdvnyZa7OsWPHmEAgYI8fP2aMMbZ161ZmaGjI8vPzuTqBgYHMzs6Oez169Gjm5eXFi8fZ2ZlNmzZN5vhlfX8B0KKgRdGU3Z7GtFSlJv2RXBebp6SkoE+fPtDU1ISVlRVsbGxgY2MDa2tr2NjYyLNLQgip11JTUyGRSLgJiAFAX18fzs7OiI2NBQDExsbCwMAA3bp14+q4u7tDRUUFcXFxXJ2+fftCKBRydTw8PHDnzh28ePGCq/PucaR1pMcpT35+PnJycngLIaT2yZVITZw4ESoqKjhy5Aji4+ORkJCAhIQEXL16FQkJCQoN8PHjx/joo49gbGwMTU1NODg44MqVK9x6VofXLBBCmi6JRALg7SOy3mVmZsatk0gkMDU15a1XU1ODkZERr055+3j3GBXVka4vT0hICPT19bnF0tKyuk0khMhBrgk5ExMTER8fX+uPg3nx4gV69eoFNzc3HDt2DM2aNUNKSgoMDQ25OnV1zQIhhNRnQUFBmDdvHvc6JyeHkilC6oBciVT79u3x33//KTqWMlauXAlLS0uEhoZyZe+eOmSMYcOGDVi0aBGGDx8O4O2s62ZmZjh48CB8fX1x69YtREZG4vLly9xw++bNmzF48GCsWbMGFhYWCA8PR0FBAX766ScIhUJ06NABiYmJWLduHSVShBAAgFgsBgBkZGTA3NycK8/IyECXLl24OpmZmbztioqK8Pz5c257sViMjIwMXh3p66rqSNeXRyQSlXnaBCGk9sl1am/lypVYuHAhYmJi8OzZs1o7L3/o0CF069YNo0aNgqmpKRwdHfH9999z6+vymoXS6HoEQpoWGxsbiMViREdHc2U5OTmIi4uDi4sLAMDFxQVZWVmIj4/n6pw6dQolJSVwdnbm6pw9exaFhYVcnaioKNjZ2XGj7S4uLrzjSOtIj0MIqT/kSqTc3d1x8eJF9O/fH6ampjA0NIShoSEMDAx4p91q6p9//sG2bdvQpk0bHD9+HDNmzMCnn36Kn3/+GUDdXrNQGl2PQEjj8+rVKyQmJiIxMRHA23/WEhMTkZaWBoFAgDlz5uCrr77CoUOHcP36dUyYMAEWFhbw9vYGALRr1w6enp74+OOPcenSJfz999+YOXMmfH19YWFhAQD48MMPIRQKMXnyZNy4cQN79+7Fxo0beaflZs+ejcjISKxduxa3b99GcHAwrly5gpkzZ9b1W0IIqYJcp/ZOnz6t6DjKVVJSgm7duuGbb74B8HZm9eTkZGzfvh1+fn51EkNF6HoEQuqHVq1a4fLlyzA2NuaVZ2VloWvXrvjnn39k3teVK1fg5ubGvZZ+x/38/BAWFoaFCxciNzcXU6dORVZWFnr37o3IyEjenHrh4eGYOXMm+vfvDxUVFfj4+GDTpk3cen19fZw4cQIBAQFwcnKCiYkJlixZwruMoGfPnoiIiMCiRYvwxRdfoE2bNjh48CDNIUVIPSRXIuXq6qroOMplbm6O9u3b88ratWuH33//HUDdXrNQGl2PQEj98ODBAxQXF5cpz8/Px+PHj6u1r379+uHt9D3lEwgEWL58OZYvX15hHSMjI+5Glop06tQJ586dq7TOqFGjMGrUqMoDJoQonVyJlFReXh7S0tJQUFDAK+/UqVONgpLq1asX7ty5wyu7e/curKysAPCvWZAmTtJrFmbMmAGAf82Ck5MTgPKvWfjyyy9RWFgIdXV1AGWvWSCE1C+HDh3ifj5+/DjvgenFxcWIjo6GtbW1EiIjhDQp1Z7CkzGWmZnJvLy8mIqKSrmLoly6dImpqamxr7/+mqWkpLDw8HCmpaXFfv31V67Ot99+ywwMDNiff/7JkpKS2PDhw5mNjQ17/fo1V8fT05M5OjqyuLg4dv78edamTRs2duxYbn1WVhYzMzNj48ePZ8nJyWzPnj1MS0uL7dixQ+ZYaWZzQqqnpjObCwQCJhAImIqKCvezdBEKhaxt27bs8OHDCo664aCZzevf7NnVpez2NKalKjXpj+T65D/88EPWq1cvdvnyZaatrc1OnDjBfvnlF2ZnZ8eOHDkizy4rdPjwYdaxY0cmEomYvb0927lzJ299SUkJW7x4MTMzM2MikYj179+f3blzh1fn2bNnbOzYsUxHR4fp6ekxf39/9vLlS16da9eusd69ezORSMSaN2/Ovv3222rFSYkUIdWjqEfEWFtbs6dPnyooqsaDEqn698e6upTdnsa0VKUm/ZHgfx9WtZibm+PPP/9E9+7doaenhytXrqBt27Y4dOgQVq1ahfPnz1d3lw1eTk4O9PX1kZ2dDT09vWpte9jWtkzZ0Pv3FRUaIfVSTb4zpGqyvr8CgaAOo2rc5PhzWin6bBSnqs+mJv2RXNdI5ebmclMKGBoa4unTp2jbti0cHBwU/ogYQgipSnR0NKKjo5GZmYmSkhLeup9++klJURFCmgK55pGys7PjLgLv3LkzduzYgcePH2P79u28u+cIIaS2LVu2DAMHDkR0dDT+++8/vHjxgrcQQkhtkmtEavbs2UhPTwcALF26FJ6enggPD4dQKERYWJgi4yOEkEpt374dYWFhGD9+vLJDIYQ0QXIlUh999BH3s5OTEx4+fIjbt2+jZcuWMDExUVhwhBBSlYKCAvTs2VPZYRBCmii5Tu29izEGTU1NdO3alZIoQkidmzJlSpUTYBJCSG2Re0LOH3/8EevXr0dKSgoAoE2bNpgzZw6mTJmisOAIIaQqb968wc6dO3Hy5El06tSJm1RXat26dUqKjBDSFMiVSC1ZsgTr1q3DrFmzuKeRx8bGYu7cuUhLS6v08QmEEKJISUlJ3JMNkpOTeevo9nFCSG2TK5Hatm0bvv/+e4wdO5YrGzZsGDp16oRZs2ZRIkUIqTN19RB1Qggpj1zXSBUWFqJbt25lyp2cnFBUVFTjoAghhBBCGgK5RqTGjx+Pbdu2lbn2YOfOnRg3bpxCAiOEEFm4ublVegrv1KlTdRgNIaSpqdHF5idOnECPHj0AAHFxcUhLS8OECRMwb948rh5d6EkIqU3S66OkCgsLkZiYiOTkZPj5+SknKEJIkyFXIpWcnIyuXbsCAO7/75lwJiYmMDEx4V3sSRd6EkJq2/r168stDw4OxqtXr+o4GkJIUyNXIkUXdxJC6ruPPvoI3bt3x5o1a5QdCiGkEavxhJyEEFIfxcbGQkNDQ9lhEEIaOZlHpEaOHImwsDDo6elh5MiRldb9448/ahwYIYTIonR/xBhDeno6rly5gsWLFyspKkJIUyFzIqWvr89d86Svr19rARFCSHWU7o9UVFRgZ2eH5cuXY+DAgUqKihDSZDCiENnZ2QwAy87Orva2h1q1KrMQ0tjV5DujLFZWVgxAmeWTTz5hjDHm6upaZt20adN4+3j48CEbPHgw09TUZM2aNWOfffYZKyws5NU5ffo0c3R0ZEKhkNna2rLQ0NBqxyrr+1tee2iRb1E0ZbenMS1VqUl/JNfF5qmpqSgqKkKbNm145SkpKVBXV4e1tbU8uyWEELnFx8fj1q1bAIAOHTrA0dFR4ce4fPkyiouLudfJyckYMGAARo0axZV9/PHHvKc7aGlpcT8XFxfDy8sLYrEYFy5cQHp6OiZMmAB1dXV88803AN72r15eXpg+fTrCw8MRHR2NKVOmwNzcHB4eHgpvEyGkZuRKpCZOnIhJkyaVSaTi4uLwww8/ICYmRhGxEUJIlTIzM+Hr64uYmBgYGBgAALKysuDm5oY9e/agWbNmCjtW6X19++23sLW1haurK1empaUFsVhc7vYnTpzAzZs3cfLkSZiZmaFLly5YsWIFAgMDERwcDKFQiO3bt8PGxgZr164FALRr1w7nz5/H+vXrKZEipB6S6669q1evolevXmXKe/TogcTExJrGRAghMps1axZevnyJGzdu4Pnz53j+/DmSk5ORk5ODTz/9tNaOW1BQgF9//RWTJk3izZkXHh4OExMTdOzYEUFBQcjLy+PWxcbGwsHBAWZmZlyZh4cHcnJycOPGDa6Ou7s771geHh6IjY2ttbYQQuQn14iUQCDAy5cvy5RnZ2fzhr0JIaS2RUZG4uTJk2jXrh1X1r59e2zZsqVWLzY/ePAgsrKyMHHiRK7sww8/hJWVFSwsLJCUlITAwEDcuXOHu5NZIpHwkigA3GuJRFJpnZycHLx+/RqamprlxpOfn4/8/HzudU5OTo3bSAipmlyJVN++fRESEoLdu3dDVVUVwNtz/yEhIejdu7dCAySEkMqUlJRAXV29TLm6ujpKSkpq7bg//vgjBg0aBAsLC65s6tSp3M8ODg4wNzdH//79cf/+fdja2tZaLAAQEhKCZcuW1eoxCCFlyXVqb+XKlTh16hTs7Ozg7+8Pf39/2NnZ4ezZs1i9erWiYySEkAq9//77mD17Np48ecKVPX78GHPnzkX//v1r5ZgPHz7EyZMnMWXKlErrOTs7AwDu3bsHABCLxcjIyODVkb6WXldVUR09Pb0KR6MAICgoCNnZ2dzy6NGj6jWKECIXuRKp9u3bIykpCaNHj0ZmZiZevnyJCRMm4Pbt2+jYsaOiYySEkAp99913yMnJgbW1NWxtbWFrawsbGxvk5ORg8+bNtXLM0NBQmJqawsvLq9J60mtGzc3NAQAuLi64fv06MjMzuTpRUVHQ09ND+/btuTrR0dG8/URFRcHFxaXSY4lEIujp6fEWQkjtk+vUHgBYWFhwt+sSQoiyWFpaIiEhASdPnsTt27cBvL3TrfQF24pSUlKC0NBQ+Pn5QU3t/7vQ+/fvIyIiAoMHD4axsTGSkpIwd+5c9O3bF506dQIADBw4EO3bt8f48eOxatUqSCQSLFq0CAEBARCJRACA6dOn47vvvsPChQsxadIknDp1Cvv27cPRo0drpT2EkJqROZFKSkpCx44doaKigqSkpErrSjsNQgipLadOncLMmTNx8eJF6OnpYcCAARgwYACAtze+dOjQAdu3b0efPn0UetyTJ08iLS0NkyZN4pULhUKcPHkSGzZsQG5uLiwtLeHj44NFixZxdVRVVXHkyBHMmDEDLi4u0NbWhp+fH2/eKRsbGxw9ehRz587Fxo0b0aJFC/zwww809QEh9ZTgf7OnVklFRQUSiQSmpqZQUVGBQCBAeZsKBIImeedeTk4O9PX1kZ2dXe0h9cPlXIQ69P59RYVGSL1Uk+8MAAwbNgxubm6YO3duues3bdqE06dP48CBAzUNtUGS9f19d+oGUjMy/jmVGX02ilPVZ1OT/kjmEanU1FRuMrrU1NRqHYQQQhTt2rVrWLlyZYXrBw4ciDVr1tRhRISQpkjmRMrKyor7+eHDh+jZsyfv+gAAKCoqwoULF3h1CSGkNmRkZJQ77YGUmpoanj59WocREUKaIrnu2nNzc8Pz58/LlGdnZ8PNza3GQVXk22+/hUAgwJw5c7iyN2/eICAgAMbGxtDR0YGPj0+ZW4fT0tLg5eUFLS0tmJqaYsGCBSgqKuLViYmJQdeuXSESidC6dWuEhYXVWjsIITXXvHlzJCcnV7g+KSmJu1uOEEJqi1yJFGOs3HO3z549g7a2do2DKs/ly5exY8eOMheyz507F4cPH8b+/ftx5swZPHnyBCNHjuTWSx8SWlBQgAsXLuDnn39GWFgYlixZwtWRPiTUzc0NiYmJmDNnDqZMmYLjx4/XSlsIITU3ePBgLF68GG/evCmz7vXr11i6dCmGDBmihMgIIU2JzBebA+ASlD///BOenp7c7brA24QlKSkJdnZ2iIyMVGiQr169QteuXbF161Z89dVX6NKlCzZs2IDs7Gw0a9YMERER+OCDDwAAt2/fRrt27RAbG4sePXrg2LFjGDJkCJ48ecI9dmH79u0IDAzE06dPIRQKERgYiKNHj/L+u/X19UVWVpbMbaGLzQmpnppebJ6RkYGuXbtCVVUVM2fOhJ2dHYC3fcCWLVtQXFyMhISEMo9baSroYvO6Rxeb11+1ebF5tUak9PX1oa+vD8YYdHV1udf6+voQi8WYOnUqfv3112oFIIuAgAB4eXmVmRcmPj4ehYWFvHJ7e3u0bNmSe8AnPSSUkMbJzMwMFy5c4B4OPGLECIwYMQJffPEFOnbsiPPnzzfZJIoQUneqNSFnaGgol9Vt3rwZOjo6tRLUu/bs2YOEhARcvny5zDqJRAKhUAgDAwNeuZmZWZUPAJWuq6xOZQ8JpQeEEqJ8VlZW+Ouvv/DixQvcu3cPjDG0adMGhoaGyg6NENJEVPsaKcYYwsPDkZ6eXhvx8Dx69AizZ89GeHg4NDQ0av141RESEsIbkbO0tFR2SIQ0WYaGhnjvvffQvXt3SqIIIXWq2omUiooK2rRpg2fPntVGPDzx8fHIzMxE165doaamBjU1NZw5cwabNm2CmpoazMzMUFBQgKysLN52GRkZVT4AVLqusjqVPSSUHhBKCCGEELnu2vv222+xYMGCSm89VoT+/fvj+vXrSExM5JZu3bph3Lhx3M/q6uq8B3zeuXMHaWlp3AM+a+shofSAUEIIIYTI9dDiCRMmIC8vD507d4ZQKCwzalPeHFPy0NXVRceOHXll2traMDY25sonT56MefPmwcjICHp6epg1axZcXFzQo0cPAPSQUEIIIYTUHrkSqQ0bNig4DPmtX78eKioq8PHxQX5+Pjw8PLB161ZuPT0klBBCCCG1pVrzSJGK0TxShFRPTeeRIpWjeaTqHs0jVX/Vi4cWV+TNmzcoKCjglVGnSAghhJCmQK6LzXNzczFz5kyYmppCW1sbhoaGvIUQQgghpCmQK5FauHAhTp06hW3btkEkEuGHH37AsmXLYGFhgV27dik6RkIIIYSQekmuU3uHDx/Grl270K9fP/j7+6NPnz5o3bo1rKysEB4ejnHjxik6TkIIIYSQekeuROr58+do1aoVgLfXQ0mnO+jduzdmzJihuOgaofIuLCeEEEJIwyTXqb1WrVohNTUVwNuHBO/btw/A25Gq0s+9I4QQQghprORKpPz9/XHt2jUAwOeff44tW7ZAQ0MDc+fOxYIFCxQaICGEEEJIfVWtU3slJSVYvXo1Dh06hIKCAjx58gRLly7F7du3ER8fj9atW6NTp061FSshhBBCSL1SrRGpr7/+Gl988QV0dHTQvHlzbNy4EQEBAbCyssLIkSMpiSKENGrBwcEQCAS8xd7enlv/5s0bBAQEwNjYGDo6OvDx8SnzQPS0tDR4eXlBS0sLpqamWLBgAYqKinh1YmJi0LVrV4hEIrRu3RphYWF10TxCiByqlUjt2rULW7duxfHjx3Hw4EEcPnwY4eHhKCkpqa34CCGkXunQoQPS09O55fz589y6uXPn4vDhw9i/fz/OnDmDJ0+eYOTIkdz64uJieHl5oaCgABcuXMDPP/+MsLAwLFmyhKuTmpoKLy8vuLm5ITExEXPmzMGUKVNw/PjxOm0nIUQ21Tq1l5aWhsGDB3Ov3d3dIRAI8OTJE7Ro0ULhwRFCSH2jpqYGsVhcpjw7Oxs//vgjIiIi8P777wMAQkND0a5dO1y8eBE9evTAiRMncPPmTZw8eRJmZmbo0qULVqxYgcDAQAQHB0MoFGL79u2wsbHB2rVrAQDt2rXD+fPnsX79enr+JyH1ULVGpIqKiqChocErU1dXR2FhoUKDIoSQ+iolJQUWFhZo1aoVxo0bh7S0NABAfHw8CgsL4e7uztW1t7dHy5YtERsbCwCIjY2Fg4MDzMzMuDoeHh7IycnBjRs3uDrv7kNaR7qPiuTn5yMnJ4e3EEJqX7VGpBhjmDhxIkQiEVf25s0bTJ8+Hdra2lzZH3/8obgICSGknnB2dkZYWBjs7OyQnp6OZcuWoU+fPkhOToZEIoFQKCwzBYyZmRkkEgkAQCKR8JIo6Xrpusrq5OTk4PXr19DU1Cw3tpCQECxbtkwRzSSEVEO1Eik/P78yZR999JHCgiGEkPps0KBB3M+dOnWCs7MzrKyssG/fvgoTnLoSFBSEefPmca9zcnJgaWmpxIgIaRqqlUiFhobWVhyEENLgGBgYoG3btrh37x4GDBiAgoICZGVl8UalMjIyuGuqxGIxLl26xNuH9K6+d+uUvtMvIyMDenp6lSZrIpGId7aAEFI35JqQkxBCCPDq1Svcv38f5ubmcHJygrq6OqKjo7n1d+7cQVpaGlxcXAAALi4uuH79OjIzM7k6UVFR0NPTQ/v27bk67+5DWke6D0JI/UKJFCGEyOizzz7DmTNn8ODBA1y4cAEjRoyAqqoqxo4dC319fUyePBnz5s3D6dOnER8fD39/f7i4uKBHjx4AgIEDB6J9+/YYP348rl27huPHj2PRokUICAjgRpOmT5+Of/75BwsXLsTt27exdetW7Nu3D3PnzlVm0wkhFZDrocWEENIU/fvvvxg7diyePXuGZs2aoXfv3rh48SKaNWsGAFi/fj1UVFTg4+OD/Px8eHh4YOvWrdz2qqqqOHLkCGbMmAEXFxdoa2vDz88Py5cv5+rY2Njg6NGjmDt3LjZu3IgWLVrghx9+oKkPCKmnBIwxpuwgGoOcnBzo6+sjOzsbenp6FdY7bGsr0/6G3r+vqNAIqZdk/c4Q+cj6/goEgjqMqnFT9J9T+mwUp6rPpib9EZ3aI4QQQgiREyVShBBCCCFyokSKEEIIIUROlEgRQgghhMiJEilCCCGEEDlRIkUIIYQQIidKpAghhBBC5ESJFCGEEEKInCiRIoQQQgiREyVShBBCCCFyokSKEEIIIURO9TqRCgkJwXvvvQddXV2YmprC29sbd+7c4dV58+YNAgICYGxsDB0dHfj4+CAjI4NXJy0tDV5eXtDS0oKpqSkWLFiAoqIiXp2YmBh07doVIpEIrVu3RlhYWG03jxBCCCENXL1OpM6cOYOAgABcvHgRUVFRKCwsxMCBA5Gbm8vVmTt3Lg4fPoz9+/fjzJkzePLkCUaOHMmtLy4uhpeXFwoKCnDhwgX8/PPPCAsLw5IlS7g6qamp8PLygpubGxITEzFnzhxMmTIFx48fr9P2EkIIIaRhETBFP666Fj19+hSmpqY4c+YM+vbti+zsbDRr1gwRERH44IMPAAC3b99Gu3btEBsbix49euDYsWMYMmQInjx5AjMzMwDA9u3bERgYiKdPn0IoFCIwMBBHjx5FcnIydyxfX19kZWUhMjJSpthkfXL0YVtbmfY39P59meoR0lDV5GnrpGqyvr8CgaAOo2rcFP3nlD4bxanqs6lJf1SvR6RKy87OBgAYGRkBAOLj41FYWAh3d3eujr29PVq2bInY2FgAQGxsLBwcHLgkCgA8PDyQk5ODGzducHXe3Ye0jnQf5cnPz0dOTg5vIYQQQkjToqbsAGRVUlKCOXPmoFevXujYsSMAQCKRQCgUwsDAgFfXzMwMEomEq/NuEiVdL11XWZ2cnBy8fv0ampqaZeIJCQnBsmXLFNK28pQ3ckWjVIQQQkj90mBGpAICApCcnIw9e/YoOxQAQFBQELKzs7nl0aNHyg6JEEIIIXWsQYxIzZw5E0eOHMHZs2fRokULrlwsFqOgoABZWVm8UamMjAyIxWKuzqVLl3j7k97V926d0nf6ZWRkQE9Pr9zRKAAQiUQQiUQ1bhshhBBCGq56PSLFGMPMmTNx4MABnDp1CjY2Nrz1Tk5OUFdXR3R0NFd2584dpKWlwcXFBQDg4uKC69evIzMzk6sTFRUFPT09tG/fnqvz7j6kdaT7aMgEAkG5CyGEEEJqrl6PSAUEBCAiIgJ//vkndHV1uWua9PX1oampCX19fUyePBnz5s2DkZER9PT0MGvWLLi4uKBHjx4AgIEDB6J9+/YYP348Vq1aBYlEgkWLFiEgIIAbUZo+fTq+++47LFy4EJMmTcKpU6ewb98+HD16VGltJ4QQQkj9V69HpLZt24bs7Gz069cP5ubm3LJ3716uzvr16zFkyBD4+Pigb9++EIvF+OOPP7j1qqqqOHLkCFRVVeHi4oKPPvoIEyZMwPLly7k6NjY2OHr0KKKiotC5c2esXbsWP/zwAzw8POq0vYSQ+k2WSYL79etXZgR4+vTpvDo0STAhjUe9HpGSZU4ODQ0NbNmyBVu2bKmwjpWVFf76669K99OvXz9cvXq12jESQpoO6STB7733HoqKivDFF19g4MCBuHnzJrS1tbl6H3/8Me+fNS0tLe5n6STBYrEYFy5cQHp6OiZMmAB1dXV88803AP5/kuDp06cjPDwc0dHRmDJlCszNzekfPELqmXqdSBFCSH1SeoLesLAwmJqaIj4+Hn379uXKtbS0uJtZSjtx4gRu3ryJkydPwszMDF26dMGKFSsQGBiI4OBgCIVCbN++HTY2Nli7di0AoF27djh//jzWr19PiRQh9Uy9PrVHCCH1WelJgqXCw8NhYmKCjh07IigoCHl5edw6miSYkMaFRqQIIUQO5U0SDAAffvghrKysYGFhgaSkJAQGBuLOnTvctZsNdZJgQkj5KJEihBA5SCcJPn/+PK986tSp3M8ODg4wNzdH//79cf/+fdjK+KxNeQQFBWHevHnc65ycHFhaWtba8Qghb9GpvUaC5osipO5IJwk+ffo0b5Lg8jg7OwMA7t27B6DiCYCl6yqrU9UkwXp6eryFEFL7KJEihBAZVTVJcHkSExMBAObm5gBokmBCGhtKpAgPjWwRUrGAgAD8+uuviIiI4CYJlkgkeP36NQDg/v37WLFiBeLj4/HgwQMcOnQIEyZMQN++fdGpUycA/EmCr127huPHj5c7SfA///yDhQsX4vbt29i6dSv27duHuXPnKq3thJDyUSJFCCEyqmqSYKFQiJMnT2LgwIGwt7fH/Pnz4ePjg8OHD3P7oEmCCWlc6GLzJopGmQipvqomCba0tMSZM2eq3A9NEkxI40EjUoQQQgghcqIRKSKTikawZHmMDyGEENJY0YgUIYQQQoicKJEihBBCCJETJVKEEEIIIXKiRIoQQgghRE50sTmpkcqmUaAL0QkhhDR2NCJFCCGEECInSqQIIYQQQuREp/YaGJqRnBBCCKk/KJEitYYm8SSEENLY0ak9QgghhBA5USJFCCGEECInOrVH6hyd8iOEENJYUCJF6g1KsAghhDQ0dGqPEEIIIURONCJF6j0aqSKEEFJfUSJFGixKsAghhCgbndprQGgyTkIIIaR+oRGpBuRQq1a818P++UdJkdRvNFJFCCGkrtCIVClbtmyBtbU1NDQ04OzsjEuXLik7JEJIE0X9ESH1HyVS79i7dy/mzZuHpUuXIiEhAZ07d4aHhwcyMzOVHRpRAIFAUK2FEGWi/oiQhoESqXesW7cOH3/8Mfz9/dG+fXts374dWlpa+Omnn5QdGlECSrCIMlF/REjDQNdI/U9BQQHi4+MRFBTElamoqMDd3R2xsbFKjKxipa+ZAui6qbqgyGSKrtsi5WmI/REhTRUlUv/z33//obi4GGZmZrxyMzMz3L59u0z9/Px85Ofnc6+zs7MBADk5OZUeJ6+kRAHRVmyPtbVM9XwfPKjVOIhsGvoIl/T3Xh7S7wolk2VVtz8C5O+TiOLQe11/VfXZ1KQ/okRKTiEhIVi2bFmZcktLSyVEQ4hy6Ovr13gfL1++VMh+mjrqk5SPfo/rL1k/G3n6I0qk/sfExASqqqrIyMjglWdkZEAsFpepHxQUhHnz5nGvS0pK8Pz5cxgbG1c4ypCTkwNLS0s8evQIenp6im1APdOU2go0rfYqqq2MMbx8+RIWFhYKjK5xqG5/BMjXJzUEje271Zja05jaUpP+iBKp/xEKhXByckJ0dDS8vb0BvO2IoqOjMXPmzDL1RSIRRCIRr8zAwECmY+np6TX4XzpZNaW2Ak2rvYpoK/0HX77q9kdAzfqkhqCxfbcaU3saS1vk7Y8okXrHvHnz4Ofnh27duqF79+7YsGEDcnNz4e/vr+zQCCFNDPVHhDQMlEi9Y8yYMXj69CmWLFkCiUSCLl26IDIysswFn4QQUtuoPyKkYaBEqpSZM2dWOHReUyKRCEuXLi0z/N4YNaW2Ak2rvU2prcpWm/1RQ9HYft8aU3saU1tqQsDo3mNCCCGEELnQzOaEEEIIIXKiRIoQQgghRE6USBFCCCGEyIkSqTq0ZcsWWFtbQ0NDA87Ozrh06ZKyQ6qx4ODgMg/1tbe359a/efMGAQEBMDY2ho6ODnx8fMpMMlhfnT17FkOHDoWFhQUEAgEOHjzIW88Yw5IlS2Bubg5NTU24u7sjJSWFV+f58+cYN24c9PT0YGBggMmTJ+PVq1d12ArZVNXWiRMnlvmcPT09eXUaSltJ/VPdvnH//v2wt7eHhoYGHBwc8Ndff9VRpLKpTnvCwsLKfLc0NDTqMNqKVdUvlCcmJgZdu3aFSCRC69atERYWVutxKhslUnVk7969mDdvHpYuXYqEhAR07twZHh4eyMzMVHZoNdahQwekp6dzy/nz57l1c+fOxeHDh7F//36cOXMGT548wciRI5UYrexyc3PRuXNnbNmypdz1q1atwqZNm7B9+3bExcVBW1sbHh4eePPmDVdn3LhxuHHjBqKionDkyBGcPXsWU6dOrasmyKyqtgKAp6cn73PevXs3b31DaSupX6rbN164cAFjx47F5MmTcfXqVXh7e8Pb2xvJycl1HHn55Onr9fT0eN+thw8f1mHEFZOlX3hXamoqvLy84ObmhsTERMyZMwdTpkzB8ePHazlSJWOkTnTv3p0FBARwr4uLi5mFhQULCQlRYlQ1t3TpUta5c+dy12VlZTF1dXW2f/9+ruzWrVsMAIuNja2jCBUDADtw4AD3uqSkhInFYrZ69WquLCsri4lEIrZ7927GGGM3b95kANjly5e5OseOHWMCgYA9fvy4zmKvrtJtZYwxPz8/Nnz48Aq3aahtJcpX3b5x9OjRzMvLi1fm7OzMpk2bVqtxyqq67QkNDWX6+vp1FJ38yusXSlu4cCHr0KEDr2zMmDHMw8OjFiNTPhqRqgMFBQWIj4+Hu7s7V6aiogJ3d3fExsYqMTLFSElJgYWFBVq1aoVx48YhLS0NABAfH4/CwkJeu+3t7dGyZcsG3+7U1FRIJBJe2/T19eHs7My1LTY2FgYGBujWrRtXx93dHSoqKoiLi6vzmGsqJiYGpqamsLOzw4wZM/Ds2TNuXWNrK6kb8vSNsbGxvPoA4OHhUS/6FHn7+levXsHKygqWlpYYPnw4bty4URfhKlx9/mxqEyVSdeC///5DcXFxmRmJzczMIJFIlBSVYjg7OyMsLAyRkZHYtm0bUlNT0adPH7x8+RISiQRCobDM874aQ7ul8Vf2mUokEpiamvLWq6mpwcjIqMG139PTE7t27UJ0dDRWrlyJM2fOYNCgQSguLgbQuNpK6o48faNEIqm3fak87bGzs8NPP/2EP//8E7/++itKSkrQs2dP/Pvvv3URskJV9Nnk5OTg9evXSoqq9tHM5qRGBg0axP3cqVMnODs7w8rKCvv27YOmpqYSIyOK5Ovry/3s4OCATp06wdbWFjExMejfv78SIyOkYXNxcYGLiwv3umfPnmjXrh127NiBFStWKDEyIisakaoDJiYmUFVVLXO3WkZGBsRisZKiqh0GBgZo27Yt7t27B7FYjIKCAmRlZfHqNIZ2S+Ov7DMVi8VlLjAtKirC8+fPG3z7W7VqBRMTE9y7dw9A424rqT3y9I1isbje9qWK6OvV1dXh6OjIfbcakoo+Gz09vUb9jzUlUnVAKBTCyckJ0dHRXFlJSQmio6N5/4k0Bq9evcL9+/dhbm4OJycnqKur89p9584dpKWlNfh229jYQCwW89qWk5ODuLg4rm0uLi7IyspCfHw8V+fUqVMoKSmBs7NzncesSP/++y+ePXsGc3NzAI27raT2yNM3uri48OoDQFRUVL3oUxTR1xcXF+P69evcd6shqc+fTa1S9tXuTcWePXuYSCRiYWFh7ObNm2zq1KnMwMCASSQSZYdWI/Pnz2cxMTEsNTWV/f3338zd3Z2ZmJiwzMxMxhhj06dPZy1btmSnTp1iV65cYS4uLszFxUXJUcvm5cuX7OrVq+zq1asMAFu3bh27evUqe/jwIWOMsW+//ZYZGBiwP//8kyUlJbHhw4czGxsb9vr1a24fnp6ezNHRkcXFxbHz58+zNm3asLFjxyqrSRWqrK0vX75kn332GYuNjWWpqans5MmTrGvXrqxNmzbszZs33D4aSltJ/VJV3zh+/Hj2+eefc/X//vtvpqamxtasWcNu3brFli5dytTV1dn169eV1QSe6rZn2bJl7Pjx4+z+/fssPj6e+fr6Mg0NDXbjxg1lNYFTVR/4+eefs/Hjx3P1//nnH6alpcUWLFjAbt26xbZs2cJUVVVZZGSksppQJyiRqkObN29mLVu2ZEKhkHXv3p1dvHhR2SHV2JgxY5i5uTkTCoWsefPmbMyYMezevXvc+tevX7NPPvmEGRoaMi0tLTZixAiWnp6uxIhld/r0aQagzOLn58cYezsFwuLFi5mZmRkTiUSsf//+7M6dO7x9PHv2jI0dO5bp6OgwPT095u/vz16+fKmE1lSusrbm5eWxgQMHsmbNmjF1dXVmZWXFPv744zL/BDSUtpL6p7K+0dXVlfvOSe3bt4+1bduWCYVC1qFDB3b06NE6jrhy1WnPnDlzuLpmZmZs8ODBLCEhQQlRl1VVH+jn58dcXV3LbNOlSxcmFApZq1atWGhoaJ3HXdcEjDFW16NghBBCCCGNAV0jRQghhBAiJ0qkCCGEEELkRIkUIYQQQoicKJEihBBCCJETJVKEEEIIIXKiRIoQQgghRE6USBFCCCGEyIkSKUIIIYQQOVEiRQghhBAiJ0qkSJ2bOHEivL29lXb88ePH45tvvlHa8atS0/fH19cXa9euVVxAhDQCEydOhEAgKLN4enpydaytrcusb9GiBbf+wIED6NGjB/T19aGrq4sOHTpgzpw5csckEAhw8ODBam9nbW2NDRs2yH1coliUSDURyuhEHjx4AIFAgMTERF75xo0bERYWpuAWyubatWv466+/8Omnnyrl+O+q6P2pqUWLFuHrr79Gdna2QvdLSEPn6emJ9PR03rJ7925eneXLl/PWX716FQAQHR2NMWPGwMfHB5cuXUJ8fDy+/vprFBYWKqMppB6hRKoJqS+diL6+PgwMDBTRpGrbvHkzRo0aBR0dHaUcvy507NgRtra2+PXXX5UdCiH1ikgkglgs5i2Ghoa8Orq6urz1zZo1AwAcPnwYvXr1woIFC2BnZ4e2bdvC29sbW7ZsqfB4BQUFmDlzJszNzaGhoQErKyuEhIQAePuPKwCMGDECAoGAe33//n0MHz4cZmZm0NHRwXvvvYeTJ09y++zXrx8ePnyIuXPncv/wAkBwcDC6dOnCO/6GDRu4/QJATEwMunfvDm1tbRgYGKBXr154+PChPG8leQclUk1IXXciNjY2AABHR0cIBAL069cPQNlTV/369cOsWbMwZ84cGBoawszMDN9//z1yc3Ph7+8PXV1dtG7dGseOHePtPzk5GYMGDYKOjg7MzMwwfvx4/PfffxXGU1xcjN9++w1Dhw7llVtbW+Orr77ChAkToKOjAysrKxw6dAhPnz7F8OHDoaOjg06dOuHKlSu87X7//Xd06NABIpEI1tbWZU6nWVtb45tvvsGkSZOgq6uLli1bYufOnVW+P1Jr1qyBubk5jI2NERAQwEtat27dijZt2kBDQwNmZmb44IMPeNsOHToUe/bsqfC9IIRUj1gsxo0bN5CcnCzzNps2bcKhQ4ewb98+3LlzB+Hh4Vxic/nyZQBAaGgo0tPTudevXr3C4MGDER0djatXr8LT0xNDhw5FWloaAOCPP/5AixYteP/0yqKoqAje3t5wdXVFUlISYmNjMXXqVC4RIzXASJPg5+fHhg8fXmkdKysrtn79+nLXhYSEsGbNmrHr16/LfMxLly4xAOzkyZMsPT2dPXv2rNxYXF1dma6uLluxYgW7e/cuW7FiBVNVVWWDBg1iO3fuZHfv3mUzZsxgxsbGLDc3lzHG2IsXL1izZs1YUFAQu3XrFktISGADBgxgbm5uFcaTkJDAADCJRFKm3UZGRmz79u3csfT09Jinpyfbt28fu3PnDvP29mbt2rVjJSUljDHGrly5wlRUVNjy5cvZnTt3WGhoKNPU1GShoaFl9rtlyxaWkpLCQkJCmIqKCrt9+3aV74+enh6bPn06u3XrFjt8+DDT0tJiO3fuZIwxdvnyZaaqqsoiIiLYgwcPWEJCAtu4cSOvTceOHWNCoZC9efNG5s+LkMbMz8+PqaqqMm1tbd7y9ddfc3WsrKyYUCjkrZd+t169esUGDx7MADArKys2ZswY9uOPP1b6HZs1axZ7//33uX6jNADswIEDVcbeoUMHtnnzZl6cpfvqpUuXss6dO/PK1q9fz6ysrBhjjD179owBYDExMVUej1QPJVJNhDI6kdTUVAaAXb16tUwspROp3r17c6+LioqYtrY2Gz9+PFeWnp7OALDY2FjGGGMrVqxgAwcO5O330aNHDAC7c+dOufEcOHCAqaqqlunUrKys2EcffVTmWIsXL+bKYmNjGQCWnp7OGGPsww8/ZAMGDODtZ8GCBax9+/YV7rekpISZmpqybdu2Vfn+WFlZsaKiIq5s1KhRbMyYMYwxxn7//Xemp6fHcnJyym0nY4xdu3aNAWAPHjyosA4hTYmfnx9zd3dnKSkpvEX6Dwxjb7+zX375JW/9ixcvePu5d+8e+/7779nkyZOZgYEB69SpE/cPXmnx8fHMyMiItWnThs2aNYsdP36ct768ROrly5ds/vz5zN7enunr6zNtbW2moqLCFixYwIuzuokUY4xNnDiRiUQiNmTIELZhwwb25MmTyt80IhM6tdeEuLm5ITExkbdMnz6dV2fBggW89RMmTAAAaGtr4+jRo7h37x4WLVoEHR0dzJ8/H927d0deXl6NY+vUqRP3s6qqKoyNjeHg4MCVmZmZAQAyMzMBvL1o/PTp09DR0eEWe3t7AG+vMSjP69evIRKJyh3Kfvf40mNVdvxbt26hV69evH306tULKSkpKC4uLne/AoEAYrGY20dlOnToAFVVVe61ubk5t92AAQNgZWWFVq1aYfz48QgPDy/zGWhqagKAQj4bQhoLbW1ttG7dmrcYGRnx6piYmPDWl76e09bWFlOmTMEPP/yAhIQE3Lx5E3v37i33eF27dkVqaipWrFiB169fY/To0WVOw5f22Wef4cCBA/jmm29w7tw5JCYmwsHBAQUFBZVup6KiAsYYr6z0NayhoaGIjY1Fz549sXfvXrRt2xYXL16sdL+kamrKDoDUHWknUhlpJ1IRW1tbriP58ssv0bZtW+zduxf+/v41ik1dXZ33WiAQ8MqkyU9JSQmAt9cRDB06FCtXriyzL3Nz83KPYWJigry8PBQUFEAoFFZ4fOmxKju+rMprlyz7qGw7XV1dJCQkICYmBidOnMCSJUsQHByMy5cvc53+8+fPAYC7xo0QonjW1tbQ0tJCbm5uhXX09PQwZswYjBkzBh988AE8PT3x/PlzGBkZQV1dnfePFwD8/fffmDhxIkaMGAHgbV/34MEDXh2hUFhmu2bNmkEikYAxxvVX5d0R7OjoCEdHRwQFBcHFxQURERHo0aOHHK0nUpRIEblV1YlIk5XSX3hF6Nq1K37//XdYW1tDTU22X2PpHS03b94sc3dLdbVr1w5///03r+zvv/9G27ZteSNJlanJ+6OmpgZ3d3e4u7tj6dKlMDAwwKlTpzBy5EgAby/Eb9GiBUxMTKq9b0Iaq/z8fEgkEl6ZmpqaTN+T4OBg5OXlYfDgwbCyskJWVhY2bdqEwsJCDBgwoNxt1q1bB3Nzczg6OkJFRQX79++HWCzm/uGxtrZGdHQ0evXqBZFIBENDQ7Rp0wZ//PEHhg4dCoFAgMWLF5f558va2hpnz56Fr68vRCIRTExM0K9fPzx9+hSrVq3CBx98gMjISBw7dgx6enoAgNTUVOzcuRPDhg2DhYUF7ty5g5SUFO6sA5EfndprQqSdyLtLZXe5vSs4OBgLFy5ETEwMUlNTcfXqVUyaNKnSTsTU1BSampqIjIxERkaGQuc1CggIwPPnzzF27FhcvnwZ9+/fx/Hjx+Hv719hYtKsWTN07doV58+fr/Hx58+fj+joaKxYsQJ3797Fzz//jO+++w6fffaZzPuQ9/05cuQINm3ahMTERDx8+BC7du1CSUkJ7OzsuDrnzp3DwIEDq90uQhqzyMhImJub85bevXvLtK2rqyv++ecfTJgwAfb29hg0aBAkEglOnDjB++69S1dXF6tWrUK3bt3w3nvv4cGDB/jrr7+govL2T+/atWsRFRUFS0tLODo6AnibfBkaGqJnz54YOnQoPDw80LVrV95+ly9fjgcPHsDW1pYbdW7Xrh22bt2KLVu2oHPnzrh06RKvP9LS0sLt27fh4+ODtm3bYurUqQgICMC0adOq/T6SUpR9kRapG35+fgxAmcXOzo6rU9lde6dOnWI+Pj7M0tKSCYVCZmZmxjw9Pdm5c+cqPe7333/PLC0tmYqKCnN1deViKX2x+ezZs3nblRcLSl2YeffuXTZixAhmYGDANDU1mb29PZszZ06Fd8gwxtjWrVtZjx49qn2s8i4M/+2331j79u2Zuro6a9myJVu9enWV++3cuTNbunQp91qW94cxxmbPns2tP3fuHHN1dWWGhoZMU1OTderUie3du5er+/r1a6avr89dmE8IIaT2CBgrdXUaIY3Y69evYWdnh71798LFxUXZ4dSKbdu24cCBAzhx4oSyQyGEkEaPTu2RJkVTUxO7du2S+ZRmQ6Suro7NmzcrOwxCCGkSaESKEEIIIURONCJFCCGEECInSqQIIYQQQuREiRQhhBBCiJwokSKEEEIIkRMlUoQQQgghcqJEihBCCCFETpRIEUIIIYTIiRIpQgghhBA5USJFCCGEECKn/wPaOQSa4395/QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_df=pd.read_parquet(data_df_file)\n",
    "\n",
    "# Load feature definitions\n",
    "with open(feature_types_dict_file, 'rb') as input_file:\n",
    "    feature_types_dict=pickle.load(input_file)\n",
    "\n",
    "# Take a quick look\n",
    "efs_neg_df=data_df[data_df['efs'] == 0]\n",
    "efs_pos_df=data_df[data_df['efs'] == 1]\n",
    "\n",
    "# Set-up a 1x2 figure\n",
    "fig, axs=plt.subplots(1,2, figsize=(6,3))\n",
    "axs=axs.flatten()\n",
    "\n",
    "axs[0].set_title('Event free survival time')\n",
    "axs[0].hist(efs_neg_df['efs_time'], bins=30, color='black', label='EFS 0')\n",
    "axs[0].hist(efs_pos_df['efs_time'], bins=30, color='firebrick', label='EFS 1')\n",
    "axs[0].set_xlabel('EFS time (months)')\n",
    "axs[0].set_ylabel('Participants')\n",
    "axs[0].legend(loc='upper right')\n",
    "\n",
    "axs[1].set_title('Event free survival binary')\n",
    "axs[1].bar(data_df['efs'].value_counts().index, data_df['efs'].value_counts(), color='black')\n",
    "axs[1].set_xlabel('EFS status')\n",
    "axs[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation\n",
    "\n",
    "### 2.1. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing=train_test_split(data_df, test_size=0.33, random_state=315)\n",
    "\n",
    "training_df=pd.DataFrame(training, columns=data_df.columns)\n",
    "testing_df=pd.DataFrame(testing, columns=data_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Save and remove un-encoded race group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_race_group=training_df['race_group']\n",
    "testing_race_group=testing_df['race_group']\n",
    "\n",
    "training_df.drop('race_group', axis=1, inplace=True)\n",
    "testing_df.drop('race_group', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Remove year htc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.drop('year_hct', axis=1, inplace=True)\n",
    "testing_df.drop('year_hct', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Box-Cox transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=feature_types_dict['Ordinal'] + feature_types_dict['Interval'] + ['efs_time']\n",
    "features.remove('year_hct')\n",
    "# training_df['year_hct']=training_df['year_hct']/100\n",
    "# testing_df['year_hct']=testing_df['year_hct']/100\n",
    "training_df[features]=power_transform(training_df[features]+1, method='box-cox')\n",
    "testing_df[features]=power_transform(testing_df[features]+1, method='box-cox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Make features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_labels_df=training_df[['efs', 'efs_time']].copy()\n",
    "training_features_df=training_df.drop(['efs', 'efs_time'], axis=1)\n",
    "#training_labels_df['log_efs_time']=np.log(training_labels_df['efs_time'])\n",
    "\n",
    "testing_labels_df=testing_df[['efs', 'efs_time']].copy()\n",
    "testing_features_df=testing_df.drop(['efs', 'efs_time'], axis=1)\n",
    "#testing_labels_df['log_efs_time']=np.log(testing_labels_df['efs_time'])\n",
    "\n",
    "# Take a quick look\n",
    "efs_neg_df=training_labels_df[training_labels_df['efs'] == 0]\n",
    "efs_pos_df=training_labels_df[training_labels_df['efs'] == 1]\n",
    "\n",
    "# Set-up a 1x2 figure\n",
    "fig, axs=plt.subplots(1,2, figsize=(6,3))\n",
    "axs=axs.flatten()\n",
    "\n",
    "axs[0].set_title('Event free survival time')\n",
    "axs[0].hist(efs_neg_df['efs_time'], bins=30, color='black', label='EFS 0')\n",
    "axs[0].hist(efs_pos_df['efs_time'], bins=30, color='firebrick', label='EFS 1')\n",
    "axs[0].set_xlabel('EFS time (months)')\n",
    "axs[0].set_ylabel('Participants')\n",
    "axs[0].legend(loc='upper right')\n",
    "\n",
    "axs[1].set_title('Event free survival binary')\n",
    "axs[1].bar(data_df['efs'].value_counts().index, data_df['efs'].value_counts(), color='black')\n",
    "axs[1].set_xlabel('EFS status')\n",
    "axs[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>1044</th>\n",
       "      <th>9306</th>\n",
       "      <th>24307</th>\n",
       "      <th>1058</th>\n",
       "      <th>24177</th>\n",
       "      <th>6076</th>\n",
       "      <th>16162</th>\n",
       "      <th>22516</th>\n",
       "      <th>28343</th>\n",
       "      <th>23311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <td>-1.551232</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>-1.801021</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>-1.801021</td>\n",
       "      <td>0.605538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <td>0.837211</td>\n",
       "      <td>-0.986511</td>\n",
       "      <td>0.837211</td>\n",
       "      <td>0.574689</td>\n",
       "      <td>-0.278621</td>\n",
       "      <td>-1.637188</td>\n",
       "      <td>-0.278621</td>\n",
       "      <td>0.111076</td>\n",
       "      <td>-1.637188</td>\n",
       "      <td>0.837211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <td>-0.090376</td>\n",
       "      <td>-1.612295</td>\n",
       "      <td>0.806635</td>\n",
       "      <td>0.806635</td>\n",
       "      <td>-1.264762</td>\n",
       "      <td>-1.612295</td>\n",
       "      <td>0.806635</td>\n",
       "      <td>-0.090376</td>\n",
       "      <td>-1.612295</td>\n",
       "      <td>0.806635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_high_res_6</th>\n",
       "      <td>0.841482</td>\n",
       "      <td>-1.212899</td>\n",
       "      <td>0.841482</td>\n",
       "      <td>0.522966</td>\n",
       "      <td>-0.468435</td>\n",
       "      <td>-1.591159</td>\n",
       "      <td>-0.468435</td>\n",
       "      <td>-0.025203</td>\n",
       "      <td>-1.591159</td>\n",
       "      <td>0.841482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_high_res_10</th>\n",
       "      <td>0.859768</td>\n",
       "      <td>-1.221335</td>\n",
       "      <td>0.859768</td>\n",
       "      <td>0.637790</td>\n",
       "      <td>-0.109663</td>\n",
       "      <td>-1.663935</td>\n",
       "      <td>-0.109663</td>\n",
       "      <td>0.237399</td>\n",
       "      <td>-1.663935</td>\n",
       "      <td>0.859768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_dqb1_high</th>\n",
       "      <td>-0.377409</td>\n",
       "      <td>-1.686427</td>\n",
       "      <td>0.655567</td>\n",
       "      <td>0.655567</td>\n",
       "      <td>0.655567</td>\n",
       "      <td>-1.686427</td>\n",
       "      <td>0.655567</td>\n",
       "      <td>0.655567</td>\n",
       "      <td>-1.686427</td>\n",
       "      <td>0.655567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_nmdp_6</th>\n",
       "      <td>-0.114339</td>\n",
       "      <td>-1.635777</td>\n",
       "      <td>0.813259</td>\n",
       "      <td>0.813259</td>\n",
       "      <td>-0.571336</td>\n",
       "      <td>-0.571336</td>\n",
       "      <td>-0.571336</td>\n",
       "      <td>0.159687</td>\n",
       "      <td>-1.635777</td>\n",
       "      <td>0.813259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_c_low</th>\n",
       "      <td>-0.519834</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_drb1_low</th>\n",
       "      <td>-0.251677</td>\n",
       "      <td>-1.584976</td>\n",
       "      <td>0.673036</td>\n",
       "      <td>0.673036</td>\n",
       "      <td>0.673036</td>\n",
       "      <td>-1.584976</td>\n",
       "      <td>0.673036</td>\n",
       "      <td>-0.251677</td>\n",
       "      <td>-1.584976</td>\n",
       "      <td>0.673036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_dqb1_low</th>\n",
       "      <td>-0.653310</td>\n",
       "      <td>-1.859082</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>-1.859082</td>\n",
       "      <td>-1.306351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_a_high</th>\n",
       "      <td>0.702089</td>\n",
       "      <td>0.702089</td>\n",
       "      <td>0.702089</td>\n",
       "      <td>0.702089</td>\n",
       "      <td>-1.560534</td>\n",
       "      <td>-1.560534</td>\n",
       "      <td>-1.560534</td>\n",
       "      <td>-0.783070</td>\n",
       "      <td>-1.560534</td>\n",
       "      <td>0.702089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_b_low</th>\n",
       "      <td>-0.291202</td>\n",
       "      <td>-1.616513</td>\n",
       "      <td>0.659026</td>\n",
       "      <td>0.659026</td>\n",
       "      <td>-1.616513</td>\n",
       "      <td>-1.616513</td>\n",
       "      <td>0.659026</td>\n",
       "      <td>0.659026</td>\n",
       "      <td>-1.616513</td>\n",
       "      <td>0.659026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_a_low</th>\n",
       "      <td>-0.228602</td>\n",
       "      <td>-1.574425</td>\n",
       "      <td>0.675510</td>\n",
       "      <td>0.675510</td>\n",
       "      <td>-1.574425</td>\n",
       "      <td>-1.574425</td>\n",
       "      <td>0.675510</td>\n",
       "      <td>-0.824037</td>\n",
       "      <td>-1.574425</td>\n",
       "      <td>0.675510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_b_high</th>\n",
       "      <td>0.703355</td>\n",
       "      <td>-1.547044</td>\n",
       "      <td>0.703355</td>\n",
       "      <td>-0.166080</td>\n",
       "      <td>0.703355</td>\n",
       "      <td>-1.547044</td>\n",
       "      <td>0.703355</td>\n",
       "      <td>0.703355</td>\n",
       "      <td>-1.547044</td>\n",
       "      <td>0.703355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comorbidity_score</th>\n",
       "      <td>-0.006807</td>\n",
       "      <td>0.951072</td>\n",
       "      <td>-1.161507</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>1.745679</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>-1.161507</td>\n",
       "      <td>1.866550</td>\n",
       "      <td>1.223255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karnofsky_score</th>\n",
       "      <td>-0.521902</td>\n",
       "      <td>0.499163</td>\n",
       "      <td>0.499163</td>\n",
       "      <td>0.499163</td>\n",
       "      <td>0.499163</td>\n",
       "      <td>-0.341160</td>\n",
       "      <td>-1.270098</td>\n",
       "      <td>1.845853</td>\n",
       "      <td>-1.794895</td>\n",
       "      <td>0.499163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <td>-0.137378</td>\n",
       "      <td>-1.436730</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>-1.029529</td>\n",
       "      <td>-1.436730</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.069009</td>\n",
       "      <td>-1.436730</td>\n",
       "      <td>0.812482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <td>-0.214243</td>\n",
       "      <td>-1.571972</td>\n",
       "      <td>0.684010</td>\n",
       "      <td>0.684010</td>\n",
       "      <td>0.684010</td>\n",
       "      <td>-1.571972</td>\n",
       "      <td>0.684010</td>\n",
       "      <td>-0.214243</td>\n",
       "      <td>-1.571972</td>\n",
       "      <td>0.684010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <td>-0.174492</td>\n",
       "      <td>-1.542186</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>-0.848656</td>\n",
       "      <td>-1.280487</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>0.182598</td>\n",
       "      <td>-1.542186</td>\n",
       "      <td>0.383075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dri_score</th>\n",
       "      <td>-0.466754</td>\n",
       "      <td>-1.397131</td>\n",
       "      <td>1.369756</td>\n",
       "      <td>1.369756</td>\n",
       "      <td>-1.397131</td>\n",
       "      <td>-1.397131</td>\n",
       "      <td>0.244748</td>\n",
       "      <td>-1.397131</td>\n",
       "      <td>0.244748</td>\n",
       "      <td>0.244748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyto_score</th>\n",
       "      <td>-0.313929</td>\n",
       "      <td>0.491678</td>\n",
       "      <td>-0.066543</td>\n",
       "      <td>-0.313929</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>-0.313929</td>\n",
       "      <td>-1.798717</td>\n",
       "      <td>0.201760</td>\n",
       "      <td>-1.798717</td>\n",
       "      <td>-0.313929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmv_status</th>\n",
       "      <td>-0.709682</td>\n",
       "      <td>-0.709682</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>-0.709682</td>\n",
       "      <td>-0.709682</td>\n",
       "      <td>-0.709682</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>-0.709682</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>-1.649843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyto_score_detail</th>\n",
       "      <td>0.242336</td>\n",
       "      <td>-0.714676</td>\n",
       "      <td>0.709367</td>\n",
       "      <td>-2.754647</td>\n",
       "      <td>-2.754647</td>\n",
       "      <td>0.709367</td>\n",
       "      <td>-0.232054</td>\n",
       "      <td>-1.206616</td>\n",
       "      <td>-0.232054</td>\n",
       "      <td>-0.232054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor_age</th>\n",
       "      <td>1.086591</td>\n",
       "      <td>-0.295218</td>\n",
       "      <td>0.857514</td>\n",
       "      <td>1.310480</td>\n",
       "      <td>-0.975020</td>\n",
       "      <td>0.175084</td>\n",
       "      <td>1.021609</td>\n",
       "      <td>0.515228</td>\n",
       "      <td>1.506459</td>\n",
       "      <td>1.209813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_at_hct</th>\n",
       "      <td>0.477644</td>\n",
       "      <td>-1.377534</td>\n",
       "      <td>-0.162103</td>\n",
       "      <td>1.253431</td>\n",
       "      <td>-1.372921</td>\n",
       "      <td>-1.754453</td>\n",
       "      <td>0.277011</td>\n",
       "      <td>-1.902698</td>\n",
       "      <td>1.577303</td>\n",
       "      <td>0.240889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psych_disturb_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_&gt;cGy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_Cy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_None</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_frac</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_single</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_unknown</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrhythmia_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graft_type_Marrow</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_hist_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renal_issue_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulm_severe_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_ALEU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_ALL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_AML</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_CML</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_HD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_HIS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IEA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IIS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IMD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IPA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_LEU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_MDS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_MPN</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_NHL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_PCD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_SAA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_SOL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_G/G</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_H/B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_H/H</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/G</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/H</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/P</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rituximab_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prod_type_PB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditioning_intensity_NMA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditioning_intensity_None</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditioning_intensity_RIC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity_-His+Lat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity_Non-US</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obesity_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrd_hct_Positive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_vivo_tcd_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_match_HvG non-per</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_match_Match</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_match_Per</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatic_severe_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior_tumor_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptic_ulcer_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CDsel+</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA+</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA+MMF</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA+MTX+</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_Cyclop</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_Cyclop+</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_FK</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_FK+MMF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_FK+MTX</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_GVHD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_None</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_ParQ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_T-DEP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_T-DEP+</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_infrequent_sklearn</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheum_issue_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_match_F-M</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_match_M-F</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_match_M-M</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_Asian</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_Black or African-American</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_More than one race</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_Native Hawaiian or other Pacific Islander</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_White</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatic_mild_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_div_match_HvG no</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_div_match_No</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_div_match_Yes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor_related_No</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor_related_Yes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melphalan_dose_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiac_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulm_moderate_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efs</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efs_time</th>\n",
       "      <td>-0.174175</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>-0.740564</td>\n",
       "      <td>1.886816</td>\n",
       "      <td>1.037292</td>\n",
       "      <td>0.695137</td>\n",
       "      <td>-1.748755</td>\n",
       "      <td>0.626030</td>\n",
       "      <td>-0.959388</td>\n",
       "      <td>0.052330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ID                                                     1044      9306   \\\n",
       "hla_match_c_high                                   -1.551232  0.605538   \n",
       "hla_high_res_8                                      0.837211 -0.986511   \n",
       "hla_low_res_6                                      -0.090376 -1.612295   \n",
       "hla_high_res_6                                      0.841482 -1.212899   \n",
       "hla_high_res_10                                     0.859768 -1.221335   \n",
       "hla_match_dqb1_high                                -0.377409 -1.686427   \n",
       "hla_nmdp_6                                         -0.114339 -1.635777   \n",
       "hla_match_c_low                                    -0.519834  0.602771   \n",
       "hla_match_drb1_low                                 -0.251677 -1.584976   \n",
       "hla_match_dqb1_low                                 -0.653310 -1.859082   \n",
       "hla_match_a_high                                    0.702089  0.702089   \n",
       "hla_match_b_low                                    -0.291202 -1.616513   \n",
       "hla_match_a_low                                    -0.228602 -1.574425   \n",
       "hla_match_b_high                                    0.703355 -1.547044   \n",
       "comorbidity_score                                  -0.006807  0.951072   \n",
       "karnofsky_score                                    -0.521902  0.499163   \n",
       "hla_low_res_8                                      -0.137378 -1.436730   \n",
       "hla_match_drb1_high                                -0.214243 -1.571972   \n",
       "hla_low_res_10                                     -0.174492 -1.542186   \n",
       "dri_score                                          -0.466754 -1.397131   \n",
       "cyto_score                                         -0.313929  0.491678   \n",
       "cmv_status                                         -0.709682 -0.709682   \n",
       "cyto_score_detail                                   0.242336 -0.714676   \n",
       "donor_age                                           1.086591 -0.295218   \n",
       "age_at_hct                                          0.477644 -1.377534   \n",
       "psych_disturb_Yes                                   0.000000  0.000000   \n",
       "diabetes_Yes                                        0.000000  0.000000   \n",
       "tbi_status_>cGy                                     0.000000  0.000000   \n",
       "tbi_status_Cy                                       0.000000  0.000000   \n",
       "tbi_status_None                                     1.000000  1.000000   \n",
       "tbi_status_frac                                     0.000000  0.000000   \n",
       "tbi_status_single                                   0.000000  0.000000   \n",
       "tbi_status_unknown                                  0.000000  0.000000   \n",
       "arrhythmia_Yes                                      0.000000  0.000000   \n",
       "graft_type_Marrow                                   0.000000  1.000000   \n",
       "vent_hist_Yes                                       0.000000  0.000000   \n",
       "renal_issue_Yes                                     0.000000  0.000000   \n",
       "pulm_severe_Yes                                     0.000000  0.000000   \n",
       "prim_disease_hct_ALEU                               0.000000  0.000000   \n",
       "prim_disease_hct_ALL                                1.000000  0.000000   \n",
       "prim_disease_hct_AML                                0.000000  0.000000   \n",
       "prim_disease_hct_CML                                0.000000  0.000000   \n",
       "prim_disease_hct_HD                                 0.000000  0.000000   \n",
       "prim_disease_hct_HIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IEA                                0.000000  0.000000   \n",
       "prim_disease_hct_IIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IMD                                0.000000  1.000000   \n",
       "prim_disease_hct_IPA                                0.000000  0.000000   \n",
       "prim_disease_hct_LEU                                0.000000  0.000000   \n",
       "prim_disease_hct_MDS                                0.000000  0.000000   \n",
       "prim_disease_hct_MPN                                0.000000  0.000000   \n",
       "prim_disease_hct_NHL                                0.000000  0.000000   \n",
       "prim_disease_hct_PCD                                0.000000  0.000000   \n",
       "prim_disease_hct_SAA                                0.000000  0.000000   \n",
       "prim_disease_hct_SOL                                0.000000  0.000000   \n",
       "tce_imm_match_G/G                                   0.000000  0.000000   \n",
       "tce_imm_match_H/B                                   0.000000  0.000000   \n",
       "tce_imm_match_H/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/B                                   0.000000  0.000000   \n",
       "tce_imm_match_P/G                                   0.000000  0.000000   \n",
       "tce_imm_match_P/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/P                                   1.000000  1.000000   \n",
       "rituximab_Yes                                       0.000000  0.000000   \n",
       "prod_type_PB                                        1.000000  0.000000   \n",
       "conditioning_intensity_NMA                          0.000000  0.000000   \n",
       "conditioning_intensity_None                         0.000000  0.000000   \n",
       "conditioning_intensity_RIC                          0.000000  1.000000   \n",
       "ethnicity_-His+Lat                                  0.000000  1.000000   \n",
       "ethnicity_Non-US                                    1.000000  0.000000   \n",
       "obesity_Yes                                         0.000000  0.000000   \n",
       "mrd_hct_Positive                                    0.000000  0.000000   \n",
       "in_vivo_tcd_Yes                                     0.000000  0.000000   \n",
       "tce_match_HvG non-per                               0.000000  0.000000   \n",
       "tce_match_Match                                     0.000000  0.000000   \n",
       "tce_match_Per                                       1.000000  0.000000   \n",
       "hepatic_severe_Yes                                  0.000000  0.000000   \n",
       "prior_tumor_Yes                                     0.000000  0.000000   \n",
       "peptic_ulcer_Yes                                    0.000000  0.000000   \n",
       "gvhd_proph_CDsel+                                   0.000000  0.000000   \n",
       "gvhd_proph_CSA                                      0.000000  0.000000   \n",
       "gvhd_proph_CSA+                                     0.000000  0.000000   \n",
       "gvhd_proph_CSA+MMF                                  0.000000  0.000000   \n",
       "gvhd_proph_CSA+MTX+                                 0.000000  0.000000   \n",
       "gvhd_proph_Cyclop                                   0.000000  0.000000   \n",
       "gvhd_proph_Cyclop+                                  0.000000  1.000000   \n",
       "gvhd_proph_FK                                       0.000000  0.000000   \n",
       "gvhd_proph_FK+MMF                                   1.000000  0.000000   \n",
       "gvhd_proph_FK+MTX                                   0.000000  0.000000   \n",
       "gvhd_proph_GVHD                                     0.000000  0.000000   \n",
       "gvhd_proph_None                                     0.000000  0.000000   \n",
       "gvhd_proph_ParQ                                     0.000000  0.000000   \n",
       "gvhd_proph_T-DEP                                    0.000000  0.000000   \n",
       "gvhd_proph_T-DEP+                                   0.000000  0.000000   \n",
       "gvhd_proph_infrequent_sklearn                       0.000000  0.000000   \n",
       "rheum_issue_Yes                                     0.000000  0.000000   \n",
       "sex_match_F-M                                       0.000000  0.000000   \n",
       "sex_match_M-F                                       0.000000  0.000000   \n",
       "sex_match_M-M                                       1.000000  0.000000   \n",
       "race_group_Asian                                    0.000000  0.000000   \n",
       "race_group_Black or African-American                0.000000  0.000000   \n",
       "race_group_More than one race                       0.000000  0.000000   \n",
       "race_group_Native Hawaiian or other Pacific Isl...  1.000000  1.000000   \n",
       "race_group_White                                    0.000000  0.000000   \n",
       "hepatic_mild_Yes                                    0.000000  0.000000   \n",
       "tce_div_match_HvG no                                0.000000  0.000000   \n",
       "tce_div_match_No                                    0.000000  0.000000   \n",
       "tce_div_match_Yes                                   1.000000  1.000000   \n",
       "donor_related_No                                    0.000000  0.000000   \n",
       "donor_related_Yes                                   1.000000  1.000000   \n",
       "melphalan_dose_Yes                                  0.000000  1.000000   \n",
       "cardiac_Yes                                         0.000000  0.000000   \n",
       "pulm_moderate_Yes                                   0.000000  0.000000   \n",
       "efs                                                 1.000000  0.000000   \n",
       "efs_time                                           -0.174175  1.049543   \n",
       "\n",
       "ID                                                     24307     1058   \\\n",
       "hla_match_c_high                                    0.605538  0.605538   \n",
       "hla_high_res_8                                      0.837211  0.574689   \n",
       "hla_low_res_6                                       0.806635  0.806635   \n",
       "hla_high_res_6                                      0.841482  0.522966   \n",
       "hla_high_res_10                                     0.859768  0.637790   \n",
       "hla_match_dqb1_high                                 0.655567  0.655567   \n",
       "hla_nmdp_6                                          0.813259  0.813259   \n",
       "hla_match_c_low                                     0.602771  0.602771   \n",
       "hla_match_drb1_low                                  0.673036  0.673036   \n",
       "hla_match_dqb1_low                                  0.584758  0.584758   \n",
       "hla_match_a_high                                    0.702089  0.702089   \n",
       "hla_match_b_low                                     0.659026  0.659026   \n",
       "hla_match_a_low                                     0.675510  0.675510   \n",
       "hla_match_b_high                                    0.703355 -0.166080   \n",
       "comorbidity_score                                  -1.161507 -0.006807   \n",
       "karnofsky_score                                     0.499163  0.499163   \n",
       "hla_low_res_8                                       0.812482  0.812482   \n",
       "hla_match_drb1_high                                 0.684010  0.684010   \n",
       "hla_low_res_10                                      0.832301  0.832301   \n",
       "dri_score                                           1.369756  1.369756   \n",
       "cyto_score                                         -0.066543 -0.313929   \n",
       "cmv_status                                          0.999684 -0.709682   \n",
       "cyto_score_detail                                   0.709367 -2.754647   \n",
       "donor_age                                           0.857514  1.310480   \n",
       "age_at_hct                                         -0.162103  1.253431   \n",
       "psych_disturb_Yes                                   0.000000  0.000000   \n",
       "diabetes_Yes                                        0.000000  0.000000   \n",
       "tbi_status_>cGy                                     0.000000  0.000000   \n",
       "tbi_status_Cy                                       0.000000  0.000000   \n",
       "tbi_status_None                                     1.000000  1.000000   \n",
       "tbi_status_frac                                     0.000000  0.000000   \n",
       "tbi_status_single                                   0.000000  0.000000   \n",
       "tbi_status_unknown                                  0.000000  0.000000   \n",
       "arrhythmia_Yes                                      0.000000  0.000000   \n",
       "graft_type_Marrow                                   1.000000  0.000000   \n",
       "vent_hist_Yes                                       0.000000  0.000000   \n",
       "renal_issue_Yes                                     0.000000  0.000000   \n",
       "pulm_severe_Yes                                     0.000000  1.000000   \n",
       "prim_disease_hct_ALEU                               0.000000  0.000000   \n",
       "prim_disease_hct_ALL                                0.000000  0.000000   \n",
       "prim_disease_hct_AML                                0.000000  1.000000   \n",
       "prim_disease_hct_CML                                0.000000  0.000000   \n",
       "prim_disease_hct_HD                                 0.000000  0.000000   \n",
       "prim_disease_hct_HIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IEA                                0.000000  0.000000   \n",
       "prim_disease_hct_IIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IMD                                0.000000  0.000000   \n",
       "prim_disease_hct_IPA                                0.000000  0.000000   \n",
       "prim_disease_hct_LEU                                0.000000  0.000000   \n",
       "prim_disease_hct_MDS                                0.000000  0.000000   \n",
       "prim_disease_hct_MPN                                0.000000  0.000000   \n",
       "prim_disease_hct_NHL                                0.000000  0.000000   \n",
       "prim_disease_hct_PCD                                1.000000  0.000000   \n",
       "prim_disease_hct_SAA                                0.000000  0.000000   \n",
       "prim_disease_hct_SOL                                0.000000  0.000000   \n",
       "tce_imm_match_G/G                                   0.000000  1.000000   \n",
       "tce_imm_match_H/B                                   0.000000  0.000000   \n",
       "tce_imm_match_H/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/B                                   0.000000  0.000000   \n",
       "tce_imm_match_P/G                                   0.000000  0.000000   \n",
       "tce_imm_match_P/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/P                                   1.000000  0.000000   \n",
       "rituximab_Yes                                       0.000000  0.000000   \n",
       "prod_type_PB                                        0.000000  1.000000   \n",
       "conditioning_intensity_NMA                          0.000000  0.000000   \n",
       "conditioning_intensity_None                         0.000000  0.000000   \n",
       "conditioning_intensity_RIC                          0.000000  1.000000   \n",
       "ethnicity_-His+Lat                                  1.000000  1.000000   \n",
       "ethnicity_Non-US                                    0.000000  0.000000   \n",
       "obesity_Yes                                         0.000000  0.000000   \n",
       "mrd_hct_Positive                                    0.000000  0.000000   \n",
       "in_vivo_tcd_Yes                                     0.000000  0.000000   \n",
       "tce_match_HvG non-per                               0.000000  0.000000   \n",
       "tce_match_Match                                     0.000000  0.000000   \n",
       "tce_match_Per                                       1.000000  0.000000   \n",
       "hepatic_severe_Yes                                  0.000000  0.000000   \n",
       "prior_tumor_Yes                                     0.000000  0.000000   \n",
       "peptic_ulcer_Yes                                    0.000000  0.000000   \n",
       "gvhd_proph_CDsel+                                   0.000000  0.000000   \n",
       "gvhd_proph_CSA                                      0.000000  0.000000   \n",
       "gvhd_proph_CSA+                                     0.000000  0.000000   \n",
       "gvhd_proph_CSA+MMF                                  0.000000  0.000000   \n",
       "gvhd_proph_CSA+MTX+                                 0.000000  0.000000   \n",
       "gvhd_proph_Cyclop                                   0.000000  0.000000   \n",
       "gvhd_proph_Cyclop+                                  0.000000  0.000000   \n",
       "gvhd_proph_FK                                       0.000000  0.000000   \n",
       "gvhd_proph_FK+MMF                                   1.000000  0.000000   \n",
       "gvhd_proph_FK+MTX                                   0.000000  1.000000   \n",
       "gvhd_proph_GVHD                                     0.000000  0.000000   \n",
       "gvhd_proph_None                                     0.000000  0.000000   \n",
       "gvhd_proph_ParQ                                     0.000000  0.000000   \n",
       "gvhd_proph_T-DEP                                    0.000000  0.000000   \n",
       "gvhd_proph_T-DEP+                                   0.000000  0.000000   \n",
       "gvhd_proph_infrequent_sklearn                       0.000000  0.000000   \n",
       "rheum_issue_Yes                                     0.000000  1.000000   \n",
       "sex_match_F-M                                       0.000000  1.000000   \n",
       "sex_match_M-F                                       0.000000  0.000000   \n",
       "sex_match_M-M                                       0.000000  0.000000   \n",
       "race_group_Asian                                    0.000000  0.000000   \n",
       "race_group_Black or African-American                1.000000  0.000000   \n",
       "race_group_More than one race                       0.000000  0.000000   \n",
       "race_group_Native Hawaiian or other Pacific Isl...  0.000000  0.000000   \n",
       "race_group_White                                    0.000000  1.000000   \n",
       "hepatic_mild_Yes                                    0.000000  0.000000   \n",
       "tce_div_match_HvG no                                0.000000  0.000000   \n",
       "tce_div_match_No                                    0.000000  0.000000   \n",
       "tce_div_match_Yes                                   1.000000  0.000000   \n",
       "donor_related_No                                    0.000000  0.000000   \n",
       "donor_related_Yes                                   1.000000  1.000000   \n",
       "melphalan_dose_Yes                                  0.000000  0.000000   \n",
       "cardiac_Yes                                         0.000000  0.000000   \n",
       "pulm_moderate_Yes                                   0.000000  0.000000   \n",
       "efs                                                 1.000000  0.000000   \n",
       "efs_time                                           -0.740564  1.886816   \n",
       "\n",
       "ID                                                     24177     6076   \\\n",
       "hla_match_c_high                                    0.605538 -1.801021   \n",
       "hla_high_res_8                                     -0.278621 -1.637188   \n",
       "hla_low_res_6                                      -1.264762 -1.612295   \n",
       "hla_high_res_6                                     -0.468435 -1.591159   \n",
       "hla_high_res_10                                    -0.109663 -1.663935   \n",
       "hla_match_dqb1_high                                 0.655567 -1.686427   \n",
       "hla_nmdp_6                                         -0.571336 -0.571336   \n",
       "hla_match_c_low                                     0.602771  0.602771   \n",
       "hla_match_drb1_low                                  0.673036 -1.584976   \n",
       "hla_match_dqb1_low                                  0.584758  0.584758   \n",
       "hla_match_a_high                                   -1.560534 -1.560534   \n",
       "hla_match_b_low                                    -1.616513 -1.616513   \n",
       "hla_match_a_low                                    -1.574425 -1.574425   \n",
       "hla_match_b_high                                    0.703355 -1.547044   \n",
       "comorbidity_score                                  -0.006807  1.745679   \n",
       "karnofsky_score                                     0.499163 -0.341160   \n",
       "hla_low_res_8                                      -1.029529 -1.436730   \n",
       "hla_match_drb1_high                                 0.684010 -1.571972   \n",
       "hla_low_res_10                                     -0.848656 -1.280487   \n",
       "dri_score                                          -1.397131 -1.397131   \n",
       "cyto_score                                          0.803899 -0.313929   \n",
       "cmv_status                                         -0.709682 -0.709682   \n",
       "cyto_score_detail                                  -2.754647  0.709367   \n",
       "donor_age                                          -0.975020  0.175084   \n",
       "age_at_hct                                         -1.372921 -1.754453   \n",
       "psych_disturb_Yes                                   0.000000  0.000000   \n",
       "diabetes_Yes                                        0.000000  0.000000   \n",
       "tbi_status_>cGy                                     0.000000  1.000000   \n",
       "tbi_status_Cy                                       0.000000  0.000000   \n",
       "tbi_status_None                                     1.000000  0.000000   \n",
       "tbi_status_frac                                     0.000000  0.000000   \n",
       "tbi_status_single                                   0.000000  0.000000   \n",
       "tbi_status_unknown                                  0.000000  0.000000   \n",
       "arrhythmia_Yes                                      0.000000  0.000000   \n",
       "graft_type_Marrow                                   1.000000  1.000000   \n",
       "vent_hist_Yes                                       0.000000  0.000000   \n",
       "renal_issue_Yes                                     0.000000  0.000000   \n",
       "pulm_severe_Yes                                     0.000000  0.000000   \n",
       "prim_disease_hct_ALEU                               0.000000  0.000000   \n",
       "prim_disease_hct_ALL                                0.000000  1.000000   \n",
       "prim_disease_hct_AML                                0.000000  0.000000   \n",
       "prim_disease_hct_CML                                0.000000  0.000000   \n",
       "prim_disease_hct_HD                                 0.000000  0.000000   \n",
       "prim_disease_hct_HIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IEA                                0.000000  0.000000   \n",
       "prim_disease_hct_IIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IMD                                0.000000  0.000000   \n",
       "prim_disease_hct_IPA                                0.000000  0.000000   \n",
       "prim_disease_hct_LEU                                0.000000  0.000000   \n",
       "prim_disease_hct_MDS                                1.000000  0.000000   \n",
       "prim_disease_hct_MPN                                0.000000  0.000000   \n",
       "prim_disease_hct_NHL                                0.000000  0.000000   \n",
       "prim_disease_hct_PCD                                0.000000  0.000000   \n",
       "prim_disease_hct_SAA                                0.000000  0.000000   \n",
       "prim_disease_hct_SOL                                0.000000  0.000000   \n",
       "tce_imm_match_G/G                                   0.000000  0.000000   \n",
       "tce_imm_match_H/B                                   0.000000  0.000000   \n",
       "tce_imm_match_H/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/B                                   0.000000  1.000000   \n",
       "tce_imm_match_P/G                                   0.000000  0.000000   \n",
       "tce_imm_match_P/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/P                                   1.000000  0.000000   \n",
       "rituximab_Yes                                       0.000000  0.000000   \n",
       "prod_type_PB                                        0.000000  0.000000   \n",
       "conditioning_intensity_NMA                          0.000000  0.000000   \n",
       "conditioning_intensity_None                         0.000000  0.000000   \n",
       "conditioning_intensity_RIC                          0.000000  0.000000   \n",
       "ethnicity_-His+Lat                                  1.000000  0.000000   \n",
       "ethnicity_Non-US                                    0.000000  0.000000   \n",
       "obesity_Yes                                         0.000000  0.000000   \n",
       "mrd_hct_Positive                                    0.000000  1.000000   \n",
       "in_vivo_tcd_Yes                                     1.000000  1.000000   \n",
       "tce_match_HvG non-per                               0.000000  0.000000   \n",
       "tce_match_Match                                     0.000000  0.000000   \n",
       "tce_match_Per                                       0.000000  1.000000   \n",
       "hepatic_severe_Yes                                  0.000000  0.000000   \n",
       "prior_tumor_Yes                                     0.000000  1.000000   \n",
       "peptic_ulcer_Yes                                    0.000000  0.000000   \n",
       "gvhd_proph_CDsel+                                   0.000000  0.000000   \n",
       "gvhd_proph_CSA                                      0.000000  0.000000   \n",
       "gvhd_proph_CSA+                                     0.000000  0.000000   \n",
       "gvhd_proph_CSA+MMF                                  0.000000  0.000000   \n",
       "gvhd_proph_CSA+MTX+                                 0.000000  0.000000   \n",
       "gvhd_proph_Cyclop                                   0.000000  1.000000   \n",
       "gvhd_proph_Cyclop+                                  0.000000  0.000000   \n",
       "gvhd_proph_FK                                       0.000000  0.000000   \n",
       "gvhd_proph_FK+MMF                                   0.000000  0.000000   \n",
       "gvhd_proph_FK+MTX                                   1.000000  0.000000   \n",
       "gvhd_proph_GVHD                                     0.000000  0.000000   \n",
       "gvhd_proph_None                                     0.000000  0.000000   \n",
       "gvhd_proph_ParQ                                     0.000000  0.000000   \n",
       "gvhd_proph_T-DEP                                    0.000000  0.000000   \n",
       "gvhd_proph_T-DEP+                                   0.000000  0.000000   \n",
       "gvhd_proph_infrequent_sklearn                       0.000000  0.000000   \n",
       "rheum_issue_Yes                                     0.000000  0.000000   \n",
       "sex_match_F-M                                       0.000000  0.000000   \n",
       "sex_match_M-F                                       1.000000  1.000000   \n",
       "sex_match_M-M                                       0.000000  0.000000   \n",
       "race_group_Asian                                    0.000000  0.000000   \n",
       "race_group_Black or African-American                0.000000  0.000000   \n",
       "race_group_More than one race                       0.000000  0.000000   \n",
       "race_group_Native Hawaiian or other Pacific Isl...  0.000000  0.000000   \n",
       "race_group_White                                    1.000000  0.000000   \n",
       "hepatic_mild_Yes                                    0.000000  0.000000   \n",
       "tce_div_match_HvG no                                0.000000  0.000000   \n",
       "tce_div_match_No                                    0.000000  0.000000   \n",
       "tce_div_match_Yes                                   1.000000  0.000000   \n",
       "donor_related_No                                    1.000000  0.000000   \n",
       "donor_related_Yes                                   0.000000  1.000000   \n",
       "melphalan_dose_Yes                                  0.000000  0.000000   \n",
       "cardiac_Yes                                         0.000000  0.000000   \n",
       "pulm_moderate_Yes                                   0.000000  1.000000   \n",
       "efs                                                 0.000000  0.000000   \n",
       "efs_time                                            1.037292  0.695137   \n",
       "\n",
       "ID                                                     16162     22516  \\\n",
       "hla_match_c_high                                    0.605538  0.605538   \n",
       "hla_high_res_8                                     -0.278621  0.111076   \n",
       "hla_low_res_6                                       0.806635 -0.090376   \n",
       "hla_high_res_6                                     -0.468435 -0.025203   \n",
       "hla_high_res_10                                    -0.109663  0.237399   \n",
       "hla_match_dqb1_high                                 0.655567  0.655567   \n",
       "hla_nmdp_6                                         -0.571336  0.159687   \n",
       "hla_match_c_low                                     0.602771  0.602771   \n",
       "hla_match_drb1_low                                  0.673036 -0.251677   \n",
       "hla_match_dqb1_low                                  0.584758  0.584758   \n",
       "hla_match_a_high                                   -1.560534 -0.783070   \n",
       "hla_match_b_low                                     0.659026  0.659026   \n",
       "hla_match_a_low                                     0.675510 -0.824037   \n",
       "hla_match_b_high                                    0.703355  0.703355   \n",
       "comorbidity_score                                  -0.006807 -1.161507   \n",
       "karnofsky_score                                    -1.270098  1.845853   \n",
       "hla_low_res_8                                       0.812482  0.069009   \n",
       "hla_match_drb1_high                                 0.684010 -0.214243   \n",
       "hla_low_res_10                                      0.832301  0.182598   \n",
       "dri_score                                           0.244748 -1.397131   \n",
       "cyto_score                                         -1.798717  0.201760   \n",
       "cmv_status                                          0.999684 -0.709682   \n",
       "cyto_score_detail                                  -0.232054 -1.206616   \n",
       "donor_age                                           1.021609  0.515228   \n",
       "age_at_hct                                          0.277011 -1.902698   \n",
       "psych_disturb_Yes                                   0.000000  0.000000   \n",
       "diabetes_Yes                                        1.000000  0.000000   \n",
       "tbi_status_>cGy                                     0.000000  0.000000   \n",
       "tbi_status_Cy                                       0.000000  1.000000   \n",
       "tbi_status_None                                     1.000000  0.000000   \n",
       "tbi_status_frac                                     0.000000  0.000000   \n",
       "tbi_status_single                                   0.000000  0.000000   \n",
       "tbi_status_unknown                                  0.000000  0.000000   \n",
       "arrhythmia_Yes                                      0.000000  0.000000   \n",
       "graft_type_Marrow                                   0.000000  0.000000   \n",
       "vent_hist_Yes                                       0.000000  0.000000   \n",
       "renal_issue_Yes                                     0.000000  0.000000   \n",
       "pulm_severe_Yes                                     0.000000  0.000000   \n",
       "prim_disease_hct_ALEU                               0.000000  0.000000   \n",
       "prim_disease_hct_ALL                                0.000000  0.000000   \n",
       "prim_disease_hct_AML                                0.000000  1.000000   \n",
       "prim_disease_hct_CML                                0.000000  0.000000   \n",
       "prim_disease_hct_HD                                 0.000000  0.000000   \n",
       "prim_disease_hct_HIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IEA                                0.000000  0.000000   \n",
       "prim_disease_hct_IIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IMD                                0.000000  0.000000   \n",
       "prim_disease_hct_IPA                                0.000000  0.000000   \n",
       "prim_disease_hct_LEU                                0.000000  0.000000   \n",
       "prim_disease_hct_MDS                                0.000000  0.000000   \n",
       "prim_disease_hct_MPN                                1.000000  0.000000   \n",
       "prim_disease_hct_NHL                                0.000000  0.000000   \n",
       "prim_disease_hct_PCD                                0.000000  0.000000   \n",
       "prim_disease_hct_SAA                                0.000000  0.000000   \n",
       "prim_disease_hct_SOL                                0.000000  0.000000   \n",
       "tce_imm_match_G/G                                   0.000000  0.000000   \n",
       "tce_imm_match_H/B                                   0.000000  0.000000   \n",
       "tce_imm_match_H/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/B                                   0.000000  0.000000   \n",
       "tce_imm_match_P/G                                   0.000000  0.000000   \n",
       "tce_imm_match_P/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/P                                   1.000000  1.000000   \n",
       "rituximab_Yes                                       0.000000  0.000000   \n",
       "prod_type_PB                                        1.000000  1.000000   \n",
       "conditioning_intensity_NMA                          0.000000  0.000000   \n",
       "conditioning_intensity_None                         0.000000  0.000000   \n",
       "conditioning_intensity_RIC                          1.000000  0.000000   \n",
       "ethnicity_-His+Lat                                  1.000000  0.000000   \n",
       "ethnicity_Non-US                                    0.000000  0.000000   \n",
       "obesity_Yes                                         0.000000  0.000000   \n",
       "mrd_hct_Positive                                    0.000000  0.000000   \n",
       "in_vivo_tcd_Yes                                     1.000000  1.000000   \n",
       "tce_match_HvG non-per                               0.000000  0.000000   \n",
       "tce_match_Match                                     0.000000  0.000000   \n",
       "tce_match_Per                                       0.000000  0.000000   \n",
       "hepatic_severe_Yes                                  1.000000  0.000000   \n",
       "prior_tumor_Yes                                     0.000000  0.000000   \n",
       "peptic_ulcer_Yes                                    0.000000  0.000000   \n",
       "gvhd_proph_CDsel+                                   0.000000  0.000000   \n",
       "gvhd_proph_CSA                                      0.000000  0.000000   \n",
       "gvhd_proph_CSA+                                     0.000000  0.000000   \n",
       "gvhd_proph_CSA+MMF                                  0.000000  0.000000   \n",
       "gvhd_proph_CSA+MTX+                                 0.000000  0.000000   \n",
       "gvhd_proph_Cyclop                                   0.000000  0.000000   \n",
       "gvhd_proph_Cyclop+                                  0.000000  0.000000   \n",
       "gvhd_proph_FK                                       0.000000  0.000000   \n",
       "gvhd_proph_FK+MMF                                   0.000000  0.000000   \n",
       "gvhd_proph_FK+MTX                                   1.000000  0.000000   \n",
       "gvhd_proph_GVHD                                     0.000000  0.000000   \n",
       "gvhd_proph_None                                     0.000000  0.000000   \n",
       "gvhd_proph_ParQ                                     0.000000  0.000000   \n",
       "gvhd_proph_T-DEP                                    0.000000  1.000000   \n",
       "gvhd_proph_T-DEP+                                   0.000000  0.000000   \n",
       "gvhd_proph_infrequent_sklearn                       0.000000  0.000000   \n",
       "rheum_issue_Yes                                     0.000000  0.000000   \n",
       "sex_match_F-M                                       1.000000  1.000000   \n",
       "sex_match_M-F                                       0.000000  0.000000   \n",
       "sex_match_M-M                                       0.000000  0.000000   \n",
       "race_group_Asian                                    0.000000  0.000000   \n",
       "race_group_Black or African-American                1.000000  1.000000   \n",
       "race_group_More than one race                       0.000000  0.000000   \n",
       "race_group_Native Hawaiian or other Pacific Isl...  0.000000  0.000000   \n",
       "race_group_White                                    0.000000  0.000000   \n",
       "hepatic_mild_Yes                                    0.000000  0.000000   \n",
       "tce_div_match_HvG no                                0.000000  0.000000   \n",
       "tce_div_match_No                                    0.000000  0.000000   \n",
       "tce_div_match_Yes                                   1.000000  1.000000   \n",
       "donor_related_No                                    1.000000  0.000000   \n",
       "donor_related_Yes                                   0.000000  1.000000   \n",
       "melphalan_dose_Yes                                  1.000000  0.000000   \n",
       "cardiac_Yes                                         0.000000  0.000000   \n",
       "pulm_moderate_Yes                                   0.000000  0.000000   \n",
       "efs                                                 1.000000  0.000000   \n",
       "efs_time                                           -1.748755  0.626030   \n",
       "\n",
       "ID                                                     28343     23311  \n",
       "hla_match_c_high                                   -1.801021  0.605538  \n",
       "hla_high_res_8                                     -1.637188  0.837211  \n",
       "hla_low_res_6                                      -1.612295  0.806635  \n",
       "hla_high_res_6                                     -1.591159  0.841482  \n",
       "hla_high_res_10                                    -1.663935  0.859768  \n",
       "hla_match_dqb1_high                                -1.686427  0.655567  \n",
       "hla_nmdp_6                                         -1.635777  0.813259  \n",
       "hla_match_c_low                                     0.602771  0.602771  \n",
       "hla_match_drb1_low                                 -1.584976  0.673036  \n",
       "hla_match_dqb1_low                                 -1.859082 -1.306351  \n",
       "hla_match_a_high                                   -1.560534  0.702089  \n",
       "hla_match_b_low                                    -1.616513  0.659026  \n",
       "hla_match_a_low                                    -1.574425  0.675510  \n",
       "hla_match_b_high                                   -1.547044  0.703355  \n",
       "comorbidity_score                                   1.866550  1.223255  \n",
       "karnofsky_score                                    -1.794895  0.499163  \n",
       "hla_low_res_8                                      -1.436730  0.812482  \n",
       "hla_match_drb1_high                                -1.571972  0.684010  \n",
       "hla_low_res_10                                     -1.542186  0.383075  \n",
       "dri_score                                           0.244748  0.244748  \n",
       "cyto_score                                         -1.798717 -0.313929  \n",
       "cmv_status                                          0.999684 -1.649843  \n",
       "cyto_score_detail                                  -0.232054 -0.232054  \n",
       "donor_age                                           1.506459  1.209813  \n",
       "age_at_hct                                          1.577303  0.240889  \n",
       "psych_disturb_Yes                                   0.000000  0.000000  \n",
       "diabetes_Yes                                        0.000000  0.000000  \n",
       "tbi_status_>cGy                                     0.000000  0.000000  \n",
       "tbi_status_Cy                                       0.000000  0.000000  \n",
       "tbi_status_None                                     1.000000  1.000000  \n",
       "tbi_status_frac                                     0.000000  0.000000  \n",
       "tbi_status_single                                   0.000000  0.000000  \n",
       "tbi_status_unknown                                  0.000000  0.000000  \n",
       "arrhythmia_Yes                                      0.000000  0.000000  \n",
       "graft_type_Marrow                                   0.000000  0.000000  \n",
       "vent_hist_Yes                                       0.000000  0.000000  \n",
       "renal_issue_Yes                                     0.000000  0.000000  \n",
       "pulm_severe_Yes                                     0.000000  0.000000  \n",
       "prim_disease_hct_ALEU                               0.000000  0.000000  \n",
       "prim_disease_hct_ALL                                0.000000  0.000000  \n",
       "prim_disease_hct_AML                                0.000000  0.000000  \n",
       "prim_disease_hct_CML                                0.000000  0.000000  \n",
       "prim_disease_hct_HD                                 0.000000  0.000000  \n",
       "prim_disease_hct_HIS                                0.000000  0.000000  \n",
       "prim_disease_hct_IEA                                0.000000  0.000000  \n",
       "prim_disease_hct_IIS                                0.000000  0.000000  \n",
       "prim_disease_hct_IMD                                0.000000  0.000000  \n",
       "prim_disease_hct_IPA                                0.000000  0.000000  \n",
       "prim_disease_hct_LEU                                0.000000  0.000000  \n",
       "prim_disease_hct_MDS                                1.000000  1.000000  \n",
       "prim_disease_hct_MPN                                0.000000  0.000000  \n",
       "prim_disease_hct_NHL                                0.000000  0.000000  \n",
       "prim_disease_hct_PCD                                0.000000  0.000000  \n",
       "prim_disease_hct_SAA                                0.000000  0.000000  \n",
       "prim_disease_hct_SOL                                0.000000  0.000000  \n",
       "tce_imm_match_G/G                                   0.000000  0.000000  \n",
       "tce_imm_match_H/B                                   0.000000  0.000000  \n",
       "tce_imm_match_H/H                                   0.000000  0.000000  \n",
       "tce_imm_match_P/B                                   0.000000  0.000000  \n",
       "tce_imm_match_P/G                                   0.000000  0.000000  \n",
       "tce_imm_match_P/H                                   0.000000  0.000000  \n",
       "tce_imm_match_P/P                                   1.000000  1.000000  \n",
       "rituximab_Yes                                       0.000000  0.000000  \n",
       "prod_type_PB                                        1.000000  1.000000  \n",
       "conditioning_intensity_NMA                          1.000000  0.000000  \n",
       "conditioning_intensity_None                         0.000000  0.000000  \n",
       "conditioning_intensity_RIC                          0.000000  1.000000  \n",
       "ethnicity_-His+Lat                                  0.000000  1.000000  \n",
       "ethnicity_Non-US                                    1.000000  0.000000  \n",
       "obesity_Yes                                         0.000000  0.000000  \n",
       "mrd_hct_Positive                                    1.000000  0.000000  \n",
       "in_vivo_tcd_Yes                                     0.000000  0.000000  \n",
       "tce_match_HvG non-per                               0.000000  0.000000  \n",
       "tce_match_Match                                     0.000000  0.000000  \n",
       "tce_match_Per                                       0.000000  0.000000  \n",
       "hepatic_severe_Yes                                  0.000000  0.000000  \n",
       "prior_tumor_Yes                                     0.000000  1.000000  \n",
       "peptic_ulcer_Yes                                    0.000000  0.000000  \n",
       "gvhd_proph_CDsel+                                   0.000000  0.000000  \n",
       "gvhd_proph_CSA                                      0.000000  0.000000  \n",
       "gvhd_proph_CSA+                                     0.000000  0.000000  \n",
       "gvhd_proph_CSA+MMF                                  0.000000  0.000000  \n",
       "gvhd_proph_CSA+MTX+                                 0.000000  0.000000  \n",
       "gvhd_proph_Cyclop                                   1.000000  0.000000  \n",
       "gvhd_proph_Cyclop+                                  0.000000  0.000000  \n",
       "gvhd_proph_FK                                       0.000000  0.000000  \n",
       "gvhd_proph_FK+MMF                                   0.000000  1.000000  \n",
       "gvhd_proph_FK+MTX                                   0.000000  0.000000  \n",
       "gvhd_proph_GVHD                                     0.000000  0.000000  \n",
       "gvhd_proph_None                                     0.000000  0.000000  \n",
       "gvhd_proph_ParQ                                     0.000000  0.000000  \n",
       "gvhd_proph_T-DEP                                    0.000000  0.000000  \n",
       "gvhd_proph_T-DEP+                                   0.000000  0.000000  \n",
       "gvhd_proph_infrequent_sklearn                       0.000000  0.000000  \n",
       "rheum_issue_Yes                                     0.000000  0.000000  \n",
       "sex_match_F-M                                       1.000000  0.000000  \n",
       "sex_match_M-F                                       0.000000  0.000000  \n",
       "sex_match_M-M                                       0.000000  1.000000  \n",
       "race_group_Asian                                    0.000000  1.000000  \n",
       "race_group_Black or African-American                0.000000  0.000000  \n",
       "race_group_More than one race                       1.000000  0.000000  \n",
       "race_group_Native Hawaiian or other Pacific Isl...  0.000000  0.000000  \n",
       "race_group_White                                    0.000000  0.000000  \n",
       "hepatic_mild_Yes                                    1.000000  0.000000  \n",
       "tce_div_match_HvG no                                0.000000  0.000000  \n",
       "tce_div_match_No                                    0.000000  0.000000  \n",
       "tce_div_match_Yes                                   1.000000  1.000000  \n",
       "donor_related_No                                    0.000000  0.000000  \n",
       "donor_related_Yes                                   1.000000  1.000000  \n",
       "melphalan_dose_Yes                                  0.000000  0.000000  \n",
       "cardiac_Yes                                         0.000000  0.000000  \n",
       "pulm_moderate_Yes                                   0.000000  1.000000  \n",
       "efs                                                 1.000000  1.000000  \n",
       "efs_time                                           -0.959388  0.052330  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head(10).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-5.976424e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.856378</td>\n",
       "      <td>-0.565358</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.605538</td>\n",
       "      <td>0.605538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.032647e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.793383</td>\n",
       "      <td>-0.986511</td>\n",
       "      <td>0.837211</td>\n",
       "      <td>0.837211</td>\n",
       "      <td>0.837211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>6.149494e-17</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.750950</td>\n",
       "      <td>-1.264762</td>\n",
       "      <td>0.806635</td>\n",
       "      <td>0.806635</td>\n",
       "      <td>0.806635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_high_res_6</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-7.898602e-17</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.817129</td>\n",
       "      <td>-1.212899</td>\n",
       "      <td>0.841482</td>\n",
       "      <td>0.841482</td>\n",
       "      <td>0.841482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_high_res_10</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.653367e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.794703</td>\n",
       "      <td>-0.979010</td>\n",
       "      <td>0.637790</td>\n",
       "      <td>0.859768</td>\n",
       "      <td>0.859768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_dqb1_high</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-1.509756e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.781526</td>\n",
       "      <td>-1.005030</td>\n",
       "      <td>0.655567</td>\n",
       "      <td>0.655567</td>\n",
       "      <td>0.655567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_nmdp_6</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.915486e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.764762</td>\n",
       "      <td>-0.759603</td>\n",
       "      <td>0.813259</td>\n",
       "      <td>0.813259</td>\n",
       "      <td>0.813259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_c_low</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-2.581315e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.832826</td>\n",
       "      <td>-0.519834</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.602771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_drb1_low</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-5.678156e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.584976</td>\n",
       "      <td>-1.584976</td>\n",
       "      <td>0.673036</td>\n",
       "      <td>0.673036</td>\n",
       "      <td>0.673036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_dqb1_low</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-2.391674e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.902492</td>\n",
       "      <td>-0.653310</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>0.584758</td>\n",
       "      <td>0.584758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_a_high</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-5.628444e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.725887</td>\n",
       "      <td>-1.560534</td>\n",
       "      <td>0.702089</td>\n",
       "      <td>0.702089</td>\n",
       "      <td>0.702089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_b_low</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.405910e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.739677</td>\n",
       "      <td>-1.616513</td>\n",
       "      <td>0.659026</td>\n",
       "      <td>0.659026</td>\n",
       "      <td>0.659026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_a_low</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.503986e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.721925</td>\n",
       "      <td>-1.574425</td>\n",
       "      <td>0.675510</td>\n",
       "      <td>0.675510</td>\n",
       "      <td>0.675510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_b_high</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.668096e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.725156</td>\n",
       "      <td>-1.547044</td>\n",
       "      <td>0.703355</td>\n",
       "      <td>0.703355</td>\n",
       "      <td>0.703355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comorbidity_score</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.307228e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.161507</td>\n",
       "      <td>-1.161507</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>0.575116</td>\n",
       "      <td>2.063844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karnofsky_score</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.107888e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-2.354341</td>\n",
       "      <td>-1.270098</td>\n",
       "      <td>0.499163</td>\n",
       "      <td>0.499163</td>\n",
       "      <td>1.845853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-1.271325e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.751903</td>\n",
       "      <td>-1.029529</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.812482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.129982e-18</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.726623</td>\n",
       "      <td>-1.571972</td>\n",
       "      <td>0.684010</td>\n",
       "      <td>0.684010</td>\n",
       "      <td>0.684010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-5.983789e-17</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.765754</td>\n",
       "      <td>-0.848656</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>0.832301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dri_score</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.325639e-17</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.397131</td>\n",
       "      <td>-1.397131</td>\n",
       "      <td>0.244748</td>\n",
       "      <td>0.371725</td>\n",
       "      <td>1.845122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyto_score</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>7.604015e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-2.026511</td>\n",
       "      <td>-0.313929</td>\n",
       "      <td>-0.313929</td>\n",
       "      <td>1.139100</td>\n",
       "      <td>1.139100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmv_status</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.866448e-18</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.649843</td>\n",
       "      <td>-0.709682</td>\n",
       "      <td>-0.709682</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.999684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyto_score_detail</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.093159e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-2.754647</td>\n",
       "      <td>-0.232054</td>\n",
       "      <td>-0.232054</td>\n",
       "      <td>0.242336</td>\n",
       "      <td>2.072887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor_age</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-2.601567e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-2.074114</td>\n",
       "      <td>-0.891539</td>\n",
       "      <td>-0.007019</td>\n",
       "      <td>0.899028</td>\n",
       "      <td>2.206925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_at_hct</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>-9.942296e-17</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-1.902698</td>\n",
       "      <td>-0.868602</td>\n",
       "      <td>0.134856</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>1.594868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psych_disturb_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.254664e-01</td>\n",
       "      <td>0.331256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.544362e-01</td>\n",
       "      <td>0.361376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_&gt;cGy</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.861318e-02</td>\n",
       "      <td>0.234905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_Cy</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.137749e-01</td>\n",
       "      <td>0.409980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_None</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>6.553690e-01</td>\n",
       "      <td>0.475260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_frac</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.249585e-03</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_single</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.301410e-03</td>\n",
       "      <td>0.065446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbi_status_unknown</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.332090e-03</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrhythmia_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.519071e-02</td>\n",
       "      <td>0.207728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graft_type_Marrow</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.873653e-01</td>\n",
       "      <td>0.452545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_hist_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.881426e-02</td>\n",
       "      <td>0.167289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renal_issue_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>6.478027e-03</td>\n",
       "      <td>0.080227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulm_severe_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.928690e-02</td>\n",
       "      <td>0.236167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_ALEU</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.850332e-03</td>\n",
       "      <td>0.053314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_ALL</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.823383e-01</td>\n",
       "      <td>0.450149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_AML</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.478752e-01</td>\n",
       "      <td>0.431790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_CML</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.182421e-04</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_HD</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.969320e-03</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_HIS</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.523632e-02</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IEA</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.120232e-02</td>\n",
       "      <td>0.220416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IIS</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.591418e-02</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IMD</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.716003e-03</td>\n",
       "      <td>0.068513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_IPA</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.996061e-02</td>\n",
       "      <td>0.237420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_LEU</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.197139e-02</td>\n",
       "      <td>0.108760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_MDS</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.048404e-01</td>\n",
       "      <td>0.306356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_MPN</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.669569e-02</td>\n",
       "      <td>0.231266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_NHL</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.513889e-02</td>\n",
       "      <td>0.207614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_PCD</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.088723e-02</td>\n",
       "      <td>0.173017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_SAA</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.456468e-02</td>\n",
       "      <td>0.154798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prim_disease_hct_SOL</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>6.892620e-03</td>\n",
       "      <td>0.082737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_G/G</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.148114e-01</td>\n",
       "      <td>0.410702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_H/B</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>8.240050e-03</td>\n",
       "      <td>0.090402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_H/H</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.788557e-02</td>\n",
       "      <td>0.213530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/B</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.332090e-03</td>\n",
       "      <td>0.048237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/G</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.036484e-03</td>\n",
       "      <td>0.032179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/H</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.746683e-03</td>\n",
       "      <td>0.052338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_imm_match_P/P</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>7.030991e-01</td>\n",
       "      <td>0.456904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rituximab_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.104063e-02</td>\n",
       "      <td>0.143523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prod_type_PB</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>7.071932e-01</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditioning_intensity_NMA</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.243263e-01</td>\n",
       "      <td>0.329962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditioning_intensity_None</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.953980e-03</td>\n",
       "      <td>0.054272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditioning_intensity_RIC</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.475850e-01</td>\n",
       "      <td>0.476216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity_-His+Lat</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>8.682110e-01</td>\n",
       "      <td>0.338270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity_Non-US</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.305970e-02</td>\n",
       "      <td>0.113533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obesity_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>6.172264e-02</td>\n",
       "      <td>0.240657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrd_hct_Positive</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.063640e-01</td>\n",
       "      <td>0.404705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_vivo_tcd_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.830328e-01</td>\n",
       "      <td>0.486139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_match_HvG non-per</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.036899e-02</td>\n",
       "      <td>0.171605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_match_Match</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.498549e-02</td>\n",
       "      <td>0.227958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_match_Per</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.890858e-01</td>\n",
       "      <td>0.492012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatic_severe_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.146144e-02</td>\n",
       "      <td>0.220943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior_tumor_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.067579e-01</td>\n",
       "      <td>0.308813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptic_ulcer_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>7.773632e-03</td>\n",
       "      <td>0.087827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CDsel+</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.021144e-03</td>\n",
       "      <td>0.044913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>6.944444e-03</td>\n",
       "      <td>0.083046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA+</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>9.328358e-04</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA+MMF</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>7.737355e-02</td>\n",
       "      <td>0.267190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_CSA+MTX+</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>8.291874e-03</td>\n",
       "      <td>0.090684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_Cyclop</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.860489e-01</td>\n",
       "      <td>0.389156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_Cyclop+</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>8.354063e-02</td>\n",
       "      <td>0.276705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_FK</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.399876e-02</td>\n",
       "      <td>0.205098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_FK+MMF</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>3.653089e-01</td>\n",
       "      <td>0.481529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_FK+MTX</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.472844e-01</td>\n",
       "      <td>0.354398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_GVHD</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.948590e-02</td>\n",
       "      <td>0.138229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_None</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>8.810116e-03</td>\n",
       "      <td>0.093450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_ParQ</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.176617e-03</td>\n",
       "      <td>0.046605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_T-DEP</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.984867e-02</td>\n",
       "      <td>0.139484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_T-DEP+</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.922678e-02</td>\n",
       "      <td>0.137325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvhd_proph_infrequent_sklearn</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.182421e-05</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheum_issue_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.565091e-02</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_match_F-M</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.748756e-01</td>\n",
       "      <td>0.446463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_match_M-F</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.371994e-01</td>\n",
       "      <td>0.425377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_match_M-M</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.806281e-01</td>\n",
       "      <td>0.449318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_Asian</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.683250e-01</td>\n",
       "      <td>0.374164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_Black or African-American</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.640755e-01</td>\n",
       "      <td>0.370354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_More than one race</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.669258e-01</td>\n",
       "      <td>0.372919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_Native Hawaiian or other Pacific Islander</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.641791e-01</td>\n",
       "      <td>0.370448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_group_White</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.693097e-01</td>\n",
       "      <td>0.375035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatic_mild_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>6.265547e-02</td>\n",
       "      <td>0.242349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_div_match_HvG no</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.052861e-02</td>\n",
       "      <td>0.219039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_div_match_No</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.161070e-02</td>\n",
       "      <td>0.145412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tce_div_match_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>7.223777e-01</td>\n",
       "      <td>0.447838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor_related_No</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>4.196725e-01</td>\n",
       "      <td>0.493518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor_related_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.680970e-01</td>\n",
       "      <td>0.495354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melphalan_dose_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>2.615568e-01</td>\n",
       "      <td>0.439494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiac_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.270522e-02</td>\n",
       "      <td>0.223450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulm_moderate_Yes</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.885883e-01</td>\n",
       "      <td>0.391191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efs</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>5.400083e-01</td>\n",
       "      <td>0.498410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efs_time</th>\n",
       "      <td>19296.0</td>\n",
       "      <td>1.204122e-16</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>-3.037316</td>\n",
       "      <td>-0.832033</td>\n",
       "      <td>-0.254804</td>\n",
       "      <td>0.939102</td>\n",
       "      <td>2.027252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      count          mean  \\\n",
       "hla_match_c_high                                    19296.0 -5.976424e-16   \n",
       "hla_high_res_8                                      19296.0  2.032647e-16   \n",
       "hla_low_res_6                                       19296.0  6.149494e-17   \n",
       "hla_high_res_6                                      19296.0 -7.898602e-17   \n",
       "hla_high_res_10                                     19296.0  1.653367e-16   \n",
       "hla_match_dqb1_high                                 19296.0 -1.509756e-16   \n",
       "hla_nmdp_6                                          19296.0  2.915486e-16   \n",
       "hla_match_c_low                                     19296.0 -2.581315e-16   \n",
       "hla_match_drb1_low                                  19296.0 -5.678156e-16   \n",
       "hla_match_dqb1_low                                  19296.0 -2.391674e-16   \n",
       "hla_match_a_high                                    19296.0 -5.628444e-16   \n",
       "hla_match_b_low                                     19296.0  4.405910e-16   \n",
       "hla_match_a_low                                     19296.0  2.503986e-16   \n",
       "hla_match_b_high                                    19296.0  1.668096e-16   \n",
       "comorbidity_score                                   19296.0  1.307228e-16   \n",
       "karnofsky_score                                     19296.0  3.107888e-16   \n",
       "hla_low_res_8                                       19296.0 -1.271325e-16   \n",
       "hla_match_drb1_high                                 19296.0  3.129982e-18   \n",
       "hla_low_res_10                                      19296.0 -5.983789e-17   \n",
       "dri_score                                           19296.0  1.325639e-17   \n",
       "cyto_score                                          19296.0  7.604015e-16   \n",
       "cmv_status                                          19296.0  3.866448e-18   \n",
       "cyto_score_detail                                   19296.0  3.093159e-16   \n",
       "donor_age                                           19296.0 -2.601567e-16   \n",
       "age_at_hct                                          19296.0 -9.942296e-17   \n",
       "psych_disturb_Yes                                   19296.0  1.254664e-01   \n",
       "diabetes_Yes                                        19296.0  1.544362e-01   \n",
       "tbi_status_>cGy                                     19296.0  5.861318e-02   \n",
       "tbi_status_Cy                                       19296.0  2.137749e-01   \n",
       "tbi_status_None                                     19296.0  6.553690e-01   \n",
       "tbi_status_frac                                     19296.0  4.249585e-03   \n",
       "tbi_status_single                                   19296.0  4.301410e-03   \n",
       "tbi_status_unknown                                  19296.0  2.332090e-03   \n",
       "arrhythmia_Yes                                      19296.0  4.519071e-02   \n",
       "graft_type_Marrow                                   19296.0  2.873653e-01   \n",
       "vent_hist_Yes                                       19296.0  2.881426e-02   \n",
       "renal_issue_Yes                                     19296.0  6.478027e-03   \n",
       "pulm_severe_Yes                                     19296.0  5.928690e-02   \n",
       "prim_disease_hct_ALEU                               19296.0  2.850332e-03   \n",
       "prim_disease_hct_ALL                                19296.0  2.823383e-01   \n",
       "prim_disease_hct_AML                                19296.0  2.478752e-01   \n",
       "prim_disease_hct_CML                                19296.0  5.182421e-04   \n",
       "prim_disease_hct_HD                                 19296.0  1.969320e-03   \n",
       "prim_disease_hct_HIS                                19296.0  1.523632e-02   \n",
       "prim_disease_hct_IEA                                19296.0  5.120232e-02   \n",
       "prim_disease_hct_IIS                                19296.0  3.591418e-02   \n",
       "prim_disease_hct_IMD                                19296.0  4.716003e-03   \n",
       "prim_disease_hct_IPA                                19296.0  5.996061e-02   \n",
       "prim_disease_hct_LEU                                19296.0  1.197139e-02   \n",
       "prim_disease_hct_MDS                                19296.0  1.048404e-01   \n",
       "prim_disease_hct_MPN                                19296.0  5.669569e-02   \n",
       "prim_disease_hct_NHL                                19296.0  4.513889e-02   \n",
       "prim_disease_hct_PCD                                19296.0  3.088723e-02   \n",
       "prim_disease_hct_SAA                                19296.0  2.456468e-02   \n",
       "prim_disease_hct_SOL                                19296.0  6.892620e-03   \n",
       "tce_imm_match_G/G                                   19296.0  2.148114e-01   \n",
       "tce_imm_match_H/B                                   19296.0  8.240050e-03   \n",
       "tce_imm_match_H/H                                   19296.0  4.788557e-02   \n",
       "tce_imm_match_P/B                                   19296.0  2.332090e-03   \n",
       "tce_imm_match_P/G                                   19296.0  1.036484e-03   \n",
       "tce_imm_match_P/H                                   19296.0  2.746683e-03   \n",
       "tce_imm_match_P/P                                   19296.0  7.030991e-01   \n",
       "rituximab_Yes                                       19296.0  2.104063e-02   \n",
       "prod_type_PB                                        19296.0  7.071932e-01   \n",
       "conditioning_intensity_NMA                          19296.0  1.243263e-01   \n",
       "conditioning_intensity_None                         19296.0  2.953980e-03   \n",
       "conditioning_intensity_RIC                          19296.0  3.475850e-01   \n",
       "ethnicity_-His+Lat                                  19296.0  8.682110e-01   \n",
       "ethnicity_Non-US                                    19296.0  1.305970e-02   \n",
       "obesity_Yes                                         19296.0  6.172264e-02   \n",
       "mrd_hct_Positive                                    19296.0  2.063640e-01   \n",
       "in_vivo_tcd_Yes                                     19296.0  3.830328e-01   \n",
       "tce_match_HvG non-per                               19296.0  3.036899e-02   \n",
       "tce_match_Match                                     19296.0  5.498549e-02   \n",
       "tce_match_Per                                       19296.0  5.890858e-01   \n",
       "hepatic_severe_Yes                                  19296.0  5.146144e-02   \n",
       "prior_tumor_Yes                                     19296.0  1.067579e-01   \n",
       "peptic_ulcer_Yes                                    19296.0  7.773632e-03   \n",
       "gvhd_proph_CDsel+                                   19296.0  2.021144e-03   \n",
       "gvhd_proph_CSA                                      19296.0  6.944444e-03   \n",
       "gvhd_proph_CSA+                                     19296.0  9.328358e-04   \n",
       "gvhd_proph_CSA+MMF                                  19296.0  7.737355e-02   \n",
       "gvhd_proph_CSA+MTX+                                 19296.0  8.291874e-03   \n",
       "gvhd_proph_Cyclop                                   19296.0  1.860489e-01   \n",
       "gvhd_proph_Cyclop+                                  19296.0  8.354063e-02   \n",
       "gvhd_proph_FK                                       19296.0  4.399876e-02   \n",
       "gvhd_proph_FK+MMF                                   19296.0  3.653089e-01   \n",
       "gvhd_proph_FK+MTX                                   19296.0  1.472844e-01   \n",
       "gvhd_proph_GVHD                                     19296.0  1.948590e-02   \n",
       "gvhd_proph_None                                     19296.0  8.810116e-03   \n",
       "gvhd_proph_ParQ                                     19296.0  2.176617e-03   \n",
       "gvhd_proph_T-DEP                                    19296.0  1.984867e-02   \n",
       "gvhd_proph_T-DEP+                                   19296.0  1.922678e-02   \n",
       "gvhd_proph_infrequent_sklearn                       19296.0  5.182421e-05   \n",
       "rheum_issue_Yes                                     19296.0  1.565091e-02   \n",
       "sex_match_F-M                                       19296.0  2.748756e-01   \n",
       "sex_match_M-F                                       19296.0  2.371994e-01   \n",
       "sex_match_M-M                                       19296.0  2.806281e-01   \n",
       "race_group_Asian                                    19296.0  1.683250e-01   \n",
       "race_group_Black or African-American                19296.0  1.640755e-01   \n",
       "race_group_More than one race                       19296.0  1.669258e-01   \n",
       "race_group_Native Hawaiian or other Pacific Isl...  19296.0  1.641791e-01   \n",
       "race_group_White                                    19296.0  1.693097e-01   \n",
       "hepatic_mild_Yes                                    19296.0  6.265547e-02   \n",
       "tce_div_match_HvG no                                19296.0  5.052861e-02   \n",
       "tce_div_match_No                                    19296.0  2.161070e-02   \n",
       "tce_div_match_Yes                                   19296.0  7.223777e-01   \n",
       "donor_related_No                                    19296.0  4.196725e-01   \n",
       "donor_related_Yes                                   19296.0  5.680970e-01   \n",
       "melphalan_dose_Yes                                  19296.0  2.615568e-01   \n",
       "cardiac_Yes                                         19296.0  5.270522e-02   \n",
       "pulm_moderate_Yes                                   19296.0  1.885883e-01   \n",
       "efs                                                 19296.0  5.400083e-01   \n",
       "efs_time                                            19296.0  1.204122e-16   \n",
       "\n",
       "                                                         std       min  \\\n",
       "hla_match_c_high                                    1.000026 -1.856378   \n",
       "hla_high_res_8                                      1.000026 -1.793383   \n",
       "hla_low_res_6                                       1.000026 -1.750950   \n",
       "hla_high_res_6                                      1.000026 -1.817129   \n",
       "hla_high_res_10                                     1.000026 -1.794703   \n",
       "hla_match_dqb1_high                                 1.000026 -1.781526   \n",
       "hla_nmdp_6                                          1.000026 -1.764762   \n",
       "hla_match_c_low                                     1.000026 -1.832826   \n",
       "hla_match_drb1_low                                  1.000026 -1.584976   \n",
       "hla_match_dqb1_low                                  1.000026 -1.902492   \n",
       "hla_match_a_high                                    1.000026 -1.725887   \n",
       "hla_match_b_low                                     1.000026 -1.739677   \n",
       "hla_match_a_low                                     1.000026 -1.721925   \n",
       "hla_match_b_high                                    1.000026 -1.725156   \n",
       "comorbidity_score                                   1.000026 -1.161507   \n",
       "karnofsky_score                                     1.000026 -2.354341   \n",
       "hla_low_res_8                                       1.000026 -1.751903   \n",
       "hla_match_drb1_high                                 1.000026 -1.726623   \n",
       "hla_low_res_10                                      1.000026 -1.765754   \n",
       "dri_score                                           1.000026 -1.397131   \n",
       "cyto_score                                          1.000026 -2.026511   \n",
       "cmv_status                                          1.000026 -1.649843   \n",
       "cyto_score_detail                                   1.000026 -2.754647   \n",
       "donor_age                                           1.000026 -2.074114   \n",
       "age_at_hct                                          1.000026 -1.902698   \n",
       "psych_disturb_Yes                                   0.331256  0.000000   \n",
       "diabetes_Yes                                        0.361376  0.000000   \n",
       "tbi_status_>cGy                                     0.234905  0.000000   \n",
       "tbi_status_Cy                                       0.409980  0.000000   \n",
       "tbi_status_None                                     0.475260  0.000000   \n",
       "tbi_status_frac                                     0.065052  0.000000   \n",
       "tbi_status_single                                   0.065446  0.000000   \n",
       "tbi_status_unknown                                  0.048237  0.000000   \n",
       "arrhythmia_Yes                                      0.207728  0.000000   \n",
       "graft_type_Marrow                                   0.452545  0.000000   \n",
       "vent_hist_Yes                                       0.167289  0.000000   \n",
       "renal_issue_Yes                                     0.080227  0.000000   \n",
       "pulm_severe_Yes                                     0.236167  0.000000   \n",
       "prim_disease_hct_ALEU                               0.053314  0.000000   \n",
       "prim_disease_hct_ALL                                0.450149  0.000000   \n",
       "prim_disease_hct_AML                                0.431790  0.000000   \n",
       "prim_disease_hct_CML                                0.022760  0.000000   \n",
       "prim_disease_hct_HD                                 0.044334  0.000000   \n",
       "prim_disease_hct_HIS                                0.122495  0.000000   \n",
       "prim_disease_hct_IEA                                0.220416  0.000000   \n",
       "prim_disease_hct_IIS                                0.186081  0.000000   \n",
       "prim_disease_hct_IMD                                0.068513  0.000000   \n",
       "prim_disease_hct_IPA                                0.237420  0.000000   \n",
       "prim_disease_hct_LEU                                0.108760  0.000000   \n",
       "prim_disease_hct_MDS                                0.306356  0.000000   \n",
       "prim_disease_hct_MPN                                0.231266  0.000000   \n",
       "prim_disease_hct_NHL                                0.207614  0.000000   \n",
       "prim_disease_hct_PCD                                0.173017  0.000000   \n",
       "prim_disease_hct_SAA                                0.154798  0.000000   \n",
       "prim_disease_hct_SOL                                0.082737  0.000000   \n",
       "tce_imm_match_G/G                                   0.410702  0.000000   \n",
       "tce_imm_match_H/B                                   0.090402  0.000000   \n",
       "tce_imm_match_H/H                                   0.213530  0.000000   \n",
       "tce_imm_match_P/B                                   0.048237  0.000000   \n",
       "tce_imm_match_P/G                                   0.032179  0.000000   \n",
       "tce_imm_match_P/H                                   0.052338  0.000000   \n",
       "tce_imm_match_P/P                                   0.456904  0.000000   \n",
       "rituximab_Yes                                       0.143523  0.000000   \n",
       "prod_type_PB                                        0.455062  0.000000   \n",
       "conditioning_intensity_NMA                          0.329962  0.000000   \n",
       "conditioning_intensity_None                         0.054272  0.000000   \n",
       "conditioning_intensity_RIC                          0.476216  0.000000   \n",
       "ethnicity_-His+Lat                                  0.338270  0.000000   \n",
       "ethnicity_Non-US                                    0.113533  0.000000   \n",
       "obesity_Yes                                         0.240657  0.000000   \n",
       "mrd_hct_Positive                                    0.404705  0.000000   \n",
       "in_vivo_tcd_Yes                                     0.486139  0.000000   \n",
       "tce_match_HvG non-per                               0.171605  0.000000   \n",
       "tce_match_Match                                     0.227958  0.000000   \n",
       "tce_match_Per                                       0.492012  0.000000   \n",
       "hepatic_severe_Yes                                  0.220943  0.000000   \n",
       "prior_tumor_Yes                                     0.308813  0.000000   \n",
       "peptic_ulcer_Yes                                    0.087827  0.000000   \n",
       "gvhd_proph_CDsel+                                   0.044913  0.000000   \n",
       "gvhd_proph_CSA                                      0.083046  0.000000   \n",
       "gvhd_proph_CSA+                                     0.030529  0.000000   \n",
       "gvhd_proph_CSA+MMF                                  0.267190  0.000000   \n",
       "gvhd_proph_CSA+MTX+                                 0.090684  0.000000   \n",
       "gvhd_proph_Cyclop                                   0.389156  0.000000   \n",
       "gvhd_proph_Cyclop+                                  0.276705  0.000000   \n",
       "gvhd_proph_FK                                       0.205098  0.000000   \n",
       "gvhd_proph_FK+MMF                                   0.481529  0.000000   \n",
       "gvhd_proph_FK+MTX                                   0.354398  0.000000   \n",
       "gvhd_proph_GVHD                                     0.138229  0.000000   \n",
       "gvhd_proph_None                                     0.093450  0.000000   \n",
       "gvhd_proph_ParQ                                     0.046605  0.000000   \n",
       "gvhd_proph_T-DEP                                    0.139484  0.000000   \n",
       "gvhd_proph_T-DEP+                                   0.137325  0.000000   \n",
       "gvhd_proph_infrequent_sklearn                       0.007199  0.000000   \n",
       "rheum_issue_Yes                                     0.124124  0.000000   \n",
       "sex_match_F-M                                       0.446463  0.000000   \n",
       "sex_match_M-F                                       0.425377  0.000000   \n",
       "sex_match_M-M                                       0.449318  0.000000   \n",
       "race_group_Asian                                    0.374164  0.000000   \n",
       "race_group_Black or African-American                0.370354  0.000000   \n",
       "race_group_More than one race                       0.372919  0.000000   \n",
       "race_group_Native Hawaiian or other Pacific Isl...  0.370448  0.000000   \n",
       "race_group_White                                    0.375035  0.000000   \n",
       "hepatic_mild_Yes                                    0.242349  0.000000   \n",
       "tce_div_match_HvG no                                0.219039  0.000000   \n",
       "tce_div_match_No                                    0.145412  0.000000   \n",
       "tce_div_match_Yes                                   0.447838  0.000000   \n",
       "donor_related_No                                    0.493518  0.000000   \n",
       "donor_related_Yes                                   0.495354  0.000000   \n",
       "melphalan_dose_Yes                                  0.439494  0.000000   \n",
       "cardiac_Yes                                         0.223450  0.000000   \n",
       "pulm_moderate_Yes                                   0.391191  0.000000   \n",
       "efs                                                 0.498410  0.000000   \n",
       "efs_time                                            1.000026 -3.037316   \n",
       "\n",
       "                                                         25%       50%  \\\n",
       "hla_match_c_high                                   -0.565358  0.605538   \n",
       "hla_high_res_8                                     -0.986511  0.837211   \n",
       "hla_low_res_6                                      -1.264762  0.806635   \n",
       "hla_high_res_6                                     -1.212899  0.841482   \n",
       "hla_high_res_10                                    -0.979010  0.637790   \n",
       "hla_match_dqb1_high                                -1.005030  0.655567   \n",
       "hla_nmdp_6                                         -0.759603  0.813259   \n",
       "hla_match_c_low                                    -0.519834  0.602771   \n",
       "hla_match_drb1_low                                 -1.584976  0.673036   \n",
       "hla_match_dqb1_low                                 -0.653310  0.584758   \n",
       "hla_match_a_high                                   -1.560534  0.702089   \n",
       "hla_match_b_low                                    -1.616513  0.659026   \n",
       "hla_match_a_low                                    -1.574425  0.675510   \n",
       "hla_match_b_high                                   -1.547044  0.703355   \n",
       "comorbidity_score                                  -1.161507 -0.006807   \n",
       "karnofsky_score                                    -1.270098  0.499163   \n",
       "hla_low_res_8                                      -1.029529  0.812482   \n",
       "hla_match_drb1_high                                -1.571972  0.684010   \n",
       "hla_low_res_10                                     -0.848656  0.832301   \n",
       "dri_score                                          -1.397131  0.244748   \n",
       "cyto_score                                         -0.313929 -0.313929   \n",
       "cmv_status                                         -0.709682 -0.709682   \n",
       "cyto_score_detail                                  -0.232054 -0.232054   \n",
       "donor_age                                          -0.891539 -0.007019   \n",
       "age_at_hct                                         -0.868602  0.134856   \n",
       "psych_disturb_Yes                                   0.000000  0.000000   \n",
       "diabetes_Yes                                        0.000000  0.000000   \n",
       "tbi_status_>cGy                                     0.000000  0.000000   \n",
       "tbi_status_Cy                                       0.000000  0.000000   \n",
       "tbi_status_None                                     0.000000  1.000000   \n",
       "tbi_status_frac                                     0.000000  0.000000   \n",
       "tbi_status_single                                   0.000000  0.000000   \n",
       "tbi_status_unknown                                  0.000000  0.000000   \n",
       "arrhythmia_Yes                                      0.000000  0.000000   \n",
       "graft_type_Marrow                                   0.000000  0.000000   \n",
       "vent_hist_Yes                                       0.000000  0.000000   \n",
       "renal_issue_Yes                                     0.000000  0.000000   \n",
       "pulm_severe_Yes                                     0.000000  0.000000   \n",
       "prim_disease_hct_ALEU                               0.000000  0.000000   \n",
       "prim_disease_hct_ALL                                0.000000  0.000000   \n",
       "prim_disease_hct_AML                                0.000000  0.000000   \n",
       "prim_disease_hct_CML                                0.000000  0.000000   \n",
       "prim_disease_hct_HD                                 0.000000  0.000000   \n",
       "prim_disease_hct_HIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IEA                                0.000000  0.000000   \n",
       "prim_disease_hct_IIS                                0.000000  0.000000   \n",
       "prim_disease_hct_IMD                                0.000000  0.000000   \n",
       "prim_disease_hct_IPA                                0.000000  0.000000   \n",
       "prim_disease_hct_LEU                                0.000000  0.000000   \n",
       "prim_disease_hct_MDS                                0.000000  0.000000   \n",
       "prim_disease_hct_MPN                                0.000000  0.000000   \n",
       "prim_disease_hct_NHL                                0.000000  0.000000   \n",
       "prim_disease_hct_PCD                                0.000000  0.000000   \n",
       "prim_disease_hct_SAA                                0.000000  0.000000   \n",
       "prim_disease_hct_SOL                                0.000000  0.000000   \n",
       "tce_imm_match_G/G                                   0.000000  0.000000   \n",
       "tce_imm_match_H/B                                   0.000000  0.000000   \n",
       "tce_imm_match_H/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/B                                   0.000000  0.000000   \n",
       "tce_imm_match_P/G                                   0.000000  0.000000   \n",
       "tce_imm_match_P/H                                   0.000000  0.000000   \n",
       "tce_imm_match_P/P                                   0.000000  1.000000   \n",
       "rituximab_Yes                                       0.000000  0.000000   \n",
       "prod_type_PB                                        0.000000  1.000000   \n",
       "conditioning_intensity_NMA                          0.000000  0.000000   \n",
       "conditioning_intensity_None                         0.000000  0.000000   \n",
       "conditioning_intensity_RIC                          0.000000  0.000000   \n",
       "ethnicity_-His+Lat                                  1.000000  1.000000   \n",
       "ethnicity_Non-US                                    0.000000  0.000000   \n",
       "obesity_Yes                                         0.000000  0.000000   \n",
       "mrd_hct_Positive                                    0.000000  0.000000   \n",
       "in_vivo_tcd_Yes                                     0.000000  0.000000   \n",
       "tce_match_HvG non-per                               0.000000  0.000000   \n",
       "tce_match_Match                                     0.000000  0.000000   \n",
       "tce_match_Per                                       0.000000  1.000000   \n",
       "hepatic_severe_Yes                                  0.000000  0.000000   \n",
       "prior_tumor_Yes                                     0.000000  0.000000   \n",
       "peptic_ulcer_Yes                                    0.000000  0.000000   \n",
       "gvhd_proph_CDsel+                                   0.000000  0.000000   \n",
       "gvhd_proph_CSA                                      0.000000  0.000000   \n",
       "gvhd_proph_CSA+                                     0.000000  0.000000   \n",
       "gvhd_proph_CSA+MMF                                  0.000000  0.000000   \n",
       "gvhd_proph_CSA+MTX+                                 0.000000  0.000000   \n",
       "gvhd_proph_Cyclop                                   0.000000  0.000000   \n",
       "gvhd_proph_Cyclop+                                  0.000000  0.000000   \n",
       "gvhd_proph_FK                                       0.000000  0.000000   \n",
       "gvhd_proph_FK+MMF                                   0.000000  0.000000   \n",
       "gvhd_proph_FK+MTX                                   0.000000  0.000000   \n",
       "gvhd_proph_GVHD                                     0.000000  0.000000   \n",
       "gvhd_proph_None                                     0.000000  0.000000   \n",
       "gvhd_proph_ParQ                                     0.000000  0.000000   \n",
       "gvhd_proph_T-DEP                                    0.000000  0.000000   \n",
       "gvhd_proph_T-DEP+                                   0.000000  0.000000   \n",
       "gvhd_proph_infrequent_sklearn                       0.000000  0.000000   \n",
       "rheum_issue_Yes                                     0.000000  0.000000   \n",
       "sex_match_F-M                                       0.000000  0.000000   \n",
       "sex_match_M-F                                       0.000000  0.000000   \n",
       "sex_match_M-M                                       0.000000  0.000000   \n",
       "race_group_Asian                                    0.000000  0.000000   \n",
       "race_group_Black or African-American                0.000000  0.000000   \n",
       "race_group_More than one race                       0.000000  0.000000   \n",
       "race_group_Native Hawaiian or other Pacific Isl...  0.000000  0.000000   \n",
       "race_group_White                                    0.000000  0.000000   \n",
       "hepatic_mild_Yes                                    0.000000  0.000000   \n",
       "tce_div_match_HvG no                                0.000000  0.000000   \n",
       "tce_div_match_No                                    0.000000  0.000000   \n",
       "tce_div_match_Yes                                   0.000000  1.000000   \n",
       "donor_related_No                                    0.000000  0.000000   \n",
       "donor_related_Yes                                   0.000000  1.000000   \n",
       "melphalan_dose_Yes                                  0.000000  0.000000   \n",
       "cardiac_Yes                                         0.000000  0.000000   \n",
       "pulm_moderate_Yes                                   0.000000  0.000000   \n",
       "efs                                                 0.000000  1.000000   \n",
       "efs_time                                           -0.832033 -0.254804   \n",
       "\n",
       "                                                         75%       max  \n",
       "hla_match_c_high                                    0.605538  0.605538  \n",
       "hla_high_res_8                                      0.837211  0.837211  \n",
       "hla_low_res_6                                       0.806635  0.806635  \n",
       "hla_high_res_6                                      0.841482  0.841482  \n",
       "hla_high_res_10                                     0.859768  0.859768  \n",
       "hla_match_dqb1_high                                 0.655567  0.655567  \n",
       "hla_nmdp_6                                          0.813259  0.813259  \n",
       "hla_match_c_low                                     0.602771  0.602771  \n",
       "hla_match_drb1_low                                  0.673036  0.673036  \n",
       "hla_match_dqb1_low                                  0.584758  0.584758  \n",
       "hla_match_a_high                                    0.702089  0.702089  \n",
       "hla_match_b_low                                     0.659026  0.659026  \n",
       "hla_match_a_low                                     0.675510  0.675510  \n",
       "hla_match_b_high                                    0.703355  0.703355  \n",
       "comorbidity_score                                   0.575116  2.063844  \n",
       "karnofsky_score                                     0.499163  1.845853  \n",
       "hla_low_res_8                                       0.812482  0.812482  \n",
       "hla_match_drb1_high                                 0.684010  0.684010  \n",
       "hla_low_res_10                                      0.832301  0.832301  \n",
       "dri_score                                           0.371725  1.845122  \n",
       "cyto_score                                          1.139100  1.139100  \n",
       "cmv_status                                          0.999684  0.999684  \n",
       "cyto_score_detail                                   0.242336  2.072887  \n",
       "donor_age                                           0.899028  2.206925  \n",
       "age_at_hct                                          0.814711  1.594868  \n",
       "psych_disturb_Yes                                   0.000000  1.000000  \n",
       "diabetes_Yes                                        0.000000  1.000000  \n",
       "tbi_status_>cGy                                     0.000000  1.000000  \n",
       "tbi_status_Cy                                       0.000000  1.000000  \n",
       "tbi_status_None                                     1.000000  1.000000  \n",
       "tbi_status_frac                                     0.000000  1.000000  \n",
       "tbi_status_single                                   0.000000  1.000000  \n",
       "tbi_status_unknown                                  0.000000  1.000000  \n",
       "arrhythmia_Yes                                      0.000000  1.000000  \n",
       "graft_type_Marrow                                   1.000000  1.000000  \n",
       "vent_hist_Yes                                       0.000000  1.000000  \n",
       "renal_issue_Yes                                     0.000000  1.000000  \n",
       "pulm_severe_Yes                                     0.000000  1.000000  \n",
       "prim_disease_hct_ALEU                               0.000000  1.000000  \n",
       "prim_disease_hct_ALL                                1.000000  1.000000  \n",
       "prim_disease_hct_AML                                0.000000  1.000000  \n",
       "prim_disease_hct_CML                                0.000000  1.000000  \n",
       "prim_disease_hct_HD                                 0.000000  1.000000  \n",
       "prim_disease_hct_HIS                                0.000000  1.000000  \n",
       "prim_disease_hct_IEA                                0.000000  1.000000  \n",
       "prim_disease_hct_IIS                                0.000000  1.000000  \n",
       "prim_disease_hct_IMD                                0.000000  1.000000  \n",
       "prim_disease_hct_IPA                                0.000000  1.000000  \n",
       "prim_disease_hct_LEU                                0.000000  1.000000  \n",
       "prim_disease_hct_MDS                                0.000000  1.000000  \n",
       "prim_disease_hct_MPN                                0.000000  1.000000  \n",
       "prim_disease_hct_NHL                                0.000000  1.000000  \n",
       "prim_disease_hct_PCD                                0.000000  1.000000  \n",
       "prim_disease_hct_SAA                                0.000000  1.000000  \n",
       "prim_disease_hct_SOL                                0.000000  1.000000  \n",
       "tce_imm_match_G/G                                   0.000000  1.000000  \n",
       "tce_imm_match_H/B                                   0.000000  1.000000  \n",
       "tce_imm_match_H/H                                   0.000000  1.000000  \n",
       "tce_imm_match_P/B                                   0.000000  1.000000  \n",
       "tce_imm_match_P/G                                   0.000000  1.000000  \n",
       "tce_imm_match_P/H                                   0.000000  1.000000  \n",
       "tce_imm_match_P/P                                   1.000000  1.000000  \n",
       "rituximab_Yes                                       0.000000  1.000000  \n",
       "prod_type_PB                                        1.000000  1.000000  \n",
       "conditioning_intensity_NMA                          0.000000  1.000000  \n",
       "conditioning_intensity_None                         0.000000  1.000000  \n",
       "conditioning_intensity_RIC                          1.000000  1.000000  \n",
       "ethnicity_-His+Lat                                  1.000000  1.000000  \n",
       "ethnicity_Non-US                                    0.000000  1.000000  \n",
       "obesity_Yes                                         0.000000  1.000000  \n",
       "mrd_hct_Positive                                    0.000000  1.000000  \n",
       "in_vivo_tcd_Yes                                     1.000000  1.000000  \n",
       "tce_match_HvG non-per                               0.000000  1.000000  \n",
       "tce_match_Match                                     0.000000  1.000000  \n",
       "tce_match_Per                                       1.000000  1.000000  \n",
       "hepatic_severe_Yes                                  0.000000  1.000000  \n",
       "prior_tumor_Yes                                     0.000000  1.000000  \n",
       "peptic_ulcer_Yes                                    0.000000  1.000000  \n",
       "gvhd_proph_CDsel+                                   0.000000  1.000000  \n",
       "gvhd_proph_CSA                                      0.000000  1.000000  \n",
       "gvhd_proph_CSA+                                     0.000000  1.000000  \n",
       "gvhd_proph_CSA+MMF                                  0.000000  1.000000  \n",
       "gvhd_proph_CSA+MTX+                                 0.000000  1.000000  \n",
       "gvhd_proph_Cyclop                                   0.000000  1.000000  \n",
       "gvhd_proph_Cyclop+                                  0.000000  1.000000  \n",
       "gvhd_proph_FK                                       0.000000  1.000000  \n",
       "gvhd_proph_FK+MMF                                   1.000000  1.000000  \n",
       "gvhd_proph_FK+MTX                                   0.000000  1.000000  \n",
       "gvhd_proph_GVHD                                     0.000000  1.000000  \n",
       "gvhd_proph_None                                     0.000000  1.000000  \n",
       "gvhd_proph_ParQ                                     0.000000  1.000000  \n",
       "gvhd_proph_T-DEP                                    0.000000  1.000000  \n",
       "gvhd_proph_T-DEP+                                   0.000000  1.000000  \n",
       "gvhd_proph_infrequent_sklearn                       0.000000  1.000000  \n",
       "rheum_issue_Yes                                     0.000000  1.000000  \n",
       "sex_match_F-M                                       1.000000  1.000000  \n",
       "sex_match_M-F                                       0.000000  1.000000  \n",
       "sex_match_M-M                                       1.000000  1.000000  \n",
       "race_group_Asian                                    0.000000  1.000000  \n",
       "race_group_Black or African-American                0.000000  1.000000  \n",
       "race_group_More than one race                       0.000000  1.000000  \n",
       "race_group_Native Hawaiian or other Pacific Isl...  0.000000  1.000000  \n",
       "race_group_White                                    0.000000  1.000000  \n",
       "hepatic_mild_Yes                                    0.000000  1.000000  \n",
       "tce_div_match_HvG no                                0.000000  1.000000  \n",
       "tce_div_match_No                                    0.000000  1.000000  \n",
       "tce_div_match_Yes                                   1.000000  1.000000  \n",
       "donor_related_No                                    1.000000  1.000000  \n",
       "donor_related_Yes                                   1.000000  1.000000  \n",
       "melphalan_dose_Yes                                  1.000000  1.000000  \n",
       "cardiac_Yes                                         0.000000  1.000000  \n",
       "pulm_moderate_Yes                                   0.000000  1.000000  \n",
       "efs                                                 1.000000  1.000000  \n",
       "efs_time                                            0.939102  2.027252  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering\n",
    "\n",
    "### 3.1. Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation log-loss: 0.666 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "if retrain_tree == True:\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.3, random_state=315)\n",
    "\n",
    "    scores=cross_val_score(\n",
    "        GradientBoostingClassifier(random_state=315),\n",
    "        training_features_df,\n",
    "        training_labels_df['efs'],\n",
    "        cv=cv\n",
    "    )\n",
    "\n",
    "    print(f'Cross-validation log-loss: {np.array(scores).mean():.3f} +/- {np.array(scores).std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.655\n",
      "Recall: 0.786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if retrain_tree == True:\n",
    "    tree_model=GradientBoostingClassifier(random_state=315)\n",
    "    tree_model.fit(training_features_df, training_labels_df['efs'])\n",
    "\n",
    "    predictions=tree_model.predict(testing_features_df)\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision=precision_score(testing_labels_df['efs'], predictions)\n",
    "    recall=recall_score(testing_labels_df['efs'], predictions)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    cm=confusion_matrix(testing_labels_df['efs'], predictions, normalize='true')\n",
    "    cm_disp=ConfusionMatrixDisplay(confusion_matrix=cm)#, display_labels=['0', 'EFS 1'])\n",
    "    _=cm_disp.plot()\n",
    "\n",
    "    plt.title('Test set gradient boosting classifier performance')\n",
    "    plt.xlabel('Predicted EFS')\n",
    "    plt.ylabel('True EFS')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f'Precision: {precision:.3f}')\n",
    "    print(f'Recall: {recall:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=0.002\n",
    "l2=0.0002\n",
    "learning_rate=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 08:11:47.165171: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-02-21 08:11:47.165328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-02-21 08:11:47.165348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2025-02-21 08:11:52.605512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7397 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:07:00.0, compute capability: 6.1\n",
      "2025-02-21 08:11:52.606717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10785 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7\n",
      "2025-02-21 08:11:52.607762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10785 MB memory:  -> device: 2, name: Tesla K80, pci bus id: 0000:06:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 08:11:55.388502: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f25d0002a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-02-21 08:11:55.388538: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2025-02-21 08:11:55.388550: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n",
      "2025-02-21 08:11:55.388559: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Tesla K80, Compute Capability 3.7\n",
      "2025-02-21 08:11:55.396639: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-21 08:11:55.555282: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 5s 17ms/step - loss: 10.6236 - precision: 0.5866 - recall: 0.5622 - val_loss: 10.6195 - val_precision: 0.5681 - val_recall: 0.5580\n",
      "Epoch 2/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.6148 - precision: 0.5868 - recall: 0.5645 - val_loss: 10.6107 - val_precision: 0.5683 - val_recall: 0.5619\n",
      "Epoch 3/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.6059 - precision: 0.5877 - recall: 0.5708 - val_loss: 10.6018 - val_precision: 0.5681 - val_recall: 0.5681\n",
      "Epoch 4/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5971 - precision: 0.5874 - recall: 0.5739 - val_loss: 10.5930 - val_precision: 0.5684 - val_recall: 0.5720\n",
      "Epoch 5/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5883 - precision: 0.5882 - recall: 0.5792 - val_loss: 10.5842 - val_precision: 0.5695 - val_recall: 0.5774\n",
      "Epoch 6/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5795 - precision: 0.5892 - recall: 0.5864 - val_loss: 10.5753 - val_precision: 0.5689 - val_recall: 0.5848\n",
      "Epoch 7/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5706 - precision: 0.5893 - recall: 0.5915 - val_loss: 10.5665 - val_precision: 0.5690 - val_recall: 0.5887\n",
      "Epoch 8/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5618 - precision: 0.5889 - recall: 0.5972 - val_loss: 10.5577 - val_precision: 0.5687 - val_recall: 0.5930\n",
      "Epoch 9/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.5530 - precision: 0.5889 - recall: 0.6019 - val_loss: 10.5488 - val_precision: 0.5682 - val_recall: 0.6000\n",
      "Epoch 10/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.5442 - precision: 0.5889 - recall: 0.6056 - val_loss: 10.5400 - val_precision: 0.5679 - val_recall: 0.6039\n",
      "Epoch 11/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5354 - precision: 0.5894 - recall: 0.6115 - val_loss: 10.5312 - val_precision: 0.5684 - val_recall: 0.6097\n",
      "Epoch 12/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5266 - precision: 0.5900 - recall: 0.6150 - val_loss: 10.5224 - val_precision: 0.5697 - val_recall: 0.6136\n",
      "Epoch 13/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5178 - precision: 0.5903 - recall: 0.6233 - val_loss: 10.5136 - val_precision: 0.5707 - val_recall: 0.6237\n",
      "Epoch 14/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.5090 - precision: 0.5916 - recall: 0.6304 - val_loss: 10.5048 - val_precision: 0.5709 - val_recall: 0.6280\n",
      "Epoch 15/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.5002 - precision: 0.5918 - recall: 0.6354 - val_loss: 10.4960 - val_precision: 0.5710 - val_recall: 0.6339\n",
      "Epoch 16/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.4915 - precision: 0.5920 - recall: 0.6406 - val_loss: 10.4872 - val_precision: 0.5716 - val_recall: 0.6366\n",
      "Epoch 17/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.4827 - precision: 0.5924 - recall: 0.6442 - val_loss: 10.4784 - val_precision: 0.5726 - val_recall: 0.6412\n",
      "Epoch 18/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.4739 - precision: 0.5921 - recall: 0.6488 - val_loss: 10.4697 - val_precision: 0.5720 - val_recall: 0.6463\n",
      "Epoch 19/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.4651 - precision: 0.5925 - recall: 0.6517 - val_loss: 10.4609 - val_precision: 0.5731 - val_recall: 0.6498\n",
      "Epoch 20/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.4564 - precision: 0.5932 - recall: 0.6558 - val_loss: 10.4521 - val_precision: 0.5733 - val_recall: 0.6556\n",
      "Epoch 21/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.4476 - precision: 0.5929 - recall: 0.6572 - val_loss: 10.4433 - val_precision: 0.5730 - val_recall: 0.6568\n",
      "Epoch 22/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.4389 - precision: 0.5924 - recall: 0.6618 - val_loss: 10.4346 - val_precision: 0.5735 - val_recall: 0.6603\n",
      "Epoch 23/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.4301 - precision: 0.5920 - recall: 0.6659 - val_loss: 10.4258 - val_precision: 0.5741 - val_recall: 0.6650\n",
      "Epoch 24/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.4214 - precision: 0.5920 - recall: 0.6670 - val_loss: 10.4171 - val_precision: 0.5755 - val_recall: 0.6677\n",
      "Epoch 25/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 10.4126 - precision: 0.5909 - recall: 0.6735 - val_loss: 10.4083 - val_precision: 0.5740 - val_recall: 0.6712\n",
      "Epoch 26/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.4039 - precision: 0.5914 - recall: 0.6761 - val_loss: 10.3996 - val_precision: 0.5753 - val_recall: 0.6747\n",
      "Epoch 27/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.3952 - precision: 0.5919 - recall: 0.6777 - val_loss: 10.3908 - val_precision: 0.5757 - val_recall: 0.6763\n",
      "Epoch 28/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.3864 - precision: 0.5929 - recall: 0.6833 - val_loss: 10.3821 - val_precision: 0.5758 - val_recall: 0.6809\n",
      "Epoch 29/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.3777 - precision: 0.5929 - recall: 0.6878 - val_loss: 10.3734 - val_precision: 0.5762 - val_recall: 0.6868\n",
      "Epoch 30/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.3690 - precision: 0.5935 - recall: 0.6890 - val_loss: 10.3646 - val_precision: 0.5762 - val_recall: 0.6883\n",
      "Epoch 31/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.3603 - precision: 0.5944 - recall: 0.6927 - val_loss: 10.3559 - val_precision: 0.5761 - val_recall: 0.6907\n",
      "Epoch 32/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.3516 - precision: 0.5942 - recall: 0.6964 - val_loss: 10.3472 - val_precision: 0.5768 - val_recall: 0.6957\n",
      "Epoch 33/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.3429 - precision: 0.5942 - recall: 0.7024 - val_loss: 10.3385 - val_precision: 0.5752 - val_recall: 0.6992\n",
      "Epoch 34/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.3341 - precision: 0.5942 - recall: 0.7054 - val_loss: 10.3298 - val_precision: 0.5755 - val_recall: 0.7027\n",
      "Epoch 35/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.3254 - precision: 0.5945 - recall: 0.7064 - val_loss: 10.3210 - val_precision: 0.5757 - val_recall: 0.7039\n",
      "Epoch 36/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.3167 - precision: 0.5942 - recall: 0.7098 - val_loss: 10.3123 - val_precision: 0.5764 - val_recall: 0.7089\n",
      "Epoch 37/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.3081 - precision: 0.5946 - recall: 0.7140 - val_loss: 10.3036 - val_precision: 0.5763 - val_recall: 0.7113\n",
      "Epoch 38/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2994 - precision: 0.5946 - recall: 0.7157 - val_loss: 10.2949 - val_precision: 0.5766 - val_recall: 0.7132\n",
      "Epoch 39/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2907 - precision: 0.5954 - recall: 0.7214 - val_loss: 10.2862 - val_precision: 0.5768 - val_recall: 0.7191\n",
      "Epoch 40/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.2820 - precision: 0.5956 - recall: 0.7233 - val_loss: 10.2776 - val_precision: 0.5778 - val_recall: 0.7206\n",
      "Epoch 41/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2733 - precision: 0.5954 - recall: 0.7242 - val_loss: 10.2689 - val_precision: 0.5778 - val_recall: 0.7226\n",
      "Epoch 42/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2646 - precision: 0.5956 - recall: 0.7268 - val_loss: 10.2602 - val_precision: 0.5784 - val_recall: 0.7249\n",
      "Epoch 43/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2560 - precision: 0.5957 - recall: 0.7304 - val_loss: 10.2515 - val_precision: 0.5783 - val_recall: 0.7288\n",
      "Epoch 44/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2473 - precision: 0.5961 - recall: 0.7339 - val_loss: 10.2428 - val_precision: 0.5778 - val_recall: 0.7311\n",
      "Epoch 45/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2387 - precision: 0.5960 - recall: 0.7346 - val_loss: 10.2342 - val_precision: 0.5784 - val_recall: 0.7335\n",
      "Epoch 46/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.2300 - precision: 0.5964 - recall: 0.7386 - val_loss: 10.2255 - val_precision: 0.5782 - val_recall: 0.7366\n",
      "Epoch 47/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.2213 - precision: 0.5967 - recall: 0.7399 - val_loss: 10.2169 - val_precision: 0.5790 - val_recall: 0.7385\n",
      "Epoch 48/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2127 - precision: 0.5969 - recall: 0.7418 - val_loss: 10.2082 - val_precision: 0.5789 - val_recall: 0.7420\n",
      "Epoch 49/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.2041 - precision: 0.5970 - recall: 0.7445 - val_loss: 10.1995 - val_precision: 0.5793 - val_recall: 0.7447\n",
      "Epoch 50/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1954 - precision: 0.5974 - recall: 0.7465 - val_loss: 10.1909 - val_precision: 0.5789 - val_recall: 0.7455\n",
      "Epoch 51/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1868 - precision: 0.5975 - recall: 0.7487 - val_loss: 10.1823 - val_precision: 0.5794 - val_recall: 0.7467\n",
      "Epoch 52/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1781 - precision: 0.5977 - recall: 0.7520 - val_loss: 10.1736 - val_precision: 0.5790 - val_recall: 0.7486\n",
      "Epoch 53/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.1695 - precision: 0.5983 - recall: 0.7531 - val_loss: 10.1650 - val_precision: 0.5802 - val_recall: 0.7514\n",
      "Epoch 54/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1609 - precision: 0.5985 - recall: 0.7571 - val_loss: 10.1563 - val_precision: 0.5810 - val_recall: 0.7537\n",
      "Epoch 55/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1523 - precision: 0.5984 - recall: 0.7583 - val_loss: 10.1477 - val_precision: 0.5807 - val_recall: 0.7549\n",
      "Epoch 56/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1436 - precision: 0.5977 - recall: 0.7603 - val_loss: 10.1391 - val_precision: 0.5812 - val_recall: 0.7576\n",
      "Epoch 57/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1350 - precision: 0.5981 - recall: 0.7648 - val_loss: 10.1304 - val_precision: 0.5807 - val_recall: 0.7603\n",
      "Epoch 58/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1264 - precision: 0.5982 - recall: 0.7650 - val_loss: 10.1218 - val_precision: 0.5813 - val_recall: 0.7611\n",
      "Epoch 59/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 10.1178 - precision: 0.5982 - recall: 0.7678 - val_loss: 10.1132 - val_precision: 0.5812 - val_recall: 0.7630\n",
      "Epoch 60/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.1092 - precision: 0.5979 - recall: 0.7690 - val_loss: 10.1046 - val_precision: 0.5811 - val_recall: 0.7642\n",
      "Epoch 61/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.1006 - precision: 0.5980 - recall: 0.7701 - val_loss: 10.0960 - val_precision: 0.5809 - val_recall: 0.7642\n",
      "Epoch 62/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.0920 - precision: 0.5977 - recall: 0.7735 - val_loss: 10.0874 - val_precision: 0.5806 - val_recall: 0.7681\n",
      "Epoch 63/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0834 - precision: 0.5975 - recall: 0.7753 - val_loss: 10.0788 - val_precision: 0.5809 - val_recall: 0.7700\n",
      "Epoch 64/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0748 - precision: 0.5980 - recall: 0.7775 - val_loss: 10.0702 - val_precision: 0.5814 - val_recall: 0.7708\n",
      "Epoch 65/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0662 - precision: 0.5980 - recall: 0.7786 - val_loss: 10.0616 - val_precision: 0.5819 - val_recall: 0.7724\n",
      "Epoch 66/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0576 - precision: 0.5980 - recall: 0.7808 - val_loss: 10.0530 - val_precision: 0.5817 - val_recall: 0.7739\n",
      "Epoch 67/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0490 - precision: 0.5976 - recall: 0.7814 - val_loss: 10.0444 - val_precision: 0.5818 - val_recall: 0.7751\n",
      "Epoch 68/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0405 - precision: 0.5978 - recall: 0.7811 - val_loss: 10.0358 - val_precision: 0.5815 - val_recall: 0.7759\n",
      "Epoch 69/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0319 - precision: 0.5975 - recall: 0.7822 - val_loss: 10.0272 - val_precision: 0.5816 - val_recall: 0.7790\n",
      "Epoch 70/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.0233 - precision: 0.5974 - recall: 0.7834 - val_loss: 10.0187 - val_precision: 0.5811 - val_recall: 0.7790\n",
      "Epoch 71/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 10.0148 - precision: 0.5982 - recall: 0.7837 - val_loss: 10.0101 - val_precision: 0.5812 - val_recall: 0.7786\n",
      "Epoch 72/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 10.0062 - precision: 0.5973 - recall: 0.7874 - val_loss: 10.0015 - val_precision: 0.5814 - val_recall: 0.7837\n",
      "Epoch 73/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9976 - precision: 0.5971 - recall: 0.7885 - val_loss: 9.9930 - val_precision: 0.5815 - val_recall: 0.7856\n",
      "Epoch 74/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9891 - precision: 0.5971 - recall: 0.7876 - val_loss: 9.9844 - val_precision: 0.5820 - val_recall: 0.7860\n",
      "Epoch 75/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 9.9805 - precision: 0.5976 - recall: 0.7894 - val_loss: 9.9758 - val_precision: 0.5819 - val_recall: 0.7868\n",
      "Epoch 76/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9720 - precision: 0.5980 - recall: 0.7926 - val_loss: 9.9673 - val_precision: 0.5827 - val_recall: 0.7899\n",
      "Epoch 77/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9634 - precision: 0.5978 - recall: 0.7944 - val_loss: 9.9587 - val_precision: 0.5832 - val_recall: 0.7922\n",
      "Epoch 78/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9549 - precision: 0.5983 - recall: 0.7943 - val_loss: 9.9502 - val_precision: 0.5838 - val_recall: 0.7930\n",
      "Epoch 79/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9464 - precision: 0.5986 - recall: 0.7949 - val_loss: 9.9417 - val_precision: 0.5835 - val_recall: 0.7922\n",
      "Epoch 80/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.9379 - precision: 0.5988 - recall: 0.7961 - val_loss: 9.9331 - val_precision: 0.5840 - val_recall: 0.7942\n",
      "Epoch 81/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9293 - precision: 0.5991 - recall: 0.7977 - val_loss: 9.9246 - val_precision: 0.5837 - val_recall: 0.7949\n",
      "Epoch 82/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9208 - precision: 0.5990 - recall: 0.7977 - val_loss: 9.9161 - val_precision: 0.5838 - val_recall: 0.7957\n",
      "Epoch 83/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9123 - precision: 0.5990 - recall: 0.7987 - val_loss: 9.9076 - val_precision: 0.5844 - val_recall: 0.7961\n",
      "Epoch 84/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.9038 - precision: 0.5990 - recall: 0.7989 - val_loss: 9.8990 - val_precision: 0.5840 - val_recall: 0.7957\n",
      "Epoch 85/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8953 - precision: 0.5985 - recall: 0.8010 - val_loss: 9.8905 - val_precision: 0.5840 - val_recall: 0.7969\n",
      "Epoch 86/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.8868 - precision: 0.5983 - recall: 0.8019 - val_loss: 9.8820 - val_precision: 0.5841 - val_recall: 0.7973\n",
      "Epoch 87/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.8783 - precision: 0.5983 - recall: 0.8022 - val_loss: 9.8735 - val_precision: 0.5835 - val_recall: 0.7969\n",
      "Epoch 88/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.8698 - precision: 0.5986 - recall: 0.8023 - val_loss: 9.8650 - val_precision: 0.5835 - val_recall: 0.7965\n",
      "Epoch 89/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8613 - precision: 0.5985 - recall: 0.8042 - val_loss: 9.8565 - val_precision: 0.5842 - val_recall: 0.7988\n",
      "Epoch 90/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.8528 - precision: 0.5988 - recall: 0.8055 - val_loss: 9.8480 - val_precision: 0.5839 - val_recall: 0.7992\n",
      "Epoch 91/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8443 - precision: 0.5993 - recall: 0.8065 - val_loss: 9.8395 - val_precision: 0.5837 - val_recall: 0.7992\n",
      "Epoch 92/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8358 - precision: 0.5995 - recall: 0.8066 - val_loss: 9.8311 - val_precision: 0.5841 - val_recall: 0.8000\n",
      "Epoch 93/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.8274 - precision: 0.5992 - recall: 0.8074 - val_loss: 9.8226 - val_precision: 0.5835 - val_recall: 0.8012\n",
      "Epoch 94/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8189 - precision: 0.5995 - recall: 0.8096 - val_loss: 9.8141 - val_precision: 0.5831 - val_recall: 0.8023\n",
      "Epoch 95/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8104 - precision: 0.5997 - recall: 0.8093 - val_loss: 9.8056 - val_precision: 0.5830 - val_recall: 0.8023\n",
      "Epoch 96/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8020 - precision: 0.5998 - recall: 0.8106 - val_loss: 9.7972 - val_precision: 0.5828 - val_recall: 0.8027\n",
      "Epoch 97/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7935 - precision: 0.5996 - recall: 0.8113 - val_loss: 9.7887 - val_precision: 0.5829 - val_recall: 0.8047\n",
      "Epoch 98/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7851 - precision: 0.5995 - recall: 0.8112 - val_loss: 9.7802 - val_precision: 0.5831 - val_recall: 0.8058\n",
      "Epoch 99/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7766 - precision: 0.5997 - recall: 0.8112 - val_loss: 9.7718 - val_precision: 0.5830 - val_recall: 0.8062\n",
      "Epoch 100/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7682 - precision: 0.5994 - recall: 0.8118 - val_loss: 9.7633 - val_precision: 0.5830 - val_recall: 0.8074\n",
      "Epoch 101/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.7597 - precision: 0.5996 - recall: 0.8125 - val_loss: 9.7549 - val_precision: 0.5837 - val_recall: 0.8086\n",
      "Epoch 102/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7513 - precision: 0.5996 - recall: 0.8132 - val_loss: 9.7465 - val_precision: 0.5836 - val_recall: 0.8093\n",
      "Epoch 103/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7428 - precision: 0.6000 - recall: 0.8135 - val_loss: 9.7380 - val_precision: 0.5837 - val_recall: 0.8097\n",
      "Epoch 104/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7344 - precision: 0.6004 - recall: 0.8149 - val_loss: 9.7296 - val_precision: 0.5839 - val_recall: 0.8097\n",
      "Epoch 105/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7260 - precision: 0.6004 - recall: 0.8154 - val_loss: 9.7211 - val_precision: 0.5838 - val_recall: 0.8101\n",
      "Epoch 106/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.7176 - precision: 0.6011 - recall: 0.8153 - val_loss: 9.7127 - val_precision: 0.5837 - val_recall: 0.8089\n",
      "Epoch 107/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7091 - precision: 0.6011 - recall: 0.8167 - val_loss: 9.7043 - val_precision: 0.5837 - val_recall: 0.8097\n",
      "Epoch 108/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.7007 - precision: 0.6011 - recall: 0.8172 - val_loss: 9.6959 - val_precision: 0.5843 - val_recall: 0.8117\n",
      "Epoch 109/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.6923 - precision: 0.6012 - recall: 0.8171 - val_loss: 9.6875 - val_precision: 0.5844 - val_recall: 0.8113\n",
      "Epoch 110/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6839 - precision: 0.6016 - recall: 0.8172 - val_loss: 9.6791 - val_precision: 0.5847 - val_recall: 0.8125\n",
      "Epoch 111/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6755 - precision: 0.6016 - recall: 0.8181 - val_loss: 9.6706 - val_precision: 0.5851 - val_recall: 0.8136\n",
      "Epoch 112/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6671 - precision: 0.6019 - recall: 0.8176 - val_loss: 9.6622 - val_precision: 0.5851 - val_recall: 0.8136\n",
      "Epoch 113/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 9.6587 - precision: 0.6022 - recall: 0.8168 - val_loss: 9.6538 - val_precision: 0.5855 - val_recall: 0.8140\n",
      "Epoch 114/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6503 - precision: 0.6027 - recall: 0.8185 - val_loss: 9.6454 - val_precision: 0.5859 - val_recall: 0.8148\n",
      "Epoch 115/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6419 - precision: 0.6025 - recall: 0.8178 - val_loss: 9.6371 - val_precision: 0.5863 - val_recall: 0.8144\n",
      "Epoch 116/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.6335 - precision: 0.6030 - recall: 0.8180 - val_loss: 9.6287 - val_precision: 0.5865 - val_recall: 0.8163\n",
      "Epoch 117/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.6252 - precision: 0.6031 - recall: 0.8169 - val_loss: 9.6203 - val_precision: 0.5866 - val_recall: 0.8167\n",
      "Epoch 118/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.6168 - precision: 0.6032 - recall: 0.8189 - val_loss: 9.6119 - val_precision: 0.5872 - val_recall: 0.8171\n",
      "Epoch 119/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6084 - precision: 0.6035 - recall: 0.8189 - val_loss: 9.6035 - val_precision: 0.5871 - val_recall: 0.8171\n",
      "Epoch 120/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6000 - precision: 0.6034 - recall: 0.8196 - val_loss: 9.5951 - val_precision: 0.5878 - val_recall: 0.8183\n",
      "Epoch 121/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5917 - precision: 0.6037 - recall: 0.8191 - val_loss: 9.5868 - val_precision: 0.5878 - val_recall: 0.8183\n",
      "Epoch 122/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 9.5833 - precision: 0.6035 - recall: 0.8191 - val_loss: 9.5784 - val_precision: 0.5875 - val_recall: 0.8175\n",
      "Epoch 123/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.5749 - precision: 0.6037 - recall: 0.8191 - val_loss: 9.5700 - val_precision: 0.5874 - val_recall: 0.8171\n",
      "Epoch 124/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5666 - precision: 0.6039 - recall: 0.8205 - val_loss: 9.5617 - val_precision: 0.5875 - val_recall: 0.8179\n",
      "Epoch 125/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5582 - precision: 0.6039 - recall: 0.8209 - val_loss: 9.5533 - val_precision: 0.5872 - val_recall: 0.8171\n",
      "Epoch 126/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5499 - precision: 0.6043 - recall: 0.8201 - val_loss: 9.5450 - val_precision: 0.5876 - val_recall: 0.8167\n",
      "Epoch 127/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5416 - precision: 0.6046 - recall: 0.8199 - val_loss: 9.5366 - val_precision: 0.5878 - val_recall: 0.8167\n",
      "Epoch 128/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5332 - precision: 0.6042 - recall: 0.8210 - val_loss: 9.5283 - val_precision: 0.5877 - val_recall: 0.8171\n",
      "Epoch 129/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.5249 - precision: 0.6045 - recall: 0.8206 - val_loss: 9.5200 - val_precision: 0.5879 - val_recall: 0.8171\n",
      "Epoch 130/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.5166 - precision: 0.6048 - recall: 0.8209 - val_loss: 9.5116 - val_precision: 0.5884 - val_recall: 0.8171\n",
      "Epoch 131/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5082 - precision: 0.6048 - recall: 0.8210 - val_loss: 9.5033 - val_precision: 0.5888 - val_recall: 0.8175\n",
      "Epoch 132/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.4999 - precision: 0.6047 - recall: 0.8215 - val_loss: 9.4950 - val_precision: 0.5884 - val_recall: 0.8171\n",
      "Epoch 133/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4916 - precision: 0.6046 - recall: 0.8223 - val_loss: 9.4867 - val_precision: 0.5885 - val_recall: 0.8179\n",
      "Epoch 134/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4833 - precision: 0.6047 - recall: 0.8210 - val_loss: 9.4784 - val_precision: 0.5888 - val_recall: 0.8156\n",
      "Epoch 135/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.4750 - precision: 0.6044 - recall: 0.8217 - val_loss: 9.4700 - val_precision: 0.5878 - val_recall: 0.8163\n",
      "Epoch 136/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.4667 - precision: 0.6045 - recall: 0.8214 - val_loss: 9.4617 - val_precision: 0.5887 - val_recall: 0.8175\n",
      "Epoch 137/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.4584 - precision: 0.6050 - recall: 0.8209 - val_loss: 9.4534 - val_precision: 0.5888 - val_recall: 0.8167\n",
      "Epoch 138/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4501 - precision: 0.6051 - recall: 0.8206 - val_loss: 9.4451 - val_precision: 0.5893 - val_recall: 0.8179\n",
      "Epoch 139/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4418 - precision: 0.6053 - recall: 0.8213 - val_loss: 9.4368 - val_precision: 0.5893 - val_recall: 0.8179\n",
      "Epoch 140/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.4335 - precision: 0.6056 - recall: 0.8210 - val_loss: 9.4285 - val_precision: 0.5897 - val_recall: 0.8187\n",
      "Epoch 141/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4252 - precision: 0.6057 - recall: 0.8210 - val_loss: 9.4203 - val_precision: 0.5900 - val_recall: 0.8179\n",
      "Epoch 142/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4169 - precision: 0.6056 - recall: 0.8213 - val_loss: 9.4120 - val_precision: 0.5902 - val_recall: 0.8198\n",
      "Epoch 143/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.4086 - precision: 0.6057 - recall: 0.8199 - val_loss: 9.4037 - val_precision: 0.5899 - val_recall: 0.8187\n",
      "Epoch 144/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4004 - precision: 0.6058 - recall: 0.8208 - val_loss: 9.3954 - val_precision: 0.5900 - val_recall: 0.8210\n",
      "Epoch 145/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.3921 - precision: 0.6058 - recall: 0.8219 - val_loss: 9.3871 - val_precision: 0.5901 - val_recall: 0.8206\n",
      "Epoch 146/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.3838 - precision: 0.6057 - recall: 0.8206 - val_loss: 9.3789 - val_precision: 0.5899 - val_recall: 0.8210\n",
      "Epoch 147/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3756 - precision: 0.6058 - recall: 0.8214 - val_loss: 9.3706 - val_precision: 0.5900 - val_recall: 0.8214\n",
      "Epoch 148/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3673 - precision: 0.6060 - recall: 0.8192 - val_loss: 9.3624 - val_precision: 0.5897 - val_recall: 0.8198\n",
      "Epoch 149/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3591 - precision: 0.6058 - recall: 0.8196 - val_loss: 9.3541 - val_precision: 0.5899 - val_recall: 0.8195\n",
      "Epoch 150/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3508 - precision: 0.6058 - recall: 0.8206 - val_loss: 9.3459 - val_precision: 0.5900 - val_recall: 0.8214\n",
      "Epoch 151/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3426 - precision: 0.6058 - recall: 0.8200 - val_loss: 9.3376 - val_precision: 0.5909 - val_recall: 0.8218\n",
      "Epoch 152/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3344 - precision: 0.6056 - recall: 0.8197 - val_loss: 9.3294 - val_precision: 0.5910 - val_recall: 0.8222\n",
      "Epoch 153/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3261 - precision: 0.6057 - recall: 0.8194 - val_loss: 9.3211 - val_precision: 0.5911 - val_recall: 0.8218\n",
      "Epoch 154/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3179 - precision: 0.6059 - recall: 0.8203 - val_loss: 9.3129 - val_precision: 0.5912 - val_recall: 0.8226\n",
      "Epoch 155/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.3097 - precision: 0.6060 - recall: 0.8195 - val_loss: 9.3047 - val_precision: 0.5917 - val_recall: 0.8226\n",
      "Epoch 156/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3014 - precision: 0.6069 - recall: 0.8191 - val_loss: 9.2964 - val_precision: 0.5919 - val_recall: 0.8233\n",
      "Epoch 157/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.2932 - precision: 0.6069 - recall: 0.8199 - val_loss: 9.2882 - val_precision: 0.5917 - val_recall: 0.8237\n",
      "Epoch 158/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.2850 - precision: 0.6068 - recall: 0.8201 - val_loss: 9.2800 - val_precision: 0.5912 - val_recall: 0.8237\n",
      "Epoch 159/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.2768 - precision: 0.6070 - recall: 0.8194 - val_loss: 9.2718 - val_precision: 0.5915 - val_recall: 0.8226\n",
      "Epoch 160/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2686 - precision: 0.6071 - recall: 0.8196 - val_loss: 9.2636 - val_precision: 0.5917 - val_recall: 0.8226\n",
      "Epoch 161/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.2604 - precision: 0.6073 - recall: 0.8181 - val_loss: 9.2554 - val_precision: 0.5913 - val_recall: 0.8214\n",
      "Epoch 162/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.2522 - precision: 0.6077 - recall: 0.8190 - val_loss: 9.2472 - val_precision: 0.5914 - val_recall: 0.8222\n",
      "Epoch 163/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2440 - precision: 0.6071 - recall: 0.8194 - val_loss: 9.2390 - val_precision: 0.5918 - val_recall: 0.8230\n",
      "Epoch 164/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.2358 - precision: 0.6077 - recall: 0.8178 - val_loss: 9.2308 - val_precision: 0.5926 - val_recall: 0.8218\n",
      "Epoch 165/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2276 - precision: 0.6075 - recall: 0.8180 - val_loss: 9.2226 - val_precision: 0.5931 - val_recall: 0.8230\n",
      "Epoch 166/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2194 - precision: 0.6084 - recall: 0.8171 - val_loss: 9.2144 - val_precision: 0.5932 - val_recall: 0.8222\n",
      "Epoch 167/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2112 - precision: 0.6075 - recall: 0.8176 - val_loss: 9.2062 - val_precision: 0.5929 - val_recall: 0.8230\n",
      "Epoch 168/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2031 - precision: 0.6078 - recall: 0.8181 - val_loss: 9.1981 - val_precision: 0.5933 - val_recall: 0.8226\n",
      "Epoch 169/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.1949 - precision: 0.6078 - recall: 0.8169 - val_loss: 9.1899 - val_precision: 0.5935 - val_recall: 0.8222\n",
      "Epoch 170/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.1867 - precision: 0.6079 - recall: 0.8186 - val_loss: 9.1817 - val_precision: 0.5930 - val_recall: 0.8226\n",
      "Epoch 171/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.1786 - precision: 0.6078 - recall: 0.8196 - val_loss: 9.1735 - val_precision: 0.5928 - val_recall: 0.8230\n",
      "Epoch 172/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.1704 - precision: 0.6077 - recall: 0.8182 - val_loss: 9.1654 - val_precision: 0.5932 - val_recall: 0.8222\n",
      "Epoch 173/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.1622 - precision: 0.6082 - recall: 0.8187 - val_loss: 9.1572 - val_precision: 0.5936 - val_recall: 0.8230\n",
      "Epoch 174/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.1541 - precision: 0.6078 - recall: 0.8194 - val_loss: 9.1491 - val_precision: 0.5937 - val_recall: 0.8233\n",
      "Epoch 175/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 9.1459 - precision: 0.6083 - recall: 0.8190 - val_loss: 9.1409 - val_precision: 0.5945 - val_recall: 0.8222\n",
      "Epoch 176/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.1378 - precision: 0.6084 - recall: 0.8178 - val_loss: 9.1328 - val_precision: 0.5948 - val_recall: 0.8218\n",
      "Epoch 177/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.1297 - precision: 0.6084 - recall: 0.8177 - val_loss: 9.1247 - val_precision: 0.5945 - val_recall: 0.8210\n",
      "Epoch 178/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.1215 - precision: 0.6084 - recall: 0.8181 - val_loss: 9.1165 - val_precision: 0.5948 - val_recall: 0.8218\n",
      "Epoch 179/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.1134 - precision: 0.6083 - recall: 0.8190 - val_loss: 9.1084 - val_precision: 0.5946 - val_recall: 0.8218\n",
      "Epoch 180/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.1053 - precision: 0.6083 - recall: 0.8180 - val_loss: 9.1003 - val_precision: 0.5949 - val_recall: 0.8218\n",
      "Epoch 181/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.0972 - precision: 0.6085 - recall: 0.8168 - val_loss: 9.0921 - val_precision: 0.5950 - val_recall: 0.8214\n",
      "Epoch 182/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0890 - precision: 0.6085 - recall: 0.8183 - val_loss: 9.0840 - val_precision: 0.5948 - val_recall: 0.8226\n",
      "Epoch 183/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.0809 - precision: 0.6086 - recall: 0.8176 - val_loss: 9.0759 - val_precision: 0.5945 - val_recall: 0.8222\n",
      "Epoch 184/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0728 - precision: 0.6088 - recall: 0.8181 - val_loss: 9.0678 - val_precision: 0.5953 - val_recall: 0.8218\n",
      "Epoch 185/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.0647 - precision: 0.6089 - recall: 0.8172 - val_loss: 9.0597 - val_precision: 0.5955 - val_recall: 0.8214\n",
      "Epoch 186/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0566 - precision: 0.6091 - recall: 0.8176 - val_loss: 9.0516 - val_precision: 0.5948 - val_recall: 0.8214\n",
      "Epoch 187/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.0485 - precision: 0.6095 - recall: 0.8173 - val_loss: 9.0435 - val_precision: 0.5955 - val_recall: 0.8210\n",
      "Epoch 188/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0404 - precision: 0.6091 - recall: 0.8178 - val_loss: 9.0354 - val_precision: 0.5952 - val_recall: 0.8210\n",
      "Epoch 189/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0323 - precision: 0.6096 - recall: 0.8178 - val_loss: 9.0273 - val_precision: 0.5953 - val_recall: 0.8214\n",
      "Epoch 190/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0243 - precision: 0.6095 - recall: 0.8177 - val_loss: 9.0192 - val_precision: 0.5957 - val_recall: 0.8210\n",
      "Epoch 191/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0162 - precision: 0.6094 - recall: 0.8181 - val_loss: 9.0112 - val_precision: 0.5954 - val_recall: 0.8210\n",
      "Epoch 192/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0081 - precision: 0.6095 - recall: 0.8182 - val_loss: 9.0031 - val_precision: 0.5955 - val_recall: 0.8210\n",
      "Epoch 193/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.0000 - precision: 0.6096 - recall: 0.8175 - val_loss: 8.9950 - val_precision: 0.5955 - val_recall: 0.8202\n",
      "Epoch 194/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.9920 - precision: 0.6097 - recall: 0.8171 - val_loss: 8.9869 - val_precision: 0.5955 - val_recall: 0.8198\n",
      "Epoch 195/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 8.9839 - precision: 0.6095 - recall: 0.8182 - val_loss: 8.9789 - val_precision: 0.5956 - val_recall: 0.8202\n",
      "Epoch 196/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9758 - precision: 0.6095 - recall: 0.8176 - val_loss: 8.9708 - val_precision: 0.5959 - val_recall: 0.8206\n",
      "Epoch 197/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.9678 - precision: 0.6097 - recall: 0.8181 - val_loss: 8.9627 - val_precision: 0.5959 - val_recall: 0.8210\n",
      "Epoch 198/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.9597 - precision: 0.6098 - recall: 0.8180 - val_loss: 8.9547 - val_precision: 0.5964 - val_recall: 0.8210\n",
      "Epoch 199/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9517 - precision: 0.6100 - recall: 0.8185 - val_loss: 8.9467 - val_precision: 0.5963 - val_recall: 0.8218\n",
      "Epoch 200/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9436 - precision: 0.6100 - recall: 0.8182 - val_loss: 8.9386 - val_precision: 0.5963 - val_recall: 0.8214\n",
      "Epoch 201/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 8.9356 - precision: 0.6101 - recall: 0.8181 - val_loss: 8.9306 - val_precision: 0.5961 - val_recall: 0.8222\n",
      "Epoch 202/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.9276 - precision: 0.6104 - recall: 0.8182 - val_loss: 8.9225 - val_precision: 0.5966 - val_recall: 0.8222\n",
      "Epoch 203/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9195 - precision: 0.6102 - recall: 0.8183 - val_loss: 8.9145 - val_precision: 0.5973 - val_recall: 0.8226\n",
      "Epoch 204/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9115 - precision: 0.6105 - recall: 0.8189 - val_loss: 8.9065 - val_precision: 0.5973 - val_recall: 0.8226\n",
      "Epoch 205/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9035 - precision: 0.6108 - recall: 0.8190 - val_loss: 8.8985 - val_precision: 0.5975 - val_recall: 0.8226\n",
      "Epoch 206/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8955 - precision: 0.6109 - recall: 0.8195 - val_loss: 8.8904 - val_precision: 0.5975 - val_recall: 0.8226\n",
      "Epoch 207/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.8875 - precision: 0.6107 - recall: 0.8192 - val_loss: 8.8824 - val_precision: 0.5971 - val_recall: 0.8218\n",
      "Epoch 208/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8795 - precision: 0.6110 - recall: 0.8190 - val_loss: 8.8744 - val_precision: 0.5969 - val_recall: 0.8218\n",
      "Epoch 209/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8715 - precision: 0.6106 - recall: 0.8199 - val_loss: 8.8664 - val_precision: 0.5967 - val_recall: 0.8222\n",
      "Epoch 210/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8635 - precision: 0.6109 - recall: 0.8185 - val_loss: 8.8584 - val_precision: 0.5971 - val_recall: 0.8222\n",
      "Epoch 211/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8555 - precision: 0.6112 - recall: 0.8194 - val_loss: 8.8504 - val_precision: 0.5971 - val_recall: 0.8222\n",
      "Epoch 212/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8475 - precision: 0.6115 - recall: 0.8190 - val_loss: 8.8424 - val_precision: 0.5974 - val_recall: 0.8222\n",
      "Epoch 213/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.8395 - precision: 0.6112 - recall: 0.8180 - val_loss: 8.8344 - val_precision: 0.5976 - val_recall: 0.8218\n",
      "Epoch 214/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.8315 - precision: 0.6111 - recall: 0.8183 - val_loss: 8.8265 - val_precision: 0.5977 - val_recall: 0.8222\n",
      "Epoch 215/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8235 - precision: 0.6110 - recall: 0.8192 - val_loss: 8.8185 - val_precision: 0.5980 - val_recall: 0.8230\n",
      "Epoch 216/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8155 - precision: 0.6112 - recall: 0.8190 - val_loss: 8.8105 - val_precision: 0.5981 - val_recall: 0.8233\n",
      "Epoch 217/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8076 - precision: 0.6111 - recall: 0.8180 - val_loss: 8.8025 - val_precision: 0.5990 - val_recall: 0.8230\n",
      "Epoch 218/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7996 - precision: 0.6111 - recall: 0.8168 - val_loss: 8.7945 - val_precision: 0.5993 - val_recall: 0.8233\n",
      "Epoch 219/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.7916 - precision: 0.6112 - recall: 0.8163 - val_loss: 8.7866 - val_precision: 0.5996 - val_recall: 0.8233\n",
      "Epoch 220/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7837 - precision: 0.6108 - recall: 0.8176 - val_loss: 8.7786 - val_precision: 0.5993 - val_recall: 0.8233\n",
      "Epoch 221/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7757 - precision: 0.6111 - recall: 0.8176 - val_loss: 8.7707 - val_precision: 0.6003 - val_recall: 0.8233\n",
      "Epoch 222/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7678 - precision: 0.6111 - recall: 0.8161 - val_loss: 8.7627 - val_precision: 0.6005 - val_recall: 0.8230\n",
      "Epoch 223/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7598 - precision: 0.6110 - recall: 0.8167 - val_loss: 8.7548 - val_precision: 0.6007 - val_recall: 0.8230\n",
      "Epoch 224/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.7519 - precision: 0.6112 - recall: 0.8153 - val_loss: 8.7468 - val_precision: 0.6006 - val_recall: 0.8226\n",
      "Epoch 225/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.7439 - precision: 0.6111 - recall: 0.8158 - val_loss: 8.7389 - val_precision: 0.6007 - val_recall: 0.8218\n",
      "Epoch 226/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7360 - precision: 0.6115 - recall: 0.8158 - val_loss: 8.7309 - val_precision: 0.6007 - val_recall: 0.8218\n",
      "Epoch 227/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7281 - precision: 0.6119 - recall: 0.8158 - val_loss: 8.7230 - val_precision: 0.6005 - val_recall: 0.8210\n",
      "Epoch 228/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7201 - precision: 0.6117 - recall: 0.8143 - val_loss: 8.7151 - val_precision: 0.6010 - val_recall: 0.8210\n",
      "Epoch 229/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.7122 - precision: 0.6118 - recall: 0.8148 - val_loss: 8.7072 - val_precision: 0.6008 - val_recall: 0.8210\n",
      "Epoch 230/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7043 - precision: 0.6118 - recall: 0.8150 - val_loss: 8.6992 - val_precision: 0.6007 - val_recall: 0.8206\n",
      "Epoch 231/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6964 - precision: 0.6117 - recall: 0.8148 - val_loss: 8.6913 - val_precision: 0.6010 - val_recall: 0.8198\n",
      "Epoch 232/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6885 - precision: 0.6122 - recall: 0.8148 - val_loss: 8.6834 - val_precision: 0.6012 - val_recall: 0.8195\n",
      "Epoch 233/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6805 - precision: 0.6122 - recall: 0.8145 - val_loss: 8.6755 - val_precision: 0.6014 - val_recall: 0.8191\n",
      "Epoch 234/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6726 - precision: 0.6124 - recall: 0.8157 - val_loss: 8.6676 - val_precision: 0.6013 - val_recall: 0.8191\n",
      "Epoch 235/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6647 - precision: 0.6127 - recall: 0.8153 - val_loss: 8.6597 - val_precision: 0.6013 - val_recall: 0.8187\n",
      "Epoch 236/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.6568 - precision: 0.6129 - recall: 0.8159 - val_loss: 8.6518 - val_precision: 0.6012 - val_recall: 0.8183\n",
      "Epoch 237/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6490 - precision: 0.6128 - recall: 0.8166 - val_loss: 8.6439 - val_precision: 0.6010 - val_recall: 0.8187\n",
      "Epoch 238/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6411 - precision: 0.6130 - recall: 0.8167 - val_loss: 8.6360 - val_precision: 0.6015 - val_recall: 0.8175\n",
      "Epoch 239/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6332 - precision: 0.6131 - recall: 0.8159 - val_loss: 8.6281 - val_precision: 0.6017 - val_recall: 0.8175\n",
      "Epoch 240/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6253 - precision: 0.6131 - recall: 0.8162 - val_loss: 8.6202 - val_precision: 0.6016 - val_recall: 0.8179\n",
      "Epoch 241/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6174 - precision: 0.6132 - recall: 0.8154 - val_loss: 8.6124 - val_precision: 0.6015 - val_recall: 0.8171\n",
      "Epoch 242/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.6096 - precision: 0.6130 - recall: 0.8163 - val_loss: 8.6045 - val_precision: 0.6017 - val_recall: 0.8175\n",
      "Epoch 243/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6017 - precision: 0.6134 - recall: 0.8153 - val_loss: 8.5966 - val_precision: 0.6022 - val_recall: 0.8175\n",
      "Epoch 244/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5938 - precision: 0.6131 - recall: 0.8154 - val_loss: 8.5888 - val_precision: 0.6018 - val_recall: 0.8179\n",
      "Epoch 245/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5860 - precision: 0.6132 - recall: 0.8161 - val_loss: 8.5809 - val_precision: 0.6020 - val_recall: 0.8187\n",
      "Epoch 246/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5781 - precision: 0.6132 - recall: 0.8158 - val_loss: 8.5731 - val_precision: 0.6021 - val_recall: 0.8179\n",
      "Epoch 247/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5703 - precision: 0.6134 - recall: 0.8161 - val_loss: 8.5652 - val_precision: 0.6017 - val_recall: 0.8171\n",
      "Epoch 248/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5624 - precision: 0.6134 - recall: 0.8157 - val_loss: 8.5574 - val_precision: 0.6018 - val_recall: 0.8175\n",
      "Epoch 249/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5546 - precision: 0.6137 - recall: 0.8158 - val_loss: 8.5495 - val_precision: 0.6018 - val_recall: 0.8175\n",
      "Epoch 250/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5467 - precision: 0.6137 - recall: 0.8166 - val_loss: 8.5417 - val_precision: 0.6019 - val_recall: 0.8183\n",
      "Epoch 251/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.5389 - precision: 0.6139 - recall: 0.8171 - val_loss: 8.5338 - val_precision: 0.6019 - val_recall: 0.8191\n",
      "Epoch 252/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5311 - precision: 0.6140 - recall: 0.8164 - val_loss: 8.5260 - val_precision: 0.6018 - val_recall: 0.8187\n",
      "Epoch 253/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5233 - precision: 0.6140 - recall: 0.8168 - val_loss: 8.5182 - val_precision: 0.6016 - val_recall: 0.8179\n",
      "Epoch 254/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.5154 - precision: 0.6143 - recall: 0.8166 - val_loss: 8.5104 - val_precision: 0.6018 - val_recall: 0.8179\n",
      "Epoch 255/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5076 - precision: 0.6144 - recall: 0.8171 - val_loss: 8.5025 - val_precision: 0.6013 - val_recall: 0.8179\n",
      "Epoch 256/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4998 - precision: 0.6143 - recall: 0.8172 - val_loss: 8.4947 - val_precision: 0.6017 - val_recall: 0.8175\n",
      "Epoch 257/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4920 - precision: 0.6147 - recall: 0.8164 - val_loss: 8.4869 - val_precision: 0.6015 - val_recall: 0.8171\n",
      "Epoch 258/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.4842 - precision: 0.6148 - recall: 0.8161 - val_loss: 8.4791 - val_precision: 0.6021 - val_recall: 0.8171\n",
      "Epoch 259/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.4764 - precision: 0.6148 - recall: 0.8163 - val_loss: 8.4713 - val_precision: 0.6018 - val_recall: 0.8167\n",
      "Epoch 260/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4686 - precision: 0.6147 - recall: 0.8163 - val_loss: 8.4635 - val_precision: 0.6016 - val_recall: 0.8167\n",
      "Epoch 261/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4608 - precision: 0.6147 - recall: 0.8166 - val_loss: 8.4557 - val_precision: 0.6018 - val_recall: 0.8167\n",
      "Epoch 262/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 8.4530 - precision: 0.6146 - recall: 0.8161 - val_loss: 8.4479 - val_precision: 0.6024 - val_recall: 0.8163\n",
      "Epoch 263/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4452 - precision: 0.6148 - recall: 0.8158 - val_loss: 8.4401 - val_precision: 0.6023 - val_recall: 0.8156\n",
      "Epoch 264/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4374 - precision: 0.6146 - recall: 0.8159 - val_loss: 8.4323 - val_precision: 0.6025 - val_recall: 0.8163\n",
      "Epoch 265/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.4297 - precision: 0.6148 - recall: 0.8158 - val_loss: 8.4246 - val_precision: 0.6024 - val_recall: 0.8163\n",
      "Epoch 266/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.4219 - precision: 0.6146 - recall: 0.8155 - val_loss: 8.4168 - val_precision: 0.6026 - val_recall: 0.8160\n",
      "Epoch 267/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.4141 - precision: 0.6148 - recall: 0.8161 - val_loss: 8.4090 - val_precision: 0.6026 - val_recall: 0.8160\n",
      "Epoch 268/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4063 - precision: 0.6151 - recall: 0.8158 - val_loss: 8.4013 - val_precision: 0.6028 - val_recall: 0.8156\n",
      "Epoch 269/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3986 - precision: 0.6153 - recall: 0.8168 - val_loss: 8.3935 - val_precision: 0.6026 - val_recall: 0.8156\n",
      "Epoch 270/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3908 - precision: 0.6152 - recall: 0.8172 - val_loss: 8.3857 - val_precision: 0.6028 - val_recall: 0.8171\n",
      "Epoch 271/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.3831 - precision: 0.6151 - recall: 0.8167 - val_loss: 8.3780 - val_precision: 0.6027 - val_recall: 0.8163\n",
      "Epoch 272/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3753 - precision: 0.6151 - recall: 0.8166 - val_loss: 8.3702 - val_precision: 0.6026 - val_recall: 0.8156\n",
      "Epoch 273/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3676 - precision: 0.6151 - recall: 0.8162 - val_loss: 8.3625 - val_precision: 0.6026 - val_recall: 0.8156\n",
      "Epoch 274/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3598 - precision: 0.6152 - recall: 0.8166 - val_loss: 8.3547 - val_precision: 0.6025 - val_recall: 0.8152\n",
      "Epoch 275/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3521 - precision: 0.6152 - recall: 0.8168 - val_loss: 8.3470 - val_precision: 0.6026 - val_recall: 0.8156\n",
      "Epoch 276/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3443 - precision: 0.6152 - recall: 0.8166 - val_loss: 8.3392 - val_precision: 0.6031 - val_recall: 0.8160\n",
      "Epoch 277/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3366 - precision: 0.6151 - recall: 0.8163 - val_loss: 8.3315 - val_precision: 0.6033 - val_recall: 0.8156\n",
      "Epoch 278/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3289 - precision: 0.6154 - recall: 0.8153 - val_loss: 8.3238 - val_precision: 0.6031 - val_recall: 0.8148\n",
      "Epoch 279/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3212 - precision: 0.6154 - recall: 0.8150 - val_loss: 8.3160 - val_precision: 0.6028 - val_recall: 0.8144\n",
      "Epoch 280/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3134 - precision: 0.6156 - recall: 0.8163 - val_loss: 8.3083 - val_precision: 0.6032 - val_recall: 0.8163\n",
      "Epoch 281/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3057 - precision: 0.6157 - recall: 0.8163 - val_loss: 8.3006 - val_precision: 0.6031 - val_recall: 0.8160\n",
      "Epoch 282/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.2980 - precision: 0.6156 - recall: 0.8155 - val_loss: 8.2929 - val_precision: 0.6028 - val_recall: 0.8144\n",
      "Epoch 283/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.2903 - precision: 0.6157 - recall: 0.8158 - val_loss: 8.2852 - val_precision: 0.6028 - val_recall: 0.8144\n",
      "Epoch 284/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2826 - precision: 0.6158 - recall: 0.8155 - val_loss: 8.2775 - val_precision: 0.6028 - val_recall: 0.8144\n",
      "Epoch 285/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2749 - precision: 0.6160 - recall: 0.8155 - val_loss: 8.2698 - val_precision: 0.6029 - val_recall: 0.8140\n",
      "Epoch 286/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.2672 - precision: 0.6158 - recall: 0.8155 - val_loss: 8.2621 - val_precision: 0.6029 - val_recall: 0.8140\n",
      "Epoch 287/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2595 - precision: 0.6158 - recall: 0.8158 - val_loss: 8.2544 - val_precision: 0.6025 - val_recall: 0.8140\n",
      "Epoch 288/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2518 - precision: 0.6158 - recall: 0.8159 - val_loss: 8.2467 - val_precision: 0.6024 - val_recall: 0.8148\n",
      "Epoch 289/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.2441 - precision: 0.6160 - recall: 0.8157 - val_loss: 8.2390 - val_precision: 0.6024 - val_recall: 0.8136\n",
      "Epoch 290/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 8.2364 - precision: 0.6160 - recall: 0.8154 - val_loss: 8.2313 - val_precision: 0.6025 - val_recall: 0.8128\n",
      "Epoch 291/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2288 - precision: 0.6160 - recall: 0.8164 - val_loss: 8.2236 - val_precision: 0.6026 - val_recall: 0.8136\n",
      "Epoch 292/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2211 - precision: 0.6160 - recall: 0.8161 - val_loss: 8.2160 - val_precision: 0.6028 - val_recall: 0.8136\n",
      "Epoch 293/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2134 - precision: 0.6158 - recall: 0.8161 - val_loss: 8.2083 - val_precision: 0.6028 - val_recall: 0.8136\n",
      "Epoch 294/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2058 - precision: 0.6159 - recall: 0.8158 - val_loss: 8.2006 - val_precision: 0.6027 - val_recall: 0.8128\n",
      "Epoch 295/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1981 - precision: 0.6162 - recall: 0.8162 - val_loss: 8.1930 - val_precision: 0.6026 - val_recall: 0.8125\n",
      "Epoch 296/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1905 - precision: 0.6164 - recall: 0.8162 - val_loss: 8.1853 - val_precision: 0.6025 - val_recall: 0.8121\n",
      "Epoch 297/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1828 - precision: 0.6166 - recall: 0.8159 - val_loss: 8.1777 - val_precision: 0.6025 - val_recall: 0.8121\n",
      "Epoch 298/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1751 - precision: 0.6166 - recall: 0.8159 - val_loss: 8.1700 - val_precision: 0.6025 - val_recall: 0.8121\n",
      "Epoch 299/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1675 - precision: 0.6167 - recall: 0.8162 - val_loss: 8.1624 - val_precision: 0.6027 - val_recall: 0.8121\n",
      "Epoch 300/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.1599 - precision: 0.6165 - recall: 0.8167 - val_loss: 8.1547 - val_precision: 0.6027 - val_recall: 0.8121\n",
      "Epoch 301/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1522 - precision: 0.6166 - recall: 0.8164 - val_loss: 8.1471 - val_precision: 0.6029 - val_recall: 0.8117\n",
      "Epoch 302/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1446 - precision: 0.6167 - recall: 0.8162 - val_loss: 8.1395 - val_precision: 0.6028 - val_recall: 0.8113\n",
      "Epoch 303/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1370 - precision: 0.6168 - recall: 0.8162 - val_loss: 8.1318 - val_precision: 0.6028 - val_recall: 0.8113\n",
      "Epoch 304/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1293 - precision: 0.6167 - recall: 0.8162 - val_loss: 8.1242 - val_precision: 0.6032 - val_recall: 0.8109\n",
      "Epoch 305/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1217 - precision: 0.6167 - recall: 0.8161 - val_loss: 8.1166 - val_precision: 0.6032 - val_recall: 0.8109\n",
      "Epoch 306/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1141 - precision: 0.6168 - recall: 0.8162 - val_loss: 8.1090 - val_precision: 0.6033 - val_recall: 0.8113\n",
      "Epoch 307/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.1065 - precision: 0.6169 - recall: 0.8161 - val_loss: 8.1013 - val_precision: 0.6033 - val_recall: 0.8113\n",
      "Epoch 308/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0989 - precision: 0.6176 - recall: 0.8158 - val_loss: 8.0937 - val_precision: 0.6028 - val_recall: 0.8097\n",
      "Epoch 309/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0913 - precision: 0.6171 - recall: 0.8161 - val_loss: 8.0861 - val_precision: 0.6033 - val_recall: 0.8101\n",
      "Epoch 310/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0837 - precision: 0.6169 - recall: 0.8159 - val_loss: 8.0785 - val_precision: 0.6034 - val_recall: 0.8097\n",
      "Epoch 311/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0761 - precision: 0.6171 - recall: 0.8158 - val_loss: 8.0709 - val_precision: 0.6033 - val_recall: 0.8101\n",
      "Epoch 312/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0685 - precision: 0.6174 - recall: 0.8158 - val_loss: 8.0633 - val_precision: 0.6032 - val_recall: 0.8105\n",
      "Epoch 313/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0609 - precision: 0.6172 - recall: 0.8155 - val_loss: 8.0557 - val_precision: 0.6032 - val_recall: 0.8105\n",
      "Epoch 314/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0533 - precision: 0.6174 - recall: 0.8155 - val_loss: 8.0482 - val_precision: 0.6024 - val_recall: 0.8078\n",
      "Epoch 315/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0457 - precision: 0.6169 - recall: 0.8157 - val_loss: 8.0406 - val_precision: 0.6027 - val_recall: 0.8086\n",
      "Epoch 316/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0382 - precision: 0.6172 - recall: 0.8153 - val_loss: 8.0330 - val_precision: 0.6029 - val_recall: 0.8070\n",
      "Epoch 317/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0306 - precision: 0.6175 - recall: 0.8149 - val_loss: 8.0254 - val_precision: 0.6030 - val_recall: 0.8062\n",
      "Epoch 318/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0230 - precision: 0.6174 - recall: 0.8154 - val_loss: 8.0179 - val_precision: 0.6032 - val_recall: 0.8074\n",
      "Epoch 319/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0154 - precision: 0.6175 - recall: 0.8149 - val_loss: 8.0103 - val_precision: 0.6028 - val_recall: 0.8054\n",
      "Epoch 320/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.0079 - precision: 0.6175 - recall: 0.8150 - val_loss: 8.0027 - val_precision: 0.6031 - val_recall: 0.8066\n",
      "Epoch 321/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.0003 - precision: 0.6176 - recall: 0.8148 - val_loss: 7.9952 - val_precision: 0.6029 - val_recall: 0.8058\n",
      "Epoch 322/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9928 - precision: 0.6176 - recall: 0.8146 - val_loss: 7.9876 - val_precision: 0.6030 - val_recall: 0.8062\n",
      "Epoch 323/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.9852 - precision: 0.6176 - recall: 0.8149 - val_loss: 7.9801 - val_precision: 0.6030 - val_recall: 0.8062\n",
      "Epoch 324/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9777 - precision: 0.6178 - recall: 0.8153 - val_loss: 7.9725 - val_precision: 0.6029 - val_recall: 0.8070\n",
      "Epoch 325/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.9701 - precision: 0.6177 - recall: 0.8144 - val_loss: 7.9650 - val_precision: 0.6033 - val_recall: 0.8047\n",
      "Epoch 326/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9626 - precision: 0.6177 - recall: 0.8149 - val_loss: 7.9574 - val_precision: 0.6031 - val_recall: 0.8047\n",
      "Epoch 327/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9550 - precision: 0.6179 - recall: 0.8144 - val_loss: 7.9499 - val_precision: 0.6031 - val_recall: 0.8047\n",
      "Epoch 328/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.9475 - precision: 0.6178 - recall: 0.8140 - val_loss: 7.9424 - val_precision: 0.6030 - val_recall: 0.8043\n",
      "Epoch 329/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.9400 - precision: 0.6177 - recall: 0.8141 - val_loss: 7.9348 - val_precision: 0.6029 - val_recall: 0.8047\n",
      "Epoch 330/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.9325 - precision: 0.6180 - recall: 0.8138 - val_loss: 7.9273 - val_precision: 0.6031 - val_recall: 0.8047\n",
      "Epoch 331/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9249 - precision: 0.6184 - recall: 0.8134 - val_loss: 7.9198 - val_precision: 0.6035 - val_recall: 0.8043\n",
      "Epoch 332/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9174 - precision: 0.6178 - recall: 0.8141 - val_loss: 7.9123 - val_precision: 0.6035 - val_recall: 0.8043\n",
      "Epoch 333/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9099 - precision: 0.6182 - recall: 0.8136 - val_loss: 7.9047 - val_precision: 0.6037 - val_recall: 0.8043\n",
      "Epoch 334/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9024 - precision: 0.6184 - recall: 0.8129 - val_loss: 7.8972 - val_precision: 0.6037 - val_recall: 0.8039\n",
      "Epoch 335/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.8949 - precision: 0.6181 - recall: 0.8132 - val_loss: 7.8897 - val_precision: 0.6036 - val_recall: 0.8047\n",
      "Epoch 336/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8874 - precision: 0.6183 - recall: 0.8129 - val_loss: 7.8822 - val_precision: 0.6033 - val_recall: 0.8031\n",
      "Epoch 337/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8799 - precision: 0.6185 - recall: 0.8127 - val_loss: 7.8747 - val_precision: 0.6033 - val_recall: 0.8019\n",
      "Epoch 338/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8724 - precision: 0.6185 - recall: 0.8127 - val_loss: 7.8672 - val_precision: 0.6032 - val_recall: 0.8019\n",
      "Epoch 339/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.8649 - precision: 0.6185 - recall: 0.8132 - val_loss: 7.8597 - val_precision: 0.6032 - val_recall: 0.8019\n",
      "Epoch 340/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.8574 - precision: 0.6185 - recall: 0.8125 - val_loss: 7.8523 - val_precision: 0.6036 - val_recall: 0.8016\n",
      "Epoch 341/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8499 - precision: 0.6185 - recall: 0.8120 - val_loss: 7.8448 - val_precision: 0.6036 - val_recall: 0.8016\n",
      "Epoch 342/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.8425 - precision: 0.6186 - recall: 0.8124 - val_loss: 7.8373 - val_precision: 0.6037 - val_recall: 0.8019\n",
      "Epoch 343/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8350 - precision: 0.6185 - recall: 0.8127 - val_loss: 7.8298 - val_precision: 0.6038 - val_recall: 0.8023\n",
      "Epoch 344/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8275 - precision: 0.6186 - recall: 0.8125 - val_loss: 7.8223 - val_precision: 0.6039 - val_recall: 0.8019\n",
      "Epoch 345/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8201 - precision: 0.6189 - recall: 0.8121 - val_loss: 7.8149 - val_precision: 0.6036 - val_recall: 0.8004\n",
      "Epoch 346/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.8126 - precision: 0.6186 - recall: 0.8125 - val_loss: 7.8074 - val_precision: 0.6039 - val_recall: 0.8019\n",
      "Epoch 347/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.8051 - precision: 0.6189 - recall: 0.8122 - val_loss: 7.8000 - val_precision: 0.6040 - val_recall: 0.8012\n",
      "Epoch 348/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.7977 - precision: 0.6190 - recall: 0.8122 - val_loss: 7.7925 - val_precision: 0.6038 - val_recall: 0.8004\n",
      "Epoch 349/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 7.7902 - precision: 0.6193 - recall: 0.8117 - val_loss: 7.7851 - val_precision: 0.6048 - val_recall: 0.8008\n",
      "Epoch 350/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7828 - precision: 0.6193 - recall: 0.8121 - val_loss: 7.7776 - val_precision: 0.6042 - val_recall: 0.8012\n",
      "Epoch 351/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7753 - precision: 0.6188 - recall: 0.8127 - val_loss: 7.7702 - val_precision: 0.6042 - val_recall: 0.8008\n",
      "Epoch 352/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.7679 - precision: 0.6189 - recall: 0.8125 - val_loss: 7.7627 - val_precision: 0.6045 - val_recall: 0.8004\n",
      "Epoch 353/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7605 - precision: 0.6190 - recall: 0.8124 - val_loss: 7.7553 - val_precision: 0.6046 - val_recall: 0.8004\n",
      "Epoch 354/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7530 - precision: 0.6193 - recall: 0.8111 - val_loss: 7.7479 - val_precision: 0.6051 - val_recall: 0.8000\n",
      "Epoch 355/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7456 - precision: 0.6189 - recall: 0.8117 - val_loss: 7.7404 - val_precision: 0.6046 - val_recall: 0.8004\n",
      "Epoch 356/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7382 - precision: 0.6192 - recall: 0.8113 - val_loss: 7.7330 - val_precision: 0.6051 - val_recall: 0.7996\n",
      "Epoch 357/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7308 - precision: 0.6195 - recall: 0.8118 - val_loss: 7.7256 - val_precision: 0.6053 - val_recall: 0.7996\n",
      "Epoch 358/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7233 - precision: 0.6194 - recall: 0.8117 - val_loss: 7.7182 - val_precision: 0.6060 - val_recall: 0.7996\n",
      "Epoch 359/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.7159 - precision: 0.6197 - recall: 0.8111 - val_loss: 7.7108 - val_precision: 0.6058 - val_recall: 0.7996\n",
      "Epoch 360/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7085 - precision: 0.6198 - recall: 0.8112 - val_loss: 7.7033 - val_precision: 0.6060 - val_recall: 0.7996\n",
      "Epoch 361/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.7011 - precision: 0.6196 - recall: 0.8107 - val_loss: 7.6959 - val_precision: 0.6064 - val_recall: 0.7996\n",
      "Epoch 362/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6937 - precision: 0.6198 - recall: 0.8108 - val_loss: 7.6885 - val_precision: 0.6065 - val_recall: 0.8000\n",
      "Epoch 363/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6863 - precision: 0.6196 - recall: 0.8116 - val_loss: 7.6811 - val_precision: 0.6066 - val_recall: 0.8004\n",
      "Epoch 364/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6789 - precision: 0.6200 - recall: 0.8111 - val_loss: 7.6738 - val_precision: 0.6068 - val_recall: 0.8004\n",
      "Epoch 365/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6715 - precision: 0.6201 - recall: 0.8110 - val_loss: 7.6664 - val_precision: 0.6069 - val_recall: 0.8008\n",
      "Epoch 366/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6642 - precision: 0.6202 - recall: 0.8107 - val_loss: 7.6590 - val_precision: 0.6067 - val_recall: 0.7996\n",
      "Epoch 367/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6568 - precision: 0.6204 - recall: 0.8099 - val_loss: 7.6516 - val_precision: 0.6067 - val_recall: 0.7988\n",
      "Epoch 368/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6494 - precision: 0.6202 - recall: 0.8102 - val_loss: 7.6442 - val_precision: 0.6070 - val_recall: 0.7992\n",
      "Epoch 369/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6420 - precision: 0.6203 - recall: 0.8103 - val_loss: 7.6368 - val_precision: 0.6072 - val_recall: 0.7992\n",
      "Epoch 370/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6347 - precision: 0.6204 - recall: 0.8102 - val_loss: 7.6295 - val_precision: 0.6072 - val_recall: 0.7992\n",
      "Epoch 371/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6273 - precision: 0.6204 - recall: 0.8099 - val_loss: 7.6221 - val_precision: 0.6072 - val_recall: 0.7992\n",
      "Epoch 372/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.6199 - precision: 0.6205 - recall: 0.8099 - val_loss: 7.6147 - val_precision: 0.6072 - val_recall: 0.7992\n",
      "Epoch 373/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.6126 - precision: 0.6206 - recall: 0.8097 - val_loss: 7.6074 - val_precision: 0.6069 - val_recall: 0.7984\n",
      "Epoch 374/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.6052 - precision: 0.6206 - recall: 0.8097 - val_loss: 7.6000 - val_precision: 0.6068 - val_recall: 0.7981\n",
      "Epoch 375/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5979 - precision: 0.6209 - recall: 0.8092 - val_loss: 7.5927 - val_precision: 0.6068 - val_recall: 0.7981\n",
      "Epoch 376/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5905 - precision: 0.6209 - recall: 0.8098 - val_loss: 7.5853 - val_precision: 0.6067 - val_recall: 0.7984\n",
      "Epoch 377/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5832 - precision: 0.6209 - recall: 0.8098 - val_loss: 7.5780 - val_precision: 0.6067 - val_recall: 0.7984\n",
      "Epoch 378/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.5758 - precision: 0.6211 - recall: 0.8087 - val_loss: 7.5707 - val_precision: 0.6068 - val_recall: 0.7981\n",
      "Epoch 379/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5685 - precision: 0.6209 - recall: 0.8097 - val_loss: 7.5633 - val_precision: 0.6070 - val_recall: 0.7981\n",
      "Epoch 380/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5612 - precision: 0.6211 - recall: 0.8089 - val_loss: 7.5560 - val_precision: 0.6072 - val_recall: 0.7981\n",
      "Epoch 381/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5538 - precision: 0.6211 - recall: 0.8093 - val_loss: 7.5487 - val_precision: 0.6069 - val_recall: 0.7977\n",
      "Epoch 382/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5465 - precision: 0.6212 - recall: 0.8093 - val_loss: 7.5413 - val_precision: 0.6070 - val_recall: 0.7977\n",
      "Epoch 383/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5392 - precision: 0.6212 - recall: 0.8094 - val_loss: 7.5340 - val_precision: 0.6069 - val_recall: 0.7977\n",
      "Epoch 384/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5319 - precision: 0.6214 - recall: 0.8097 - val_loss: 7.5267 - val_precision: 0.6072 - val_recall: 0.7977\n",
      "Epoch 385/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5246 - precision: 0.6218 - recall: 0.8092 - val_loss: 7.5194 - val_precision: 0.6072 - val_recall: 0.7977\n",
      "Epoch 386/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5173 - precision: 0.6219 - recall: 0.8088 - val_loss: 7.5121 - val_precision: 0.6076 - val_recall: 0.7977\n",
      "Epoch 387/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5100 - precision: 0.6221 - recall: 0.8088 - val_loss: 7.5048 - val_precision: 0.6075 - val_recall: 0.7973\n",
      "Epoch 388/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.5027 - precision: 0.6223 - recall: 0.8088 - val_loss: 7.4975 - val_precision: 0.6075 - val_recall: 0.7973\n",
      "Epoch 389/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4954 - precision: 0.6226 - recall: 0.8088 - val_loss: 7.4902 - val_precision: 0.6075 - val_recall: 0.7973\n",
      "Epoch 390/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.4881 - precision: 0.6226 - recall: 0.8089 - val_loss: 7.4829 - val_precision: 0.6075 - val_recall: 0.7973\n",
      "Epoch 391/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.4808 - precision: 0.6226 - recall: 0.8097 - val_loss: 7.4756 - val_precision: 0.6076 - val_recall: 0.7977\n",
      "Epoch 392/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4735 - precision: 0.6226 - recall: 0.8090 - val_loss: 7.4683 - val_precision: 0.6074 - val_recall: 0.7969\n",
      "Epoch 393/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4662 - precision: 0.6228 - recall: 0.8089 - val_loss: 7.4611 - val_precision: 0.6074 - val_recall: 0.7969\n",
      "Epoch 394/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.4590 - precision: 0.6229 - recall: 0.8088 - val_loss: 7.4538 - val_precision: 0.6079 - val_recall: 0.7969\n",
      "Epoch 395/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4517 - precision: 0.6227 - recall: 0.8085 - val_loss: 7.4465 - val_precision: 0.6081 - val_recall: 0.7977\n",
      "Epoch 396/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.4444 - precision: 0.6227 - recall: 0.8085 - val_loss: 7.4392 - val_precision: 0.6081 - val_recall: 0.7977\n",
      "Epoch 397/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.4372 - precision: 0.6228 - recall: 0.8087 - val_loss: 7.4320 - val_precision: 0.6087 - val_recall: 0.7977\n",
      "Epoch 398/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4299 - precision: 0.6228 - recall: 0.8084 - val_loss: 7.4247 - val_precision: 0.6087 - val_recall: 0.7977\n",
      "Epoch 399/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4226 - precision: 0.6229 - recall: 0.8082 - val_loss: 7.4175 - val_precision: 0.6087 - val_recall: 0.7977\n",
      "Epoch 400/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4154 - precision: 0.6230 - recall: 0.8076 - val_loss: 7.4102 - val_precision: 0.6087 - val_recall: 0.7977\n",
      "Epoch 401/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.4081 - precision: 0.6227 - recall: 0.8085 - val_loss: 7.4029 - val_precision: 0.6089 - val_recall: 0.7984\n",
      "Epoch 402/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.4009 - precision: 0.6230 - recall: 0.8080 - val_loss: 7.3957 - val_precision: 0.6089 - val_recall: 0.7977\n",
      "Epoch 403/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3936 - precision: 0.6230 - recall: 0.8075 - val_loss: 7.3885 - val_precision: 0.6089 - val_recall: 0.7977\n",
      "Epoch 404/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.3864 - precision: 0.6232 - recall: 0.8079 - val_loss: 7.3812 - val_precision: 0.6092 - val_recall: 0.7977\n",
      "Epoch 405/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3792 - precision: 0.6234 - recall: 0.8071 - val_loss: 7.3740 - val_precision: 0.6092 - val_recall: 0.7969\n",
      "Epoch 406/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3720 - precision: 0.6233 - recall: 0.8075 - val_loss: 7.3668 - val_precision: 0.6087 - val_recall: 0.7973\n",
      "Epoch 407/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.3647 - precision: 0.6234 - recall: 0.8075 - val_loss: 7.3595 - val_precision: 0.6089 - val_recall: 0.7977\n",
      "Epoch 408/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3575 - precision: 0.6233 - recall: 0.8076 - val_loss: 7.3523 - val_precision: 0.6089 - val_recall: 0.7977\n",
      "Epoch 409/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3503 - precision: 0.6234 - recall: 0.8078 - val_loss: 7.3451 - val_precision: 0.6091 - val_recall: 0.7973\n",
      "Epoch 410/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3431 - precision: 0.6231 - recall: 0.8076 - val_loss: 7.3379 - val_precision: 0.6091 - val_recall: 0.7973\n",
      "Epoch 411/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3359 - precision: 0.6233 - recall: 0.8076 - val_loss: 7.3307 - val_precision: 0.6090 - val_recall: 0.7981\n",
      "Epoch 412/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3287 - precision: 0.6233 - recall: 0.8078 - val_loss: 7.3235 - val_precision: 0.6091 - val_recall: 0.7981\n",
      "Epoch 413/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3215 - precision: 0.6235 - recall: 0.8076 - val_loss: 7.3163 - val_precision: 0.6093 - val_recall: 0.7981\n",
      "Epoch 414/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3143 - precision: 0.6233 - recall: 0.8075 - val_loss: 7.3091 - val_precision: 0.6093 - val_recall: 0.7981\n",
      "Epoch 415/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.3071 - precision: 0.6235 - recall: 0.8074 - val_loss: 7.3019 - val_precision: 0.6091 - val_recall: 0.7973\n",
      "Epoch 416/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2999 - precision: 0.6234 - recall: 0.8080 - val_loss: 7.2947 - val_precision: 0.6091 - val_recall: 0.7981\n",
      "Epoch 417/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2927 - precision: 0.6235 - recall: 0.8076 - val_loss: 7.2875 - val_precision: 0.6092 - val_recall: 0.7977\n",
      "Epoch 418/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2855 - precision: 0.6236 - recall: 0.8075 - val_loss: 7.2803 - val_precision: 0.6090 - val_recall: 0.7977\n",
      "Epoch 419/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.2784 - precision: 0.6234 - recall: 0.8075 - val_loss: 7.2732 - val_precision: 0.6091 - val_recall: 0.7981\n",
      "Epoch 420/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2712 - precision: 0.6238 - recall: 0.8070 - val_loss: 7.2660 - val_precision: 0.6096 - val_recall: 0.7973\n",
      "Epoch 421/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.2640 - precision: 0.6231 - recall: 0.8074 - val_loss: 7.2588 - val_precision: 0.6094 - val_recall: 0.7977\n",
      "Epoch 422/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2568 - precision: 0.6232 - recall: 0.8079 - val_loss: 7.2517 - val_precision: 0.6094 - val_recall: 0.7977\n",
      "Epoch 423/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2497 - precision: 0.6234 - recall: 0.8071 - val_loss: 7.2445 - val_precision: 0.6096 - val_recall: 0.7977\n",
      "Epoch 424/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 7.2425 - precision: 0.6237 - recall: 0.8069 - val_loss: 7.2373 - val_precision: 0.6093 - val_recall: 0.7969\n",
      "Epoch 425/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 7.2354 - precision: 0.6242 - recall: 0.8069 - val_loss: 7.2302 - val_precision: 0.6092 - val_recall: 0.7965\n",
      "Epoch 426/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.2282 - precision: 0.6245 - recall: 0.8066 - val_loss: 7.2230 - val_precision: 0.6092 - val_recall: 0.7965\n",
      "Epoch 427/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2211 - precision: 0.6243 - recall: 0.8070 - val_loss: 7.2159 - val_precision: 0.6092 - val_recall: 0.7965\n",
      "Epoch 428/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2139 - precision: 0.6245 - recall: 0.8073 - val_loss: 7.2088 - val_precision: 0.6089 - val_recall: 0.7965\n",
      "Epoch 429/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.2068 - precision: 0.6245 - recall: 0.8059 - val_loss: 7.2016 - val_precision: 0.6098 - val_recall: 0.7961\n",
      "Epoch 430/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1997 - precision: 0.6244 - recall: 0.8061 - val_loss: 7.1945 - val_precision: 0.6099 - val_recall: 0.7957\n",
      "Epoch 431/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1925 - precision: 0.6245 - recall: 0.8052 - val_loss: 7.1874 - val_precision: 0.6096 - val_recall: 0.7953\n",
      "Epoch 432/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1854 - precision: 0.6244 - recall: 0.8059 - val_loss: 7.1802 - val_precision: 0.6098 - val_recall: 0.7965\n",
      "Epoch 433/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1783 - precision: 0.6244 - recall: 0.8054 - val_loss: 7.1731 - val_precision: 0.6102 - val_recall: 0.7961\n",
      "Epoch 434/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.1712 - precision: 0.6245 - recall: 0.8052 - val_loss: 7.1660 - val_precision: 0.6103 - val_recall: 0.7965\n",
      "Epoch 435/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1641 - precision: 0.6246 - recall: 0.8045 - val_loss: 7.1589 - val_precision: 0.6103 - val_recall: 0.7957\n",
      "Epoch 436/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1569 - precision: 0.6247 - recall: 0.8048 - val_loss: 7.1518 - val_precision: 0.6103 - val_recall: 0.7953\n",
      "Epoch 437/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1498 - precision: 0.6247 - recall: 0.8042 - val_loss: 7.1447 - val_precision: 0.6103 - val_recall: 0.7953\n",
      "Epoch 438/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.1427 - precision: 0.6247 - recall: 0.8050 - val_loss: 7.1375 - val_precision: 0.6098 - val_recall: 0.7961\n",
      "Epoch 439/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.1356 - precision: 0.6247 - recall: 0.8046 - val_loss: 7.1304 - val_precision: 0.6099 - val_recall: 0.7957\n",
      "Epoch 440/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1285 - precision: 0.6247 - recall: 0.8045 - val_loss: 7.1234 - val_precision: 0.6099 - val_recall: 0.7957\n",
      "Epoch 441/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1214 - precision: 0.6246 - recall: 0.8047 - val_loss: 7.1163 - val_precision: 0.6098 - val_recall: 0.7961\n",
      "Epoch 442/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1144 - precision: 0.6246 - recall: 0.8043 - val_loss: 7.1092 - val_precision: 0.6101 - val_recall: 0.7969\n",
      "Epoch 443/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1073 - precision: 0.6246 - recall: 0.8041 - val_loss: 7.1021 - val_precision: 0.6102 - val_recall: 0.7961\n",
      "Epoch 444/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.1002 - precision: 0.6249 - recall: 0.8043 - val_loss: 7.0950 - val_precision: 0.6100 - val_recall: 0.7965\n",
      "Epoch 445/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0931 - precision: 0.6251 - recall: 0.8038 - val_loss: 7.0879 - val_precision: 0.6098 - val_recall: 0.7961\n",
      "Epoch 446/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0860 - precision: 0.6251 - recall: 0.8036 - val_loss: 7.0809 - val_precision: 0.6100 - val_recall: 0.7961\n",
      "Epoch 447/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0790 - precision: 0.6249 - recall: 0.8037 - val_loss: 7.0738 - val_precision: 0.6101 - val_recall: 0.7965\n",
      "Epoch 448/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0719 - precision: 0.6251 - recall: 0.8039 - val_loss: 7.0667 - val_precision: 0.6101 - val_recall: 0.7965\n",
      "Epoch 449/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0648 - precision: 0.6251 - recall: 0.8027 - val_loss: 7.0597 - val_precision: 0.6101 - val_recall: 0.7957\n",
      "Epoch 450/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0578 - precision: 0.6251 - recall: 0.8028 - val_loss: 7.0526 - val_precision: 0.6102 - val_recall: 0.7949\n",
      "Epoch 451/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0507 - precision: 0.6253 - recall: 0.8023 - val_loss: 7.0456 - val_precision: 0.6103 - val_recall: 0.7942\n",
      "Epoch 452/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.0437 - precision: 0.6251 - recall: 0.8031 - val_loss: 7.0385 - val_precision: 0.6103 - val_recall: 0.7957\n",
      "Epoch 453/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.0366 - precision: 0.6252 - recall: 0.8020 - val_loss: 7.0315 - val_precision: 0.6104 - val_recall: 0.7949\n",
      "Epoch 454/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0296 - precision: 0.6252 - recall: 0.8020 - val_loss: 7.0244 - val_precision: 0.6104 - val_recall: 0.7949\n",
      "Epoch 455/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0226 - precision: 0.6252 - recall: 0.8022 - val_loss: 7.0174 - val_precision: 0.6106 - val_recall: 0.7949\n",
      "Epoch 456/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0155 - precision: 0.6252 - recall: 0.8017 - val_loss: 7.0104 - val_precision: 0.6106 - val_recall: 0.7949\n",
      "Epoch 457/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 7.0085 - precision: 0.6252 - recall: 0.8023 - val_loss: 7.0033 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 458/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.0015 - precision: 0.6256 - recall: 0.8020 - val_loss: 6.9963 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 459/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9945 - precision: 0.6255 - recall: 0.8020 - val_loss: 6.9893 - val_precision: 0.6111 - val_recall: 0.7949\n",
      "Epoch 460/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9874 - precision: 0.6255 - recall: 0.8027 - val_loss: 6.9823 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 461/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9804 - precision: 0.6255 - recall: 0.8031 - val_loss: 6.9753 - val_precision: 0.6108 - val_recall: 0.7949\n",
      "Epoch 462/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9734 - precision: 0.6256 - recall: 0.8025 - val_loss: 6.9682 - val_precision: 0.6106 - val_recall: 0.7946\n",
      "Epoch 463/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9664 - precision: 0.6256 - recall: 0.8023 - val_loss: 6.9612 - val_precision: 0.6106 - val_recall: 0.7949\n",
      "Epoch 464/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.9594 - precision: 0.6257 - recall: 0.8018 - val_loss: 6.9542 - val_precision: 0.6108 - val_recall: 0.7938\n",
      "Epoch 465/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9524 - precision: 0.6258 - recall: 0.8022 - val_loss: 6.9472 - val_precision: 0.6109 - val_recall: 0.7942\n",
      "Epoch 466/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9454 - precision: 0.6260 - recall: 0.8017 - val_loss: 6.9403 - val_precision: 0.6102 - val_recall: 0.7926\n",
      "Epoch 467/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9384 - precision: 0.6256 - recall: 0.8019 - val_loss: 6.9333 - val_precision: 0.6106 - val_recall: 0.7946\n",
      "Epoch 468/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.9314 - precision: 0.6259 - recall: 0.8020 - val_loss: 6.9263 - val_precision: 0.6104 - val_recall: 0.7938\n",
      "Epoch 469/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9245 - precision: 0.6259 - recall: 0.8019 - val_loss: 6.9193 - val_precision: 0.6106 - val_recall: 0.7946\n",
      "Epoch 470/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9175 - precision: 0.6259 - recall: 0.8023 - val_loss: 6.9123 - val_precision: 0.6106 - val_recall: 0.7949\n",
      "Epoch 471/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9105 - precision: 0.6262 - recall: 0.8019 - val_loss: 6.9054 - val_precision: 0.6109 - val_recall: 0.7942\n",
      "Epoch 472/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.9036 - precision: 0.6261 - recall: 0.8022 - val_loss: 6.8984 - val_precision: 0.6107 - val_recall: 0.7942\n",
      "Epoch 473/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8966 - precision: 0.6261 - recall: 0.8019 - val_loss: 6.8914 - val_precision: 0.6108 - val_recall: 0.7946\n",
      "Epoch 474/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.8896 - precision: 0.6264 - recall: 0.8022 - val_loss: 6.8845 - val_precision: 0.6108 - val_recall: 0.7946\n",
      "Epoch 475/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8827 - precision: 0.6262 - recall: 0.8018 - val_loss: 6.8775 - val_precision: 0.6106 - val_recall: 0.7946\n",
      "Epoch 476/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 6.8757 - precision: 0.6265 - recall: 0.8024 - val_loss: 6.8706 - val_precision: 0.6108 - val_recall: 0.7946\n",
      "Epoch 477/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8688 - precision: 0.6263 - recall: 0.8018 - val_loss: 6.8636 - val_precision: 0.6110 - val_recall: 0.7946\n",
      "Epoch 478/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.8618 - precision: 0.6264 - recall: 0.8022 - val_loss: 6.8567 - val_precision: 0.6111 - val_recall: 0.7942\n",
      "Epoch 479/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8549 - precision: 0.6265 - recall: 0.8029 - val_loss: 6.8497 - val_precision: 0.6109 - val_recall: 0.7949\n",
      "Epoch 480/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8480 - precision: 0.6265 - recall: 0.8029 - val_loss: 6.8428 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 481/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.8410 - precision: 0.6265 - recall: 0.8031 - val_loss: 6.8359 - val_precision: 0.6111 - val_recall: 0.7949\n",
      "Epoch 482/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8341 - precision: 0.6267 - recall: 0.8025 - val_loss: 6.8290 - val_precision: 0.6111 - val_recall: 0.7949\n",
      "Epoch 483/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8272 - precision: 0.6266 - recall: 0.8025 - val_loss: 6.8220 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 484/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8203 - precision: 0.6267 - recall: 0.8028 - val_loss: 6.8151 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 485/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.8134 - precision: 0.6266 - recall: 0.8025 - val_loss: 6.8082 - val_precision: 0.6109 - val_recall: 0.7949\n",
      "Epoch 486/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.8064 - precision: 0.6269 - recall: 0.8017 - val_loss: 6.8013 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 487/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7995 - precision: 0.6269 - recall: 0.8032 - val_loss: 6.7944 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 488/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7926 - precision: 0.6270 - recall: 0.8013 - val_loss: 6.7875 - val_precision: 0.6111 - val_recall: 0.7953\n",
      "Epoch 489/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7857 - precision: 0.6272 - recall: 0.8017 - val_loss: 6.7806 - val_precision: 0.6112 - val_recall: 0.7953\n",
      "Epoch 490/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7789 - precision: 0.6268 - recall: 0.8027 - val_loss: 6.7737 - val_precision: 0.6110 - val_recall: 0.7957\n",
      "Epoch 491/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7720 - precision: 0.6271 - recall: 0.8010 - val_loss: 6.7668 - val_precision: 0.6114 - val_recall: 0.7953\n",
      "Epoch 492/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7651 - precision: 0.6272 - recall: 0.8018 - val_loss: 6.7599 - val_precision: 0.6114 - val_recall: 0.7953\n",
      "Epoch 493/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7582 - precision: 0.6275 - recall: 0.8010 - val_loss: 6.7531 - val_precision: 0.6118 - val_recall: 0.7953\n",
      "Epoch 494/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7513 - precision: 0.6271 - recall: 0.8025 - val_loss: 6.7462 - val_precision: 0.6115 - val_recall: 0.7957\n",
      "Epoch 495/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.7444 - precision: 0.6272 - recall: 0.8025 - val_loss: 6.7393 - val_precision: 0.6114 - val_recall: 0.7957\n",
      "Epoch 496/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 6.7376 - precision: 0.6271 - recall: 0.8028 - val_loss: 6.7324 - val_precision: 0.6117 - val_recall: 0.7957\n",
      "Epoch 497/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7307 - precision: 0.6273 - recall: 0.8022 - val_loss: 6.7256 - val_precision: 0.6118 - val_recall: 0.7953\n",
      "Epoch 498/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7239 - precision: 0.6276 - recall: 0.8015 - val_loss: 6.7187 - val_precision: 0.6119 - val_recall: 0.7949\n",
      "Epoch 499/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7170 - precision: 0.6271 - recall: 0.8018 - val_loss: 6.7119 - val_precision: 0.6118 - val_recall: 0.7953\n",
      "Epoch 500/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.7102 - precision: 0.6273 - recall: 0.8014 - val_loss: 6.7050 - val_precision: 0.6119 - val_recall: 0.7949\n",
      "Epoch 501/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.7033 - precision: 0.6272 - recall: 0.8001 - val_loss: 6.6982 - val_precision: 0.6117 - val_recall: 0.7946\n",
      "Epoch 502/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.6965 - precision: 0.6272 - recall: 0.8014 - val_loss: 6.6913 - val_precision: 0.6118 - val_recall: 0.7953\n",
      "Epoch 503/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.6896 - precision: 0.6271 - recall: 0.8015 - val_loss: 6.6845 - val_precision: 0.6114 - val_recall: 0.7942\n",
      "Epoch 504/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6828 - precision: 0.6270 - recall: 0.8014 - val_loss: 6.6777 - val_precision: 0.6118 - val_recall: 0.7953\n",
      "Epoch 505/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.6760 - precision: 0.6271 - recall: 0.8015 - val_loss: 6.6708 - val_precision: 0.6119 - val_recall: 0.7957\n",
      "Epoch 506/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6691 - precision: 0.6270 - recall: 0.8013 - val_loss: 6.6640 - val_precision: 0.6119 - val_recall: 0.7946\n",
      "Epoch 507/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.6623 - precision: 0.6269 - recall: 0.8005 - val_loss: 6.6572 - val_precision: 0.6121 - val_recall: 0.7938\n",
      "Epoch 508/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6555 - precision: 0.6270 - recall: 0.8004 - val_loss: 6.6504 - val_precision: 0.6124 - val_recall: 0.7949\n",
      "Epoch 509/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6487 - precision: 0.6271 - recall: 0.8006 - val_loss: 6.6436 - val_precision: 0.6124 - val_recall: 0.7949\n",
      "Epoch 510/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6419 - precision: 0.6269 - recall: 0.8014 - val_loss: 6.6368 - val_precision: 0.6123 - val_recall: 0.7953\n",
      "Epoch 511/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.6351 - precision: 0.6271 - recall: 0.8009 - val_loss: 6.6300 - val_precision: 0.6121 - val_recall: 0.7946\n",
      "Epoch 512/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6283 - precision: 0.6270 - recall: 0.8001 - val_loss: 6.6232 - val_precision: 0.6124 - val_recall: 0.7942\n",
      "Epoch 513/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.6215 - precision: 0.6272 - recall: 0.8004 - val_loss: 6.6164 - val_precision: 0.6124 - val_recall: 0.7949\n",
      "Epoch 514/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.6147 - precision: 0.6273 - recall: 0.7996 - val_loss: 6.6096 - val_precision: 0.6123 - val_recall: 0.7946\n",
      "Epoch 515/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6079 - precision: 0.6273 - recall: 0.8005 - val_loss: 6.6028 - val_precision: 0.6125 - val_recall: 0.7946\n",
      "Epoch 516/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.6011 - precision: 0.6274 - recall: 0.7997 - val_loss: 6.5960 - val_precision: 0.6126 - val_recall: 0.7938\n",
      "Epoch 517/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5943 - precision: 0.6274 - recall: 0.8003 - val_loss: 6.5892 - val_precision: 0.6126 - val_recall: 0.7938\n",
      "Epoch 518/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.5875 - precision: 0.6275 - recall: 0.8005 - val_loss: 6.5824 - val_precision: 0.6126 - val_recall: 0.7938\n",
      "Epoch 519/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5808 - precision: 0.6274 - recall: 0.8000 - val_loss: 6.5757 - val_precision: 0.6126 - val_recall: 0.7938\n",
      "Epoch 520/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5740 - precision: 0.6274 - recall: 0.7997 - val_loss: 6.5689 - val_precision: 0.6124 - val_recall: 0.7938\n",
      "Epoch 521/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5672 - precision: 0.6273 - recall: 0.7996 - val_loss: 6.5621 - val_precision: 0.6126 - val_recall: 0.7938\n",
      "Epoch 522/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.5605 - precision: 0.6276 - recall: 0.8003 - val_loss: 6.5554 - val_precision: 0.6122 - val_recall: 0.7938\n",
      "Epoch 523/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5537 - precision: 0.6277 - recall: 0.8005 - val_loss: 6.5486 - val_precision: 0.6121 - val_recall: 0.7934\n",
      "Epoch 524/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 6.5470 - precision: 0.6279 - recall: 0.8006 - val_loss: 6.5419 - val_precision: 0.6122 - val_recall: 0.7938\n",
      "Epoch 525/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.5402 - precision: 0.6278 - recall: 0.8003 - val_loss: 6.5351 - val_precision: 0.6123 - val_recall: 0.7934\n",
      "Epoch 526/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5335 - precision: 0.6277 - recall: 0.7996 - val_loss: 6.5284 - val_precision: 0.6123 - val_recall: 0.7934\n",
      "Epoch 527/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5267 - precision: 0.6277 - recall: 0.7996 - val_loss: 6.5216 - val_precision: 0.6126 - val_recall: 0.7938\n",
      "Epoch 528/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5200 - precision: 0.6277 - recall: 0.7996 - val_loss: 6.5149 - val_precision: 0.6126 - val_recall: 0.7938\n",
      "Epoch 529/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5132 - precision: 0.6278 - recall: 0.7996 - val_loss: 6.5082 - val_precision: 0.6127 - val_recall: 0.7942\n",
      "Epoch 530/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.5065 - precision: 0.6280 - recall: 0.8006 - val_loss: 6.5015 - val_precision: 0.6127 - val_recall: 0.7942\n",
      "Epoch 531/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4998 - precision: 0.6279 - recall: 0.7995 - val_loss: 6.4947 - val_precision: 0.6129 - val_recall: 0.7942\n",
      "Epoch 532/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4931 - precision: 0.6278 - recall: 0.7999 - val_loss: 6.4880 - val_precision: 0.6131 - val_recall: 0.7942\n",
      "Epoch 533/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4864 - precision: 0.6281 - recall: 0.7992 - val_loss: 6.4813 - val_precision: 0.6131 - val_recall: 0.7942\n",
      "Epoch 534/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4797 - precision: 0.6278 - recall: 0.7999 - val_loss: 6.4746 - val_precision: 0.6131 - val_recall: 0.7949\n",
      "Epoch 535/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4730 - precision: 0.6278 - recall: 0.7992 - val_loss: 6.4679 - val_precision: 0.6131 - val_recall: 0.7942\n",
      "Epoch 536/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4662 - precision: 0.6279 - recall: 0.7997 - val_loss: 6.4612 - val_precision: 0.6131 - val_recall: 0.7949\n",
      "Epoch 537/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.4596 - precision: 0.6279 - recall: 0.7997 - val_loss: 6.4545 - val_precision: 0.6131 - val_recall: 0.7949\n",
      "Epoch 538/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4529 - precision: 0.6278 - recall: 0.7996 - val_loss: 6.4478 - val_precision: 0.6131 - val_recall: 0.7949\n",
      "Epoch 539/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4462 - precision: 0.6277 - recall: 0.7991 - val_loss: 6.4411 - val_precision: 0.6131 - val_recall: 0.7942\n",
      "Epoch 540/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4395 - precision: 0.6279 - recall: 0.7997 - val_loss: 6.4344 - val_precision: 0.6133 - val_recall: 0.7949\n",
      "Epoch 541/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.4328 - precision: 0.6279 - recall: 0.7995 - val_loss: 6.4278 - val_precision: 0.6133 - val_recall: 0.7949\n",
      "Epoch 542/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.4261 - precision: 0.6280 - recall: 0.7995 - val_loss: 6.4211 - val_precision: 0.6133 - val_recall: 0.7942\n",
      "Epoch 543/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4194 - precision: 0.6281 - recall: 0.7994 - val_loss: 6.4144 - val_precision: 0.6135 - val_recall: 0.7942\n",
      "Epoch 544/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4128 - precision: 0.6283 - recall: 0.8000 - val_loss: 6.4077 - val_precision: 0.6135 - val_recall: 0.7949\n",
      "Epoch 545/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.4061 - precision: 0.6282 - recall: 0.7992 - val_loss: 6.4011 - val_precision: 0.6138 - val_recall: 0.7942\n",
      "Epoch 546/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.3995 - precision: 0.6282 - recall: 0.7997 - val_loss: 6.3944 - val_precision: 0.6138 - val_recall: 0.7953\n",
      "Epoch 547/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3928 - precision: 0.6282 - recall: 0.8004 - val_loss: 6.3878 - val_precision: 0.6139 - val_recall: 0.7949\n",
      "Epoch 548/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3861 - precision: 0.6281 - recall: 0.8006 - val_loss: 6.3811 - val_precision: 0.6140 - val_recall: 0.7953\n",
      "Epoch 549/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3795 - precision: 0.6284 - recall: 0.8003 - val_loss: 6.3745 - val_precision: 0.6138 - val_recall: 0.7946\n",
      "Epoch 550/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3728 - precision: 0.6284 - recall: 0.7997 - val_loss: 6.3678 - val_precision: 0.6139 - val_recall: 0.7938\n",
      "Epoch 551/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3662 - precision: 0.6285 - recall: 0.7996 - val_loss: 6.3612 - val_precision: 0.6140 - val_recall: 0.7934\n",
      "Epoch 552/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3596 - precision: 0.6283 - recall: 0.7997 - val_loss: 6.3545 - val_precision: 0.6138 - val_recall: 0.7942\n",
      "Epoch 553/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3529 - precision: 0.6284 - recall: 0.8006 - val_loss: 6.3479 - val_precision: 0.6138 - val_recall: 0.7942\n",
      "Epoch 554/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3463 - precision: 0.6286 - recall: 0.7995 - val_loss: 6.3413 - val_precision: 0.6138 - val_recall: 0.7934\n",
      "Epoch 555/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.3397 - precision: 0.6283 - recall: 0.8005 - val_loss: 6.3347 - val_precision: 0.6138 - val_recall: 0.7942\n",
      "Epoch 556/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3331 - precision: 0.6285 - recall: 0.7990 - val_loss: 6.3280 - val_precision: 0.6135 - val_recall: 0.7938\n",
      "Epoch 557/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3264 - precision: 0.6284 - recall: 0.7994 - val_loss: 6.3214 - val_precision: 0.6135 - val_recall: 0.7938\n",
      "Epoch 558/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3198 - precision: 0.6284 - recall: 0.7994 - val_loss: 6.3148 - val_precision: 0.6137 - val_recall: 0.7938\n",
      "Epoch 559/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.3132 - precision: 0.6285 - recall: 0.7994 - val_loss: 6.3082 - val_precision: 0.6138 - val_recall: 0.7942\n",
      "Epoch 560/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.3066 - precision: 0.6284 - recall: 0.7994 - val_loss: 6.3016 - val_precision: 0.6140 - val_recall: 0.7946\n",
      "Epoch 561/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.3000 - precision: 0.6285 - recall: 0.7994 - val_loss: 6.2950 - val_precision: 0.6136 - val_recall: 0.7934\n",
      "Epoch 562/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.2934 - precision: 0.6285 - recall: 0.7996 - val_loss: 6.2884 - val_precision: 0.6136 - val_recall: 0.7934\n",
      "Epoch 563/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2868 - precision: 0.6285 - recall: 0.7999 - val_loss: 6.2818 - val_precision: 0.6137 - val_recall: 0.7938\n",
      "Epoch 564/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2803 - precision: 0.6285 - recall: 0.7987 - val_loss: 6.2753 - val_precision: 0.6139 - val_recall: 0.7930\n",
      "Epoch 565/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2737 - precision: 0.6284 - recall: 0.7995 - val_loss: 6.2687 - val_precision: 0.6137 - val_recall: 0.7938\n",
      "Epoch 566/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2671 - precision: 0.6285 - recall: 0.7994 - val_loss: 6.2621 - val_precision: 0.6140 - val_recall: 0.7934\n",
      "Epoch 567/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2605 - precision: 0.6286 - recall: 0.8004 - val_loss: 6.2555 - val_precision: 0.6141 - val_recall: 0.7938\n",
      "Epoch 568/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2540 - precision: 0.6284 - recall: 0.7994 - val_loss: 6.2490 - val_precision: 0.6140 - val_recall: 0.7934\n",
      "Epoch 569/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.2474 - precision: 0.6286 - recall: 0.8005 - val_loss: 6.2424 - val_precision: 0.6141 - val_recall: 0.7938\n",
      "Epoch 570/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2408 - precision: 0.6287 - recall: 0.8003 - val_loss: 6.2358 - val_precision: 0.6141 - val_recall: 0.7938\n",
      "Epoch 571/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2343 - precision: 0.6287 - recall: 0.8001 - val_loss: 6.2293 - val_precision: 0.6143 - val_recall: 0.7938\n",
      "Epoch 572/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2277 - precision: 0.6287 - recall: 0.8003 - val_loss: 6.2227 - val_precision: 0.6143 - val_recall: 0.7938\n",
      "Epoch 573/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.2212 - precision: 0.6288 - recall: 0.8000 - val_loss: 6.2162 - val_precision: 0.6143 - val_recall: 0.7938\n",
      "Epoch 574/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.2146 - precision: 0.6287 - recall: 0.8004 - val_loss: 6.2096 - val_precision: 0.6143 - val_recall: 0.7938\n",
      "Epoch 575/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.2081 - precision: 0.6289 - recall: 0.8004 - val_loss: 6.2031 - val_precision: 0.6140 - val_recall: 0.7930\n",
      "Epoch 576/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.2015 - precision: 0.6288 - recall: 0.7999 - val_loss: 6.1966 - val_precision: 0.6139 - val_recall: 0.7926\n",
      "Epoch 577/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1950 - precision: 0.6289 - recall: 0.8006 - val_loss: 6.1900 - val_precision: 0.6140 - val_recall: 0.7934\n",
      "Epoch 578/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1885 - precision: 0.6290 - recall: 0.8008 - val_loss: 6.1835 - val_precision: 0.6139 - val_recall: 0.7926\n",
      "Epoch 579/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1819 - precision: 0.6289 - recall: 0.8010 - val_loss: 6.1770 - val_precision: 0.6136 - val_recall: 0.7926\n",
      "Epoch 580/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1754 - precision: 0.6288 - recall: 0.8011 - val_loss: 6.1704 - val_precision: 0.6134 - val_recall: 0.7926\n",
      "Epoch 581/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1689 - precision: 0.6288 - recall: 0.8005 - val_loss: 6.1639 - val_precision: 0.6135 - val_recall: 0.7918\n",
      "Epoch 582/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 6.1624 - precision: 0.6290 - recall: 0.8005 - val_loss: 6.1574 - val_precision: 0.6137 - val_recall: 0.7918\n",
      "Epoch 583/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1559 - precision: 0.6290 - recall: 0.8000 - val_loss: 6.1509 - val_precision: 0.6135 - val_recall: 0.7918\n",
      "Epoch 584/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1493 - precision: 0.6290 - recall: 0.8006 - val_loss: 6.1444 - val_precision: 0.6135 - val_recall: 0.7918\n",
      "Epoch 585/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1428 - precision: 0.6290 - recall: 0.8008 - val_loss: 6.1379 - val_precision: 0.6135 - val_recall: 0.7918\n",
      "Epoch 586/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.1363 - precision: 0.6288 - recall: 0.8005 - val_loss: 6.1314 - val_precision: 0.6136 - val_recall: 0.7922\n",
      "Epoch 587/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1298 - precision: 0.6290 - recall: 0.8005 - val_loss: 6.1249 - val_precision: 0.6136 - val_recall: 0.7926\n",
      "Epoch 588/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.1234 - precision: 0.6293 - recall: 0.7995 - val_loss: 6.1184 - val_precision: 0.6142 - val_recall: 0.7922\n",
      "Epoch 589/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1169 - precision: 0.6294 - recall: 0.7995 - val_loss: 6.1119 - val_precision: 0.6145 - val_recall: 0.7922\n",
      "Epoch 590/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.1104 - precision: 0.6292 - recall: 0.8001 - val_loss: 6.1054 - val_precision: 0.6144 - val_recall: 0.7930\n",
      "Epoch 591/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.1039 - precision: 0.6292 - recall: 0.8003 - val_loss: 6.0990 - val_precision: 0.6145 - val_recall: 0.7926\n",
      "Epoch 592/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0974 - precision: 0.6293 - recall: 0.8000 - val_loss: 6.0925 - val_precision: 0.6144 - val_recall: 0.7922\n",
      "Epoch 593/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.0910 - precision: 0.6290 - recall: 0.7999 - val_loss: 6.0860 - val_precision: 0.6145 - val_recall: 0.7922\n",
      "Epoch 594/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0845 - precision: 0.6294 - recall: 0.7991 - val_loss: 6.0796 - val_precision: 0.6146 - val_recall: 0.7918\n",
      "Epoch 595/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0780 - precision: 0.6291 - recall: 0.7991 - val_loss: 6.0731 - val_precision: 0.6146 - val_recall: 0.7918\n",
      "Epoch 596/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0716 - precision: 0.6293 - recall: 0.7992 - val_loss: 6.0667 - val_precision: 0.6146 - val_recall: 0.7918\n",
      "Epoch 597/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0651 - precision: 0.6292 - recall: 0.7986 - val_loss: 6.0602 - val_precision: 0.6148 - val_recall: 0.7918\n",
      "Epoch 598/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0587 - precision: 0.6293 - recall: 0.7985 - val_loss: 6.0538 - val_precision: 0.6144 - val_recall: 0.7922\n",
      "Epoch 599/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.0522 - precision: 0.6292 - recall: 0.7985 - val_loss: 6.0473 - val_precision: 0.6146 - val_recall: 0.7918\n",
      "Epoch 600/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0458 - precision: 0.6294 - recall: 0.7980 - val_loss: 6.0409 - val_precision: 0.6149 - val_recall: 0.7911\n",
      "Epoch 601/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0394 - precision: 0.6294 - recall: 0.7987 - val_loss: 6.0344 - val_precision: 0.6144 - val_recall: 0.7918\n",
      "Epoch 602/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0329 - precision: 0.6294 - recall: 0.7987 - val_loss: 6.0280 - val_precision: 0.6144 - val_recall: 0.7918\n",
      "Epoch 603/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 6.0265 - precision: 0.6292 - recall: 0.7981 - val_loss: 6.0216 - val_precision: 0.6149 - val_recall: 0.7911\n",
      "Epoch 604/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 6.0201 - precision: 0.6292 - recall: 0.7983 - val_loss: 6.0152 - val_precision: 0.6146 - val_recall: 0.7918\n",
      "Epoch 605/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0137 - precision: 0.6293 - recall: 0.7982 - val_loss: 6.0088 - val_precision: 0.6151 - val_recall: 0.7911\n",
      "Epoch 606/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0072 - precision: 0.6293 - recall: 0.7975 - val_loss: 6.0023 - val_precision: 0.6153 - val_recall: 0.7911\n",
      "Epoch 607/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 6.0008 - precision: 0.6292 - recall: 0.7977 - val_loss: 5.9959 - val_precision: 0.6155 - val_recall: 0.7911\n",
      "Epoch 608/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9944 - precision: 0.6291 - recall: 0.7977 - val_loss: 5.9895 - val_precision: 0.6156 - val_recall: 0.7914\n",
      "Epoch 609/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.9880 - precision: 0.6293 - recall: 0.7975 - val_loss: 5.9831 - val_precision: 0.6154 - val_recall: 0.7907\n",
      "Epoch 610/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.9816 - precision: 0.6291 - recall: 0.7982 - val_loss: 5.9767 - val_precision: 0.6152 - val_recall: 0.7918\n",
      "Epoch 611/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.9752 - precision: 0.6290 - recall: 0.7981 - val_loss: 5.9703 - val_precision: 0.6156 - val_recall: 0.7914\n",
      "Epoch 612/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.9688 - precision: 0.6292 - recall: 0.7977 - val_loss: 5.9639 - val_precision: 0.6155 - val_recall: 0.7911\n",
      "Epoch 613/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9624 - precision: 0.6291 - recall: 0.7981 - val_loss: 5.9576 - val_precision: 0.6155 - val_recall: 0.7911\n",
      "Epoch 614/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9561 - precision: 0.6290 - recall: 0.7980 - val_loss: 5.9512 - val_precision: 0.6155 - val_recall: 0.7911\n",
      "Epoch 615/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9497 - precision: 0.6290 - recall: 0.7980 - val_loss: 5.9448 - val_precision: 0.6153 - val_recall: 0.7911\n",
      "Epoch 616/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9433 - precision: 0.6288 - recall: 0.7977 - val_loss: 5.9384 - val_precision: 0.6153 - val_recall: 0.7911\n",
      "Epoch 617/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9369 - precision: 0.6291 - recall: 0.7973 - val_loss: 5.9320 - val_precision: 0.6157 - val_recall: 0.7911\n",
      "Epoch 618/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9306 - precision: 0.6290 - recall: 0.7972 - val_loss: 5.9257 - val_precision: 0.6158 - val_recall: 0.7914\n",
      "Epoch 619/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9242 - precision: 0.6293 - recall: 0.7971 - val_loss: 5.9193 - val_precision: 0.6156 - val_recall: 0.7907\n",
      "Epoch 620/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.9178 - precision: 0.6291 - recall: 0.7971 - val_loss: 5.9130 - val_precision: 0.6155 - val_recall: 0.7911\n",
      "Epoch 621/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.9115 - precision: 0.6289 - recall: 0.7975 - val_loss: 5.9066 - val_precision: 0.6156 - val_recall: 0.7914\n",
      "Epoch 622/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.9051 - precision: 0.6292 - recall: 0.7969 - val_loss: 5.9003 - val_precision: 0.6155 - val_recall: 0.7903\n",
      "Epoch 623/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8988 - precision: 0.6288 - recall: 0.7971 - val_loss: 5.8939 - val_precision: 0.6157 - val_recall: 0.7911\n",
      "Epoch 624/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8924 - precision: 0.6289 - recall: 0.7969 - val_loss: 5.8876 - val_precision: 0.6157 - val_recall: 0.7911\n",
      "Epoch 625/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8861 - precision: 0.6289 - recall: 0.7967 - val_loss: 5.8812 - val_precision: 0.6161 - val_recall: 0.7911\n",
      "Epoch 626/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8798 - precision: 0.6291 - recall: 0.7967 - val_loss: 5.8749 - val_precision: 0.6158 - val_recall: 0.7914\n",
      "Epoch 627/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.8734 - precision: 0.6288 - recall: 0.7968 - val_loss: 5.8686 - val_precision: 0.6159 - val_recall: 0.7911\n",
      "Epoch 628/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 5.8671 - precision: 0.6289 - recall: 0.7964 - val_loss: 5.8622 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 629/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8608 - precision: 0.6287 - recall: 0.7967 - val_loss: 5.8559 - val_precision: 0.6160 - val_recall: 0.7914\n",
      "Epoch 630/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8545 - precision: 0.6288 - recall: 0.7966 - val_loss: 5.8496 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 631/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8481 - precision: 0.6286 - recall: 0.7969 - val_loss: 5.8433 - val_precision: 0.6162 - val_recall: 0.7914\n",
      "Epoch 632/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.8418 - precision: 0.6286 - recall: 0.7959 - val_loss: 5.8370 - val_precision: 0.6158 - val_recall: 0.7903\n",
      "Epoch 633/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8355 - precision: 0.6286 - recall: 0.7962 - val_loss: 5.8307 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 634/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.8292 - precision: 0.6287 - recall: 0.7961 - val_loss: 5.8244 - val_precision: 0.6161 - val_recall: 0.7911\n",
      "Epoch 635/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8229 - precision: 0.6287 - recall: 0.7961 - val_loss: 5.8181 - val_precision: 0.6164 - val_recall: 0.7911\n",
      "Epoch 636/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8166 - precision: 0.6292 - recall: 0.7962 - val_loss: 5.8118 - val_precision: 0.6162 - val_recall: 0.7903\n",
      "Epoch 637/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8103 - precision: 0.6286 - recall: 0.7967 - val_loss: 5.8055 - val_precision: 0.6162 - val_recall: 0.7911\n",
      "Epoch 638/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.8040 - precision: 0.6287 - recall: 0.7967 - val_loss: 5.7992 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 639/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7978 - precision: 0.6291 - recall: 0.7966 - val_loss: 5.7929 - val_precision: 0.6161 - val_recall: 0.7907\n",
      "Epoch 640/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7915 - precision: 0.6291 - recall: 0.7969 - val_loss: 5.7866 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 641/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7852 - precision: 0.6291 - recall: 0.7968 - val_loss: 5.7804 - val_precision: 0.6158 - val_recall: 0.7903\n",
      "Epoch 642/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7789 - precision: 0.6292 - recall: 0.7971 - val_loss: 5.7741 - val_precision: 0.6156 - val_recall: 0.7903\n",
      "Epoch 643/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7727 - precision: 0.6294 - recall: 0.7969 - val_loss: 5.7679 - val_precision: 0.6156 - val_recall: 0.7903\n",
      "Epoch 644/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.7664 - precision: 0.6294 - recall: 0.7966 - val_loss: 5.7616 - val_precision: 0.6162 - val_recall: 0.7903\n",
      "Epoch 645/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7602 - precision: 0.6294 - recall: 0.7967 - val_loss: 5.7553 - val_precision: 0.6158 - val_recall: 0.7903\n",
      "Epoch 646/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7539 - precision: 0.6294 - recall: 0.7964 - val_loss: 5.7491 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 647/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7477 - precision: 0.6294 - recall: 0.7963 - val_loss: 5.7429 - val_precision: 0.6156 - val_recall: 0.7903\n",
      "Epoch 648/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.7414 - precision: 0.6292 - recall: 0.7962 - val_loss: 5.7366 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 649/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7352 - precision: 0.6293 - recall: 0.7961 - val_loss: 5.7304 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 650/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7290 - precision: 0.6293 - recall: 0.7957 - val_loss: 5.7241 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 651/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7227 - precision: 0.6292 - recall: 0.7948 - val_loss: 5.7179 - val_precision: 0.6156 - val_recall: 0.7903\n",
      "Epoch 652/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.7165 - precision: 0.6292 - recall: 0.7961 - val_loss: 5.7117 - val_precision: 0.6159 - val_recall: 0.7911\n",
      "Epoch 653/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.7103 - precision: 0.6292 - recall: 0.7953 - val_loss: 5.7055 - val_precision: 0.6156 - val_recall: 0.7903\n",
      "Epoch 654/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.7041 - precision: 0.6293 - recall: 0.7954 - val_loss: 5.6993 - val_precision: 0.6157 - val_recall: 0.7911\n",
      "Epoch 655/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 5.6978 - precision: 0.6293 - recall: 0.7957 - val_loss: 5.6930 - val_precision: 0.6156 - val_recall: 0.7907\n",
      "Epoch 656/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6916 - precision: 0.6293 - recall: 0.7955 - val_loss: 5.6868 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 657/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6854 - precision: 0.6293 - recall: 0.7955 - val_loss: 5.6806 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 658/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6792 - precision: 0.6295 - recall: 0.7955 - val_loss: 5.6744 - val_precision: 0.6154 - val_recall: 0.7907\n",
      "Epoch 659/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6730 - precision: 0.6296 - recall: 0.7959 - val_loss: 5.6682 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 660/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.6668 - precision: 0.6296 - recall: 0.7954 - val_loss: 5.6621 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 661/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6606 - precision: 0.6297 - recall: 0.7966 - val_loss: 5.6559 - val_precision: 0.6159 - val_recall: 0.7911\n",
      "Epoch 662/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.6545 - precision: 0.6296 - recall: 0.7948 - val_loss: 5.6497 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 663/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6483 - precision: 0.6296 - recall: 0.7952 - val_loss: 5.6435 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 664/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6421 - precision: 0.6296 - recall: 0.7958 - val_loss: 5.6373 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 665/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.6359 - precision: 0.6298 - recall: 0.7943 - val_loss: 5.6312 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 666/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6298 - precision: 0.6297 - recall: 0.7949 - val_loss: 5.6250 - val_precision: 0.6158 - val_recall: 0.7907\n",
      "Epoch 667/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6236 - precision: 0.6296 - recall: 0.7961 - val_loss: 5.6188 - val_precision: 0.6159 - val_recall: 0.7911\n",
      "Epoch 668/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6174 - precision: 0.6299 - recall: 0.7949 - val_loss: 5.6127 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 669/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6113 - precision: 0.6298 - recall: 0.7953 - val_loss: 5.6065 - val_precision: 0.6163 - val_recall: 0.7907\n",
      "Epoch 670/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.6051 - precision: 0.6299 - recall: 0.7952 - val_loss: 5.6004 - val_precision: 0.6164 - val_recall: 0.7911\n",
      "Epoch 671/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5990 - precision: 0.6299 - recall: 0.7948 - val_loss: 5.5942 - val_precision: 0.6164 - val_recall: 0.7911\n",
      "Epoch 672/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5928 - precision: 0.6297 - recall: 0.7962 - val_loss: 5.5881 - val_precision: 0.6164 - val_recall: 0.7914\n",
      "Epoch 673/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5867 - precision: 0.6297 - recall: 0.7952 - val_loss: 5.5819 - val_precision: 0.6164 - val_recall: 0.7911\n",
      "Epoch 674/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5805 - precision: 0.6297 - recall: 0.7961 - val_loss: 5.5758 - val_precision: 0.6164 - val_recall: 0.7914\n",
      "Epoch 675/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.5744 - precision: 0.6297 - recall: 0.7959 - val_loss: 5.5697 - val_precision: 0.6164 - val_recall: 0.7914\n",
      "Epoch 676/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5683 - precision: 0.6298 - recall: 0.7959 - val_loss: 5.5635 - val_precision: 0.6164 - val_recall: 0.7914\n",
      "Epoch 677/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5622 - precision: 0.6299 - recall: 0.7961 - val_loss: 5.5574 - val_precision: 0.6161 - val_recall: 0.7911\n",
      "Epoch 678/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5560 - precision: 0.6298 - recall: 0.7955 - val_loss: 5.5513 - val_precision: 0.6161 - val_recall: 0.7911\n",
      "Epoch 679/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5499 - precision: 0.6300 - recall: 0.7957 - val_loss: 5.5452 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 680/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.5438 - precision: 0.6298 - recall: 0.7964 - val_loss: 5.5391 - val_precision: 0.6162 - val_recall: 0.7914\n",
      "Epoch 681/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5377 - precision: 0.6298 - recall: 0.7963 - val_loss: 5.5330 - val_precision: 0.6159 - val_recall: 0.7907\n",
      "Epoch 682/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.5316 - precision: 0.6300 - recall: 0.7954 - val_loss: 5.5269 - val_precision: 0.6162 - val_recall: 0.7903\n",
      "Epoch 683/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.5255 - precision: 0.6302 - recall: 0.7946 - val_loss: 5.5208 - val_precision: 0.6160 - val_recall: 0.7895\n",
      "Epoch 684/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5194 - precision: 0.6302 - recall: 0.7944 - val_loss: 5.5147 - val_precision: 0.6159 - val_recall: 0.7891\n",
      "Epoch 685/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5133 - precision: 0.6304 - recall: 0.7946 - val_loss: 5.5086 - val_precision: 0.6160 - val_recall: 0.7891\n",
      "Epoch 686/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5072 - precision: 0.6302 - recall: 0.7946 - val_loss: 5.5025 - val_precision: 0.6162 - val_recall: 0.7891\n",
      "Epoch 687/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.5011 - precision: 0.6302 - recall: 0.7949 - val_loss: 5.4964 - val_precision: 0.6160 - val_recall: 0.7891\n",
      "Epoch 688/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.4950 - precision: 0.6303 - recall: 0.7945 - val_loss: 5.4903 - val_precision: 0.6162 - val_recall: 0.7891\n",
      "Epoch 689/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.4890 - precision: 0.6304 - recall: 0.7944 - val_loss: 5.4843 - val_precision: 0.6161 - val_recall: 0.7887\n",
      "Epoch 690/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.4829 - precision: 0.6304 - recall: 0.7952 - val_loss: 5.4782 - val_precision: 0.6159 - val_recall: 0.7887\n",
      "Epoch 691/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.4768 - precision: 0.6304 - recall: 0.7953 - val_loss: 5.4721 - val_precision: 0.6159 - val_recall: 0.7887\n",
      "Epoch 692/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.4708 - precision: 0.6303 - recall: 0.7944 - val_loss: 5.4661 - val_precision: 0.6163 - val_recall: 0.7887\n",
      "Epoch 693/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4647 - precision: 0.6305 - recall: 0.7948 - val_loss: 5.4600 - val_precision: 0.6163 - val_recall: 0.7887\n",
      "Epoch 694/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4586 - precision: 0.6303 - recall: 0.7939 - val_loss: 5.4539 - val_precision: 0.6165 - val_recall: 0.7887\n",
      "Epoch 695/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4526 - precision: 0.6303 - recall: 0.7948 - val_loss: 5.4479 - val_precision: 0.6165 - val_recall: 0.7887\n",
      "Epoch 696/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.4465 - precision: 0.6302 - recall: 0.7941 - val_loss: 5.4418 - val_precision: 0.6165 - val_recall: 0.7887\n",
      "Epoch 697/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.4405 - precision: 0.6300 - recall: 0.7943 - val_loss: 5.4358 - val_precision: 0.6160 - val_recall: 0.7891\n",
      "Epoch 698/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4345 - precision: 0.6300 - recall: 0.7935 - val_loss: 5.4298 - val_precision: 0.6162 - val_recall: 0.7883\n",
      "Epoch 699/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4284 - precision: 0.6300 - recall: 0.7929 - val_loss: 5.4237 - val_precision: 0.6163 - val_recall: 0.7879\n",
      "Epoch 700/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4224 - precision: 0.6299 - recall: 0.7939 - val_loss: 5.4177 - val_precision: 0.6159 - val_recall: 0.7887\n",
      "Epoch 701/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 5.4164 - precision: 0.6301 - recall: 0.7930 - val_loss: 5.4117 - val_precision: 0.6164 - val_recall: 0.7883\n",
      "Epoch 702/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4103 - precision: 0.6299 - recall: 0.7940 - val_loss: 5.4057 - val_precision: 0.6160 - val_recall: 0.7891\n",
      "Epoch 703/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.4043 - precision: 0.6299 - recall: 0.7934 - val_loss: 5.3996 - val_precision: 0.6164 - val_recall: 0.7891\n",
      "Epoch 704/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3983 - precision: 0.6298 - recall: 0.7930 - val_loss: 5.3936 - val_precision: 0.6163 - val_recall: 0.7887\n",
      "Epoch 705/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3923 - precision: 0.6297 - recall: 0.7929 - val_loss: 5.3876 - val_precision: 0.6164 - val_recall: 0.7891\n",
      "Epoch 706/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3863 - precision: 0.6299 - recall: 0.7926 - val_loss: 5.3816 - val_precision: 0.6162 - val_recall: 0.7891\n",
      "Epoch 707/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3803 - precision: 0.6297 - recall: 0.7929 - val_loss: 5.3756 - val_precision: 0.6162 - val_recall: 0.7891\n",
      "Epoch 708/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.3743 - precision: 0.6299 - recall: 0.7926 - val_loss: 5.3696 - val_precision: 0.6161 - val_recall: 0.7887\n",
      "Epoch 709/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3683 - precision: 0.6299 - recall: 0.7925 - val_loss: 5.3636 - val_precision: 0.6161 - val_recall: 0.7887\n",
      "Epoch 710/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3623 - precision: 0.6295 - recall: 0.7931 - val_loss: 5.3576 - val_precision: 0.6162 - val_recall: 0.7891\n",
      "Epoch 711/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3563 - precision: 0.6296 - recall: 0.7929 - val_loss: 5.3516 - val_precision: 0.6162 - val_recall: 0.7891\n",
      "Epoch 712/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3503 - precision: 0.6296 - recall: 0.7922 - val_loss: 5.3457 - val_precision: 0.6161 - val_recall: 0.7887\n",
      "Epoch 713/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.3443 - precision: 0.6296 - recall: 0.7924 - val_loss: 5.3397 - val_precision: 0.6161 - val_recall: 0.7887\n",
      "Epoch 714/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3384 - precision: 0.6296 - recall: 0.7922 - val_loss: 5.3337 - val_precision: 0.6160 - val_recall: 0.7883\n",
      "Epoch 715/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3324 - precision: 0.6296 - recall: 0.7922 - val_loss: 5.3278 - val_precision: 0.6160 - val_recall: 0.7883\n",
      "Epoch 716/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3264 - precision: 0.6295 - recall: 0.7927 - val_loss: 5.3218 - val_precision: 0.6160 - val_recall: 0.7883\n",
      "Epoch 717/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3205 - precision: 0.6297 - recall: 0.7924 - val_loss: 5.3158 - val_precision: 0.6160 - val_recall: 0.7883\n",
      "Epoch 718/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3145 - precision: 0.6297 - recall: 0.7922 - val_loss: 5.3099 - val_precision: 0.6161 - val_recall: 0.7879\n",
      "Epoch 719/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.3086 - precision: 0.6297 - recall: 0.7921 - val_loss: 5.3039 - val_precision: 0.6163 - val_recall: 0.7879\n",
      "Epoch 720/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.3026 - precision: 0.6299 - recall: 0.7924 - val_loss: 5.2980 - val_precision: 0.6163 - val_recall: 0.7879\n",
      "Epoch 721/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2967 - precision: 0.6299 - recall: 0.7912 - val_loss: 5.2920 - val_precision: 0.6163 - val_recall: 0.7875\n",
      "Epoch 722/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2907 - precision: 0.6299 - recall: 0.7917 - val_loss: 5.2861 - val_precision: 0.6163 - val_recall: 0.7875\n",
      "Epoch 723/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2848 - precision: 0.6298 - recall: 0.7917 - val_loss: 5.2802 - val_precision: 0.6163 - val_recall: 0.7875\n",
      "Epoch 724/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.2789 - precision: 0.6299 - recall: 0.7917 - val_loss: 5.2742 - val_precision: 0.6163 - val_recall: 0.7875\n",
      "Epoch 725/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2729 - precision: 0.6300 - recall: 0.7916 - val_loss: 5.2683 - val_precision: 0.6160 - val_recall: 0.7864\n",
      "Epoch 726/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2670 - precision: 0.6299 - recall: 0.7911 - val_loss: 5.2624 - val_precision: 0.6160 - val_recall: 0.7864\n",
      "Epoch 727/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2611 - precision: 0.6300 - recall: 0.7916 - val_loss: 5.2565 - val_precision: 0.6160 - val_recall: 0.7864\n",
      "Epoch 728/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2552 - precision: 0.6301 - recall: 0.7907 - val_loss: 5.2506 - val_precision: 0.6162 - val_recall: 0.7864\n",
      "Epoch 729/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2492 - precision: 0.6301 - recall: 0.7913 - val_loss: 5.2446 - val_precision: 0.6162 - val_recall: 0.7864\n",
      "Epoch 730/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2433 - precision: 0.6301 - recall: 0.7915 - val_loss: 5.2387 - val_precision: 0.6162 - val_recall: 0.7860\n",
      "Epoch 731/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2374 - precision: 0.6298 - recall: 0.7907 - val_loss: 5.2328 - val_precision: 0.6162 - val_recall: 0.7860\n",
      "Epoch 732/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2315 - precision: 0.6300 - recall: 0.7913 - val_loss: 5.2269 - val_precision: 0.6162 - val_recall: 0.7860\n",
      "Epoch 733/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2256 - precision: 0.6300 - recall: 0.7913 - val_loss: 5.2211 - val_precision: 0.6164 - val_recall: 0.7860\n",
      "Epoch 734/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2197 - precision: 0.6301 - recall: 0.7908 - val_loss: 5.2152 - val_precision: 0.6164 - val_recall: 0.7852\n",
      "Epoch 735/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.2139 - precision: 0.6301 - recall: 0.7910 - val_loss: 5.2093 - val_precision: 0.6164 - val_recall: 0.7852\n",
      "Epoch 736/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.2080 - precision: 0.6301 - recall: 0.7908 - val_loss: 5.2034 - val_precision: 0.6164 - val_recall: 0.7852\n",
      "Epoch 737/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.2021 - precision: 0.6303 - recall: 0.7899 - val_loss: 5.1975 - val_precision: 0.6164 - val_recall: 0.7848\n",
      "Epoch 738/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.1962 - precision: 0.6301 - recall: 0.7902 - val_loss: 5.1917 - val_precision: 0.6164 - val_recall: 0.7848\n",
      "Epoch 739/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1904 - precision: 0.6304 - recall: 0.7903 - val_loss: 5.1858 - val_precision: 0.6166 - val_recall: 0.7848\n",
      "Epoch 740/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.1845 - precision: 0.6304 - recall: 0.7901 - val_loss: 5.1799 - val_precision: 0.6167 - val_recall: 0.7844\n",
      "Epoch 741/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1786 - precision: 0.6304 - recall: 0.7901 - val_loss: 5.1741 - val_precision: 0.6168 - val_recall: 0.7848\n",
      "Epoch 742/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1728 - precision: 0.6304 - recall: 0.7897 - val_loss: 5.1682 - val_precision: 0.6168 - val_recall: 0.7848\n",
      "Epoch 743/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1669 - precision: 0.6306 - recall: 0.7894 - val_loss: 5.1624 - val_precision: 0.6168 - val_recall: 0.7848\n",
      "Epoch 744/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1611 - precision: 0.6304 - recall: 0.7897 - val_loss: 5.1565 - val_precision: 0.6167 - val_recall: 0.7844\n",
      "Epoch 745/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1552 - precision: 0.6306 - recall: 0.7890 - val_loss: 5.1507 - val_precision: 0.6170 - val_recall: 0.7840\n",
      "Epoch 746/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1494 - precision: 0.6306 - recall: 0.7892 - val_loss: 5.1448 - val_precision: 0.6171 - val_recall: 0.7844\n",
      "Epoch 747/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.1435 - precision: 0.6307 - recall: 0.7892 - val_loss: 5.1390 - val_precision: 0.6171 - val_recall: 0.7844\n",
      "Epoch 748/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.1377 - precision: 0.6307 - recall: 0.7892 - val_loss: 5.1332 - val_precision: 0.6171 - val_recall: 0.7844\n",
      "Epoch 749/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.1319 - precision: 0.6306 - recall: 0.7890 - val_loss: 5.1273 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 750/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1261 - precision: 0.6306 - recall: 0.7893 - val_loss: 5.1215 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 751/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1202 - precision: 0.6307 - recall: 0.7889 - val_loss: 5.1157 - val_precision: 0.6174 - val_recall: 0.7848\n",
      "Epoch 752/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1144 - precision: 0.6308 - recall: 0.7884 - val_loss: 5.1099 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 753/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1086 - precision: 0.6308 - recall: 0.7898 - val_loss: 5.1041 - val_precision: 0.6174 - val_recall: 0.7848\n",
      "Epoch 754/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.1028 - precision: 0.6309 - recall: 0.7897 - val_loss: 5.0983 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 755/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0970 - precision: 0.6309 - recall: 0.7892 - val_loss: 5.0925 - val_precision: 0.6172 - val_recall: 0.7840\n",
      "Epoch 756/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0912 - precision: 0.6310 - recall: 0.7893 - val_loss: 5.0867 - val_precision: 0.6172 - val_recall: 0.7840\n",
      "Epoch 757/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.0854 - precision: 0.6310 - recall: 0.7897 - val_loss: 5.0809 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 758/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0796 - precision: 0.6310 - recall: 0.7896 - val_loss: 5.0751 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 759/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0738 - precision: 0.6311 - recall: 0.7894 - val_loss: 5.0693 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 760/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0680 - precision: 0.6311 - recall: 0.7885 - val_loss: 5.0635 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 761/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.0622 - precision: 0.6312 - recall: 0.7890 - val_loss: 5.0577 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 762/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0565 - precision: 0.6311 - recall: 0.7882 - val_loss: 5.0520 - val_precision: 0.6173 - val_recall: 0.7844\n",
      "Epoch 763/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0507 - precision: 0.6311 - recall: 0.7882 - val_loss: 5.0462 - val_precision: 0.6170 - val_recall: 0.7837\n",
      "Epoch 764/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0449 - precision: 0.6312 - recall: 0.7880 - val_loss: 5.0405 - val_precision: 0.6172 - val_recall: 0.7840\n",
      "Epoch 765/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.0392 - precision: 0.6310 - recall: 0.7882 - val_loss: 5.0347 - val_precision: 0.6172 - val_recall: 0.7840\n",
      "Epoch 766/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0334 - precision: 0.6311 - recall: 0.7879 - val_loss: 5.0289 - val_precision: 0.6172 - val_recall: 0.7840\n",
      "Epoch 767/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0277 - precision: 0.6312 - recall: 0.7873 - val_loss: 5.0232 - val_precision: 0.6172 - val_recall: 0.7840\n",
      "Epoch 768/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0219 - precision: 0.6312 - recall: 0.7876 - val_loss: 5.0175 - val_precision: 0.6172 - val_recall: 0.7837\n",
      "Epoch 769/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.0162 - precision: 0.6313 - recall: 0.7875 - val_loss: 5.0117 - val_precision: 0.6173 - val_recall: 0.7840\n",
      "Epoch 770/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 5.0104 - precision: 0.6312 - recall: 0.7876 - val_loss: 5.0060 - val_precision: 0.6173 - val_recall: 0.7840\n",
      "Epoch 771/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 5.0047 - precision: 0.6313 - recall: 0.7869 - val_loss: 5.0002 - val_precision: 0.6178 - val_recall: 0.7837\n",
      "Epoch 772/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9990 - precision: 0.6313 - recall: 0.7869 - val_loss: 4.9945 - val_precision: 0.6178 - val_recall: 0.7837\n",
      "Epoch 773/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9933 - precision: 0.6312 - recall: 0.7868 - val_loss: 4.9888 - val_precision: 0.6176 - val_recall: 0.7829\n",
      "Epoch 774/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9875 - precision: 0.6313 - recall: 0.7864 - val_loss: 4.9831 - val_precision: 0.6176 - val_recall: 0.7829\n",
      "Epoch 775/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9818 - precision: 0.6313 - recall: 0.7866 - val_loss: 4.9774 - val_precision: 0.6176 - val_recall: 0.7829\n",
      "Epoch 776/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.9761 - precision: 0.6314 - recall: 0.7866 - val_loss: 4.9717 - val_precision: 0.6175 - val_recall: 0.7833\n",
      "Epoch 777/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.9704 - precision: 0.6314 - recall: 0.7870 - val_loss: 4.9660 - val_precision: 0.6174 - val_recall: 0.7829\n",
      "Epoch 778/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9647 - precision: 0.6314 - recall: 0.7873 - val_loss: 4.9603 - val_precision: 0.6174 - val_recall: 0.7829\n",
      "Epoch 779/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9590 - precision: 0.6313 - recall: 0.7866 - val_loss: 4.9546 - val_precision: 0.6176 - val_recall: 0.7829\n",
      "Epoch 780/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9533 - precision: 0.6314 - recall: 0.7865 - val_loss: 4.9489 - val_precision: 0.6174 - val_recall: 0.7825\n",
      "Epoch 781/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9476 - precision: 0.6315 - recall: 0.7860 - val_loss: 4.9432 - val_precision: 0.6175 - val_recall: 0.7821\n",
      "Epoch 782/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.9419 - precision: 0.6317 - recall: 0.7861 - val_loss: 4.9375 - val_precision: 0.6174 - val_recall: 0.7825\n",
      "Epoch 783/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9362 - precision: 0.6318 - recall: 0.7861 - val_loss: 4.9318 - val_precision: 0.6179 - val_recall: 0.7821\n",
      "Epoch 784/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9306 - precision: 0.6317 - recall: 0.7862 - val_loss: 4.9261 - val_precision: 0.6176 - val_recall: 0.7825\n",
      "Epoch 785/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9249 - precision: 0.6318 - recall: 0.7864 - val_loss: 4.9205 - val_precision: 0.6176 - val_recall: 0.7825\n",
      "Epoch 786/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9192 - precision: 0.6320 - recall: 0.7864 - val_loss: 4.9148 - val_precision: 0.6175 - val_recall: 0.7821\n",
      "Epoch 787/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.9135 - precision: 0.6319 - recall: 0.7856 - val_loss: 4.9091 - val_precision: 0.6178 - val_recall: 0.7813\n",
      "Epoch 788/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.9079 - precision: 0.6318 - recall: 0.7852 - val_loss: 4.9035 - val_precision: 0.6180 - val_recall: 0.7813\n",
      "Epoch 789/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 4.9022 - precision: 0.6319 - recall: 0.7852 - val_loss: 4.8978 - val_precision: 0.6182 - val_recall: 0.7813\n",
      "Epoch 790/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 4.8966 - precision: 0.6320 - recall: 0.7852 - val_loss: 4.8922 - val_precision: 0.6180 - val_recall: 0.7813\n",
      "Epoch 791/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8909 - precision: 0.6320 - recall: 0.7855 - val_loss: 4.8865 - val_precision: 0.6178 - val_recall: 0.7813\n",
      "Epoch 792/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8853 - precision: 0.6318 - recall: 0.7846 - val_loss: 4.8809 - val_precision: 0.6178 - val_recall: 0.7813\n",
      "Epoch 793/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8796 - precision: 0.6320 - recall: 0.7852 - val_loss: 4.8752 - val_precision: 0.6178 - val_recall: 0.7813\n",
      "Epoch 794/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8740 - precision: 0.6320 - recall: 0.7854 - val_loss: 4.8696 - val_precision: 0.6179 - val_recall: 0.7809\n",
      "Epoch 795/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8683 - precision: 0.6321 - recall: 0.7850 - val_loss: 4.8640 - val_precision: 0.6179 - val_recall: 0.7809\n",
      "Epoch 796/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8627 - precision: 0.6321 - recall: 0.7854 - val_loss: 4.8583 - val_precision: 0.6183 - val_recall: 0.7809\n",
      "Epoch 797/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8571 - precision: 0.6324 - recall: 0.7845 - val_loss: 4.8527 - val_precision: 0.6184 - val_recall: 0.7805\n",
      "Epoch 798/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8515 - precision: 0.6324 - recall: 0.7845 - val_loss: 4.8471 - val_precision: 0.6185 - val_recall: 0.7809\n",
      "Epoch 799/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8458 - precision: 0.6322 - recall: 0.7845 - val_loss: 4.8415 - val_precision: 0.6184 - val_recall: 0.7805\n",
      "Epoch 800/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8402 - precision: 0.6326 - recall: 0.7841 - val_loss: 4.8359 - val_precision: 0.6186 - val_recall: 0.7805\n",
      "Epoch 801/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8346 - precision: 0.6325 - recall: 0.7846 - val_loss: 4.8303 - val_precision: 0.6182 - val_recall: 0.7805\n",
      "Epoch 802/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.8290 - precision: 0.6324 - recall: 0.7843 - val_loss: 4.8246 - val_precision: 0.6182 - val_recall: 0.7805\n",
      "Epoch 803/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8234 - precision: 0.6325 - recall: 0.7837 - val_loss: 4.8190 - val_precision: 0.6183 - val_recall: 0.7802\n",
      "Epoch 804/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.8178 - precision: 0.6324 - recall: 0.7838 - val_loss: 4.8135 - val_precision: 0.6181 - val_recall: 0.7798\n",
      "Epoch 805/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8122 - precision: 0.6324 - recall: 0.7836 - val_loss: 4.8079 - val_precision: 0.6181 - val_recall: 0.7798\n",
      "Epoch 806/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8066 - precision: 0.6325 - recall: 0.7839 - val_loss: 4.8023 - val_precision: 0.6181 - val_recall: 0.7798\n",
      "Epoch 807/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.8010 - precision: 0.6327 - recall: 0.7828 - val_loss: 4.7967 - val_precision: 0.6182 - val_recall: 0.7794\n",
      "Epoch 808/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7954 - precision: 0.6324 - recall: 0.7838 - val_loss: 4.7911 - val_precision: 0.6183 - val_recall: 0.7798\n",
      "Epoch 809/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7899 - precision: 0.6327 - recall: 0.7834 - val_loss: 4.7855 - val_precision: 0.6185 - val_recall: 0.7790\n",
      "Epoch 810/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.7843 - precision: 0.6330 - recall: 0.7832 - val_loss: 4.7800 - val_precision: 0.6185 - val_recall: 0.7786\n",
      "Epoch 811/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7787 - precision: 0.6331 - recall: 0.7827 - val_loss: 4.7744 - val_precision: 0.6186 - val_recall: 0.7782\n",
      "Epoch 812/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7731 - precision: 0.6331 - recall: 0.7829 - val_loss: 4.7688 - val_precision: 0.6186 - val_recall: 0.7782\n",
      "Epoch 813/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7676 - precision: 0.6330 - recall: 0.7825 - val_loss: 4.7633 - val_precision: 0.6188 - val_recall: 0.7782\n",
      "Epoch 814/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7620 - precision: 0.6330 - recall: 0.7828 - val_loss: 4.7577 - val_precision: 0.6188 - val_recall: 0.7782\n",
      "Epoch 815/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7565 - precision: 0.6330 - recall: 0.7827 - val_loss: 4.7521 - val_precision: 0.6189 - val_recall: 0.7786\n",
      "Epoch 816/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.7509 - precision: 0.6333 - recall: 0.7820 - val_loss: 4.7466 - val_precision: 0.6191 - val_recall: 0.7778\n",
      "Epoch 817/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7454 - precision: 0.6332 - recall: 0.7825 - val_loss: 4.7411 - val_precision: 0.6190 - val_recall: 0.7782\n",
      "Epoch 818/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7398 - precision: 0.6332 - recall: 0.7823 - val_loss: 4.7355 - val_precision: 0.6190 - val_recall: 0.7782\n",
      "Epoch 819/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7343 - precision: 0.6331 - recall: 0.7823 - val_loss: 4.7300 - val_precision: 0.6194 - val_recall: 0.7782\n",
      "Epoch 820/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.7287 - precision: 0.6331 - recall: 0.7822 - val_loss: 4.7244 - val_precision: 0.6192 - val_recall: 0.7782\n",
      "Epoch 821/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7232 - precision: 0.6332 - recall: 0.7814 - val_loss: 4.7189 - val_precision: 0.6193 - val_recall: 0.7778\n",
      "Epoch 822/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7177 - precision: 0.6333 - recall: 0.7814 - val_loss: 4.7134 - val_precision: 0.6193 - val_recall: 0.7778\n",
      "Epoch 823/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7122 - precision: 0.6334 - recall: 0.7813 - val_loss: 4.7079 - val_precision: 0.6190 - val_recall: 0.7770\n",
      "Epoch 824/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7067 - precision: 0.6335 - recall: 0.7810 - val_loss: 4.7024 - val_precision: 0.6190 - val_recall: 0.7770\n",
      "Epoch 825/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.7011 - precision: 0.6332 - recall: 0.7817 - val_loss: 4.6969 - val_precision: 0.6190 - val_recall: 0.7774\n",
      "Epoch 826/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6956 - precision: 0.6335 - recall: 0.7809 - val_loss: 4.6914 - val_precision: 0.6188 - val_recall: 0.7763\n",
      "Epoch 827/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6901 - precision: 0.6333 - recall: 0.7809 - val_loss: 4.6859 - val_precision: 0.6189 - val_recall: 0.7759\n",
      "Epoch 828/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6846 - precision: 0.6331 - recall: 0.7803 - val_loss: 4.6804 - val_precision: 0.6189 - val_recall: 0.7759\n",
      "Epoch 829/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6791 - precision: 0.6333 - recall: 0.7805 - val_loss: 4.6749 - val_precision: 0.6187 - val_recall: 0.7759\n",
      "Epoch 830/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6736 - precision: 0.6334 - recall: 0.7796 - val_loss: 4.6694 - val_precision: 0.6186 - val_recall: 0.7751\n",
      "Epoch 831/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6682 - precision: 0.6335 - recall: 0.7797 - val_loss: 4.6639 - val_precision: 0.6184 - val_recall: 0.7751\n",
      "Epoch 832/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6627 - precision: 0.6334 - recall: 0.7795 - val_loss: 4.6584 - val_precision: 0.6184 - val_recall: 0.7751\n",
      "Epoch 833/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6572 - precision: 0.6335 - recall: 0.7789 - val_loss: 4.6529 - val_precision: 0.6183 - val_recall: 0.7739\n",
      "Epoch 834/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6517 - precision: 0.6334 - recall: 0.7790 - val_loss: 4.6475 - val_precision: 0.6186 - val_recall: 0.7743\n",
      "Epoch 835/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.6462 - precision: 0.6335 - recall: 0.7791 - val_loss: 4.6420 - val_precision: 0.6185 - val_recall: 0.7739\n",
      "Epoch 836/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.6408 - precision: 0.6335 - recall: 0.7785 - val_loss: 4.6365 - val_precision: 0.6184 - val_recall: 0.7732\n",
      "Epoch 837/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6353 - precision: 0.6335 - recall: 0.7791 - val_loss: 4.6311 - val_precision: 0.6185 - val_recall: 0.7735\n",
      "Epoch 838/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6299 - precision: 0.6335 - recall: 0.7791 - val_loss: 4.6256 - val_precision: 0.6184 - val_recall: 0.7732\n",
      "Epoch 839/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6244 - precision: 0.6336 - recall: 0.7792 - val_loss: 4.6202 - val_precision: 0.6184 - val_recall: 0.7732\n",
      "Epoch 840/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6190 - precision: 0.6336 - recall: 0.7780 - val_loss: 4.6147 - val_precision: 0.6182 - val_recall: 0.7724\n",
      "Epoch 841/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6135 - precision: 0.6335 - recall: 0.7790 - val_loss: 4.6093 - val_precision: 0.6184 - val_recall: 0.7732\n",
      "Epoch 842/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.6081 - precision: 0.6338 - recall: 0.7781 - val_loss: 4.6039 - val_precision: 0.6192 - val_recall: 0.7724\n",
      "Epoch 843/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.6026 - precision: 0.6341 - recall: 0.7778 - val_loss: 4.5984 - val_precision: 0.6195 - val_recall: 0.7724\n",
      "Epoch 844/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5972 - precision: 0.6340 - recall: 0.7780 - val_loss: 4.5930 - val_precision: 0.6195 - val_recall: 0.7716\n",
      "Epoch 845/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5918 - precision: 0.6339 - recall: 0.7776 - val_loss: 4.5876 - val_precision: 0.6194 - val_recall: 0.7720\n",
      "Epoch 846/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5864 - precision: 0.6341 - recall: 0.7771 - val_loss: 4.5822 - val_precision: 0.6193 - val_recall: 0.7704\n",
      "Epoch 847/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.5809 - precision: 0.6341 - recall: 0.7769 - val_loss: 4.5767 - val_precision: 0.6194 - val_recall: 0.7708\n",
      "Epoch 848/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.5755 - precision: 0.6342 - recall: 0.7761 - val_loss: 4.5713 - val_precision: 0.6199 - val_recall: 0.7704\n",
      "Epoch 849/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5701 - precision: 0.6341 - recall: 0.7763 - val_loss: 4.5659 - val_precision: 0.6199 - val_recall: 0.7704\n",
      "Epoch 850/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5647 - precision: 0.6341 - recall: 0.7761 - val_loss: 4.5605 - val_precision: 0.6201 - val_recall: 0.7704\n",
      "Epoch 851/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5593 - precision: 0.6344 - recall: 0.7755 - val_loss: 4.5551 - val_precision: 0.6203 - val_recall: 0.7693\n",
      "Epoch 852/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5539 - precision: 0.6345 - recall: 0.7759 - val_loss: 4.5497 - val_precision: 0.6203 - val_recall: 0.7693\n",
      "Epoch 853/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5485 - precision: 0.6345 - recall: 0.7759 - val_loss: 4.5443 - val_precision: 0.6205 - val_recall: 0.7693\n",
      "Epoch 854/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5431 - precision: 0.6344 - recall: 0.7755 - val_loss: 4.5389 - val_precision: 0.6204 - val_recall: 0.7689\n",
      "Epoch 855/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5377 - precision: 0.6343 - recall: 0.7752 - val_loss: 4.5336 - val_precision: 0.6206 - val_recall: 0.7689\n",
      "Epoch 856/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5323 - precision: 0.6346 - recall: 0.7752 - val_loss: 4.5282 - val_precision: 0.6206 - val_recall: 0.7689\n",
      "Epoch 857/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5269 - precision: 0.6345 - recall: 0.7750 - val_loss: 4.5228 - val_precision: 0.6206 - val_recall: 0.7689\n",
      "Epoch 858/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5216 - precision: 0.6346 - recall: 0.7738 - val_loss: 4.5174 - val_precision: 0.6210 - val_recall: 0.7689\n",
      "Epoch 859/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5162 - precision: 0.6347 - recall: 0.7735 - val_loss: 4.5120 - val_precision: 0.6209 - val_recall: 0.7685\n",
      "Epoch 860/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5108 - precision: 0.6344 - recall: 0.7738 - val_loss: 4.5067 - val_precision: 0.6208 - val_recall: 0.7689\n",
      "Epoch 861/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5054 - precision: 0.6347 - recall: 0.7735 - val_loss: 4.5013 - val_precision: 0.6207 - val_recall: 0.7685\n",
      "Epoch 862/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.5001 - precision: 0.6345 - recall: 0.7735 - val_loss: 4.4959 - val_precision: 0.6213 - val_recall: 0.7673\n",
      "Epoch 863/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.4947 - precision: 0.6345 - recall: 0.7729 - val_loss: 4.4906 - val_precision: 0.6213 - val_recall: 0.7673\n",
      "Epoch 864/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.4894 - precision: 0.6346 - recall: 0.7725 - val_loss: 4.4852 - val_precision: 0.6217 - val_recall: 0.7673\n",
      "Epoch 865/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4840 - precision: 0.6344 - recall: 0.7726 - val_loss: 4.4799 - val_precision: 0.6215 - val_recall: 0.7665\n",
      "Epoch 866/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4787 - precision: 0.6346 - recall: 0.7722 - val_loss: 4.4745 - val_precision: 0.6215 - val_recall: 0.7665\n",
      "Epoch 867/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4733 - precision: 0.6348 - recall: 0.7718 - val_loss: 4.4692 - val_precision: 0.6218 - val_recall: 0.7665\n",
      "Epoch 868/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4680 - precision: 0.6348 - recall: 0.7722 - val_loss: 4.4639 - val_precision: 0.6218 - val_recall: 0.7665\n",
      "Epoch 869/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4627 - precision: 0.6348 - recall: 0.7722 - val_loss: 4.4585 - val_precision: 0.6220 - val_recall: 0.7665\n",
      "Epoch 870/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4573 - precision: 0.6349 - recall: 0.7721 - val_loss: 4.4532 - val_precision: 0.6220 - val_recall: 0.7665\n",
      "Epoch 871/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4520 - precision: 0.6352 - recall: 0.7713 - val_loss: 4.4479 - val_precision: 0.6224 - val_recall: 0.7665\n",
      "Epoch 872/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.4467 - precision: 0.6352 - recall: 0.7710 - val_loss: 4.4426 - val_precision: 0.6224 - val_recall: 0.7665\n",
      "Epoch 873/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.4414 - precision: 0.6351 - recall: 0.7711 - val_loss: 4.4373 - val_precision: 0.6224 - val_recall: 0.7665\n",
      "Epoch 874/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.4360 - precision: 0.6352 - recall: 0.7710 - val_loss: 4.4319 - val_precision: 0.6224 - val_recall: 0.7665\n",
      "Epoch 875/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4307 - precision: 0.6353 - recall: 0.7707 - val_loss: 4.4266 - val_precision: 0.6227 - val_recall: 0.7661\n",
      "Epoch 876/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4254 - precision: 0.6355 - recall: 0.7699 - val_loss: 4.4214 - val_precision: 0.6228 - val_recall: 0.7658\n",
      "Epoch 877/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4201 - precision: 0.6354 - recall: 0.7696 - val_loss: 4.4160 - val_precision: 0.6228 - val_recall: 0.7658\n",
      "Epoch 878/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4148 - precision: 0.6356 - recall: 0.7690 - val_loss: 4.4108 - val_precision: 0.6231 - val_recall: 0.7654\n",
      "Epoch 879/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4095 - precision: 0.6354 - recall: 0.7701 - val_loss: 4.4055 - val_precision: 0.6230 - val_recall: 0.7658\n",
      "Epoch 880/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.4042 - precision: 0.6354 - recall: 0.7696 - val_loss: 4.4002 - val_precision: 0.6231 - val_recall: 0.7654\n",
      "Epoch 881/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3990 - precision: 0.6355 - recall: 0.7688 - val_loss: 4.3949 - val_precision: 0.6230 - val_recall: 0.7646\n",
      "Epoch 882/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3937 - precision: 0.6355 - recall: 0.7684 - val_loss: 4.3896 - val_precision: 0.6232 - val_recall: 0.7646\n",
      "Epoch 883/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3884 - precision: 0.6355 - recall: 0.7682 - val_loss: 4.3843 - val_precision: 0.6231 - val_recall: 0.7642\n",
      "Epoch 884/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.3831 - precision: 0.6353 - recall: 0.7674 - val_loss: 4.3791 - val_precision: 0.6231 - val_recall: 0.7634\n",
      "Epoch 885/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.3779 - precision: 0.6355 - recall: 0.7690 - val_loss: 4.3738 - val_precision: 0.6232 - val_recall: 0.7646\n",
      "Epoch 886/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3726 - precision: 0.6353 - recall: 0.7675 - val_loss: 4.3685 - val_precision: 0.6233 - val_recall: 0.7642\n",
      "Epoch 887/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3673 - precision: 0.6355 - recall: 0.7680 - val_loss: 4.3633 - val_precision: 0.6232 - val_recall: 0.7638\n",
      "Epoch 888/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3621 - precision: 0.6354 - recall: 0.7678 - val_loss: 4.3580 - val_precision: 0.6232 - val_recall: 0.7638\n",
      "Epoch 889/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3568 - precision: 0.6353 - recall: 0.7673 - val_loss: 4.3528 - val_precision: 0.6231 - val_recall: 0.7634\n",
      "Epoch 890/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3516 - precision: 0.6351 - recall: 0.7666 - val_loss: 4.3476 - val_precision: 0.6233 - val_recall: 0.7634\n",
      "Epoch 891/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3463 - precision: 0.6354 - recall: 0.7656 - val_loss: 4.3423 - val_precision: 0.6235 - val_recall: 0.7634\n",
      "Epoch 892/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3411 - precision: 0.6352 - recall: 0.7656 - val_loss: 4.3371 - val_precision: 0.6236 - val_recall: 0.7634\n",
      "Epoch 893/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.3359 - precision: 0.6352 - recall: 0.7665 - val_loss: 4.3318 - val_precision: 0.6238 - val_recall: 0.7638\n",
      "Epoch 894/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3306 - precision: 0.6353 - recall: 0.7652 - val_loss: 4.3266 - val_precision: 0.6238 - val_recall: 0.7638\n",
      "Epoch 895/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.3254 - precision: 0.6353 - recall: 0.7652 - val_loss: 4.3214 - val_precision: 0.6239 - val_recall: 0.7630\n",
      "Epoch 896/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3202 - precision: 0.6356 - recall: 0.7645 - val_loss: 4.3162 - val_precision: 0.6238 - val_recall: 0.7626\n",
      "Epoch 897/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3150 - precision: 0.6356 - recall: 0.7647 - val_loss: 4.3110 - val_precision: 0.6239 - val_recall: 0.7630\n",
      "Epoch 898/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3098 - precision: 0.6355 - recall: 0.7648 - val_loss: 4.3058 - val_precision: 0.6238 - val_recall: 0.7626\n",
      "Epoch 899/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.3046 - precision: 0.6360 - recall: 0.7648 - val_loss: 4.3006 - val_precision: 0.6239 - val_recall: 0.7623\n",
      "Epoch 900/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2994 - precision: 0.6361 - recall: 0.7638 - val_loss: 4.2954 - val_precision: 0.6239 - val_recall: 0.7623\n",
      "Epoch 901/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.2942 - precision: 0.6362 - recall: 0.7638 - val_loss: 4.2902 - val_precision: 0.6239 - val_recall: 0.7623\n",
      "Epoch 902/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2890 - precision: 0.6362 - recall: 0.7638 - val_loss: 4.2850 - val_precision: 0.6239 - val_recall: 0.7623\n",
      "Epoch 903/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2838 - precision: 0.6364 - recall: 0.7642 - val_loss: 4.2798 - val_precision: 0.6240 - val_recall: 0.7619\n",
      "Epoch 904/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2786 - precision: 0.6363 - recall: 0.7628 - val_loss: 4.2746 - val_precision: 0.6242 - val_recall: 0.7619\n",
      "Epoch 905/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2734 - precision: 0.6363 - recall: 0.7632 - val_loss: 4.2694 - val_precision: 0.6242 - val_recall: 0.7619\n",
      "Epoch 906/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.2682 - precision: 0.6364 - recall: 0.7638 - val_loss: 4.2643 - val_precision: 0.6242 - val_recall: 0.7619\n",
      "Epoch 907/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.2630 - precision: 0.6363 - recall: 0.7636 - val_loss: 4.2591 - val_precision: 0.6242 - val_recall: 0.7619\n",
      "Epoch 908/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2579 - precision: 0.6362 - recall: 0.7629 - val_loss: 4.2539 - val_precision: 0.6240 - val_recall: 0.7615\n",
      "Epoch 909/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2527 - precision: 0.6366 - recall: 0.7641 - val_loss: 4.2487 - val_precision: 0.6242 - val_recall: 0.7619\n",
      "Epoch 910/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.2475 - precision: 0.6365 - recall: 0.7634 - val_loss: 4.2436 - val_precision: 0.6240 - val_recall: 0.7615\n",
      "Epoch 911/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2424 - precision: 0.6366 - recall: 0.7633 - val_loss: 4.2384 - val_precision: 0.6240 - val_recall: 0.7615\n",
      "Epoch 912/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2372 - precision: 0.6371 - recall: 0.7620 - val_loss: 4.2333 - val_precision: 0.6241 - val_recall: 0.7611\n",
      "Epoch 913/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2321 - precision: 0.6371 - recall: 0.7619 - val_loss: 4.2281 - val_precision: 0.6245 - val_recall: 0.7611\n",
      "Epoch 914/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2269 - precision: 0.6368 - recall: 0.7623 - val_loss: 4.2230 - val_precision: 0.6241 - val_recall: 0.7611\n",
      "Epoch 915/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.2218 - precision: 0.6371 - recall: 0.7613 - val_loss: 4.2179 - val_precision: 0.6245 - val_recall: 0.7611\n",
      "Epoch 916/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2167 - precision: 0.6370 - recall: 0.7611 - val_loss: 4.2127 - val_precision: 0.6245 - val_recall: 0.7603\n",
      "Epoch 917/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.2115 - precision: 0.6371 - recall: 0.7617 - val_loss: 4.2076 - val_precision: 0.6244 - val_recall: 0.7607\n",
      "Epoch 918/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2064 - precision: 0.6374 - recall: 0.7614 - val_loss: 4.2025 - val_precision: 0.6245 - val_recall: 0.7603\n",
      "Epoch 919/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.2013 - precision: 0.6371 - recall: 0.7608 - val_loss: 4.1974 - val_precision: 0.6245 - val_recall: 0.7603\n",
      "Epoch 920/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.1961 - precision: 0.6372 - recall: 0.7606 - val_loss: 4.1922 - val_precision: 0.6247 - val_recall: 0.7603\n",
      "Epoch 921/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1910 - precision: 0.6374 - recall: 0.7601 - val_loss: 4.1871 - val_precision: 0.6249 - val_recall: 0.7603\n",
      "Epoch 922/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1859 - precision: 0.6373 - recall: 0.7605 - val_loss: 4.1820 - val_precision: 0.6247 - val_recall: 0.7603\n",
      "Epoch 923/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.1808 - precision: 0.6375 - recall: 0.7606 - val_loss: 4.1769 - val_precision: 0.6249 - val_recall: 0.7603\n",
      "Epoch 924/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1757 - precision: 0.6374 - recall: 0.7604 - val_loss: 4.1718 - val_precision: 0.6249 - val_recall: 0.7603\n",
      "Epoch 925/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1706 - precision: 0.6374 - recall: 0.7604 - val_loss: 4.1667 - val_precision: 0.6245 - val_recall: 0.7603\n",
      "Epoch 926/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.1655 - precision: 0.6375 - recall: 0.7603 - val_loss: 4.1616 - val_precision: 0.6249 - val_recall: 0.7603\n",
      "Epoch 927/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1604 - precision: 0.6376 - recall: 0.7601 - val_loss: 4.1565 - val_precision: 0.6249 - val_recall: 0.7603\n",
      "Epoch 928/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1553 - precision: 0.6378 - recall: 0.7601 - val_loss: 4.1515 - val_precision: 0.6251 - val_recall: 0.7603\n",
      "Epoch 929/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1503 - precision: 0.6380 - recall: 0.7590 - val_loss: 4.1464 - val_precision: 0.6250 - val_recall: 0.7599\n",
      "Epoch 930/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1452 - precision: 0.6380 - recall: 0.7587 - val_loss: 4.1413 - val_precision: 0.6252 - val_recall: 0.7595\n",
      "Epoch 931/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1401 - precision: 0.6382 - recall: 0.7590 - val_loss: 4.1362 - val_precision: 0.6247 - val_recall: 0.7591\n",
      "Epoch 932/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1350 - precision: 0.6380 - recall: 0.7583 - val_loss: 4.1312 - val_precision: 0.6254 - val_recall: 0.7588\n",
      "Epoch 933/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1300 - precision: 0.6379 - recall: 0.7595 - val_loss: 4.1261 - val_precision: 0.6246 - val_recall: 0.7588\n",
      "Epoch 934/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1249 - precision: 0.6382 - recall: 0.7587 - val_loss: 4.1210 - val_precision: 0.6252 - val_recall: 0.7588\n",
      "Epoch 935/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1198 - precision: 0.6381 - recall: 0.7578 - val_loss: 4.1160 - val_precision: 0.6256 - val_recall: 0.7588\n",
      "Epoch 936/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1148 - precision: 0.6380 - recall: 0.7583 - val_loss: 4.1109 - val_precision: 0.6252 - val_recall: 0.7588\n",
      "Epoch 937/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1097 - precision: 0.6381 - recall: 0.7581 - val_loss: 4.1059 - val_precision: 0.6252 - val_recall: 0.7588\n",
      "Epoch 938/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.1047 - precision: 0.6382 - recall: 0.7580 - val_loss: 4.1008 - val_precision: 0.6252 - val_recall: 0.7588\n",
      "Epoch 939/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.0997 - precision: 0.6383 - recall: 0.7577 - val_loss: 4.0958 - val_precision: 0.6258 - val_recall: 0.7588\n",
      "Epoch 940/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0946 - precision: 0.6382 - recall: 0.7577 - val_loss: 4.0908 - val_precision: 0.6256 - val_recall: 0.7588\n",
      "Epoch 941/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0896 - precision: 0.6384 - recall: 0.7578 - val_loss: 4.0858 - val_precision: 0.6256 - val_recall: 0.7588\n",
      "Epoch 942/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0846 - precision: 0.6386 - recall: 0.7562 - val_loss: 4.0807 - val_precision: 0.6256 - val_recall: 0.7580\n",
      "Epoch 943/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0795 - precision: 0.6386 - recall: 0.7567 - val_loss: 4.0757 - val_precision: 0.6255 - val_recall: 0.7584\n",
      "Epoch 944/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.0745 - precision: 0.6387 - recall: 0.7569 - val_loss: 4.0707 - val_precision: 0.6254 - val_recall: 0.7580\n",
      "Epoch 945/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0695 - precision: 0.6386 - recall: 0.7564 - val_loss: 4.0657 - val_precision: 0.6254 - val_recall: 0.7580\n",
      "Epoch 946/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0645 - precision: 0.6388 - recall: 0.7569 - val_loss: 4.0607 - val_precision: 0.6255 - val_recall: 0.7584\n",
      "Epoch 947/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0595 - precision: 0.6388 - recall: 0.7555 - val_loss: 4.0557 - val_precision: 0.6252 - val_recall: 0.7576\n",
      "Epoch 948/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.0545 - precision: 0.6386 - recall: 0.7562 - val_loss: 4.0507 - val_precision: 0.6252 - val_recall: 0.7576\n",
      "Epoch 949/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.0495 - precision: 0.6387 - recall: 0.7557 - val_loss: 4.0457 - val_precision: 0.6252 - val_recall: 0.7576\n",
      "Epoch 950/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 4.0445 - precision: 0.6388 - recall: 0.7558 - val_loss: 4.0407 - val_precision: 0.6252 - val_recall: 0.7576\n",
      "Epoch 951/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0395 - precision: 0.6388 - recall: 0.7559 - val_loss: 4.0357 - val_precision: 0.6250 - val_recall: 0.7568\n",
      "Epoch 952/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.0345 - precision: 0.6389 - recall: 0.7554 - val_loss: 4.0307 - val_precision: 0.6254 - val_recall: 0.7568\n",
      "Epoch 953/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0295 - precision: 0.6388 - recall: 0.7555 - val_loss: 4.0257 - val_precision: 0.6254 - val_recall: 0.7568\n",
      "Epoch 954/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0245 - precision: 0.6388 - recall: 0.7548 - val_loss: 4.0207 - val_precision: 0.6256 - val_recall: 0.7568\n",
      "Epoch 955/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0196 - precision: 0.6387 - recall: 0.7548 - val_loss: 4.0158 - val_precision: 0.6255 - val_recall: 0.7564\n",
      "Epoch 956/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0146 - precision: 0.6387 - recall: 0.7546 - val_loss: 4.0108 - val_precision: 0.6252 - val_recall: 0.7556\n",
      "Epoch 957/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 4.0096 - precision: 0.6388 - recall: 0.7543 - val_loss: 4.0058 - val_precision: 0.6252 - val_recall: 0.7556\n",
      "Epoch 958/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 4.0047 - precision: 0.6389 - recall: 0.7544 - val_loss: 4.0009 - val_precision: 0.6252 - val_recall: 0.7556\n",
      "Epoch 959/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9997 - precision: 0.6389 - recall: 0.7544 - val_loss: 3.9959 - val_precision: 0.6252 - val_recall: 0.7556\n",
      "Epoch 960/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.9947 - precision: 0.6390 - recall: 0.7544 - val_loss: 3.9910 - val_precision: 0.6251 - val_recall: 0.7553\n",
      "Epoch 961/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9898 - precision: 0.6392 - recall: 0.7544 - val_loss: 3.9860 - val_precision: 0.6250 - val_recall: 0.7549\n",
      "Epoch 962/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9848 - precision: 0.6391 - recall: 0.7543 - val_loss: 3.9811 - val_precision: 0.6250 - val_recall: 0.7549\n",
      "Epoch 963/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.9799 - precision: 0.6391 - recall: 0.7541 - val_loss: 3.9761 - val_precision: 0.6250 - val_recall: 0.7549\n",
      "Epoch 964/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.9750 - precision: 0.6391 - recall: 0.7543 - val_loss: 3.9712 - val_precision: 0.6252 - val_recall: 0.7549\n",
      "Epoch 965/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.9700 - precision: 0.6392 - recall: 0.7540 - val_loss: 3.9663 - val_precision: 0.6252 - val_recall: 0.7549\n",
      "Epoch 966/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9651 - precision: 0.6393 - recall: 0.7541 - val_loss: 3.9614 - val_precision: 0.6252 - val_recall: 0.7549\n",
      "Epoch 967/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9602 - precision: 0.6392 - recall: 0.7540 - val_loss: 3.9564 - val_precision: 0.6252 - val_recall: 0.7549\n",
      "Epoch 968/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9552 - precision: 0.6394 - recall: 0.7543 - val_loss: 3.9515 - val_precision: 0.6251 - val_recall: 0.7545\n",
      "Epoch 969/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9503 - precision: 0.6397 - recall: 0.7538 - val_loss: 3.9466 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 970/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9454 - precision: 0.6396 - recall: 0.7540 - val_loss: 3.9417 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 971/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9405 - precision: 0.6397 - recall: 0.7538 - val_loss: 3.9368 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 972/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9356 - precision: 0.6396 - recall: 0.7535 - val_loss: 3.9319 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 973/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9307 - precision: 0.6396 - recall: 0.7529 - val_loss: 3.9270 - val_precision: 0.6246 - val_recall: 0.7521\n",
      "Epoch 974/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9258 - precision: 0.6396 - recall: 0.7534 - val_loss: 3.9221 - val_precision: 0.6247 - val_recall: 0.7525\n",
      "Epoch 975/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9209 - precision: 0.6396 - recall: 0.7530 - val_loss: 3.9172 - val_precision: 0.6246 - val_recall: 0.7521\n",
      "Epoch 976/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9160 - precision: 0.6396 - recall: 0.7529 - val_loss: 3.9123 - val_precision: 0.6246 - val_recall: 0.7521\n",
      "Epoch 977/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9111 - precision: 0.6395 - recall: 0.7531 - val_loss: 3.9074 - val_precision: 0.6247 - val_recall: 0.7525\n",
      "Epoch 978/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.9063 - precision: 0.6396 - recall: 0.7526 - val_loss: 3.9026 - val_precision: 0.6246 - val_recall: 0.7521\n",
      "Epoch 979/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.9014 - precision: 0.6399 - recall: 0.7524 - val_loss: 3.8977 - val_precision: 0.6246 - val_recall: 0.7521\n",
      "Epoch 980/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8965 - precision: 0.6398 - recall: 0.7525 - val_loss: 3.8928 - val_precision: 0.6247 - val_recall: 0.7525\n",
      "Epoch 981/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8917 - precision: 0.6400 - recall: 0.7525 - val_loss: 3.8880 - val_precision: 0.6246 - val_recall: 0.7521\n",
      "Epoch 982/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8868 - precision: 0.6398 - recall: 0.7513 - val_loss: 3.8831 - val_precision: 0.6246 - val_recall: 0.7518\n",
      "Epoch 983/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.8819 - precision: 0.6398 - recall: 0.7512 - val_loss: 3.8783 - val_precision: 0.6246 - val_recall: 0.7518\n",
      "Epoch 984/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8771 - precision: 0.6399 - recall: 0.7521 - val_loss: 3.8734 - val_precision: 0.6246 - val_recall: 0.7518\n",
      "Epoch 985/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.8722 - precision: 0.6398 - recall: 0.7516 - val_loss: 3.8686 - val_precision: 0.6245 - val_recall: 0.7514\n",
      "Epoch 986/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8674 - precision: 0.6402 - recall: 0.7513 - val_loss: 3.8637 - val_precision: 0.6247 - val_recall: 0.7506\n",
      "Epoch 987/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8625 - precision: 0.6403 - recall: 0.7513 - val_loss: 3.8589 - val_precision: 0.6249 - val_recall: 0.7506\n",
      "Epoch 988/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8577 - precision: 0.6403 - recall: 0.7513 - val_loss: 3.8540 - val_precision: 0.6249 - val_recall: 0.7506\n",
      "Epoch 989/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.8529 - precision: 0.6405 - recall: 0.7515 - val_loss: 3.8492 - val_precision: 0.6249 - val_recall: 0.7506\n",
      "Epoch 990/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.8480 - precision: 0.6405 - recall: 0.7512 - val_loss: 3.8444 - val_precision: 0.6251 - val_recall: 0.7506\n",
      "Epoch 991/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8432 - precision: 0.6406 - recall: 0.7517 - val_loss: 3.8396 - val_precision: 0.6249 - val_recall: 0.7506\n",
      "Epoch 992/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8384 - precision: 0.6406 - recall: 0.7515 - val_loss: 3.8347 - val_precision: 0.6249 - val_recall: 0.7506\n",
      "Epoch 993/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.8336 - precision: 0.6404 - recall: 0.7510 - val_loss: 3.8299 - val_precision: 0.6249 - val_recall: 0.7506\n",
      "Epoch 994/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8287 - precision: 0.6406 - recall: 0.7515 - val_loss: 3.8251 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 995/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8239 - precision: 0.6404 - recall: 0.7506 - val_loss: 3.8203 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 996/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8191 - precision: 0.6405 - recall: 0.7507 - val_loss: 3.8155 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 997/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8143 - precision: 0.6405 - recall: 0.7502 - val_loss: 3.8107 - val_precision: 0.6250 - val_recall: 0.7498\n",
      "Epoch 998/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8095 - precision: 0.6406 - recall: 0.7512 - val_loss: 3.8059 - val_precision: 0.6251 - val_recall: 0.7506\n",
      "Epoch 999/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.8047 - precision: 0.6406 - recall: 0.7504 - val_loss: 3.8011 - val_precision: 0.6252 - val_recall: 0.7502\n",
      "Epoch 1000/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.7999 - precision: 0.6407 - recall: 0.7511 - val_loss: 3.7963 - val_precision: 0.6252 - val_recall: 0.7502\n",
      "Epoch 1001/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7952 - precision: 0.6406 - recall: 0.7501 - val_loss: 3.7915 - val_precision: 0.6251 - val_recall: 0.7494\n",
      "Epoch 1002/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 3.7904 - precision: 0.6408 - recall: 0.7507 - val_loss: 3.7868 - val_precision: 0.6250 - val_recall: 0.7498\n",
      "Epoch 1003/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7856 - precision: 0.6408 - recall: 0.7507 - val_loss: 3.7820 - val_precision: 0.6252 - val_recall: 0.7498\n",
      "Epoch 1004/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7808 - precision: 0.6407 - recall: 0.7506 - val_loss: 3.7772 - val_precision: 0.6252 - val_recall: 0.7498\n",
      "Epoch 1005/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7760 - precision: 0.6408 - recall: 0.7501 - val_loss: 3.7724 - val_precision: 0.6254 - val_recall: 0.7498\n",
      "Epoch 1006/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.7713 - precision: 0.6411 - recall: 0.7503 - val_loss: 3.7677 - val_precision: 0.6254 - val_recall: 0.7498\n",
      "Epoch 1007/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.7665 - precision: 0.6411 - recall: 0.7501 - val_loss: 3.7629 - val_precision: 0.6252 - val_recall: 0.7490\n",
      "Epoch 1008/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7618 - precision: 0.6410 - recall: 0.7501 - val_loss: 3.7582 - val_precision: 0.6253 - val_recall: 0.7494\n",
      "Epoch 1009/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7570 - precision: 0.6409 - recall: 0.7502 - val_loss: 3.7534 - val_precision: 0.6255 - val_recall: 0.7486\n",
      "Epoch 1010/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7523 - precision: 0.6411 - recall: 0.7506 - val_loss: 3.7487 - val_precision: 0.6256 - val_recall: 0.7498\n",
      "Epoch 1011/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7475 - precision: 0.6411 - recall: 0.7506 - val_loss: 3.7439 - val_precision: 0.6256 - val_recall: 0.7498\n",
      "Epoch 1012/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7428 - precision: 0.6410 - recall: 0.7501 - val_loss: 3.7392 - val_precision: 0.6257 - val_recall: 0.7494\n",
      "Epoch 1013/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.7380 - precision: 0.6410 - recall: 0.7502 - val_loss: 3.7345 - val_precision: 0.6259 - val_recall: 0.7498\n",
      "Epoch 1014/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7333 - precision: 0.6411 - recall: 0.7501 - val_loss: 3.7297 - val_precision: 0.6259 - val_recall: 0.7494\n",
      "Epoch 1015/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.7286 - precision: 0.6410 - recall: 0.7494 - val_loss: 3.7250 - val_precision: 0.6260 - val_recall: 0.7490\n",
      "Epoch 1016/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7238 - precision: 0.6411 - recall: 0.7498 - val_loss: 3.7203 - val_precision: 0.6260 - val_recall: 0.7490\n",
      "Epoch 1017/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7191 - precision: 0.6411 - recall: 0.7493 - val_loss: 3.7156 - val_precision: 0.6258 - val_recall: 0.7482\n",
      "Epoch 1018/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.7144 - precision: 0.6412 - recall: 0.7492 - val_loss: 3.7108 - val_precision: 0.6258 - val_recall: 0.7482\n",
      "Epoch 1019/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7097 - precision: 0.6413 - recall: 0.7485 - val_loss: 3.7061 - val_precision: 0.6261 - val_recall: 0.7475\n",
      "Epoch 1020/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7050 - precision: 0.6412 - recall: 0.7490 - val_loss: 3.7014 - val_precision: 0.6260 - val_recall: 0.7482\n",
      "Epoch 1021/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.7003 - precision: 0.6413 - recall: 0.7483 - val_loss: 3.6967 - val_precision: 0.6261 - val_recall: 0.7475\n",
      "Epoch 1022/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6956 - precision: 0.6413 - recall: 0.7478 - val_loss: 3.6920 - val_precision: 0.6261 - val_recall: 0.7475\n",
      "Epoch 1023/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.6909 - precision: 0.6414 - recall: 0.7482 - val_loss: 3.6873 - val_precision: 0.6261 - val_recall: 0.7475\n",
      "Epoch 1024/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.6862 - precision: 0.6413 - recall: 0.7485 - val_loss: 3.6826 - val_precision: 0.6261 - val_recall: 0.7475\n",
      "Epoch 1025/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6815 - precision: 0.6412 - recall: 0.7485 - val_loss: 3.6780 - val_precision: 0.6263 - val_recall: 0.7479\n",
      "Epoch 1026/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 3.6768 - precision: 0.6413 - recall: 0.7482 - val_loss: 3.6733 - val_precision: 0.6260 - val_recall: 0.7471\n",
      "Epoch 1027/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6721 - precision: 0.6413 - recall: 0.7480 - val_loss: 3.6686 - val_precision: 0.6263 - val_recall: 0.7475\n",
      "Epoch 1028/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6674 - precision: 0.6412 - recall: 0.7483 - val_loss: 3.6639 - val_precision: 0.6261 - val_recall: 0.7479\n",
      "Epoch 1029/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6628 - precision: 0.6412 - recall: 0.7478 - val_loss: 3.6593 - val_precision: 0.6259 - val_recall: 0.7467\n",
      "Epoch 1030/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6581 - precision: 0.6411 - recall: 0.7476 - val_loss: 3.6546 - val_precision: 0.6259 - val_recall: 0.7467\n",
      "Epoch 1031/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6534 - precision: 0.6411 - recall: 0.7476 - val_loss: 3.6499 - val_precision: 0.6259 - val_recall: 0.7467\n",
      "Epoch 1032/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6488 - precision: 0.6408 - recall: 0.7461 - val_loss: 3.6453 - val_precision: 0.6259 - val_recall: 0.7459\n",
      "Epoch 1033/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6441 - precision: 0.6410 - recall: 0.7464 - val_loss: 3.6406 - val_precision: 0.6259 - val_recall: 0.7467\n",
      "Epoch 1034/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.6395 - precision: 0.6409 - recall: 0.7462 - val_loss: 3.6360 - val_precision: 0.6257 - val_recall: 0.7459\n",
      "Epoch 1035/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6348 - precision: 0.6408 - recall: 0.7460 - val_loss: 3.6313 - val_precision: 0.6255 - val_recall: 0.7455\n",
      "Epoch 1036/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6302 - precision: 0.6408 - recall: 0.7454 - val_loss: 3.6267 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1037/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6255 - precision: 0.6408 - recall: 0.7460 - val_loss: 3.6220 - val_precision: 0.6257 - val_recall: 0.7459\n",
      "Epoch 1038/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6209 - precision: 0.6408 - recall: 0.7460 - val_loss: 3.6174 - val_precision: 0.6255 - val_recall: 0.7455\n",
      "Epoch 1039/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6162 - precision: 0.6409 - recall: 0.7456 - val_loss: 3.6128 - val_precision: 0.6255 - val_recall: 0.7455\n",
      "Epoch 1040/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.6116 - precision: 0.6408 - recall: 0.7454 - val_loss: 3.6082 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1041/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6070 - precision: 0.6409 - recall: 0.7451 - val_loss: 3.6035 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1042/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.6024 - precision: 0.6410 - recall: 0.7454 - val_loss: 3.5989 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1043/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5978 - precision: 0.6409 - recall: 0.7459 - val_loss: 3.5943 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1044/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5932 - precision: 0.6411 - recall: 0.7455 - val_loss: 3.5897 - val_precision: 0.6253 - val_recall: 0.7447\n",
      "Epoch 1045/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5886 - precision: 0.6408 - recall: 0.7439 - val_loss: 3.5851 - val_precision: 0.6252 - val_recall: 0.7444\n",
      "Epoch 1046/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.5840 - precision: 0.6409 - recall: 0.7443 - val_loss: 3.5805 - val_precision: 0.6252 - val_recall: 0.7444\n",
      "Epoch 1047/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5794 - precision: 0.6408 - recall: 0.7454 - val_loss: 3.5759 - val_precision: 0.6250 - val_recall: 0.7444\n",
      "Epoch 1048/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5748 - precision: 0.6408 - recall: 0.7447 - val_loss: 3.5713 - val_precision: 0.6251 - val_recall: 0.7447\n",
      "Epoch 1049/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.5702 - precision: 0.6410 - recall: 0.7437 - val_loss: 3.5667 - val_precision: 0.6251 - val_recall: 0.7447\n",
      "Epoch 1050/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5656 - precision: 0.6411 - recall: 0.7441 - val_loss: 3.5622 - val_precision: 0.6253 - val_recall: 0.7447\n",
      "Epoch 1051/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5610 - precision: 0.6408 - recall: 0.7445 - val_loss: 3.5576 - val_precision: 0.6251 - val_recall: 0.7447\n",
      "Epoch 1052/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5564 - precision: 0.6412 - recall: 0.7438 - val_loss: 3.5530 - val_precision: 0.6259 - val_recall: 0.7447\n",
      "Epoch 1053/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.5519 - precision: 0.6410 - recall: 0.7441 - val_loss: 3.5485 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1054/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5473 - precision: 0.6410 - recall: 0.7442 - val_loss: 3.5439 - val_precision: 0.6255 - val_recall: 0.7447\n",
      "Epoch 1055/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5427 - precision: 0.6410 - recall: 0.7443 - val_loss: 3.5393 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1056/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5382 - precision: 0.6410 - recall: 0.7437 - val_loss: 3.5348 - val_precision: 0.6255 - val_recall: 0.7447\n",
      "Epoch 1057/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5336 - precision: 0.6410 - recall: 0.7443 - val_loss: 3.5302 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1058/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.5291 - precision: 0.6409 - recall: 0.7442 - val_loss: 3.5257 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1059/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5245 - precision: 0.6410 - recall: 0.7445 - val_loss: 3.5211 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1060/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5200 - precision: 0.6410 - recall: 0.7443 - val_loss: 3.5166 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1061/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5155 - precision: 0.6409 - recall: 0.7445 - val_loss: 3.5121 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1062/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5109 - precision: 0.6409 - recall: 0.7436 - val_loss: 3.5075 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1063/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.5064 - precision: 0.6409 - recall: 0.7434 - val_loss: 3.5030 - val_precision: 0.6254 - val_recall: 0.7440\n",
      "Epoch 1064/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.5019 - precision: 0.6408 - recall: 0.7431 - val_loss: 3.4985 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1065/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4974 - precision: 0.6412 - recall: 0.7428 - val_loss: 3.4940 - val_precision: 0.6253 - val_recall: 0.7436\n",
      "Epoch 1066/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4928 - precision: 0.6410 - recall: 0.7429 - val_loss: 3.4895 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1067/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.4883 - precision: 0.6410 - recall: 0.7434 - val_loss: 3.4850 - val_precision: 0.6254 - val_recall: 0.7444\n",
      "Epoch 1068/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4838 - precision: 0.6408 - recall: 0.7434 - val_loss: 3.4805 - val_precision: 0.6254 - val_recall: 0.7444\n",
      "Epoch 1069/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.4793 - precision: 0.6411 - recall: 0.7428 - val_loss: 3.4760 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1070/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.4748 - precision: 0.6412 - recall: 0.7434 - val_loss: 3.4715 - val_precision: 0.6253 - val_recall: 0.7436\n",
      "Epoch 1071/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.4703 - precision: 0.6410 - recall: 0.7429 - val_loss: 3.4670 - val_precision: 0.6255 - val_recall: 0.7436\n",
      "Epoch 1072/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4658 - precision: 0.6410 - recall: 0.7431 - val_loss: 3.4625 - val_precision: 0.6254 - val_recall: 0.7440\n",
      "Epoch 1073/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4613 - precision: 0.6411 - recall: 0.7424 - val_loss: 3.4580 - val_precision: 0.6254 - val_recall: 0.7432\n",
      "Epoch 1074/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4569 - precision: 0.6413 - recall: 0.7418 - val_loss: 3.4535 - val_precision: 0.6258 - val_recall: 0.7432\n",
      "Epoch 1075/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4524 - precision: 0.6412 - recall: 0.7424 - val_loss: 3.4491 - val_precision: 0.6256 - val_recall: 0.7432\n",
      "Epoch 1076/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4479 - precision: 0.6412 - recall: 0.7423 - val_loss: 3.4446 - val_precision: 0.6256 - val_recall: 0.7432\n",
      "Epoch 1077/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4434 - precision: 0.6412 - recall: 0.7423 - val_loss: 3.4401 - val_precision: 0.6256 - val_recall: 0.7432\n",
      "Epoch 1078/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4390 - precision: 0.6412 - recall: 0.7419 - val_loss: 3.4357 - val_precision: 0.6256 - val_recall: 0.7432\n",
      "Epoch 1079/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4345 - precision: 0.6411 - recall: 0.7417 - val_loss: 3.4312 - val_precision: 0.6257 - val_recall: 0.7428\n",
      "Epoch 1080/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4301 - precision: 0.6411 - recall: 0.7415 - val_loss: 3.4268 - val_precision: 0.6256 - val_recall: 0.7432\n",
      "Epoch 1081/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4256 - precision: 0.6411 - recall: 0.7410 - val_loss: 3.4223 - val_precision: 0.6254 - val_recall: 0.7424\n",
      "Epoch 1082/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4212 - precision: 0.6409 - recall: 0.7413 - val_loss: 3.4179 - val_precision: 0.6254 - val_recall: 0.7424\n",
      "Epoch 1083/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4167 - precision: 0.6409 - recall: 0.7413 - val_loss: 3.4134 - val_precision: 0.6254 - val_recall: 0.7424\n",
      "Epoch 1084/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.4123 - precision: 0.6409 - recall: 0.7409 - val_loss: 3.4090 - val_precision: 0.6254 - val_recall: 0.7424\n",
      "Epoch 1085/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4078 - precision: 0.6409 - recall: 0.7411 - val_loss: 3.4046 - val_precision: 0.6254 - val_recall: 0.7424\n",
      "Epoch 1086/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.4034 - precision: 0.6410 - recall: 0.7413 - val_loss: 3.4001 - val_precision: 0.6254 - val_recall: 0.7424\n",
      "Epoch 1087/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3990 - precision: 0.6412 - recall: 0.7408 - val_loss: 3.3957 - val_precision: 0.6252 - val_recall: 0.7420\n",
      "Epoch 1088/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3946 - precision: 0.6412 - recall: 0.7411 - val_loss: 3.3913 - val_precision: 0.6254 - val_recall: 0.7424\n",
      "Epoch 1089/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3901 - precision: 0.6412 - recall: 0.7406 - val_loss: 3.3869 - val_precision: 0.6257 - val_recall: 0.7416\n",
      "Epoch 1090/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3857 - precision: 0.6412 - recall: 0.7408 - val_loss: 3.3825 - val_precision: 0.6257 - val_recall: 0.7416\n",
      "Epoch 1091/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3813 - precision: 0.6411 - recall: 0.7400 - val_loss: 3.3781 - val_precision: 0.6256 - val_recall: 0.7412\n",
      "Epoch 1092/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3769 - precision: 0.6411 - recall: 0.7401 - val_loss: 3.3736 - val_precision: 0.6257 - val_recall: 0.7416\n",
      "Epoch 1093/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3725 - precision: 0.6412 - recall: 0.7408 - val_loss: 3.3692 - val_precision: 0.6258 - val_recall: 0.7424\n",
      "Epoch 1094/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.3681 - precision: 0.6412 - recall: 0.7403 - val_loss: 3.3649 - val_precision: 0.6257 - val_recall: 0.7416\n",
      "Epoch 1095/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3637 - precision: 0.6411 - recall: 0.7410 - val_loss: 3.3605 - val_precision: 0.6258 - val_recall: 0.7424\n",
      "Epoch 1096/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3593 - precision: 0.6411 - recall: 0.7415 - val_loss: 3.3561 - val_precision: 0.6258 - val_recall: 0.7424\n",
      "Epoch 1097/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3549 - precision: 0.6409 - recall: 0.7401 - val_loss: 3.3517 - val_precision: 0.6258 - val_recall: 0.7412\n",
      "Epoch 1098/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3506 - precision: 0.6410 - recall: 0.7405 - val_loss: 3.3473 - val_precision: 0.6257 - val_recall: 0.7420\n",
      "Epoch 1099/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.3462 - precision: 0.6411 - recall: 0.7408 - val_loss: 3.3429 - val_precision: 0.6256 - val_recall: 0.7424\n",
      "Epoch 1100/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3418 - precision: 0.6411 - recall: 0.7409 - val_loss: 3.3386 - val_precision: 0.6259 - val_recall: 0.7420\n",
      "Epoch 1101/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3374 - precision: 0.6410 - recall: 0.7405 - val_loss: 3.3342 - val_precision: 0.6252 - val_recall: 0.7412\n",
      "Epoch 1102/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3331 - precision: 0.6411 - recall: 0.7404 - val_loss: 3.3298 - val_precision: 0.6261 - val_recall: 0.7409\n",
      "Epoch 1103/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3287 - precision: 0.6411 - recall: 0.7403 - val_loss: 3.3255 - val_precision: 0.6251 - val_recall: 0.7409\n",
      "Epoch 1104/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3243 - precision: 0.6414 - recall: 0.7395 - val_loss: 3.3211 - val_precision: 0.6262 - val_recall: 0.7405\n",
      "Epoch 1105/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3200 - precision: 0.6417 - recall: 0.7397 - val_loss: 3.3168 - val_precision: 0.6258 - val_recall: 0.7405\n",
      "Epoch 1106/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3156 - precision: 0.6413 - recall: 0.7405 - val_loss: 3.3124 - val_precision: 0.6257 - val_recall: 0.7409\n",
      "Epoch 1107/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 3.3113 - precision: 0.6416 - recall: 0.7397 - val_loss: 3.3081 - val_precision: 0.6262 - val_recall: 0.7405\n",
      "Epoch 1108/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.3069 - precision: 0.6417 - recall: 0.7396 - val_loss: 3.3037 - val_precision: 0.6256 - val_recall: 0.7405\n",
      "Epoch 1109/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.3026 - precision: 0.6417 - recall: 0.7403 - val_loss: 3.2994 - val_precision: 0.6256 - val_recall: 0.7405\n",
      "Epoch 1110/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2983 - precision: 0.6417 - recall: 0.7389 - val_loss: 3.2951 - val_precision: 0.6260 - val_recall: 0.7405\n",
      "Epoch 1111/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2939 - precision: 0.6417 - recall: 0.7389 - val_loss: 3.2907 - val_precision: 0.6262 - val_recall: 0.7405\n",
      "Epoch 1112/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2896 - precision: 0.6418 - recall: 0.7386 - val_loss: 3.2864 - val_precision: 0.6257 - val_recall: 0.7397\n",
      "Epoch 1113/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.2853 - precision: 0.6418 - recall: 0.7396 - val_loss: 3.2821 - val_precision: 0.6259 - val_recall: 0.7401\n",
      "Epoch 1114/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.2810 - precision: 0.6419 - recall: 0.7392 - val_loss: 3.2778 - val_precision: 0.6258 - val_recall: 0.7393\n",
      "Epoch 1115/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2767 - precision: 0.6418 - recall: 0.7395 - val_loss: 3.2735 - val_precision: 0.6259 - val_recall: 0.7401\n",
      "Epoch 1116/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.2724 - precision: 0.6419 - recall: 0.7392 - val_loss: 3.2692 - val_precision: 0.6259 - val_recall: 0.7397\n",
      "Epoch 1117/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2681 - precision: 0.6420 - recall: 0.7387 - val_loss: 3.2649 - val_precision: 0.6257 - val_recall: 0.7389\n",
      "Epoch 1118/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2638 - precision: 0.6421 - recall: 0.7389 - val_loss: 3.2606 - val_precision: 0.6258 - val_recall: 0.7393\n",
      "Epoch 1119/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.2595 - precision: 0.6421 - recall: 0.7391 - val_loss: 3.2563 - val_precision: 0.6258 - val_recall: 0.7393\n",
      "Epoch 1120/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2552 - precision: 0.6420 - recall: 0.7386 - val_loss: 3.2520 - val_precision: 0.6259 - val_recall: 0.7389\n",
      "Epoch 1121/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2509 - precision: 0.6420 - recall: 0.7385 - val_loss: 3.2477 - val_precision: 0.6256 - val_recall: 0.7393\n",
      "Epoch 1122/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2466 - precision: 0.6418 - recall: 0.7385 - val_loss: 3.2434 - val_precision: 0.6255 - val_recall: 0.7389\n",
      "Epoch 1123/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2423 - precision: 0.6420 - recall: 0.7382 - val_loss: 3.2392 - val_precision: 0.6256 - val_recall: 0.7385\n",
      "Epoch 1124/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2380 - precision: 0.6422 - recall: 0.7397 - val_loss: 3.2349 - val_precision: 0.6255 - val_recall: 0.7389\n",
      "Epoch 1125/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2338 - precision: 0.6423 - recall: 0.7390 - val_loss: 3.2306 - val_precision: 0.6257 - val_recall: 0.7377\n",
      "Epoch 1126/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2295 - precision: 0.6419 - recall: 0.7385 - val_loss: 3.2264 - val_precision: 0.6254 - val_recall: 0.7385\n",
      "Epoch 1127/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2253 - precision: 0.6421 - recall: 0.7383 - val_loss: 3.2221 - val_precision: 0.6257 - val_recall: 0.7377\n",
      "Epoch 1128/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2210 - precision: 0.6420 - recall: 0.7377 - val_loss: 3.2179 - val_precision: 0.6256 - val_recall: 0.7374\n",
      "Epoch 1129/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2167 - precision: 0.6423 - recall: 0.7383 - val_loss: 3.2136 - val_precision: 0.6253 - val_recall: 0.7377\n",
      "Epoch 1130/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2125 - precision: 0.6422 - recall: 0.7382 - val_loss: 3.2094 - val_precision: 0.6255 - val_recall: 0.7377\n",
      "Epoch 1131/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2082 - precision: 0.6424 - recall: 0.7392 - val_loss: 3.2051 - val_precision: 0.6253 - val_recall: 0.7377\n",
      "Epoch 1132/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.2040 - precision: 0.6420 - recall: 0.7371 - val_loss: 3.2009 - val_precision: 0.6255 - val_recall: 0.7370\n",
      "Epoch 1133/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1998 - precision: 0.6425 - recall: 0.7389 - val_loss: 3.1966 - val_precision: 0.6254 - val_recall: 0.7374\n",
      "Epoch 1134/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1955 - precision: 0.6424 - recall: 0.7385 - val_loss: 3.1924 - val_precision: 0.6254 - val_recall: 0.7374\n",
      "Epoch 1135/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1913 - precision: 0.6424 - recall: 0.7385 - val_loss: 3.1882 - val_precision: 0.6254 - val_recall: 0.7374\n",
      "Epoch 1136/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1871 - precision: 0.6422 - recall: 0.7380 - val_loss: 3.1840 - val_precision: 0.6252 - val_recall: 0.7366\n",
      "Epoch 1137/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1829 - precision: 0.6423 - recall: 0.7377 - val_loss: 3.1798 - val_precision: 0.6250 - val_recall: 0.7362\n",
      "Epoch 1138/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1786 - precision: 0.6427 - recall: 0.7373 - val_loss: 3.1756 - val_precision: 0.6255 - val_recall: 0.7362\n",
      "Epoch 1139/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1744 - precision: 0.6425 - recall: 0.7378 - val_loss: 3.1713 - val_precision: 0.6250 - val_recall: 0.7362\n",
      "Epoch 1140/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.1702 - precision: 0.6427 - recall: 0.7367 - val_loss: 3.1671 - val_precision: 0.6255 - val_recall: 0.7358\n",
      "Epoch 1141/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.1660 - precision: 0.6428 - recall: 0.7373 - val_loss: 3.1629 - val_precision: 0.6251 - val_recall: 0.7358\n",
      "Epoch 1142/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1618 - precision: 0.6427 - recall: 0.7369 - val_loss: 3.1587 - val_precision: 0.6251 - val_recall: 0.7358\n",
      "Epoch 1143/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1576 - precision: 0.6427 - recall: 0.7371 - val_loss: 3.1546 - val_precision: 0.6253 - val_recall: 0.7358\n",
      "Epoch 1144/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1534 - precision: 0.6426 - recall: 0.7364 - val_loss: 3.1504 - val_precision: 0.6256 - val_recall: 0.7354\n",
      "Epoch 1145/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1493 - precision: 0.6425 - recall: 0.7364 - val_loss: 3.1462 - val_precision: 0.6254 - val_recall: 0.7354\n",
      "Epoch 1146/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1451 - precision: 0.6426 - recall: 0.7373 - val_loss: 3.1420 - val_precision: 0.6253 - val_recall: 0.7358\n",
      "Epoch 1147/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1409 - precision: 0.6425 - recall: 0.7372 - val_loss: 3.1378 - val_precision: 0.6251 - val_recall: 0.7350\n",
      "Epoch 1148/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1367 - precision: 0.6425 - recall: 0.7369 - val_loss: 3.1337 - val_precision: 0.6251 - val_recall: 0.7350\n",
      "Epoch 1149/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1326 - precision: 0.6425 - recall: 0.7368 - val_loss: 3.1295 - val_precision: 0.6251 - val_recall: 0.7350\n",
      "Epoch 1150/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1284 - precision: 0.6428 - recall: 0.7362 - val_loss: 3.1254 - val_precision: 0.6250 - val_recall: 0.7346\n",
      "Epoch 1151/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1243 - precision: 0.6425 - recall: 0.7366 - val_loss: 3.1212 - val_precision: 0.6250 - val_recall: 0.7346\n",
      "Epoch 1152/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1201 - precision: 0.6428 - recall: 0.7362 - val_loss: 3.1171 - val_precision: 0.6249 - val_recall: 0.7339\n",
      "Epoch 1153/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.1160 - precision: 0.6427 - recall: 0.7364 - val_loss: 3.1129 - val_precision: 0.6250 - val_recall: 0.7346\n",
      "Epoch 1154/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1118 - precision: 0.6427 - recall: 0.7359 - val_loss: 3.1088 - val_precision: 0.6247 - val_recall: 0.7339\n",
      "Epoch 1155/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1077 - precision: 0.6426 - recall: 0.7361 - val_loss: 3.1046 - val_precision: 0.6248 - val_recall: 0.7342\n",
      "Epoch 1156/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.1035 - precision: 0.6427 - recall: 0.7363 - val_loss: 3.1005 - val_precision: 0.6247 - val_recall: 0.7339\n",
      "Epoch 1157/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0994 - precision: 0.6426 - recall: 0.7361 - val_loss: 3.0964 - val_precision: 0.6248 - val_recall: 0.7342\n",
      "Epoch 1158/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0953 - precision: 0.6428 - recall: 0.7353 - val_loss: 3.0923 - val_precision: 0.6248 - val_recall: 0.7342\n",
      "Epoch 1159/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0912 - precision: 0.6426 - recall: 0.7358 - val_loss: 3.0881 - val_precision: 0.6248 - val_recall: 0.7342\n",
      "Epoch 1160/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 3.0870 - precision: 0.6429 - recall: 0.7355 - val_loss: 3.0840 - val_precision: 0.6248 - val_recall: 0.7342\n",
      "Epoch 1161/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0829 - precision: 0.6426 - recall: 0.7359 - val_loss: 3.0799 - val_precision: 0.6246 - val_recall: 0.7342\n",
      "Epoch 1162/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0788 - precision: 0.6427 - recall: 0.7359 - val_loss: 3.0758 - val_precision: 0.6247 - val_recall: 0.7339\n",
      "Epoch 1163/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0747 - precision: 0.6428 - recall: 0.7358 - val_loss: 3.0717 - val_precision: 0.6247 - val_recall: 0.7331\n",
      "Epoch 1164/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0706 - precision: 0.6426 - recall: 0.7355 - val_loss: 3.0676 - val_precision: 0.6246 - val_recall: 0.7335\n",
      "Epoch 1165/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0665 - precision: 0.6429 - recall: 0.7349 - val_loss: 3.0635 - val_precision: 0.6250 - val_recall: 0.7327\n",
      "Epoch 1166/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0624 - precision: 0.6430 - recall: 0.7350 - val_loss: 3.0594 - val_precision: 0.6246 - val_recall: 0.7335\n",
      "Epoch 1167/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 3.0583 - precision: 0.6429 - recall: 0.7349 - val_loss: 3.0553 - val_precision: 0.6246 - val_recall: 0.7335\n",
      "Epoch 1168/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0542 - precision: 0.6428 - recall: 0.7355 - val_loss: 3.0513 - val_precision: 0.6246 - val_recall: 0.7335\n",
      "Epoch 1169/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0502 - precision: 0.6429 - recall: 0.7358 - val_loss: 3.0472 - val_precision: 0.6246 - val_recall: 0.7342\n",
      "Epoch 1170/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0461 - precision: 0.6429 - recall: 0.7352 - val_loss: 3.0431 - val_precision: 0.6246 - val_recall: 0.7335\n",
      "Epoch 1171/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0420 - precision: 0.6428 - recall: 0.7354 - val_loss: 3.0390 - val_precision: 0.6248 - val_recall: 0.7342\n",
      "Epoch 1172/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0379 - precision: 0.6430 - recall: 0.7350 - val_loss: 3.0350 - val_precision: 0.6248 - val_recall: 0.7323\n",
      "Epoch 1173/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0339 - precision: 0.6429 - recall: 0.7354 - val_loss: 3.0309 - val_precision: 0.6248 - val_recall: 0.7342\n",
      "Epoch 1174/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0298 - precision: 0.6429 - recall: 0.7354 - val_loss: 3.0268 - val_precision: 0.6250 - val_recall: 0.7342\n",
      "Epoch 1175/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 3.0258 - precision: 0.6431 - recall: 0.7352 - val_loss: 3.0228 - val_precision: 0.6249 - val_recall: 0.7339\n",
      "Epoch 1176/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0217 - precision: 0.6430 - recall: 0.7352 - val_loss: 3.0187 - val_precision: 0.6248 - val_recall: 0.7335\n",
      "Epoch 1177/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0177 - precision: 0.6431 - recall: 0.7355 - val_loss: 3.0147 - val_precision: 0.6249 - val_recall: 0.7339\n",
      "Epoch 1178/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0136 - precision: 0.6433 - recall: 0.7353 - val_loss: 3.0106 - val_precision: 0.6252 - val_recall: 0.7335\n",
      "Epoch 1179/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0096 - precision: 0.6434 - recall: 0.7349 - val_loss: 3.0066 - val_precision: 0.6250 - val_recall: 0.7323\n",
      "Epoch 1180/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 3.0055 - precision: 0.6433 - recall: 0.7350 - val_loss: 3.0026 - val_precision: 0.6249 - val_recall: 0.7331\n",
      "Epoch 1181/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 3.0015 - precision: 0.6431 - recall: 0.7355 - val_loss: 2.9985 - val_precision: 0.6248 - val_recall: 0.7335\n",
      "Epoch 1182/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9975 - precision: 0.6430 - recall: 0.7353 - val_loss: 2.9945 - val_precision: 0.6247 - val_recall: 0.7331\n",
      "Epoch 1183/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9934 - precision: 0.6433 - recall: 0.7350 - val_loss: 2.9905 - val_precision: 0.6254 - val_recall: 0.7327\n",
      "Epoch 1184/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9894 - precision: 0.6433 - recall: 0.7353 - val_loss: 2.9865 - val_precision: 0.6254 - val_recall: 0.7327\n",
      "Epoch 1185/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9854 - precision: 0.6432 - recall: 0.7352 - val_loss: 2.9825 - val_precision: 0.6247 - val_recall: 0.7331\n",
      "Epoch 1186/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9814 - precision: 0.6434 - recall: 0.7352 - val_loss: 2.9784 - val_precision: 0.6249 - val_recall: 0.7331\n",
      "Epoch 1187/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9774 - precision: 0.6434 - recall: 0.7350 - val_loss: 2.9744 - val_precision: 0.6252 - val_recall: 0.7323\n",
      "Epoch 1188/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9734 - precision: 0.6432 - recall: 0.7354 - val_loss: 2.9704 - val_precision: 0.6249 - val_recall: 0.7331\n",
      "Epoch 1189/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9694 - precision: 0.6434 - recall: 0.7352 - val_loss: 2.9664 - val_precision: 0.6253 - val_recall: 0.7331\n",
      "Epoch 1190/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9654 - precision: 0.6434 - recall: 0.7352 - val_loss: 2.9624 - val_precision: 0.6250 - val_recall: 0.7335\n",
      "Epoch 1191/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9614 - precision: 0.6432 - recall: 0.7355 - val_loss: 2.9584 - val_precision: 0.6250 - val_recall: 0.7335\n",
      "Epoch 1192/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9574 - precision: 0.6433 - recall: 0.7354 - val_loss: 2.9545 - val_precision: 0.6249 - val_recall: 0.7331\n",
      "Epoch 1193/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9534 - precision: 0.6431 - recall: 0.7355 - val_loss: 2.9505 - val_precision: 0.6252 - val_recall: 0.7335\n",
      "Epoch 1194/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9494 - precision: 0.6433 - recall: 0.7350 - val_loss: 2.9465 - val_precision: 0.6250 - val_recall: 0.7335\n",
      "Epoch 1195/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9454 - precision: 0.6431 - recall: 0.7363 - val_loss: 2.9425 - val_precision: 0.6251 - val_recall: 0.7339\n",
      "Epoch 1196/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9415 - precision: 0.6433 - recall: 0.7355 - val_loss: 2.9385 - val_precision: 0.6248 - val_recall: 0.7327\n",
      "Epoch 1197/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9375 - precision: 0.6435 - recall: 0.7353 - val_loss: 2.9346 - val_precision: 0.6248 - val_recall: 0.7327\n",
      "Epoch 1198/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 2.9335 - precision: 0.6435 - recall: 0.7345 - val_loss: 2.9306 - val_precision: 0.6250 - val_recall: 0.7327\n",
      "Epoch 1199/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9296 - precision: 0.6434 - recall: 0.7353 - val_loss: 2.9267 - val_precision: 0.6248 - val_recall: 0.7327\n",
      "Epoch 1200/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9256 - precision: 0.6432 - recall: 0.7358 - val_loss: 2.9227 - val_precision: 0.6248 - val_recall: 0.7327\n",
      "Epoch 1201/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9216 - precision: 0.6434 - recall: 0.7352 - val_loss: 2.9188 - val_precision: 0.6254 - val_recall: 0.7327\n",
      "Epoch 1202/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9177 - precision: 0.6433 - recall: 0.7357 - val_loss: 2.9148 - val_precision: 0.6250 - val_recall: 0.7327\n",
      "Epoch 1203/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9138 - precision: 0.6431 - recall: 0.7359 - val_loss: 2.9109 - val_precision: 0.6250 - val_recall: 0.7327\n",
      "Epoch 1204/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.9098 - precision: 0.6435 - recall: 0.7361 - val_loss: 2.9069 - val_precision: 0.6252 - val_recall: 0.7327\n",
      "Epoch 1205/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9059 - precision: 0.6434 - recall: 0.7354 - val_loss: 2.9030 - val_precision: 0.6252 - val_recall: 0.7323\n",
      "Epoch 1206/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.9019 - precision: 0.6433 - recall: 0.7350 - val_loss: 2.8991 - val_precision: 0.6257 - val_recall: 0.7323\n",
      "Epoch 1207/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8980 - precision: 0.6435 - recall: 0.7349 - val_loss: 2.8952 - val_precision: 0.6255 - val_recall: 0.7323\n",
      "Epoch 1208/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8941 - precision: 0.6435 - recall: 0.7345 - val_loss: 2.8912 - val_precision: 0.6259 - val_recall: 0.7323\n",
      "Epoch 1209/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8902 - precision: 0.6435 - recall: 0.7348 - val_loss: 2.8873 - val_precision: 0.6263 - val_recall: 0.7323\n",
      "Epoch 1210/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8863 - precision: 0.6435 - recall: 0.7348 - val_loss: 2.8834 - val_precision: 0.6261 - val_recall: 0.7323\n",
      "Epoch 1211/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8823 - precision: 0.6435 - recall: 0.7353 - val_loss: 2.8795 - val_precision: 0.6261 - val_recall: 0.7323\n",
      "Epoch 1212/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8784 - precision: 0.6438 - recall: 0.7348 - val_loss: 2.8756 - val_precision: 0.6267 - val_recall: 0.7323\n",
      "Epoch 1213/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8745 - precision: 0.6436 - recall: 0.7344 - val_loss: 2.8717 - val_precision: 0.6267 - val_recall: 0.7323\n",
      "Epoch 1214/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8706 - precision: 0.6437 - recall: 0.7346 - val_loss: 2.8678 - val_precision: 0.6267 - val_recall: 0.7323\n",
      "Epoch 1215/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8667 - precision: 0.6436 - recall: 0.7344 - val_loss: 2.8639 - val_precision: 0.6267 - val_recall: 0.7323\n",
      "Epoch 1216/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8628 - precision: 0.6438 - recall: 0.7349 - val_loss: 2.8600 - val_precision: 0.6267 - val_recall: 0.7323\n",
      "Epoch 1217/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8590 - precision: 0.6437 - recall: 0.7344 - val_loss: 2.8561 - val_precision: 0.6266 - val_recall: 0.7319\n",
      "Epoch 1218/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8551 - precision: 0.6437 - recall: 0.7344 - val_loss: 2.8522 - val_precision: 0.6266 - val_recall: 0.7319\n",
      "Epoch 1219/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8512 - precision: 0.6437 - recall: 0.7343 - val_loss: 2.8484 - val_precision: 0.6268 - val_recall: 0.7327\n",
      "Epoch 1220/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8473 - precision: 0.6437 - recall: 0.7344 - val_loss: 2.8445 - val_precision: 0.6268 - val_recall: 0.7327\n",
      "Epoch 1221/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8434 - precision: 0.6438 - recall: 0.7348 - val_loss: 2.8406 - val_precision: 0.6268 - val_recall: 0.7327\n",
      "Epoch 1222/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8396 - precision: 0.6438 - recall: 0.7348 - val_loss: 2.8368 - val_precision: 0.6266 - val_recall: 0.7327\n",
      "Epoch 1223/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8357 - precision: 0.6439 - recall: 0.7348 - val_loss: 2.8329 - val_precision: 0.6266 - val_recall: 0.7319\n",
      "Epoch 1224/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8319 - precision: 0.6439 - recall: 0.7349 - val_loss: 2.8290 - val_precision: 0.6265 - val_recall: 0.7323\n",
      "Epoch 1225/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8280 - precision: 0.6439 - recall: 0.7344 - val_loss: 2.8252 - val_precision: 0.6265 - val_recall: 0.7323\n",
      "Epoch 1226/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8241 - precision: 0.6439 - recall: 0.7344 - val_loss: 2.8213 - val_precision: 0.6265 - val_recall: 0.7323\n",
      "Epoch 1227/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8203 - precision: 0.6437 - recall: 0.7345 - val_loss: 2.8175 - val_precision: 0.6265 - val_recall: 0.7323\n",
      "Epoch 1228/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8165 - precision: 0.6437 - recall: 0.7348 - val_loss: 2.8137 - val_precision: 0.6267 - val_recall: 0.7323\n",
      "Epoch 1229/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8126 - precision: 0.6440 - recall: 0.7339 - val_loss: 2.8098 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1230/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.8088 - precision: 0.6436 - recall: 0.7350 - val_loss: 2.8060 - val_precision: 0.6268 - val_recall: 0.7327\n",
      "Epoch 1231/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8050 - precision: 0.6437 - recall: 0.7354 - val_loss: 2.8022 - val_precision: 0.6266 - val_recall: 0.7327\n",
      "Epoch 1232/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.8011 - precision: 0.6438 - recall: 0.7350 - val_loss: 2.7983 - val_precision: 0.6270 - val_recall: 0.7327\n",
      "Epoch 1233/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7973 - precision: 0.6437 - recall: 0.7348 - val_loss: 2.7945 - val_precision: 0.6270 - val_recall: 0.7327\n",
      "Epoch 1234/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7935 - precision: 0.6436 - recall: 0.7350 - val_loss: 2.7907 - val_precision: 0.6270 - val_recall: 0.7327\n",
      "Epoch 1235/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7897 - precision: 0.6438 - recall: 0.7353 - val_loss: 2.7869 - val_precision: 0.6270 - val_recall: 0.7327\n",
      "Epoch 1236/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7859 - precision: 0.6437 - recall: 0.7345 - val_loss: 2.7831 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1237/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.7821 - precision: 0.6439 - recall: 0.7343 - val_loss: 2.7793 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1238/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7782 - precision: 0.6438 - recall: 0.7348 - val_loss: 2.7755 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1239/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7744 - precision: 0.6439 - recall: 0.7357 - val_loss: 2.7717 - val_precision: 0.6268 - val_recall: 0.7327\n",
      "Epoch 1240/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7706 - precision: 0.6440 - recall: 0.7348 - val_loss: 2.7679 - val_precision: 0.6270 - val_recall: 0.7327\n",
      "Epoch 1241/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7669 - precision: 0.6438 - recall: 0.7340 - val_loss: 2.7641 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1242/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.7631 - precision: 0.6439 - recall: 0.7346 - val_loss: 2.7603 - val_precision: 0.6270 - val_recall: 0.7327\n",
      "Epoch 1243/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7593 - precision: 0.6440 - recall: 0.7346 - val_loss: 2.7565 - val_precision: 0.6269 - val_recall: 0.7323\n",
      "Epoch 1244/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7555 - precision: 0.6439 - recall: 0.7336 - val_loss: 2.7527 - val_precision: 0.6269 - val_recall: 0.7323\n",
      "Epoch 1245/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.7517 - precision: 0.6439 - recall: 0.7338 - val_loss: 2.7490 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1246/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7479 - precision: 0.6439 - recall: 0.7345 - val_loss: 2.7452 - val_precision: 0.6269 - val_recall: 0.7323\n",
      "Epoch 1247/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7442 - precision: 0.6437 - recall: 0.7346 - val_loss: 2.7414 - val_precision: 0.6269 - val_recall: 0.7323\n",
      "Epoch 1248/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7404 - precision: 0.6438 - recall: 0.7346 - val_loss: 2.7377 - val_precision: 0.6269 - val_recall: 0.7323\n",
      "Epoch 1249/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7366 - precision: 0.6437 - recall: 0.7344 - val_loss: 2.7339 - val_precision: 0.6269 - val_recall: 0.7323\n",
      "Epoch 1250/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7329 - precision: 0.6435 - recall: 0.7345 - val_loss: 2.7301 - val_precision: 0.6269 - val_recall: 0.7323\n",
      "Epoch 1251/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7291 - precision: 0.6440 - recall: 0.7343 - val_loss: 2.7264 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1252/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7254 - precision: 0.6439 - recall: 0.7346 - val_loss: 2.7227 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1253/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 2.7216 - precision: 0.6439 - recall: 0.7341 - val_loss: 2.7189 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1254/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7179 - precision: 0.6439 - recall: 0.7344 - val_loss: 2.7152 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1255/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7142 - precision: 0.6440 - recall: 0.7345 - val_loss: 2.7114 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1256/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.7104 - precision: 0.6439 - recall: 0.7344 - val_loss: 2.7077 - val_precision: 0.6271 - val_recall: 0.7323\n",
      "Epoch 1257/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7067 - precision: 0.6440 - recall: 0.7339 - val_loss: 2.7040 - val_precision: 0.6273 - val_recall: 0.7323\n",
      "Epoch 1258/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.7030 - precision: 0.6440 - recall: 0.7348 - val_loss: 2.7003 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1259/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6993 - precision: 0.6441 - recall: 0.7345 - val_loss: 2.6965 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1260/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.6956 - precision: 0.6439 - recall: 0.7350 - val_loss: 2.6928 - val_precision: 0.6270 - val_recall: 0.7327\n",
      "Epoch 1261/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6918 - precision: 0.6439 - recall: 0.7346 - val_loss: 2.6891 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1262/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6881 - precision: 0.6439 - recall: 0.7354 - val_loss: 2.6854 - val_precision: 0.6272 - val_recall: 0.7327\n",
      "Epoch 1263/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6844 - precision: 0.6442 - recall: 0.7339 - val_loss: 2.6817 - val_precision: 0.6277 - val_recall: 0.7327\n",
      "Epoch 1264/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6807 - precision: 0.6439 - recall: 0.7340 - val_loss: 2.6780 - val_precision: 0.6272 - val_recall: 0.7331\n",
      "Epoch 1265/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6770 - precision: 0.6441 - recall: 0.7344 - val_loss: 2.6743 - val_precision: 0.6276 - val_recall: 0.7331\n",
      "Epoch 1266/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6734 - precision: 0.6440 - recall: 0.7339 - val_loss: 2.6707 - val_precision: 0.6279 - val_recall: 0.7327\n",
      "Epoch 1267/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.6697 - precision: 0.6442 - recall: 0.7343 - val_loss: 2.6670 - val_precision: 0.6278 - val_recall: 0.7331\n",
      "Epoch 1268/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.6660 - precision: 0.6441 - recall: 0.7335 - val_loss: 2.6633 - val_precision: 0.6280 - val_recall: 0.7323\n",
      "Epoch 1269/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.6623 - precision: 0.6440 - recall: 0.7336 - val_loss: 2.6596 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1270/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.6586 - precision: 0.6440 - recall: 0.7338 - val_loss: 2.6559 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1271/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6550 - precision: 0.6441 - recall: 0.7341 - val_loss: 2.6523 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1272/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6513 - precision: 0.6441 - recall: 0.7339 - val_loss: 2.6486 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1273/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6476 - precision: 0.6442 - recall: 0.7336 - val_loss: 2.6450 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1274/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6440 - precision: 0.6442 - recall: 0.7336 - val_loss: 2.6413 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1275/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6403 - precision: 0.6443 - recall: 0.7336 - val_loss: 2.6377 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1276/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6367 - precision: 0.6442 - recall: 0.7344 - val_loss: 2.6340 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1277/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.6330 - precision: 0.6441 - recall: 0.7335 - val_loss: 2.6304 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1278/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6294 - precision: 0.6442 - recall: 0.7334 - val_loss: 2.6267 - val_precision: 0.6280 - val_recall: 0.7323\n",
      "Epoch 1279/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6258 - precision: 0.6442 - recall: 0.7349 - val_loss: 2.6231 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1280/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6221 - precision: 0.6442 - recall: 0.7340 - val_loss: 2.6195 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1281/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6185 - precision: 0.6442 - recall: 0.7340 - val_loss: 2.6158 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1282/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6149 - precision: 0.6442 - recall: 0.7343 - val_loss: 2.6122 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1283/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6112 - precision: 0.6443 - recall: 0.7339 - val_loss: 2.6086 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1284/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6076 - precision: 0.6443 - recall: 0.7349 - val_loss: 2.6050 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1285/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.6040 - precision: 0.6440 - recall: 0.7339 - val_loss: 2.6014 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1286/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.6004 - precision: 0.6441 - recall: 0.7341 - val_loss: 2.5978 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1287/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5968 - precision: 0.6441 - recall: 0.7335 - val_loss: 2.5942 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1288/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5932 - precision: 0.6441 - recall: 0.7339 - val_loss: 2.5906 - val_precision: 0.6282 - val_recall: 0.7323\n",
      "Epoch 1289/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5896 - precision: 0.6441 - recall: 0.7341 - val_loss: 2.5870 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1290/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5860 - precision: 0.6442 - recall: 0.7345 - val_loss: 2.5834 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1291/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5824 - precision: 0.6441 - recall: 0.7339 - val_loss: 2.5798 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1292/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5789 - precision: 0.6442 - recall: 0.7343 - val_loss: 2.5762 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1293/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5753 - precision: 0.6441 - recall: 0.7340 - val_loss: 2.5727 - val_precision: 0.6282 - val_recall: 0.7323\n",
      "Epoch 1294/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5717 - precision: 0.6441 - recall: 0.7338 - val_loss: 2.5691 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1295/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5681 - precision: 0.6442 - recall: 0.7346 - val_loss: 2.5655 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1296/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5646 - precision: 0.6443 - recall: 0.7346 - val_loss: 2.5620 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1297/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5610 - precision: 0.6440 - recall: 0.7339 - val_loss: 2.5584 - val_precision: 0.6280 - val_recall: 0.7319\n",
      "Epoch 1298/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 2.5575 - precision: 0.6442 - recall: 0.7352 - val_loss: 2.5548 - val_precision: 0.6278 - val_recall: 0.7319\n",
      "Epoch 1299/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5539 - precision: 0.6442 - recall: 0.7349 - val_loss: 2.5513 - val_precision: 0.6278 - val_recall: 0.7319\n",
      "Epoch 1300/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5504 - precision: 0.6442 - recall: 0.7349 - val_loss: 2.5478 - val_precision: 0.6278 - val_recall: 0.7319\n",
      "Epoch 1301/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5468 - precision: 0.6443 - recall: 0.7349 - val_loss: 2.5442 - val_precision: 0.6277 - val_recall: 0.7315\n",
      "Epoch 1302/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.5433 - precision: 0.6442 - recall: 0.7345 - val_loss: 2.5407 - val_precision: 0.6278 - val_recall: 0.7311\n",
      "Epoch 1303/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5397 - precision: 0.6441 - recall: 0.7341 - val_loss: 2.5372 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1304/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5362 - precision: 0.6442 - recall: 0.7346 - val_loss: 2.5336 - val_precision: 0.6278 - val_recall: 0.7311\n",
      "Epoch 1305/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5327 - precision: 0.6443 - recall: 0.7350 - val_loss: 2.5301 - val_precision: 0.6278 - val_recall: 0.7311\n",
      "Epoch 1306/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.5292 - precision: 0.6444 - recall: 0.7352 - val_loss: 2.5266 - val_precision: 0.6281 - val_recall: 0.7307\n",
      "Epoch 1307/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5256 - precision: 0.6441 - recall: 0.7344 - val_loss: 2.5231 - val_precision: 0.6280 - val_recall: 0.7311\n",
      "Epoch 1308/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5221 - precision: 0.6442 - recall: 0.7345 - val_loss: 2.5196 - val_precision: 0.6281 - val_recall: 0.7307\n",
      "Epoch 1309/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5186 - precision: 0.6441 - recall: 0.7340 - val_loss: 2.5160 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1310/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5151 - precision: 0.6441 - recall: 0.7335 - val_loss: 2.5125 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1311/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.5116 - precision: 0.6442 - recall: 0.7344 - val_loss: 2.5090 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1312/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5081 - precision: 0.6442 - recall: 0.7345 - val_loss: 2.5055 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1313/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5046 - precision: 0.6442 - recall: 0.7350 - val_loss: 2.5020 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1314/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.5011 - precision: 0.6445 - recall: 0.7345 - val_loss: 2.4986 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1315/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4976 - precision: 0.6443 - recall: 0.7349 - val_loss: 2.4951 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1316/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.4942 - precision: 0.6443 - recall: 0.7350 - val_loss: 2.4916 - val_precision: 0.6281 - val_recall: 0.7307\n",
      "Epoch 1317/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4907 - precision: 0.6443 - recall: 0.7348 - val_loss: 2.4881 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1318/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4872 - precision: 0.6445 - recall: 0.7348 - val_loss: 2.4847 - val_precision: 0.6281 - val_recall: 0.7307\n",
      "Epoch 1319/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4837 - precision: 0.6445 - recall: 0.7348 - val_loss: 2.4812 - val_precision: 0.6283 - val_recall: 0.7307\n",
      "Epoch 1320/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4803 - precision: 0.6443 - recall: 0.7350 - val_loss: 2.4777 - val_precision: 0.6283 - val_recall: 0.7315\n",
      "Epoch 1321/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4768 - precision: 0.6445 - recall: 0.7353 - val_loss: 2.4743 - val_precision: 0.6283 - val_recall: 0.7315\n",
      "Epoch 1322/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4734 - precision: 0.6447 - recall: 0.7346 - val_loss: 2.4708 - val_precision: 0.6284 - val_recall: 0.7311\n",
      "Epoch 1323/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4699 - precision: 0.6446 - recall: 0.7346 - val_loss: 2.4674 - val_precision: 0.6286 - val_recall: 0.7311\n",
      "Epoch 1324/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4665 - precision: 0.6446 - recall: 0.7344 - val_loss: 2.4639 - val_precision: 0.6288 - val_recall: 0.7311\n",
      "Epoch 1325/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4630 - precision: 0.6447 - recall: 0.7343 - val_loss: 2.4605 - val_precision: 0.6291 - val_recall: 0.7319\n",
      "Epoch 1326/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4596 - precision: 0.6445 - recall: 0.7354 - val_loss: 2.4570 - val_precision: 0.6289 - val_recall: 0.7327\n",
      "Epoch 1327/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4562 - precision: 0.6447 - recall: 0.7348 - val_loss: 2.4536 - val_precision: 0.6291 - val_recall: 0.7319\n",
      "Epoch 1328/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.4527 - precision: 0.6447 - recall: 0.7352 - val_loss: 2.4502 - val_precision: 0.6290 - val_recall: 0.7323\n",
      "Epoch 1329/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4493 - precision: 0.6446 - recall: 0.7344 - val_loss: 2.4468 - val_precision: 0.6291 - val_recall: 0.7319\n",
      "Epoch 1330/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4459 - precision: 0.6445 - recall: 0.7350 - val_loss: 2.4433 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1331/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4425 - precision: 0.6449 - recall: 0.7349 - val_loss: 2.4399 - val_precision: 0.6290 - val_recall: 0.7315\n",
      "Epoch 1332/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.4390 - precision: 0.6447 - recall: 0.7346 - val_loss: 2.4365 - val_precision: 0.6290 - val_recall: 0.7315\n",
      "Epoch 1333/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.4356 - precision: 0.6447 - recall: 0.7348 - val_loss: 2.4331 - val_precision: 0.6290 - val_recall: 0.7315\n",
      "Epoch 1334/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4322 - precision: 0.6452 - recall: 0.7345 - val_loss: 2.4297 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1335/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4288 - precision: 0.6447 - recall: 0.7343 - val_loss: 2.4263 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1336/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4254 - precision: 0.6451 - recall: 0.7341 - val_loss: 2.4229 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1337/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.4220 - precision: 0.6448 - recall: 0.7349 - val_loss: 2.4195 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1338/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4187 - precision: 0.6448 - recall: 0.7348 - val_loss: 2.4161 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1339/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4153 - precision: 0.6449 - recall: 0.7344 - val_loss: 2.4128 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1340/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4119 - precision: 0.6451 - recall: 0.7345 - val_loss: 2.4094 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1341/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4085 - precision: 0.6450 - recall: 0.7345 - val_loss: 2.4060 - val_precision: 0.6292 - val_recall: 0.7315\n",
      "Epoch 1342/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4052 - precision: 0.6446 - recall: 0.7349 - val_loss: 2.4026 - val_precision: 0.6294 - val_recall: 0.7323\n",
      "Epoch 1343/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.4018 - precision: 0.6447 - recall: 0.7349 - val_loss: 2.3993 - val_precision: 0.6293 - val_recall: 0.7319\n",
      "Epoch 1344/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3984 - precision: 0.6448 - recall: 0.7349 - val_loss: 2.3959 - val_precision: 0.6294 - val_recall: 0.7323\n",
      "Epoch 1345/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3951 - precision: 0.6448 - recall: 0.7350 - val_loss: 2.3926 - val_precision: 0.6295 - val_recall: 0.7319\n",
      "Epoch 1346/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.3917 - precision: 0.6448 - recall: 0.7349 - val_loss: 2.3892 - val_precision: 0.6294 - val_recall: 0.7323\n",
      "Epoch 1347/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3884 - precision: 0.6448 - recall: 0.7349 - val_loss: 2.3859 - val_precision: 0.6297 - val_recall: 0.7319\n",
      "Epoch 1348/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 2.3850 - precision: 0.6449 - recall: 0.7352 - val_loss: 2.3825 - val_precision: 0.6296 - val_recall: 0.7323\n",
      "Epoch 1349/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3817 - precision: 0.6449 - recall: 0.7355 - val_loss: 2.3792 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1350/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.3783 - precision: 0.6448 - recall: 0.7339 - val_loss: 2.3759 - val_precision: 0.6297 - val_recall: 0.7319\n",
      "Epoch 1351/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3750 - precision: 0.6449 - recall: 0.7353 - val_loss: 2.3725 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1352/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3717 - precision: 0.6449 - recall: 0.7349 - val_loss: 2.3692 - val_precision: 0.6299 - val_recall: 0.7323\n",
      "Epoch 1353/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.3684 - precision: 0.6448 - recall: 0.7354 - val_loss: 2.3659 - val_precision: 0.6296 - val_recall: 0.7327\n",
      "Epoch 1354/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3650 - precision: 0.6449 - recall: 0.7352 - val_loss: 2.3626 - val_precision: 0.6294 - val_recall: 0.7323\n",
      "Epoch 1355/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3617 - precision: 0.6449 - recall: 0.7350 - val_loss: 2.3593 - val_precision: 0.6296 - val_recall: 0.7327\n",
      "Epoch 1356/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3584 - precision: 0.6449 - recall: 0.7349 - val_loss: 2.3559 - val_precision: 0.6294 - val_recall: 0.7323\n",
      "Epoch 1357/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3551 - precision: 0.6448 - recall: 0.7348 - val_loss: 2.3526 - val_precision: 0.6293 - val_recall: 0.7319\n",
      "Epoch 1358/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3518 - precision: 0.6447 - recall: 0.7352 - val_loss: 2.3493 - val_precision: 0.6293 - val_recall: 0.7327\n",
      "Epoch 1359/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3485 - precision: 0.6448 - recall: 0.7350 - val_loss: 2.3460 - val_precision: 0.6294 - val_recall: 0.7323\n",
      "Epoch 1360/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3452 - precision: 0.6447 - recall: 0.7352 - val_loss: 2.3427 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1361/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3419 - precision: 0.6449 - recall: 0.7350 - val_loss: 2.3395 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1362/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3386 - precision: 0.6446 - recall: 0.7354 - val_loss: 2.3362 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1363/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3354 - precision: 0.6444 - recall: 0.7352 - val_loss: 2.3329 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1364/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3321 - precision: 0.6445 - recall: 0.7352 - val_loss: 2.3296 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1365/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.3288 - precision: 0.6444 - recall: 0.7352 - val_loss: 2.3263 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1366/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3255 - precision: 0.6447 - recall: 0.7352 - val_loss: 2.3231 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1367/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.3223 - precision: 0.6448 - recall: 0.7345 - val_loss: 2.3198 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1368/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3190 - precision: 0.6447 - recall: 0.7352 - val_loss: 2.3166 - val_precision: 0.6292 - val_recall: 0.7323\n",
      "Epoch 1369/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3157 - precision: 0.6446 - recall: 0.7352 - val_loss: 2.3133 - val_precision: 0.6291 - val_recall: 0.7327\n",
      "Epoch 1370/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.3125 - precision: 0.6441 - recall: 0.7353 - val_loss: 2.3100 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1371/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3092 - precision: 0.6444 - recall: 0.7352 - val_loss: 2.3068 - val_precision: 0.6291 - val_recall: 0.7327\n",
      "Epoch 1372/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3060 - precision: 0.6443 - recall: 0.7350 - val_loss: 2.3036 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1373/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.3028 - precision: 0.6442 - recall: 0.7350 - val_loss: 2.3003 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1374/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2995 - precision: 0.6442 - recall: 0.7352 - val_loss: 2.2971 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1375/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2963 - precision: 0.6441 - recall: 0.7350 - val_loss: 2.2938 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1376/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2930 - precision: 0.6443 - recall: 0.7348 - val_loss: 2.2906 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1377/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2898 - precision: 0.6442 - recall: 0.7352 - val_loss: 2.2874 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1378/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2866 - precision: 0.6442 - recall: 0.7352 - val_loss: 2.2842 - val_precision: 0.6287 - val_recall: 0.7327\n",
      "Epoch 1379/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2834 - precision: 0.6442 - recall: 0.7349 - val_loss: 2.2810 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1380/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2802 - precision: 0.6442 - recall: 0.7348 - val_loss: 2.2777 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1381/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2770 - precision: 0.6441 - recall: 0.7352 - val_loss: 2.2745 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1382/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2737 - precision: 0.6441 - recall: 0.7348 - val_loss: 2.2713 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1383/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2705 - precision: 0.6441 - recall: 0.7345 - val_loss: 2.2681 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1384/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2674 - precision: 0.6441 - recall: 0.7338 - val_loss: 2.2649 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1385/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2642 - precision: 0.6442 - recall: 0.7343 - val_loss: 2.2617 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1386/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2610 - precision: 0.6441 - recall: 0.7348 - val_loss: 2.2586 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1387/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2578 - precision: 0.6440 - recall: 0.7349 - val_loss: 2.2554 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1388/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2546 - precision: 0.6441 - recall: 0.7353 - val_loss: 2.2522 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1389/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2514 - precision: 0.6441 - recall: 0.7349 - val_loss: 2.2490 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1390/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2483 - precision: 0.6441 - recall: 0.7346 - val_loss: 2.2459 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1391/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2451 - precision: 0.6441 - recall: 0.7349 - val_loss: 2.2427 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1392/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2419 - precision: 0.6440 - recall: 0.7345 - val_loss: 2.2395 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1393/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2388 - precision: 0.6441 - recall: 0.7349 - val_loss: 2.2364 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1394/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2356 - precision: 0.6440 - recall: 0.7350 - val_loss: 2.2332 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1395/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2325 - precision: 0.6441 - recall: 0.7358 - val_loss: 2.2301 - val_precision: 0.6288 - val_recall: 0.7335\n",
      "Epoch 1396/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2293 - precision: 0.6441 - recall: 0.7350 - val_loss: 2.2269 - val_precision: 0.6284 - val_recall: 0.7323\n",
      "Epoch 1397/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2262 - precision: 0.6442 - recall: 0.7354 - val_loss: 2.2238 - val_precision: 0.6284 - val_recall: 0.7323\n",
      "Epoch 1398/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2230 - precision: 0.6442 - recall: 0.7352 - val_loss: 2.2206 - val_precision: 0.6283 - val_recall: 0.7319\n",
      "Epoch 1399/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2199 - precision: 0.6441 - recall: 0.7355 - val_loss: 2.2175 - val_precision: 0.6285 - val_recall: 0.7327\n",
      "Epoch 1400/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2168 - precision: 0.6442 - recall: 0.7352 - val_loss: 2.2144 - val_precision: 0.6283 - val_recall: 0.7319\n",
      "Epoch 1401/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2136 - precision: 0.6440 - recall: 0.7350 - val_loss: 2.2113 - val_precision: 0.6283 - val_recall: 0.7319\n",
      "Epoch 1402/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2105 - precision: 0.6441 - recall: 0.7353 - val_loss: 2.2081 - val_precision: 0.6284 - val_recall: 0.7323\n",
      "Epoch 1403/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.2074 - precision: 0.6441 - recall: 0.7355 - val_loss: 2.2050 - val_precision: 0.6284 - val_recall: 0.7323\n",
      "Epoch 1404/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2043 - precision: 0.6440 - recall: 0.7352 - val_loss: 2.2019 - val_precision: 0.6286 - val_recall: 0.7323\n",
      "Epoch 1405/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.2012 - precision: 0.6441 - recall: 0.7361 - val_loss: 2.1988 - val_precision: 0.6286 - val_recall: 0.7331\n",
      "Epoch 1406/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1981 - precision: 0.6445 - recall: 0.7353 - val_loss: 2.1957 - val_precision: 0.6285 - val_recall: 0.7319\n",
      "Epoch 1407/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 2.1950 - precision: 0.6441 - recall: 0.7358 - val_loss: 2.1926 - val_precision: 0.6284 - val_recall: 0.7331\n",
      "Epoch 1408/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1919 - precision: 0.6441 - recall: 0.7361 - val_loss: 2.1895 - val_precision: 0.6284 - val_recall: 0.7323\n",
      "Epoch 1409/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1888 - precision: 0.6441 - recall: 0.7361 - val_loss: 2.1864 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1410/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1857 - precision: 0.6443 - recall: 0.7362 - val_loss: 2.1833 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1411/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1826 - precision: 0.6445 - recall: 0.7359 - val_loss: 2.1803 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1412/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1795 - precision: 0.6444 - recall: 0.7361 - val_loss: 2.1772 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1413/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1765 - precision: 0.6446 - recall: 0.7361 - val_loss: 2.1741 - val_precision: 0.6282 - val_recall: 0.7323\n",
      "Epoch 1414/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1734 - precision: 0.6444 - recall: 0.7362 - val_loss: 2.1710 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1415/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1703 - precision: 0.6445 - recall: 0.7362 - val_loss: 2.1680 - val_precision: 0.6282 - val_recall: 0.7323\n",
      "Epoch 1416/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1673 - precision: 0.6445 - recall: 0.7366 - val_loss: 2.1649 - val_precision: 0.6284 - val_recall: 0.7331\n",
      "Epoch 1417/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1642 - precision: 0.6446 - recall: 0.7367 - val_loss: 2.1619 - val_precision: 0.6284 - val_recall: 0.7331\n",
      "Epoch 1418/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1612 - precision: 0.6447 - recall: 0.7362 - val_loss: 2.1588 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1419/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1581 - precision: 0.6445 - recall: 0.7366 - val_loss: 2.1558 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1420/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1551 - precision: 0.6444 - recall: 0.7363 - val_loss: 2.1527 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1421/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1520 - precision: 0.6446 - recall: 0.7362 - val_loss: 2.1497 - val_precision: 0.6282 - val_recall: 0.7323\n",
      "Epoch 1422/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1490 - precision: 0.6447 - recall: 0.7363 - val_loss: 2.1467 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1423/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1460 - precision: 0.6444 - recall: 0.7368 - val_loss: 2.1436 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1424/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1429 - precision: 0.6444 - recall: 0.7369 - val_loss: 2.1406 - val_precision: 0.6284 - val_recall: 0.7331\n",
      "Epoch 1425/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1399 - precision: 0.6444 - recall: 0.7371 - val_loss: 2.1376 - val_precision: 0.6283 - val_recall: 0.7327\n",
      "Epoch 1426/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1369 - precision: 0.6445 - recall: 0.7368 - val_loss: 2.1346 - val_precision: 0.6282 - val_recall: 0.7331\n",
      "Epoch 1427/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1339 - precision: 0.6445 - recall: 0.7366 - val_loss: 2.1316 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1428/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1309 - precision: 0.6443 - recall: 0.7373 - val_loss: 2.1286 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1429/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1279 - precision: 0.6446 - recall: 0.7369 - val_loss: 2.1256 - val_precision: 0.6281 - val_recall: 0.7327\n",
      "Epoch 1430/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1249 - precision: 0.6446 - recall: 0.7369 - val_loss: 2.1225 - val_precision: 0.6282 - val_recall: 0.7331\n",
      "Epoch 1431/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1219 - precision: 0.6441 - recall: 0.7373 - val_loss: 2.1195 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1432/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1189 - precision: 0.6440 - recall: 0.7373 - val_loss: 2.1166 - val_precision: 0.6279 - val_recall: 0.7327\n",
      "Epoch 1433/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1159 - precision: 0.6444 - recall: 0.7369 - val_loss: 2.1136 - val_precision: 0.6278 - val_recall: 0.7323\n",
      "Epoch 1434/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1129 - precision: 0.6441 - recall: 0.7371 - val_loss: 2.1106 - val_precision: 0.6281 - val_recall: 0.7335\n",
      "Epoch 1435/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 2.1099 - precision: 0.6441 - recall: 0.7373 - val_loss: 2.1076 - val_precision: 0.6281 - val_recall: 0.7335\n",
      "Epoch 1436/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.1070 - precision: 0.6442 - recall: 0.7373 - val_loss: 2.1046 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1437/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1040 - precision: 0.6443 - recall: 0.7373 - val_loss: 2.1017 - val_precision: 0.6280 - val_recall: 0.7331\n",
      "Epoch 1438/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.1010 - precision: 0.6440 - recall: 0.7376 - val_loss: 2.0987 - val_precision: 0.6280 - val_recall: 0.7339\n",
      "Epoch 1439/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0981 - precision: 0.6443 - recall: 0.7376 - val_loss: 2.0957 - val_precision: 0.6282 - val_recall: 0.7331\n",
      "Epoch 1440/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0951 - precision: 0.6442 - recall: 0.7372 - val_loss: 2.0928 - val_precision: 0.6281 - val_recall: 0.7335\n",
      "Epoch 1441/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0921 - precision: 0.6440 - recall: 0.7376 - val_loss: 2.0898 - val_precision: 0.6281 - val_recall: 0.7335\n",
      "Epoch 1442/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0892 - precision: 0.6442 - recall: 0.7377 - val_loss: 2.0869 - val_precision: 0.6281 - val_recall: 0.7335\n",
      "Epoch 1443/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0862 - precision: 0.6443 - recall: 0.7373 - val_loss: 2.0839 - val_precision: 0.6281 - val_recall: 0.7335\n",
      "Epoch 1444/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0833 - precision: 0.6442 - recall: 0.7377 - val_loss: 2.0810 - val_precision: 0.6280 - val_recall: 0.7339\n",
      "Epoch 1445/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0804 - precision: 0.6442 - recall: 0.7382 - val_loss: 2.0781 - val_precision: 0.6280 - val_recall: 0.7339\n",
      "Epoch 1446/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0774 - precision: 0.6443 - recall: 0.7382 - val_loss: 2.0751 - val_precision: 0.6282 - val_recall: 0.7342\n",
      "Epoch 1447/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0745 - precision: 0.6442 - recall: 0.7382 - val_loss: 2.0722 - val_precision: 0.6280 - val_recall: 0.7342\n",
      "Epoch 1448/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0716 - precision: 0.6442 - recall: 0.7382 - val_loss: 2.0693 - val_precision: 0.6280 - val_recall: 0.7342\n",
      "Epoch 1449/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0686 - precision: 0.6442 - recall: 0.7380 - val_loss: 2.0664 - val_precision: 0.6282 - val_recall: 0.7342\n",
      "Epoch 1450/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0657 - precision: 0.6437 - recall: 0.7383 - val_loss: 2.0634 - val_precision: 0.6279 - val_recall: 0.7346\n",
      "Epoch 1451/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0628 - precision: 0.6441 - recall: 0.7383 - val_loss: 2.0605 - val_precision: 0.6281 - val_recall: 0.7346\n",
      "Epoch 1452/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0599 - precision: 0.6441 - recall: 0.7383 - val_loss: 2.0576 - val_precision: 0.6281 - val_recall: 0.7346\n",
      "Epoch 1453/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0570 - precision: 0.6440 - recall: 0.7381 - val_loss: 2.0547 - val_precision: 0.6281 - val_recall: 0.7346\n",
      "Epoch 1454/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0541 - precision: 0.6439 - recall: 0.7383 - val_loss: 2.0518 - val_precision: 0.6281 - val_recall: 0.7346\n",
      "Epoch 1455/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0512 - precision: 0.6440 - recall: 0.7381 - val_loss: 2.0489 - val_precision: 0.6280 - val_recall: 0.7342\n",
      "Epoch 1456/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0483 - precision: 0.6441 - recall: 0.7381 - val_loss: 2.0460 - val_precision: 0.6280 - val_recall: 0.7342\n",
      "Epoch 1457/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0454 - precision: 0.6438 - recall: 0.7383 - val_loss: 2.0431 - val_precision: 0.6282 - val_recall: 0.7350\n",
      "Epoch 1458/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0425 - precision: 0.6441 - recall: 0.7382 - val_loss: 2.0402 - val_precision: 0.6280 - val_recall: 0.7350\n",
      "Epoch 1459/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0396 - precision: 0.6437 - recall: 0.7383 - val_loss: 2.0374 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1460/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0368 - precision: 0.6437 - recall: 0.7383 - val_loss: 2.0345 - val_precision: 0.6280 - val_recall: 0.7350\n",
      "Epoch 1461/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 2.0339 - precision: 0.6437 - recall: 0.7382 - val_loss: 2.0316 - val_precision: 0.6278 - val_recall: 0.7350\n",
      "Epoch 1462/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0310 - precision: 0.6435 - recall: 0.7385 - val_loss: 2.0287 - val_precision: 0.6278 - val_recall: 0.7350\n",
      "Epoch 1463/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0281 - precision: 0.6437 - recall: 0.7383 - val_loss: 2.0259 - val_precision: 0.6278 - val_recall: 0.7350\n",
      "Epoch 1464/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0253 - precision: 0.6435 - recall: 0.7386 - val_loss: 2.0230 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1465/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0224 - precision: 0.6436 - recall: 0.7386 - val_loss: 2.0201 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1466/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0196 - precision: 0.6435 - recall: 0.7382 - val_loss: 2.0173 - val_precision: 0.6277 - val_recall: 0.7346\n",
      "Epoch 1467/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0167 - precision: 0.6435 - recall: 0.7381 - val_loss: 2.0144 - val_precision: 0.6278 - val_recall: 0.7350\n",
      "Epoch 1468/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0139 - precision: 0.6435 - recall: 0.7385 - val_loss: 2.0116 - val_precision: 0.6277 - val_recall: 0.7346\n",
      "Epoch 1469/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0110 - precision: 0.6435 - recall: 0.7385 - val_loss: 2.0088 - val_precision: 0.6279 - val_recall: 0.7346\n",
      "Epoch 1470/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0082 - precision: 0.6435 - recall: 0.7386 - val_loss: 2.0059 - val_precision: 0.6281 - val_recall: 0.7354\n",
      "Epoch 1471/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0053 - precision: 0.6435 - recall: 0.7382 - val_loss: 2.0031 - val_precision: 0.6277 - val_recall: 0.7342\n",
      "Epoch 1472/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 2.0025 - precision: 0.6434 - recall: 0.7381 - val_loss: 2.0002 - val_precision: 0.6277 - val_recall: 0.7342\n",
      "Epoch 1473/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9997 - precision: 0.6435 - recall: 0.7389 - val_loss: 1.9974 - val_precision: 0.6278 - val_recall: 0.7358\n",
      "Epoch 1474/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9969 - precision: 0.6435 - recall: 0.7387 - val_loss: 1.9946 - val_precision: 0.6277 - val_recall: 0.7342\n",
      "Epoch 1475/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9940 - precision: 0.6434 - recall: 0.7392 - val_loss: 1.9918 - val_precision: 0.6278 - val_recall: 0.7350\n",
      "Epoch 1476/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9912 - precision: 0.6435 - recall: 0.7387 - val_loss: 1.9890 - val_precision: 0.6277 - val_recall: 0.7346\n",
      "Epoch 1477/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9884 - precision: 0.6435 - recall: 0.7391 - val_loss: 1.9861 - val_precision: 0.6278 - val_recall: 0.7350\n",
      "Epoch 1478/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9856 - precision: 0.6434 - recall: 0.7395 - val_loss: 1.9833 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1479/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9828 - precision: 0.6435 - recall: 0.7396 - val_loss: 1.9805 - val_precision: 0.6277 - val_recall: 0.7354\n",
      "Epoch 1480/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9800 - precision: 0.6434 - recall: 0.7387 - val_loss: 1.9777 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1481/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.9772 - precision: 0.6436 - recall: 0.7401 - val_loss: 1.9749 - val_precision: 0.6275 - val_recall: 0.7354\n",
      "Epoch 1482/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9744 - precision: 0.6435 - recall: 0.7399 - val_loss: 1.9722 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1483/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9716 - precision: 0.6436 - recall: 0.7395 - val_loss: 1.9694 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1484/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9688 - precision: 0.6435 - recall: 0.7391 - val_loss: 1.9666 - val_precision: 0.6276 - val_recall: 0.7350\n",
      "Epoch 1485/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9661 - precision: 0.6437 - recall: 0.7403 - val_loss: 1.9638 - val_precision: 0.6275 - val_recall: 0.7354\n",
      "Epoch 1486/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9633 - precision: 0.6435 - recall: 0.7399 - val_loss: 1.9610 - val_precision: 0.6274 - val_recall: 0.7350\n",
      "Epoch 1487/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9605 - precision: 0.6436 - recall: 0.7401 - val_loss: 1.9583 - val_precision: 0.6276 - val_recall: 0.7358\n",
      "Epoch 1488/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9577 - precision: 0.6436 - recall: 0.7399 - val_loss: 1.9555 - val_precision: 0.6274 - val_recall: 0.7350\n",
      "Epoch 1489/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9550 - precision: 0.6436 - recall: 0.7401 - val_loss: 1.9527 - val_precision: 0.6274 - val_recall: 0.7350\n",
      "Epoch 1490/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9522 - precision: 0.6436 - recall: 0.7401 - val_loss: 1.9500 - val_precision: 0.6274 - val_recall: 0.7350\n",
      "Epoch 1491/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9495 - precision: 0.6437 - recall: 0.7406 - val_loss: 1.9472 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1492/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9467 - precision: 0.6437 - recall: 0.7409 - val_loss: 1.9445 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1493/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9440 - precision: 0.6435 - recall: 0.7403 - val_loss: 1.9417 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1494/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9412 - precision: 0.6436 - recall: 0.7400 - val_loss: 1.9390 - val_precision: 0.6272 - val_recall: 0.7350\n",
      "Epoch 1495/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9385 - precision: 0.6436 - recall: 0.7408 - val_loss: 1.9363 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1496/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9358 - precision: 0.6436 - recall: 0.7406 - val_loss: 1.9335 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1497/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9330 - precision: 0.6436 - recall: 0.7406 - val_loss: 1.9308 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1498/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9303 - precision: 0.6435 - recall: 0.7401 - val_loss: 1.9281 - val_precision: 0.6272 - val_recall: 0.7350\n",
      "Epoch 1499/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9276 - precision: 0.6436 - recall: 0.7405 - val_loss: 1.9254 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1500/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9249 - precision: 0.6438 - recall: 0.7411 - val_loss: 1.9226 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1501/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9221 - precision: 0.6436 - recall: 0.7406 - val_loss: 1.9199 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1502/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9194 - precision: 0.6437 - recall: 0.7409 - val_loss: 1.9172 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1503/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9167 - precision: 0.6438 - recall: 0.7415 - val_loss: 1.9145 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1504/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9140 - precision: 0.6438 - recall: 0.7415 - val_loss: 1.9118 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1505/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9113 - precision: 0.6438 - recall: 0.7415 - val_loss: 1.9091 - val_precision: 0.6273 - val_recall: 0.7354\n",
      "Epoch 1506/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9086 - precision: 0.6437 - recall: 0.7418 - val_loss: 1.9064 - val_precision: 0.6271 - val_recall: 0.7354\n",
      "Epoch 1507/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.9059 - precision: 0.6435 - recall: 0.7414 - val_loss: 1.9037 - val_precision: 0.6272 - val_recall: 0.7358\n",
      "Epoch 1508/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9033 - precision: 0.6436 - recall: 0.7415 - val_loss: 1.9011 - val_precision: 0.6272 - val_recall: 0.7358\n",
      "Epoch 1509/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.9006 - precision: 0.6436 - recall: 0.7415 - val_loss: 1.8984 - val_precision: 0.6272 - val_recall: 0.7358\n",
      "Epoch 1510/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.8979 - precision: 0.6436 - recall: 0.7414 - val_loss: 1.8957 - val_precision: 0.6272 - val_recall: 0.7358\n",
      "Epoch 1511/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8952 - precision: 0.6436 - recall: 0.7413 - val_loss: 1.8930 - val_precision: 0.6274 - val_recall: 0.7358\n",
      "Epoch 1512/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8926 - precision: 0.6436 - recall: 0.7420 - val_loss: 1.8903 - val_precision: 0.6274 - val_recall: 0.7366\n",
      "Epoch 1513/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8899 - precision: 0.6435 - recall: 0.7414 - val_loss: 1.8877 - val_precision: 0.6273 - val_recall: 0.7362\n",
      "Epoch 1514/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8872 - precision: 0.6436 - recall: 0.7415 - val_loss: 1.8850 - val_precision: 0.6275 - val_recall: 0.7362\n",
      "Epoch 1515/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8846 - precision: 0.6435 - recall: 0.7414 - val_loss: 1.8824 - val_precision: 0.6275 - val_recall: 0.7362\n",
      "Epoch 1516/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.8819 - precision: 0.6434 - recall: 0.7415 - val_loss: 1.8797 - val_precision: 0.6277 - val_recall: 0.7366\n",
      "Epoch 1517/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8793 - precision: 0.6434 - recall: 0.7418 - val_loss: 1.8771 - val_precision: 0.6277 - val_recall: 0.7366\n",
      "Epoch 1518/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8766 - precision: 0.6434 - recall: 0.7419 - val_loss: 1.8744 - val_precision: 0.6276 - val_recall: 0.7370\n",
      "Epoch 1519/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8740 - precision: 0.6434 - recall: 0.7423 - val_loss: 1.8718 - val_precision: 0.6275 - val_recall: 0.7374\n",
      "Epoch 1520/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8713 - precision: 0.6434 - recall: 0.7418 - val_loss: 1.8691 - val_precision: 0.6276 - val_recall: 0.7370\n",
      "Epoch 1521/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8687 - precision: 0.6434 - recall: 0.7415 - val_loss: 1.8665 - val_precision: 0.6276 - val_recall: 0.7370\n",
      "Epoch 1522/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8661 - precision: 0.6434 - recall: 0.7415 - val_loss: 1.8639 - val_precision: 0.6277 - val_recall: 0.7366\n",
      "Epoch 1523/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8634 - precision: 0.6434 - recall: 0.7423 - val_loss: 1.8613 - val_precision: 0.6276 - val_recall: 0.7370\n",
      "Epoch 1524/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8608 - precision: 0.6435 - recall: 0.7417 - val_loss: 1.8586 - val_precision: 0.6278 - val_recall: 0.7370\n",
      "Epoch 1525/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8582 - precision: 0.6434 - recall: 0.7417 - val_loss: 1.8560 - val_precision: 0.6278 - val_recall: 0.7370\n",
      "Epoch 1526/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8556 - precision: 0.6437 - recall: 0.7417 - val_loss: 1.8534 - val_precision: 0.6279 - val_recall: 0.7374\n",
      "Epoch 1527/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8530 - precision: 0.6432 - recall: 0.7420 - val_loss: 1.8508 - val_precision: 0.6281 - val_recall: 0.7381\n",
      "Epoch 1528/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8504 - precision: 0.6435 - recall: 0.7419 - val_loss: 1.8482 - val_precision: 0.6279 - val_recall: 0.7374\n",
      "Epoch 1529/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8478 - precision: 0.6432 - recall: 0.7419 - val_loss: 1.8456 - val_precision: 0.6281 - val_recall: 0.7381\n",
      "Epoch 1530/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8452 - precision: 0.6432 - recall: 0.7422 - val_loss: 1.8430 - val_precision: 0.6281 - val_recall: 0.7381\n",
      "Epoch 1531/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8426 - precision: 0.6434 - recall: 0.7418 - val_loss: 1.8404 - val_precision: 0.6279 - val_recall: 0.7374\n",
      "Epoch 1532/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8400 - precision: 0.6433 - recall: 0.7422 - val_loss: 1.8378 - val_precision: 0.6279 - val_recall: 0.7381\n",
      "Epoch 1533/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.8374 - precision: 0.6431 - recall: 0.7420 - val_loss: 1.8352 - val_precision: 0.6279 - val_recall: 0.7381\n",
      "Epoch 1534/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8348 - precision: 0.6432 - recall: 0.7424 - val_loss: 1.8326 - val_precision: 0.6279 - val_recall: 0.7381\n",
      "Epoch 1535/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8322 - precision: 0.6435 - recall: 0.7422 - val_loss: 1.8301 - val_precision: 0.6279 - val_recall: 0.7381\n",
      "Epoch 1536/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8297 - precision: 0.6433 - recall: 0.7423 - val_loss: 1.8275 - val_precision: 0.6281 - val_recall: 0.7385\n",
      "Epoch 1537/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.8271 - precision: 0.6431 - recall: 0.7424 - val_loss: 1.8249 - val_precision: 0.6283 - val_recall: 0.7393\n",
      "Epoch 1538/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8245 - precision: 0.6431 - recall: 0.7424 - val_loss: 1.8224 - val_precision: 0.6281 - val_recall: 0.7385\n",
      "Epoch 1539/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8220 - precision: 0.6431 - recall: 0.7424 - val_loss: 1.8198 - val_precision: 0.6281 - val_recall: 0.7385\n",
      "Epoch 1540/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8194 - precision: 0.6431 - recall: 0.7424 - val_loss: 1.8172 - val_precision: 0.6284 - val_recall: 0.7381\n",
      "Epoch 1541/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8168 - precision: 0.6430 - recall: 0.7422 - val_loss: 1.8147 - val_precision: 0.6284 - val_recall: 0.7381\n",
      "Epoch 1542/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8143 - precision: 0.6431 - recall: 0.7420 - val_loss: 1.8121 - val_precision: 0.6284 - val_recall: 0.7381\n",
      "Epoch 1543/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8117 - precision: 0.6432 - recall: 0.7420 - val_loss: 1.8096 - val_precision: 0.6284 - val_recall: 0.7381\n",
      "Epoch 1544/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8092 - precision: 0.6427 - recall: 0.7425 - val_loss: 1.8070 - val_precision: 0.6288 - val_recall: 0.7401\n",
      "Epoch 1545/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8067 - precision: 0.6429 - recall: 0.7423 - val_loss: 1.8045 - val_precision: 0.6286 - val_recall: 0.7389\n",
      "Epoch 1546/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8041 - precision: 0.6429 - recall: 0.7422 - val_loss: 1.8020 - val_precision: 0.6285 - val_recall: 0.7393\n",
      "Epoch 1547/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.8016 - precision: 0.6427 - recall: 0.7423 - val_loss: 1.7995 - val_precision: 0.6286 - val_recall: 0.7397\n",
      "Epoch 1548/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7991 - precision: 0.6427 - recall: 0.7427 - val_loss: 1.7969 - val_precision: 0.6285 - val_recall: 0.7393\n",
      "Epoch 1549/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7966 - precision: 0.6430 - recall: 0.7422 - val_loss: 1.7944 - val_precision: 0.6283 - val_recall: 0.7385\n",
      "Epoch 1550/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7940 - precision: 0.6428 - recall: 0.7423 - val_loss: 1.7919 - val_precision: 0.6284 - val_recall: 0.7389\n",
      "Epoch 1551/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7915 - precision: 0.6427 - recall: 0.7424 - val_loss: 1.7894 - val_precision: 0.6286 - val_recall: 0.7397\n",
      "Epoch 1552/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7890 - precision: 0.6428 - recall: 0.7424 - val_loss: 1.7869 - val_precision: 0.6283 - val_recall: 0.7385\n",
      "Epoch 1553/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7865 - precision: 0.6429 - recall: 0.7423 - val_loss: 1.7844 - val_precision: 0.6283 - val_recall: 0.7385\n",
      "Epoch 1554/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7840 - precision: 0.6429 - recall: 0.7425 - val_loss: 1.7819 - val_precision: 0.6285 - val_recall: 0.7393\n",
      "Epoch 1555/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7815 - precision: 0.6428 - recall: 0.7425 - val_loss: 1.7794 - val_precision: 0.6284 - val_recall: 0.7389\n",
      "Epoch 1556/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7790 - precision: 0.6427 - recall: 0.7427 - val_loss: 1.7769 - val_precision: 0.6281 - val_recall: 0.7393\n",
      "Epoch 1557/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7765 - precision: 0.6429 - recall: 0.7425 - val_loss: 1.7744 - val_precision: 0.6283 - val_recall: 0.7385\n",
      "Epoch 1558/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7740 - precision: 0.6427 - recall: 0.7427 - val_loss: 1.7719 - val_precision: 0.6281 - val_recall: 0.7393\n",
      "Epoch 1559/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7716 - precision: 0.6424 - recall: 0.7428 - val_loss: 1.7694 - val_precision: 0.6282 - val_recall: 0.7397\n",
      "Epoch 1560/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7691 - precision: 0.6425 - recall: 0.7427 - val_loss: 1.7669 - val_precision: 0.6281 - val_recall: 0.7393\n",
      "Epoch 1561/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7666 - precision: 0.6424 - recall: 0.7428 - val_loss: 1.7645 - val_precision: 0.6281 - val_recall: 0.7393\n",
      "Epoch 1562/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7641 - precision: 0.6422 - recall: 0.7432 - val_loss: 1.7620 - val_precision: 0.6283 - val_recall: 0.7401\n",
      "Epoch 1563/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7617 - precision: 0.6422 - recall: 0.7432 - val_loss: 1.7595 - val_precision: 0.6283 - val_recall: 0.7401\n",
      "Epoch 1564/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7592 - precision: 0.6423 - recall: 0.7429 - val_loss: 1.7571 - val_precision: 0.6282 - val_recall: 0.7397\n",
      "Epoch 1565/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7567 - precision: 0.6423 - recall: 0.7431 - val_loss: 1.7546 - val_precision: 0.6282 - val_recall: 0.7397\n",
      "Epoch 1566/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7543 - precision: 0.6423 - recall: 0.7428 - val_loss: 1.7522 - val_precision: 0.6281 - val_recall: 0.7393\n",
      "Epoch 1567/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7518 - precision: 0.6423 - recall: 0.7431 - val_loss: 1.7497 - val_precision: 0.6282 - val_recall: 0.7397\n",
      "Epoch 1568/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7494 - precision: 0.6423 - recall: 0.7431 - val_loss: 1.7473 - val_precision: 0.6282 - val_recall: 0.7397\n",
      "Epoch 1569/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7470 - precision: 0.6423 - recall: 0.7431 - val_loss: 1.7448 - val_precision: 0.6280 - val_recall: 0.7397\n",
      "Epoch 1570/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7445 - precision: 0.6422 - recall: 0.7434 - val_loss: 1.7424 - val_precision: 0.6279 - val_recall: 0.7401\n",
      "Epoch 1571/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7421 - precision: 0.6422 - recall: 0.7434 - val_loss: 1.7400 - val_precision: 0.6278 - val_recall: 0.7397\n",
      "Epoch 1572/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7397 - precision: 0.6426 - recall: 0.7429 - val_loss: 1.7375 - val_precision: 0.6281 - val_recall: 0.7385\n",
      "Epoch 1573/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7372 - precision: 0.6423 - recall: 0.7429 - val_loss: 1.7351 - val_precision: 0.6278 - val_recall: 0.7397\n",
      "Epoch 1574/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7348 - precision: 0.6422 - recall: 0.7436 - val_loss: 1.7327 - val_precision: 0.6278 - val_recall: 0.7397\n",
      "Epoch 1575/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7324 - precision: 0.6425 - recall: 0.7433 - val_loss: 1.7303 - val_precision: 0.6278 - val_recall: 0.7397\n",
      "Epoch 1576/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7300 - precision: 0.6421 - recall: 0.7436 - val_loss: 1.7279 - val_precision: 0.6278 - val_recall: 0.7397\n",
      "Epoch 1577/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7276 - precision: 0.6424 - recall: 0.7432 - val_loss: 1.7255 - val_precision: 0.6279 - val_recall: 0.7393\n",
      "Epoch 1578/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7252 - precision: 0.6424 - recall: 0.7432 - val_loss: 1.7231 - val_precision: 0.6279 - val_recall: 0.7393\n",
      "Epoch 1579/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7228 - precision: 0.6423 - recall: 0.7437 - val_loss: 1.7207 - val_precision: 0.6278 - val_recall: 0.7397\n",
      "Epoch 1580/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7204 - precision: 0.6426 - recall: 0.7433 - val_loss: 1.7183 - val_precision: 0.6279 - val_recall: 0.7393\n",
      "Epoch 1581/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7180 - precision: 0.6424 - recall: 0.7437 - val_loss: 1.7159 - val_precision: 0.6279 - val_recall: 0.7393\n",
      "Epoch 1582/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7156 - precision: 0.6424 - recall: 0.7439 - val_loss: 1.7135 - val_precision: 0.6276 - val_recall: 0.7397\n",
      "Epoch 1583/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7132 - precision: 0.6423 - recall: 0.7443 - val_loss: 1.7111 - val_precision: 0.6274 - val_recall: 0.7397\n",
      "Epoch 1584/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7108 - precision: 0.6423 - recall: 0.7437 - val_loss: 1.7087 - val_precision: 0.6274 - val_recall: 0.7397\n",
      "Epoch 1585/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7085 - precision: 0.6425 - recall: 0.7439 - val_loss: 1.7064 - val_precision: 0.6272 - val_recall: 0.7397\n",
      "Epoch 1586/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.7061 - precision: 0.6422 - recall: 0.7442 - val_loss: 1.7040 - val_precision: 0.6272 - val_recall: 0.7397\n",
      "Epoch 1587/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7037 - precision: 0.6424 - recall: 0.7442 - val_loss: 1.7016 - val_precision: 0.6272 - val_recall: 0.7397\n",
      "Epoch 1588/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.7014 - precision: 0.6423 - recall: 0.7442 - val_loss: 1.6993 - val_precision: 0.6272 - val_recall: 0.7397\n",
      "Epoch 1589/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6990 - precision: 0.6427 - recall: 0.7443 - val_loss: 1.6969 - val_precision: 0.6272 - val_recall: 0.7397\n",
      "Epoch 1590/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6966 - precision: 0.6424 - recall: 0.7450 - val_loss: 1.6945 - val_precision: 0.6273 - val_recall: 0.7401\n",
      "Epoch 1591/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6943 - precision: 0.6426 - recall: 0.7441 - val_loss: 1.6922 - val_precision: 0.6272 - val_recall: 0.7397\n",
      "Epoch 1592/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6920 - precision: 0.6423 - recall: 0.7447 - val_loss: 1.6899 - val_precision: 0.6273 - val_recall: 0.7401\n",
      "Epoch 1593/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6896 - precision: 0.6424 - recall: 0.7450 - val_loss: 1.6875 - val_precision: 0.6273 - val_recall: 0.7401\n",
      "Epoch 1594/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6873 - precision: 0.6424 - recall: 0.7447 - val_loss: 1.6852 - val_precision: 0.6273 - val_recall: 0.7401\n",
      "Epoch 1595/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6849 - precision: 0.6426 - recall: 0.7456 - val_loss: 1.6829 - val_precision: 0.6271 - val_recall: 0.7401\n",
      "Epoch 1596/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6826 - precision: 0.6424 - recall: 0.7450 - val_loss: 1.6805 - val_precision: 0.6273 - val_recall: 0.7401\n",
      "Epoch 1597/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6803 - precision: 0.6426 - recall: 0.7457 - val_loss: 1.6782 - val_precision: 0.6271 - val_recall: 0.7401\n",
      "Epoch 1598/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6780 - precision: 0.6426 - recall: 0.7456 - val_loss: 1.6759 - val_precision: 0.6270 - val_recall: 0.7397\n",
      "Epoch 1599/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6756 - precision: 0.6426 - recall: 0.7456 - val_loss: 1.6736 - val_precision: 0.6270 - val_recall: 0.7397\n",
      "Epoch 1600/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6733 - precision: 0.6426 - recall: 0.7455 - val_loss: 1.6713 - val_precision: 0.6270 - val_recall: 0.7397\n",
      "Epoch 1601/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6710 - precision: 0.6427 - recall: 0.7457 - val_loss: 1.6690 - val_precision: 0.6270 - val_recall: 0.7397\n",
      "Epoch 1602/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6687 - precision: 0.6426 - recall: 0.7460 - val_loss: 1.6666 - val_precision: 0.6269 - val_recall: 0.7401\n",
      "Epoch 1603/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6664 - precision: 0.6428 - recall: 0.7457 - val_loss: 1.6644 - val_precision: 0.6268 - val_recall: 0.7397\n",
      "Epoch 1604/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6641 - precision: 0.6427 - recall: 0.7460 - val_loss: 1.6621 - val_precision: 0.6269 - val_recall: 0.7401\n",
      "Epoch 1605/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6618 - precision: 0.6427 - recall: 0.7460 - val_loss: 1.6598 - val_precision: 0.6270 - val_recall: 0.7397\n",
      "Epoch 1606/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6596 - precision: 0.6426 - recall: 0.7461 - val_loss: 1.6575 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1607/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6573 - precision: 0.6427 - recall: 0.7464 - val_loss: 1.6552 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1608/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6550 - precision: 0.6426 - recall: 0.7461 - val_loss: 1.6529 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1609/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.6527 - precision: 0.6427 - recall: 0.7464 - val_loss: 1.6506 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1610/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6504 - precision: 0.6427 - recall: 0.7464 - val_loss: 1.6484 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1611/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6482 - precision: 0.6426 - recall: 0.7464 - val_loss: 1.6461 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1612/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6459 - precision: 0.6425 - recall: 0.7470 - val_loss: 1.6438 - val_precision: 0.6269 - val_recall: 0.7412\n",
      "Epoch 1613/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6436 - precision: 0.6426 - recall: 0.7468 - val_loss: 1.6416 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1614/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6414 - precision: 0.6427 - recall: 0.7468 - val_loss: 1.6393 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1615/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6391 - precision: 0.6427 - recall: 0.7466 - val_loss: 1.6371 - val_precision: 0.6270 - val_recall: 0.7405\n",
      "Epoch 1616/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6369 - precision: 0.6426 - recall: 0.7468 - val_loss: 1.6348 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1617/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6346 - precision: 0.6424 - recall: 0.7468 - val_loss: 1.6326 - val_precision: 0.6266 - val_recall: 0.7405\n",
      "Epoch 1618/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6324 - precision: 0.6426 - recall: 0.7470 - val_loss: 1.6303 - val_precision: 0.6267 - val_recall: 0.7409\n",
      "Epoch 1619/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6302 - precision: 0.6425 - recall: 0.7469 - val_loss: 1.6281 - val_precision: 0.6268 - val_recall: 0.7405\n",
      "Epoch 1620/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6279 - precision: 0.6425 - recall: 0.7469 - val_loss: 1.6259 - val_precision: 0.6269 - val_recall: 0.7409\n",
      "Epoch 1621/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6257 - precision: 0.6426 - recall: 0.7470 - val_loss: 1.6236 - val_precision: 0.6269 - val_recall: 0.7409\n",
      "Epoch 1622/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.6235 - precision: 0.6425 - recall: 0.7469 - val_loss: 1.6214 - val_precision: 0.6272 - val_recall: 0.7416\n",
      "Epoch 1623/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6213 - precision: 0.6425 - recall: 0.7468 - val_loss: 1.6192 - val_precision: 0.6270 - val_recall: 0.7405\n",
      "Epoch 1624/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6190 - precision: 0.6425 - recall: 0.7468 - val_loss: 1.6170 - val_precision: 0.6274 - val_recall: 0.7416\n",
      "Epoch 1625/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6168 - precision: 0.6424 - recall: 0.7473 - val_loss: 1.6148 - val_precision: 0.6273 - val_recall: 0.7420\n",
      "Epoch 1626/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.6146 - precision: 0.6425 - recall: 0.7469 - val_loss: 1.6126 - val_precision: 0.6274 - val_recall: 0.7416\n",
      "Epoch 1627/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6124 - precision: 0.6427 - recall: 0.7466 - val_loss: 1.6104 - val_precision: 0.6275 - val_recall: 0.7420\n",
      "Epoch 1628/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6102 - precision: 0.6425 - recall: 0.7468 - val_loss: 1.6082 - val_precision: 0.6275 - val_recall: 0.7420\n",
      "Epoch 1629/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6080 - precision: 0.6425 - recall: 0.7470 - val_loss: 1.6060 - val_precision: 0.6275 - val_recall: 0.7420\n",
      "Epoch 1630/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6058 - precision: 0.6425 - recall: 0.7471 - val_loss: 1.6038 - val_precision: 0.6275 - val_recall: 0.7420\n",
      "Epoch 1631/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.6036 - precision: 0.6426 - recall: 0.7468 - val_loss: 1.6016 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1632/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.6015 - precision: 0.6426 - recall: 0.7475 - val_loss: 1.5994 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1633/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5993 - precision: 0.6425 - recall: 0.7473 - val_loss: 1.5972 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1634/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5971 - precision: 0.6425 - recall: 0.7471 - val_loss: 1.5951 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1635/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5949 - precision: 0.6424 - recall: 0.7475 - val_loss: 1.5929 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1636/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5928 - precision: 0.6424 - recall: 0.7475 - val_loss: 1.5907 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1637/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5906 - precision: 0.6425 - recall: 0.7474 - val_loss: 1.5886 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1638/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5885 - precision: 0.6424 - recall: 0.7475 - val_loss: 1.5864 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1639/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5863 - precision: 0.6424 - recall: 0.7471 - val_loss: 1.5843 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1640/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5842 - precision: 0.6424 - recall: 0.7475 - val_loss: 1.5821 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1641/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5820 - precision: 0.6424 - recall: 0.7478 - val_loss: 1.5800 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 1642/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5799 - precision: 0.6424 - recall: 0.7475 - val_loss: 1.5778 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1643/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5777 - precision: 0.6425 - recall: 0.7478 - val_loss: 1.5757 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1644/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5756 - precision: 0.6424 - recall: 0.7475 - val_loss: 1.5736 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1645/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5735 - precision: 0.6425 - recall: 0.7478 - val_loss: 1.5714 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 1646/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5714 - precision: 0.6425 - recall: 0.7483 - val_loss: 1.5693 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 1647/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5692 - precision: 0.6425 - recall: 0.7480 - val_loss: 1.5672 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 1648/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5671 - precision: 0.6425 - recall: 0.7483 - val_loss: 1.5651 - val_precision: 0.6272 - val_recall: 0.7424\n",
      "Epoch 1649/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5650 - precision: 0.6427 - recall: 0.7485 - val_loss: 1.5630 - val_precision: 0.6272 - val_recall: 0.7424\n",
      "Epoch 1650/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5629 - precision: 0.6428 - recall: 0.7485 - val_loss: 1.5609 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 1651/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5608 - precision: 0.6425 - recall: 0.7476 - val_loss: 1.5588 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 1652/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5587 - precision: 0.6427 - recall: 0.7485 - val_loss: 1.5567 - val_precision: 0.6268 - val_recall: 0.7424\n",
      "Epoch 1653/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5566 - precision: 0.6427 - recall: 0.7485 - val_loss: 1.5546 - val_precision: 0.6268 - val_recall: 0.7424\n",
      "Epoch 1654/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5545 - precision: 0.6428 - recall: 0.7484 - val_loss: 1.5525 - val_precision: 0.6271 - val_recall: 0.7420\n",
      "Epoch 1655/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.5524 - precision: 0.6430 - recall: 0.7484 - val_loss: 1.5504 - val_precision: 0.6268 - val_recall: 0.7424\n",
      "Epoch 1656/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5504 - precision: 0.6430 - recall: 0.7489 - val_loss: 1.5483 - val_precision: 0.6268 - val_recall: 0.7424\n",
      "Epoch 1657/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5483 - precision: 0.6431 - recall: 0.7488 - val_loss: 1.5463 - val_precision: 0.6270 - val_recall: 0.7424\n",
      "Epoch 1658/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5462 - precision: 0.6430 - recall: 0.7492 - val_loss: 1.5442 - val_precision: 0.6268 - val_recall: 0.7424\n",
      "Epoch 1659/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5441 - precision: 0.6431 - recall: 0.7490 - val_loss: 1.5421 - val_precision: 0.6269 - val_recall: 0.7420\n",
      "Epoch 1660/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5421 - precision: 0.6432 - recall: 0.7493 - val_loss: 1.5400 - val_precision: 0.6269 - val_recall: 0.7420\n",
      "Epoch 1661/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5400 - precision: 0.6431 - recall: 0.7489 - val_loss: 1.5380 - val_precision: 0.6269 - val_recall: 0.7420\n",
      "Epoch 1662/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5379 - precision: 0.6432 - recall: 0.7493 - val_loss: 1.5359 - val_precision: 0.6270 - val_recall: 0.7424\n",
      "Epoch 1663/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5359 - precision: 0.6432 - recall: 0.7498 - val_loss: 1.5339 - val_precision: 0.6267 - val_recall: 0.7428\n",
      "Epoch 1664/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5338 - precision: 0.6432 - recall: 0.7496 - val_loss: 1.5318 - val_precision: 0.6268 - val_recall: 0.7424\n",
      "Epoch 1665/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5318 - precision: 0.6433 - recall: 0.7498 - val_loss: 1.5298 - val_precision: 0.6266 - val_recall: 0.7424\n",
      "Epoch 1666/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5298 - precision: 0.6432 - recall: 0.7493 - val_loss: 1.5277 - val_precision: 0.6267 - val_recall: 0.7420\n",
      "Epoch 1667/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5277 - precision: 0.6433 - recall: 0.7498 - val_loss: 1.5257 - val_precision: 0.6266 - val_recall: 0.7424\n",
      "Epoch 1668/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5257 - precision: 0.6433 - recall: 0.7499 - val_loss: 1.5237 - val_precision: 0.6266 - val_recall: 0.7424\n",
      "Epoch 1669/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5237 - precision: 0.6432 - recall: 0.7499 - val_loss: 1.5217 - val_precision: 0.6266 - val_recall: 0.7424\n",
      "Epoch 1670/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5216 - precision: 0.6431 - recall: 0.7501 - val_loss: 1.5196 - val_precision: 0.6265 - val_recall: 0.7428\n",
      "Epoch 1671/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5196 - precision: 0.6431 - recall: 0.7501 - val_loss: 1.5176 - val_precision: 0.6264 - val_recall: 0.7424\n",
      "Epoch 1672/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5176 - precision: 0.6431 - recall: 0.7501 - val_loss: 1.5156 - val_precision: 0.6263 - val_recall: 0.7428\n",
      "Epoch 1673/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5156 - precision: 0.6432 - recall: 0.7502 - val_loss: 1.5136 - val_precision: 0.6263 - val_recall: 0.7428\n",
      "Epoch 1674/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.5136 - precision: 0.6431 - recall: 0.7501 - val_loss: 1.5116 - val_precision: 0.6261 - val_recall: 0.7420\n",
      "Epoch 1675/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5116 - precision: 0.6431 - recall: 0.7501 - val_loss: 1.5096 - val_precision: 0.6260 - val_recall: 0.7424\n",
      "Epoch 1676/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5096 - precision: 0.6432 - recall: 0.7499 - val_loss: 1.5076 - val_precision: 0.6265 - val_recall: 0.7420\n",
      "Epoch 1677/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5076 - precision: 0.6431 - recall: 0.7504 - val_loss: 1.5056 - val_precision: 0.6262 - val_recall: 0.7432\n",
      "Epoch 1678/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5056 - precision: 0.6432 - recall: 0.7504 - val_loss: 1.5036 - val_precision: 0.6262 - val_recall: 0.7424\n",
      "Epoch 1679/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5036 - precision: 0.6430 - recall: 0.7507 - val_loss: 1.5016 - val_precision: 0.6263 - val_recall: 0.7428\n",
      "Epoch 1680/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.5016 - precision: 0.6431 - recall: 0.7501 - val_loss: 1.4996 - val_precision: 0.6261 - val_recall: 0.7420\n",
      "Epoch 1681/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4996 - precision: 0.6432 - recall: 0.7507 - val_loss: 1.4976 - val_precision: 0.6263 - val_recall: 0.7428\n",
      "Epoch 1682/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4976 - precision: 0.6429 - recall: 0.7504 - val_loss: 1.4956 - val_precision: 0.6263 - val_recall: 0.7428\n",
      "Epoch 1683/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4957 - precision: 0.6431 - recall: 0.7507 - val_loss: 1.4937 - val_precision: 0.6263 - val_recall: 0.7428\n",
      "Epoch 1684/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4937 - precision: 0.6432 - recall: 0.7503 - val_loss: 1.4917 - val_precision: 0.6263 - val_recall: 0.7428\n",
      "Epoch 1685/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4917 - precision: 0.6430 - recall: 0.7508 - val_loss: 1.4897 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1686/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4898 - precision: 0.6432 - recall: 0.7508 - val_loss: 1.4878 - val_precision: 0.6262 - val_recall: 0.7432\n",
      "Epoch 1687/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4878 - precision: 0.6430 - recall: 0.7512 - val_loss: 1.4858 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1688/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4859 - precision: 0.6430 - recall: 0.7511 - val_loss: 1.4839 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1689/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4839 - precision: 0.6428 - recall: 0.7511 - val_loss: 1.4819 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1690/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4820 - precision: 0.6431 - recall: 0.7507 - val_loss: 1.4800 - val_precision: 0.6260 - val_recall: 0.7432\n",
      "Epoch 1691/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4800 - precision: 0.6429 - recall: 0.7511 - val_loss: 1.4780 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1692/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4781 - precision: 0.6430 - recall: 0.7508 - val_loss: 1.4761 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1693/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.4762 - precision: 0.6430 - recall: 0.7510 - val_loss: 1.4742 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1694/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4742 - precision: 0.6429 - recall: 0.7510 - val_loss: 1.4722 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1695/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4723 - precision: 0.6429 - recall: 0.7512 - val_loss: 1.4703 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1696/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4704 - precision: 0.6428 - recall: 0.7508 - val_loss: 1.4684 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1697/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4685 - precision: 0.6428 - recall: 0.7508 - val_loss: 1.4665 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1698/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4666 - precision: 0.6428 - recall: 0.7511 - val_loss: 1.4646 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1699/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4647 - precision: 0.6428 - recall: 0.7508 - val_loss: 1.4627 - val_precision: 0.6262 - val_recall: 0.7432\n",
      "Epoch 1700/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4627 - precision: 0.6427 - recall: 0.7515 - val_loss: 1.4607 - val_precision: 0.6263 - val_recall: 0.7440\n",
      "Epoch 1701/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4608 - precision: 0.6426 - recall: 0.7511 - val_loss: 1.4588 - val_precision: 0.6265 - val_recall: 0.7440\n",
      "Epoch 1702/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4589 - precision: 0.6427 - recall: 0.7511 - val_loss: 1.4570 - val_precision: 0.6262 - val_recall: 0.7432\n",
      "Epoch 1703/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4570 - precision: 0.6427 - recall: 0.7512 - val_loss: 1.4551 - val_precision: 0.6265 - val_recall: 0.7440\n",
      "Epoch 1704/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4552 - precision: 0.6427 - recall: 0.7513 - val_loss: 1.4532 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1705/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4533 - precision: 0.6427 - recall: 0.7512 - val_loss: 1.4513 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1706/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4514 - precision: 0.6427 - recall: 0.7513 - val_loss: 1.4494 - val_precision: 0.6265 - val_recall: 0.7440\n",
      "Epoch 1707/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4495 - precision: 0.6427 - recall: 0.7512 - val_loss: 1.4475 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1708/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4476 - precision: 0.6427 - recall: 0.7513 - val_loss: 1.4456 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1709/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4458 - precision: 0.6428 - recall: 0.7516 - val_loss: 1.4438 - val_precision: 0.6264 - val_recall: 0.7436\n",
      "Epoch 1710/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4439 - precision: 0.6428 - recall: 0.7517 - val_loss: 1.4419 - val_precision: 0.6261 - val_recall: 0.7436\n",
      "Epoch 1711/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4420 - precision: 0.6429 - recall: 0.7520 - val_loss: 1.4400 - val_precision: 0.6259 - val_recall: 0.7436\n",
      "Epoch 1712/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4402 - precision: 0.6429 - recall: 0.7521 - val_loss: 1.4382 - val_precision: 0.6259 - val_recall: 0.7436\n",
      "Epoch 1713/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4383 - precision: 0.6429 - recall: 0.7520 - val_loss: 1.4363 - val_precision: 0.6259 - val_recall: 0.7436\n",
      "Epoch 1714/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4365 - precision: 0.6428 - recall: 0.7517 - val_loss: 1.4345 - val_precision: 0.6259 - val_recall: 0.7436\n",
      "Epoch 1715/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4346 - precision: 0.6429 - recall: 0.7521 - val_loss: 1.4326 - val_precision: 0.6259 - val_recall: 0.7440\n",
      "Epoch 1716/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4328 - precision: 0.6429 - recall: 0.7521 - val_loss: 1.4308 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1717/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4309 - precision: 0.6430 - recall: 0.7522 - val_loss: 1.4290 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1718/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4291 - precision: 0.6429 - recall: 0.7521 - val_loss: 1.4271 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1719/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4273 - precision: 0.6430 - recall: 0.7520 - val_loss: 1.4253 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1720/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4254 - precision: 0.6430 - recall: 0.7522 - val_loss: 1.4235 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1721/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4236 - precision: 0.6430 - recall: 0.7525 - val_loss: 1.4216 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1722/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4218 - precision: 0.6430 - recall: 0.7522 - val_loss: 1.4198 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1723/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4200 - precision: 0.6431 - recall: 0.7518 - val_loss: 1.4180 - val_precision: 0.6257 - val_recall: 0.7440\n",
      "Epoch 1724/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4182 - precision: 0.6429 - recall: 0.7524 - val_loss: 1.4162 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1725/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4164 - precision: 0.6429 - recall: 0.7526 - val_loss: 1.4144 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1726/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.4146 - precision: 0.6429 - recall: 0.7526 - val_loss: 1.4126 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1727/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4128 - precision: 0.6429 - recall: 0.7526 - val_loss: 1.4108 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1728/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4110 - precision: 0.6430 - recall: 0.7526 - val_loss: 1.4090 - val_precision: 0.6254 - val_recall: 0.7444\n",
      "Epoch 1729/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4092 - precision: 0.6430 - recall: 0.7525 - val_loss: 1.4072 - val_precision: 0.6254 - val_recall: 0.7444\n",
      "Epoch 1730/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4074 - precision: 0.6429 - recall: 0.7526 - val_loss: 1.4054 - val_precision: 0.6254 - val_recall: 0.7444\n",
      "Epoch 1731/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4056 - precision: 0.6430 - recall: 0.7529 - val_loss: 1.4036 - val_precision: 0.6254 - val_recall: 0.7444\n",
      "Epoch 1732/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4038 - precision: 0.6429 - recall: 0.7525 - val_loss: 1.4019 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1733/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4021 - precision: 0.6429 - recall: 0.7525 - val_loss: 1.4001 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1734/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.4003 - precision: 0.6429 - recall: 0.7525 - val_loss: 1.3983 - val_precision: 0.6256 - val_recall: 0.7444\n",
      "Epoch 1735/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3985 - precision: 0.6431 - recall: 0.7530 - val_loss: 1.3965 - val_precision: 0.6253 - val_recall: 0.7447\n",
      "Epoch 1736/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3968 - precision: 0.6430 - recall: 0.7529 - val_loss: 1.3948 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1737/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3950 - precision: 0.6430 - recall: 0.7531 - val_loss: 1.3930 - val_precision: 0.6248 - val_recall: 0.7451\n",
      "Epoch 1738/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3932 - precision: 0.6430 - recall: 0.7529 - val_loss: 1.3913 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1739/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3915 - precision: 0.6429 - recall: 0.7527 - val_loss: 1.3895 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1740/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3897 - precision: 0.6429 - recall: 0.7527 - val_loss: 1.3878 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1741/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3880 - precision: 0.6430 - recall: 0.7531 - val_loss: 1.3860 - val_precision: 0.6254 - val_recall: 0.7451\n",
      "Epoch 1742/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3863 - precision: 0.6428 - recall: 0.7529 - val_loss: 1.3843 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1743/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3845 - precision: 0.6428 - recall: 0.7530 - val_loss: 1.3826 - val_precision: 0.6256 - val_recall: 0.7451\n",
      "Epoch 1744/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3828 - precision: 0.6428 - recall: 0.7529 - val_loss: 1.3808 - val_precision: 0.6250 - val_recall: 0.7451\n",
      "Epoch 1745/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3811 - precision: 0.6430 - recall: 0.7535 - val_loss: 1.3791 - val_precision: 0.6250 - val_recall: 0.7451\n",
      "Epoch 1746/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3794 - precision: 0.6428 - recall: 0.7529 - val_loss: 1.3774 - val_precision: 0.6251 - val_recall: 0.7447\n",
      "Epoch 1747/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3776 - precision: 0.6429 - recall: 0.7530 - val_loss: 1.3757 - val_precision: 0.6254 - val_recall: 0.7463\n",
      "Epoch 1748/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3759 - precision: 0.6428 - recall: 0.7529 - val_loss: 1.3740 - val_precision: 0.6252 - val_recall: 0.7459\n",
      "Epoch 1749/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3742 - precision: 0.6429 - recall: 0.7532 - val_loss: 1.3723 - val_precision: 0.6254 - val_recall: 0.7463\n",
      "Epoch 1750/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3725 - precision: 0.6428 - recall: 0.7530 - val_loss: 1.3706 - val_precision: 0.6254 - val_recall: 0.7463\n",
      "Epoch 1751/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3708 - precision: 0.6429 - recall: 0.7536 - val_loss: 1.3689 - val_precision: 0.6254 - val_recall: 0.7463\n",
      "Epoch 1752/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3691 - precision: 0.6428 - recall: 0.7536 - val_loss: 1.3672 - val_precision: 0.6254 - val_recall: 0.7463\n",
      "Epoch 1753/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3674 - precision: 0.6427 - recall: 0.7535 - val_loss: 1.3655 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1754/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3657 - precision: 0.6428 - recall: 0.7534 - val_loss: 1.3638 - val_precision: 0.6252 - val_recall: 0.7459\n",
      "Epoch 1755/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3640 - precision: 0.6429 - recall: 0.7535 - val_loss: 1.3621 - val_precision: 0.6252 - val_recall: 0.7459\n",
      "Epoch 1756/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3624 - precision: 0.6428 - recall: 0.7539 - val_loss: 1.3604 - val_precision: 0.6250 - val_recall: 0.7459\n",
      "Epoch 1757/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3607 - precision: 0.6429 - recall: 0.7534 - val_loss: 1.3587 - val_precision: 0.6252 - val_recall: 0.7459\n",
      "Epoch 1758/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3590 - precision: 0.6428 - recall: 0.7536 - val_loss: 1.3571 - val_precision: 0.6250 - val_recall: 0.7459\n",
      "Epoch 1759/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3573 - precision: 0.6429 - recall: 0.7535 - val_loss: 1.3554 - val_precision: 0.6250 - val_recall: 0.7459\n",
      "Epoch 1760/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3557 - precision: 0.6428 - recall: 0.7534 - val_loss: 1.3537 - val_precision: 0.6252 - val_recall: 0.7459\n",
      "Epoch 1761/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3540 - precision: 0.6428 - recall: 0.7532 - val_loss: 1.3521 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1762/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3524 - precision: 0.6429 - recall: 0.7534 - val_loss: 1.3504 - val_precision: 0.6251 - val_recall: 0.7455\n",
      "Epoch 1763/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3507 - precision: 0.6428 - recall: 0.7534 - val_loss: 1.3488 - val_precision: 0.6254 - val_recall: 0.7463\n",
      "Epoch 1764/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3491 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.3471 - val_precision: 0.6250 - val_recall: 0.7463\n",
      "Epoch 1765/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3474 - precision: 0.6430 - recall: 0.7535 - val_loss: 1.3455 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1766/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3458 - precision: 0.6429 - recall: 0.7536 - val_loss: 1.3438 - val_precision: 0.6252 - val_recall: 0.7459\n",
      "Epoch 1767/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3441 - precision: 0.6427 - recall: 0.7536 - val_loss: 1.3422 - val_precision: 0.6251 - val_recall: 0.7467\n",
      "Epoch 1768/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3425 - precision: 0.6428 - recall: 0.7535 - val_loss: 1.3406 - val_precision: 0.6251 - val_recall: 0.7467\n",
      "Epoch 1769/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3409 - precision: 0.6426 - recall: 0.7538 - val_loss: 1.3389 - val_precision: 0.6251 - val_recall: 0.7467\n",
      "Epoch 1770/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3393 - precision: 0.6426 - recall: 0.7535 - val_loss: 1.3373 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1771/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3376 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.3357 - val_precision: 0.6251 - val_recall: 0.7467\n",
      "Epoch 1772/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3360 - precision: 0.6427 - recall: 0.7538 - val_loss: 1.3341 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1773/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3344 - precision: 0.6426 - recall: 0.7540 - val_loss: 1.3325 - val_precision: 0.6252 - val_recall: 0.7471\n",
      "Epoch 1774/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.3328 - precision: 0.6426 - recall: 0.7538 - val_loss: 1.3309 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1775/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3312 - precision: 0.6427 - recall: 0.7535 - val_loss: 1.3293 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1776/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3296 - precision: 0.6427 - recall: 0.7530 - val_loss: 1.3277 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1777/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.3280 - precision: 0.6427 - recall: 0.7540 - val_loss: 1.3261 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1778/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3264 - precision: 0.6426 - recall: 0.7538 - val_loss: 1.3245 - val_precision: 0.6252 - val_recall: 0.7463\n",
      "Epoch 1779/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 1.3248 - precision: 0.6425 - recall: 0.7538 - val_loss: 1.3229 - val_precision: 0.6250 - val_recall: 0.7463\n",
      "Epoch 1780/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3233 - precision: 0.6426 - recall: 0.7538 - val_loss: 1.3213 - val_precision: 0.6252 - val_recall: 0.7471\n",
      "Epoch 1781/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3217 - precision: 0.6425 - recall: 0.7536 - val_loss: 1.3197 - val_precision: 0.6252 - val_recall: 0.7471\n",
      "Epoch 1782/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3201 - precision: 0.6426 - recall: 0.7536 - val_loss: 1.3182 - val_precision: 0.6250 - val_recall: 0.7463\n",
      "Epoch 1783/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3185 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.3166 - val_precision: 0.6252 - val_recall: 0.7471\n",
      "Epoch 1784/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3170 - precision: 0.6426 - recall: 0.7538 - val_loss: 1.3150 - val_precision: 0.6253 - val_recall: 0.7475\n",
      "Epoch 1785/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3154 - precision: 0.6426 - recall: 0.7536 - val_loss: 1.3135 - val_precision: 0.6251 - val_recall: 0.7467\n",
      "Epoch 1786/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3138 - precision: 0.6426 - recall: 0.7536 - val_loss: 1.3119 - val_precision: 0.6253 - val_recall: 0.7467\n",
      "Epoch 1787/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3123 - precision: 0.6426 - recall: 0.7536 - val_loss: 1.3104 - val_precision: 0.6253 - val_recall: 0.7467\n",
      "Epoch 1788/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3107 - precision: 0.6425 - recall: 0.7538 - val_loss: 1.3088 - val_precision: 0.6254 - val_recall: 0.7479\n",
      "Epoch 1789/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3092 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.3073 - val_precision: 0.6253 - val_recall: 0.7475\n",
      "Epoch 1790/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3076 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.3057 - val_precision: 0.6253 - val_recall: 0.7475\n",
      "Epoch 1791/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3061 - precision: 0.6427 - recall: 0.7536 - val_loss: 1.3042 - val_precision: 0.6255 - val_recall: 0.7475\n",
      "Epoch 1792/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3046 - precision: 0.6425 - recall: 0.7539 - val_loss: 1.3026 - val_precision: 0.6254 - val_recall: 0.7479\n",
      "Epoch 1793/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3030 - precision: 0.6424 - recall: 0.7540 - val_loss: 1.3011 - val_precision: 0.6254 - val_recall: 0.7479\n",
      "Epoch 1794/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.3015 - precision: 0.6427 - recall: 0.7539 - val_loss: 1.2996 - val_precision: 0.6255 - val_recall: 0.7475\n",
      "Epoch 1795/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.3000 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.2981 - val_precision: 0.6255 - val_recall: 0.7475\n",
      "Epoch 1796/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2985 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.2966 - val_precision: 0.6253 - val_recall: 0.7475\n",
      "Epoch 1797/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2970 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.2951 - val_precision: 0.6254 - val_recall: 0.7479\n",
      "Epoch 1798/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2955 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.2935 - val_precision: 0.6257 - val_recall: 0.7479\n",
      "Epoch 1799/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2940 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.2920 - val_precision: 0.6254 - val_recall: 0.7479\n",
      "Epoch 1800/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2925 - precision: 0.6426 - recall: 0.7539 - val_loss: 1.2905 - val_precision: 0.6256 - val_recall: 0.7482\n",
      "Epoch 1801/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2910 - precision: 0.6427 - recall: 0.7540 - val_loss: 1.2890 - val_precision: 0.6256 - val_recall: 0.7482\n",
      "Epoch 1802/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2895 - precision: 0.6427 - recall: 0.7539 - val_loss: 1.2875 - val_precision: 0.6256 - val_recall: 0.7490\n",
      "Epoch 1803/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2880 - precision: 0.6427 - recall: 0.7543 - val_loss: 1.2861 - val_precision: 0.6255 - val_recall: 0.7486\n",
      "Epoch 1804/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2865 - precision: 0.6426 - recall: 0.7541 - val_loss: 1.2846 - val_precision: 0.6254 - val_recall: 0.7490\n",
      "Epoch 1805/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2850 - precision: 0.6425 - recall: 0.7543 - val_loss: 1.2831 - val_precision: 0.6253 - val_recall: 0.7486\n",
      "Epoch 1806/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2835 - precision: 0.6425 - recall: 0.7543 - val_loss: 1.2816 - val_precision: 0.6254 - val_recall: 0.7490\n",
      "Epoch 1807/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2821 - precision: 0.6425 - recall: 0.7543 - val_loss: 1.2802 - val_precision: 0.6253 - val_recall: 0.7486\n",
      "Epoch 1808/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2806 - precision: 0.6425 - recall: 0.7541 - val_loss: 1.2787 - val_precision: 0.6253 - val_recall: 0.7486\n",
      "Epoch 1809/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2791 - precision: 0.6424 - recall: 0.7543 - val_loss: 1.2772 - val_precision: 0.6253 - val_recall: 0.7486\n",
      "Epoch 1810/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2777 - precision: 0.6423 - recall: 0.7543 - val_loss: 1.2758 - val_precision: 0.6254 - val_recall: 0.7490\n",
      "Epoch 1811/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2762 - precision: 0.6424 - recall: 0.7544 - val_loss: 1.2743 - val_precision: 0.6252 - val_recall: 0.7490\n",
      "Epoch 1812/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2748 - precision: 0.6424 - recall: 0.7541 - val_loss: 1.2729 - val_precision: 0.6251 - val_recall: 0.7486\n",
      "Epoch 1813/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2733 - precision: 0.6425 - recall: 0.7546 - val_loss: 1.2714 - val_precision: 0.6249 - val_recall: 0.7494\n",
      "Epoch 1814/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2719 - precision: 0.6423 - recall: 0.7545 - val_loss: 1.2700 - val_precision: 0.6249 - val_recall: 0.7494\n",
      "Epoch 1815/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2704 - precision: 0.6424 - recall: 0.7546 - val_loss: 1.2685 - val_precision: 0.6249 - val_recall: 0.7494\n",
      "Epoch 1816/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2690 - precision: 0.6424 - recall: 0.7549 - val_loss: 1.2671 - val_precision: 0.6249 - val_recall: 0.7494\n",
      "Epoch 1817/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2676 - precision: 0.6424 - recall: 0.7549 - val_loss: 1.2656 - val_precision: 0.6249 - val_recall: 0.7494\n",
      "Epoch 1818/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2661 - precision: 0.6425 - recall: 0.7552 - val_loss: 1.2642 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1819/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2647 - precision: 0.6424 - recall: 0.7550 - val_loss: 1.2628 - val_precision: 0.6250 - val_recall: 0.7498\n",
      "Epoch 1820/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2633 - precision: 0.6425 - recall: 0.7552 - val_loss: 1.2614 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1821/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2619 - precision: 0.6424 - recall: 0.7548 - val_loss: 1.2600 - val_precision: 0.6253 - val_recall: 0.7494\n",
      "Epoch 1822/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2604 - precision: 0.6425 - recall: 0.7549 - val_loss: 1.2585 - val_precision: 0.6249 - val_recall: 0.7494\n",
      "Epoch 1823/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2590 - precision: 0.6427 - recall: 0.7546 - val_loss: 1.2571 - val_precision: 0.6251 - val_recall: 0.7494\n",
      "Epoch 1824/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 1.2576 - precision: 0.6425 - recall: 0.7549 - val_loss: 1.2557 - val_precision: 0.6249 - val_recall: 0.7494\n",
      "Epoch 1825/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2562 - precision: 0.6425 - recall: 0.7550 - val_loss: 1.2543 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1826/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2548 - precision: 0.6424 - recall: 0.7550 - val_loss: 1.2529 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1827/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2534 - precision: 0.6424 - recall: 0.7550 - val_loss: 1.2515 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1828/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2520 - precision: 0.6425 - recall: 0.7550 - val_loss: 1.2501 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1829/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2507 - precision: 0.6425 - recall: 0.7550 - val_loss: 1.2488 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1830/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2493 - precision: 0.6426 - recall: 0.7549 - val_loss: 1.2474 - val_precision: 0.6248 - val_recall: 0.7498\n",
      "Epoch 1831/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2479 - precision: 0.6425 - recall: 0.7550 - val_loss: 1.2460 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1832/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2465 - precision: 0.6426 - recall: 0.7554 - val_loss: 1.2446 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1833/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2452 - precision: 0.6425 - recall: 0.7554 - val_loss: 1.2433 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1834/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2438 - precision: 0.6426 - recall: 0.7553 - val_loss: 1.2419 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1835/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2424 - precision: 0.6427 - recall: 0.7554 - val_loss: 1.2405 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1836/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2411 - precision: 0.6427 - recall: 0.7557 - val_loss: 1.2392 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1837/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2397 - precision: 0.6427 - recall: 0.7557 - val_loss: 1.2378 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1838/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2384 - precision: 0.6427 - recall: 0.7557 - val_loss: 1.2365 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1839/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2370 - precision: 0.6427 - recall: 0.7554 - val_loss: 1.2351 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1840/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2357 - precision: 0.6427 - recall: 0.7557 - val_loss: 1.2338 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1841/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2344 - precision: 0.6426 - recall: 0.7559 - val_loss: 1.2325 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1842/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2330 - precision: 0.6425 - recall: 0.7557 - val_loss: 1.2311 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1843/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2317 - precision: 0.6426 - recall: 0.7555 - val_loss: 1.2298 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1844/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2304 - precision: 0.6427 - recall: 0.7555 - val_loss: 1.2285 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1845/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2291 - precision: 0.6425 - recall: 0.7549 - val_loss: 1.2272 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1846/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.2277 - precision: 0.6426 - recall: 0.7553 - val_loss: 1.2259 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1847/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2264 - precision: 0.6426 - recall: 0.7553 - val_loss: 1.2245 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1848/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2251 - precision: 0.6427 - recall: 0.7554 - val_loss: 1.2232 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1849/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2238 - precision: 0.6427 - recall: 0.7554 - val_loss: 1.2219 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1850/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2225 - precision: 0.6426 - recall: 0.7554 - val_loss: 1.2206 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1851/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2212 - precision: 0.6426 - recall: 0.7554 - val_loss: 1.2193 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1852/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2199 - precision: 0.6427 - recall: 0.7559 - val_loss: 1.2180 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1853/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2186 - precision: 0.6428 - recall: 0.7555 - val_loss: 1.2168 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1854/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2174 - precision: 0.6427 - recall: 0.7552 - val_loss: 1.2155 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1855/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2161 - precision: 0.6427 - recall: 0.7554 - val_loss: 1.2142 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1856/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2148 - precision: 0.6427 - recall: 0.7557 - val_loss: 1.2129 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1857/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2135 - precision: 0.6428 - recall: 0.7557 - val_loss: 1.2117 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1858/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2123 - precision: 0.6427 - recall: 0.7558 - val_loss: 1.2104 - val_precision: 0.6251 - val_recall: 0.7506\n",
      "Epoch 1859/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2110 - precision: 0.6427 - recall: 0.7558 - val_loss: 1.2091 - val_precision: 0.6251 - val_recall: 0.7506\n",
      "Epoch 1860/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2098 - precision: 0.6427 - recall: 0.7559 - val_loss: 1.2079 - val_precision: 0.6250 - val_recall: 0.7502\n",
      "Epoch 1861/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2085 - precision: 0.6427 - recall: 0.7557 - val_loss: 1.2066 - val_precision: 0.6251 - val_recall: 0.7506\n",
      "Epoch 1862/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2073 - precision: 0.6427 - recall: 0.7558 - val_loss: 1.2054 - val_precision: 0.6250 - val_recall: 0.7510\n",
      "Epoch 1863/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2060 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.2041 - val_precision: 0.6250 - val_recall: 0.7510\n",
      "Epoch 1864/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2048 - precision: 0.6426 - recall: 0.7562 - val_loss: 1.2029 - val_precision: 0.6248 - val_recall: 0.7510\n",
      "Epoch 1865/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2035 - precision: 0.6427 - recall: 0.7559 - val_loss: 1.2016 - val_precision: 0.6250 - val_recall: 0.7510\n",
      "Epoch 1866/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.2023 - precision: 0.6427 - recall: 0.7561 - val_loss: 1.2004 - val_precision: 0.6248 - val_recall: 0.7510\n",
      "Epoch 1867/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.2011 - precision: 0.6427 - recall: 0.7561 - val_loss: 1.1992 - val_precision: 0.6248 - val_recall: 0.7510\n",
      "Epoch 1868/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1998 - precision: 0.6426 - recall: 0.7559 - val_loss: 1.1980 - val_precision: 0.6248 - val_recall: 0.7510\n",
      "Epoch 1869/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1986 - precision: 0.6428 - recall: 0.7557 - val_loss: 1.1967 - val_precision: 0.6251 - val_recall: 0.7506\n",
      "Epoch 1870/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 1.1974 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.1955 - val_precision: 0.6250 - val_recall: 0.7518\n",
      "Epoch 1871/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1962 - precision: 0.6425 - recall: 0.7555 - val_loss: 1.1943 - val_precision: 0.6249 - val_recall: 0.7514\n",
      "Epoch 1872/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1950 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.1931 - val_precision: 0.6250 - val_recall: 0.7518\n",
      "Epoch 1873/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1938 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.1919 - val_precision: 0.6250 - val_recall: 0.7518\n",
      "Epoch 1874/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1926 - precision: 0.6427 - recall: 0.7558 - val_loss: 1.1907 - val_precision: 0.6250 - val_recall: 0.7518\n",
      "Epoch 1875/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1914 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.1895 - val_precision: 0.6250 - val_recall: 0.7518\n",
      "Epoch 1876/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.1902 - precision: 0.6427 - recall: 0.7559 - val_loss: 1.1883 - val_precision: 0.6252 - val_recall: 0.7518\n",
      "Epoch 1877/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1890 - precision: 0.6426 - recall: 0.7555 - val_loss: 1.1871 - val_precision: 0.6252 - val_recall: 0.7518\n",
      "Epoch 1878/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1878 - precision: 0.6427 - recall: 0.7558 - val_loss: 1.1859 - val_precision: 0.6252 - val_recall: 0.7518\n",
      "Epoch 1879/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1866 - precision: 0.6427 - recall: 0.7559 - val_loss: 1.1848 - val_precision: 0.6252 - val_recall: 0.7521\n",
      "Epoch 1880/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1855 - precision: 0.6426 - recall: 0.7563 - val_loss: 1.1836 - val_precision: 0.6254 - val_recall: 0.7521\n",
      "Epoch 1881/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1843 - precision: 0.6426 - recall: 0.7559 - val_loss: 1.1824 - val_precision: 0.6254 - val_recall: 0.7521\n",
      "Epoch 1882/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1831 - precision: 0.6426 - recall: 0.7564 - val_loss: 1.1812 - val_precision: 0.6250 - val_recall: 0.7521\n",
      "Epoch 1883/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1820 - precision: 0.6426 - recall: 0.7559 - val_loss: 1.1801 - val_precision: 0.6254 - val_recall: 0.7521\n",
      "Epoch 1884/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1808 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1789 - val_precision: 0.6253 - val_recall: 0.7525\n",
      "Epoch 1885/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1796 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1778 - val_precision: 0.6255 - val_recall: 0.7525\n",
      "Epoch 1886/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1785 - precision: 0.6425 - recall: 0.7557 - val_loss: 1.1766 - val_precision: 0.6254 - val_recall: 0.7521\n",
      "Epoch 1887/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1773 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1755 - val_precision: 0.6255 - val_recall: 0.7525\n",
      "Epoch 1888/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1762 - precision: 0.6424 - recall: 0.7559 - val_loss: 1.1743 - val_precision: 0.6255 - val_recall: 0.7525\n",
      "Epoch 1889/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1751 - precision: 0.6424 - recall: 0.7561 - val_loss: 1.1732 - val_precision: 0.6253 - val_recall: 0.7525\n",
      "Epoch 1890/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1739 - precision: 0.6426 - recall: 0.7559 - val_loss: 1.1721 - val_precision: 0.6255 - val_recall: 0.7525\n",
      "Epoch 1891/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1728 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1709 - val_precision: 0.6255 - val_recall: 0.7525\n",
      "Epoch 1892/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1717 - precision: 0.6424 - recall: 0.7559 - val_loss: 1.1698 - val_precision: 0.6255 - val_recall: 0.7525\n",
      "Epoch 1893/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1706 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1687 - val_precision: 0.6253 - val_recall: 0.7525\n",
      "Epoch 1894/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1694 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1676 - val_precision: 0.6253 - val_recall: 0.7525\n",
      "Epoch 1895/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1683 - precision: 0.6424 - recall: 0.7559 - val_loss: 1.1665 - val_precision: 0.6255 - val_recall: 0.7525\n",
      "Epoch 1896/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1672 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1654 - val_precision: 0.6253 - val_recall: 0.7525\n",
      "Epoch 1897/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1661 - precision: 0.6424 - recall: 0.7562 - val_loss: 1.1643 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1898/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1650 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1632 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1899/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1639 - precision: 0.6424 - recall: 0.7561 - val_loss: 1.1621 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1900/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1628 - precision: 0.6424 - recall: 0.7561 - val_loss: 1.1610 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1901/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1617 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1599 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1902/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1607 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1588 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1903/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1596 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1577 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1904/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1585 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1566 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1905/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1574 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1556 - val_precision: 0.6251 - val_recall: 0.7525\n",
      "Epoch 1906/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1564 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1545 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 1907/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1553 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1534 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 1908/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1542 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1524 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 1909/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1532 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1513 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 1910/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1521 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1503 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 1911/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1511 - precision: 0.6426 - recall: 0.7562 - val_loss: 1.1492 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 1912/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1500 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1481 - val_precision: 0.6250 - val_recall: 0.7529\n",
      "Epoch 1913/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1490 - precision: 0.6426 - recall: 0.7562 - val_loss: 1.1471 - val_precision: 0.6253 - val_recall: 0.7525\n",
      "Epoch 1914/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1479 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1460 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1915/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1469 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1450 - val_precision: 0.6253 - val_recall: 0.7533\n",
      "Epoch 1916/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1458 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1440 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1917/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1448 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1429 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1918/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1437 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1419 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1919/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1427 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1408 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1920/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1417 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1398 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 1921/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1406 - precision: 0.6424 - recall: 0.7562 - val_loss: 1.1388 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1922/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1396 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1378 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 1923/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.1386 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1367 - val_precision: 0.6246 - val_recall: 0.7529\n",
      "Epoch 1924/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1376 - precision: 0.6424 - recall: 0.7562 - val_loss: 1.1357 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 1925/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1366 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1347 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 1926/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1355 - precision: 0.6426 - recall: 0.7562 - val_loss: 1.1337 - val_precision: 0.6248 - val_recall: 0.7529\n",
      "Epoch 1927/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1345 - precision: 0.6424 - recall: 0.7559 - val_loss: 1.1327 - val_precision: 0.6248 - val_recall: 0.7529\n",
      "Epoch 1928/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1335 - precision: 0.6424 - recall: 0.7562 - val_loss: 1.1317 - val_precision: 0.6248 - val_recall: 0.7529\n",
      "Epoch 1929/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1325 - precision: 0.6424 - recall: 0.7562 - val_loss: 1.1306 - val_precision: 0.6248 - val_recall: 0.7529\n",
      "Epoch 1930/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1315 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1296 - val_precision: 0.6248 - val_recall: 0.7529\n",
      "Epoch 1931/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1305 - precision: 0.6424 - recall: 0.7562 - val_loss: 1.1286 - val_precision: 0.6252 - val_recall: 0.7541\n",
      "Epoch 1932/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1295 - precision: 0.6424 - recall: 0.7564 - val_loss: 1.1276 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1933/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1285 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1266 - val_precision: 0.6249 - val_recall: 0.7533\n",
      "Epoch 1934/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1275 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1256 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1935/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1265 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1246 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1936/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1255 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1236 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1937/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1245 - precision: 0.6426 - recall: 0.7561 - val_loss: 1.1226 - val_precision: 0.6249 - val_recall: 0.7533\n",
      "Epoch 1938/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1235 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1216 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1939/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1225 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1206 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1940/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1215 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1197 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1941/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1205 - precision: 0.6425 - recall: 0.7564 - val_loss: 1.1187 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1942/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1196 - precision: 0.6424 - recall: 0.7563 - val_loss: 1.1177 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1943/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1186 - precision: 0.6424 - recall: 0.7563 - val_loss: 1.1167 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1944/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1176 - precision: 0.6423 - recall: 0.7561 - val_loss: 1.1157 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1945/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1166 - precision: 0.6425 - recall: 0.7561 - val_loss: 1.1148 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1946/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1157 - precision: 0.6424 - recall: 0.7562 - val_loss: 1.1138 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1947/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.1147 - precision: 0.6424 - recall: 0.7564 - val_loss: 1.1128 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1948/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1137 - precision: 0.6424 - recall: 0.7561 - val_loss: 1.1119 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1949/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1128 - precision: 0.6426 - recall: 0.7561 - val_loss: 1.1109 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1950/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1118 - precision: 0.6426 - recall: 0.7561 - val_loss: 1.1099 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1951/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1108 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1090 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1952/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1099 - precision: 0.6425 - recall: 0.7562 - val_loss: 1.1080 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1953/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1089 - precision: 0.6426 - recall: 0.7564 - val_loss: 1.1070 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1954/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1080 - precision: 0.6425 - recall: 0.7563 - val_loss: 1.1061 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1955/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1070 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.1051 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1956/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1061 - precision: 0.6425 - recall: 0.7564 - val_loss: 1.1042 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1957/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1051 - precision: 0.6426 - recall: 0.7568 - val_loss: 1.1032 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1958/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1042 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.1023 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1959/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1032 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.1014 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1960/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1023 - precision: 0.6426 - recall: 0.7567 - val_loss: 1.1004 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1961/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1013 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.0995 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1962/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.1004 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.0985 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1963/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0995 - precision: 0.6426 - recall: 0.7567 - val_loss: 1.0976 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1964/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0985 - precision: 0.6425 - recall: 0.7564 - val_loss: 1.0967 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1965/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0976 - precision: 0.6426 - recall: 0.7564 - val_loss: 1.0957 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1966/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0967 - precision: 0.6424 - recall: 0.7564 - val_loss: 1.0948 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1967/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0958 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.0939 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 1968/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0948 - precision: 0.6424 - recall: 0.7564 - val_loss: 1.0930 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1969/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0939 - precision: 0.6425 - recall: 0.7564 - val_loss: 1.0920 - val_precision: 0.6252 - val_recall: 0.7537\n",
      "Epoch 1970/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0930 - precision: 0.6425 - recall: 0.7564 - val_loss: 1.0911 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1971/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0921 - precision: 0.6424 - recall: 0.7567 - val_loss: 1.0902 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1972/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0912 - precision: 0.6424 - recall: 0.7564 - val_loss: 1.0893 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1973/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0903 - precision: 0.6424 - recall: 0.7567 - val_loss: 1.0884 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1974/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0893 - precision: 0.6424 - recall: 0.7564 - val_loss: 1.0875 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1975/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0884 - precision: 0.6424 - recall: 0.7563 - val_loss: 1.0866 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1976/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0875 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.0857 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1977/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0866 - precision: 0.6425 - recall: 0.7566 - val_loss: 1.0848 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1978/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0857 - precision: 0.6426 - recall: 0.7567 - val_loss: 1.0838 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1979/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0848 - precision: 0.6426 - recall: 0.7557 - val_loss: 1.0830 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 1980/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0839 - precision: 0.6426 - recall: 0.7557 - val_loss: 1.0821 - val_precision: 0.6249 - val_recall: 0.7533\n",
      "Epoch 1981/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0830 - precision: 0.6426 - recall: 0.7557 - val_loss: 1.0812 - val_precision: 0.6249 - val_recall: 0.7533\n",
      "Epoch 1982/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0821 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.0803 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1983/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0812 - precision: 0.6427 - recall: 0.7564 - val_loss: 1.0794 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 1984/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0804 - precision: 0.6424 - recall: 0.7567 - val_loss: 1.0785 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 1985/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0795 - precision: 0.6427 - recall: 0.7564 - val_loss: 1.0776 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 1986/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0786 - precision: 0.6427 - recall: 0.7563 - val_loss: 1.0767 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 1987/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0777 - precision: 0.6426 - recall: 0.7566 - val_loss: 1.0758 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 1988/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0768 - precision: 0.6426 - recall: 0.7562 - val_loss: 1.0749 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 1989/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0759 - precision: 0.6427 - recall: 0.7564 - val_loss: 1.0741 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1990/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0751 - precision: 0.6427 - recall: 0.7563 - val_loss: 1.0732 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1991/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0742 - precision: 0.6428 - recall: 0.7562 - val_loss: 1.0723 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 1992/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0733 - precision: 0.6429 - recall: 0.7561 - val_loss: 1.0714 - val_precision: 0.6246 - val_recall: 0.7529\n",
      "Epoch 1993/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0724 - precision: 0.6429 - recall: 0.7561 - val_loss: 1.0706 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1994/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0716 - precision: 0.6429 - recall: 0.7563 - val_loss: 1.0697 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1995/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0707 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.0688 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 1996/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0698 - precision: 0.6429 - recall: 0.7563 - val_loss: 1.0680 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 1997/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0690 - precision: 0.6429 - recall: 0.7561 - val_loss: 1.0671 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 1998/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0681 - precision: 0.6427 - recall: 0.7561 - val_loss: 1.0662 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 1999/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0673 - precision: 0.6429 - recall: 0.7559 - val_loss: 1.0654 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2000/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0664 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.0645 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2001/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0656 - precision: 0.6428 - recall: 0.7561 - val_loss: 1.0637 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2002/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0647 - precision: 0.6427 - recall: 0.7559 - val_loss: 1.0628 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2003/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0639 - precision: 0.6427 - recall: 0.7562 - val_loss: 1.0620 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2004/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0630 - precision: 0.6428 - recall: 0.7559 - val_loss: 1.0611 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2005/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0622 - precision: 0.6427 - recall: 0.7559 - val_loss: 1.0603 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2006/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0613 - precision: 0.6428 - recall: 0.7561 - val_loss: 1.0594 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2007/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0605 - precision: 0.6428 - recall: 0.7559 - val_loss: 1.0586 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2008/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0596 - precision: 0.6428 - recall: 0.7559 - val_loss: 1.0578 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2009/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0588 - precision: 0.6429 - recall: 0.7559 - val_loss: 1.0569 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2010/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0580 - precision: 0.6427 - recall: 0.7563 - val_loss: 1.0561 - val_precision: 0.6245 - val_recall: 0.7533\n",
      "Epoch 2011/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0571 - precision: 0.6427 - recall: 0.7561 - val_loss: 1.0553 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2012/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0563 - precision: 0.6428 - recall: 0.7559 - val_loss: 1.0544 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2013/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0555 - precision: 0.6429 - recall: 0.7561 - val_loss: 1.0536 - val_precision: 0.6245 - val_recall: 0.7533\n",
      "Epoch 2014/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0547 - precision: 0.6430 - recall: 0.7559 - val_loss: 1.0528 - val_precision: 0.6245 - val_recall: 0.7533\n",
      "Epoch 2015/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.0538 - precision: 0.6429 - recall: 0.7558 - val_loss: 1.0520 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2016/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0530 - precision: 0.6428 - recall: 0.7559 - val_loss: 1.0512 - val_precision: 0.6245 - val_recall: 0.7533\n",
      "Epoch 2017/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0522 - precision: 0.6429 - recall: 0.7562 - val_loss: 1.0503 - val_precision: 0.6245 - val_recall: 0.7533\n",
      "Epoch 2018/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0514 - precision: 0.6430 - recall: 0.7558 - val_loss: 1.0495 - val_precision: 0.6245 - val_recall: 0.7533\n",
      "Epoch 2019/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0506 - precision: 0.6430 - recall: 0.7561 - val_loss: 1.0487 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2020/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0498 - precision: 0.6430 - recall: 0.7559 - val_loss: 1.0479 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2021/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0490 - precision: 0.6430 - recall: 0.7559 - val_loss: 1.0471 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2022/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0482 - precision: 0.6430 - recall: 0.7559 - val_loss: 1.0463 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2023/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0474 - precision: 0.6430 - recall: 0.7558 - val_loss: 1.0455 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2024/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0466 - precision: 0.6431 - recall: 0.7561 - val_loss: 1.0447 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2025/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0458 - precision: 0.6432 - recall: 0.7561 - val_loss: 1.0439 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2026/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0450 - precision: 0.6432 - recall: 0.7559 - val_loss: 1.0431 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2027/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0442 - precision: 0.6432 - recall: 0.7559 - val_loss: 1.0423 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2028/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0434 - precision: 0.6432 - recall: 0.7563 - val_loss: 1.0415 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2029/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0426 - precision: 0.6431 - recall: 0.7558 - val_loss: 1.0407 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2030/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0418 - precision: 0.6432 - recall: 0.7558 - val_loss: 1.0399 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2031/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0410 - precision: 0.6432 - recall: 0.7559 - val_loss: 1.0391 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2032/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0402 - precision: 0.6432 - recall: 0.7561 - val_loss: 1.0383 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2033/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0394 - precision: 0.6431 - recall: 0.7558 - val_loss: 1.0375 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2034/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0386 - precision: 0.6432 - recall: 0.7557 - val_loss: 1.0368 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2035/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0379 - precision: 0.6432 - recall: 0.7555 - val_loss: 1.0360 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2036/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0371 - precision: 0.6433 - recall: 0.7558 - val_loss: 1.0352 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2037/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0363 - precision: 0.6432 - recall: 0.7555 - val_loss: 1.0344 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2038/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0355 - precision: 0.6432 - recall: 0.7555 - val_loss: 1.0337 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2039/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0348 - precision: 0.6432 - recall: 0.7555 - val_loss: 1.0329 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2040/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0340 - precision: 0.6432 - recall: 0.7554 - val_loss: 1.0321 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2041/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 1.0332 - precision: 0.6432 - recall: 0.7554 - val_loss: 1.0313 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2042/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0325 - precision: 0.6432 - recall: 0.7554 - val_loss: 1.0306 - val_precision: 0.6248 - val_recall: 0.7541\n",
      "Epoch 2043/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0317 - precision: 0.6432 - recall: 0.7554 - val_loss: 1.0298 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2044/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0309 - precision: 0.6433 - recall: 0.7553 - val_loss: 1.0291 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2045/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0302 - precision: 0.6433 - recall: 0.7554 - val_loss: 1.0283 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2046/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0294 - precision: 0.6433 - recall: 0.7554 - val_loss: 1.0275 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2047/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0287 - precision: 0.6432 - recall: 0.7552 - val_loss: 1.0268 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2048/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0279 - precision: 0.6432 - recall: 0.7550 - val_loss: 1.0260 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2049/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0272 - precision: 0.6432 - recall: 0.7552 - val_loss: 1.0253 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2050/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0264 - precision: 0.6432 - recall: 0.7552 - val_loss: 1.0245 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2051/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0257 - precision: 0.6432 - recall: 0.7554 - val_loss: 1.0238 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2052/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0249 - precision: 0.6433 - recall: 0.7553 - val_loss: 1.0231 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2053/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0242 - precision: 0.6432 - recall: 0.7552 - val_loss: 1.0223 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2054/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0235 - precision: 0.6432 - recall: 0.7555 - val_loss: 1.0216 - val_precision: 0.6246 - val_recall: 0.7537\n",
      "Epoch 2055/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0227 - precision: 0.6432 - recall: 0.7557 - val_loss: 1.0208 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2056/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0220 - precision: 0.6432 - recall: 0.7552 - val_loss: 1.0201 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2057/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0213 - precision: 0.6434 - recall: 0.7552 - val_loss: 1.0194 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2058/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0205 - precision: 0.6432 - recall: 0.7555 - val_loss: 1.0187 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2059/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0198 - precision: 0.6433 - recall: 0.7555 - val_loss: 1.0179 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2060/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0191 - precision: 0.6432 - recall: 0.7554 - val_loss: 1.0172 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2061/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0184 - precision: 0.6433 - recall: 0.7553 - val_loss: 1.0165 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2062/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0176 - precision: 0.6433 - recall: 0.7555 - val_loss: 1.0158 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2063/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0169 - precision: 0.6433 - recall: 0.7552 - val_loss: 1.0150 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2064/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0162 - precision: 0.6433 - recall: 0.7550 - val_loss: 1.0143 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2065/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0155 - precision: 0.6434 - recall: 0.7549 - val_loss: 1.0136 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2066/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0148 - precision: 0.6432 - recall: 0.7549 - val_loss: 1.0129 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2067/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0141 - precision: 0.6433 - recall: 0.7550 - val_loss: 1.0122 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2068/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0134 - precision: 0.6434 - recall: 0.7552 - val_loss: 1.0115 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2069/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0127 - precision: 0.6433 - recall: 0.7550 - val_loss: 1.0108 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2070/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0119 - precision: 0.6432 - recall: 0.7550 - val_loss: 1.0101 - val_precision: 0.6250 - val_recall: 0.7541\n",
      "Epoch 2071/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0112 - precision: 0.6432 - recall: 0.7552 - val_loss: 1.0094 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2072/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0105 - precision: 0.6433 - recall: 0.7550 - val_loss: 1.0087 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2073/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0098 - precision: 0.6433 - recall: 0.7550 - val_loss: 1.0080 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2074/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0092 - precision: 0.6434 - recall: 0.7550 - val_loss: 1.0073 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2075/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0085 - precision: 0.6432 - recall: 0.7552 - val_loss: 1.0066 - val_precision: 0.6250 - val_recall: 0.7541\n",
      "Epoch 2076/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0078 - precision: 0.6433 - recall: 0.7552 - val_loss: 1.0059 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2077/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0071 - precision: 0.6434 - recall: 0.7549 - val_loss: 1.0052 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2078/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0064 - precision: 0.6434 - recall: 0.7549 - val_loss: 1.0045 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2079/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0057 - precision: 0.6435 - recall: 0.7554 - val_loss: 1.0038 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2080/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0050 - precision: 0.6435 - recall: 0.7553 - val_loss: 1.0031 - val_precision: 0.6247 - val_recall: 0.7533\n",
      "Epoch 2081/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0043 - precision: 0.6435 - recall: 0.7553 - val_loss: 1.0025 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2082/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0037 - precision: 0.6434 - recall: 0.7552 - val_loss: 1.0018 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2083/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0030 - precision: 0.6434 - recall: 0.7553 - val_loss: 1.0011 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2084/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0023 - precision: 0.6434 - recall: 0.7553 - val_loss: 1.0004 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2085/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0017 - precision: 0.6434 - recall: 0.7552 - val_loss: 0.9998 - val_precision: 0.6248 - val_recall: 0.7537\n",
      "Epoch 2086/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 1.0010 - precision: 0.6436 - recall: 0.7549 - val_loss: 0.9991 - val_precision: 0.6249 - val_recall: 0.7533\n",
      "Epoch 2087/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 1.0003 - precision: 0.6436 - recall: 0.7549 - val_loss: 0.9984 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2088/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9997 - precision: 0.6436 - recall: 0.7552 - val_loss: 0.9978 - val_precision: 0.6249 - val_recall: 0.7533\n",
      "Epoch 2089/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9990 - precision: 0.6437 - recall: 0.7549 - val_loss: 0.9971 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2090/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9983 - precision: 0.6437 - recall: 0.7550 - val_loss: 0.9965 - val_precision: 0.6249 - val_recall: 0.7533\n",
      "Epoch 2091/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9977 - precision: 0.6437 - recall: 0.7554 - val_loss: 0.9958 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 2092/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9970 - precision: 0.6438 - recall: 0.7554 - val_loss: 0.9951 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2093/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9964 - precision: 0.6438 - recall: 0.7552 - val_loss: 0.9945 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2094/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9957 - precision: 0.6438 - recall: 0.7552 - val_loss: 0.9938 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2095/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9951 - precision: 0.6437 - recall: 0.7549 - val_loss: 0.9932 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2096/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9944 - precision: 0.6439 - recall: 0.7549 - val_loss: 0.9925 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2097/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9938 - precision: 0.6438 - recall: 0.7550 - val_loss: 0.9919 - val_precision: 0.6250 - val_recall: 0.7537\n",
      "Epoch 2098/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9931 - precision: 0.6437 - recall: 0.7549 - val_loss: 0.9913 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2099/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9925 - precision: 0.6438 - recall: 0.7550 - val_loss: 0.9906 - val_precision: 0.6251 - val_recall: 0.7533\n",
      "Epoch 2100/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9918 - precision: 0.6439 - recall: 0.7552 - val_loss: 0.9900 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 2101/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9912 - precision: 0.6440 - recall: 0.7550 - val_loss: 0.9893 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 2102/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9906 - precision: 0.6440 - recall: 0.7552 - val_loss: 0.9887 - val_precision: 0.6253 - val_recall: 0.7533\n",
      "Epoch 2103/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9899 - precision: 0.6440 - recall: 0.7550 - val_loss: 0.9881 - val_precision: 0.6253 - val_recall: 0.7533\n",
      "Epoch 2104/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9893 - precision: 0.6439 - recall: 0.7554 - val_loss: 0.9874 - val_precision: 0.6253 - val_recall: 0.7533\n",
      "Epoch 2105/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9887 - precision: 0.6440 - recall: 0.7553 - val_loss: 0.9868 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 2106/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9881 - precision: 0.6441 - recall: 0.7550 - val_loss: 0.9862 - val_precision: 0.6252 - val_recall: 0.7529\n",
      "Epoch 2107/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9874 - precision: 0.6442 - recall: 0.7552 - val_loss: 0.9856 - val_precision: 0.6253 - val_recall: 0.7533\n",
      "Epoch 2108/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9868 - precision: 0.6442 - recall: 0.7552 - val_loss: 0.9849 - val_precision: 0.6254 - val_recall: 0.7529\n",
      "Epoch 2109/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9862 - precision: 0.6441 - recall: 0.7548 - val_loss: 0.9843 - val_precision: 0.6254 - val_recall: 0.7529\n",
      "Epoch 2110/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9856 - precision: 0.6442 - recall: 0.7550 - val_loss: 0.9837 - val_precision: 0.6255 - val_recall: 0.7533\n",
      "Epoch 2111/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9850 - precision: 0.6439 - recall: 0.7543 - val_loss: 0.9831 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2112/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9844 - precision: 0.6441 - recall: 0.7546 - val_loss: 0.9825 - val_precision: 0.6254 - val_recall: 0.7521\n",
      "Epoch 2113/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9837 - precision: 0.6441 - recall: 0.7548 - val_loss: 0.9819 - val_precision: 0.6254 - val_recall: 0.7521\n",
      "Epoch 2114/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9831 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9813 - val_precision: 0.6254 - val_recall: 0.7518\n",
      "Epoch 2115/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9825 - precision: 0.6440 - recall: 0.7543 - val_loss: 0.9807 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2116/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9819 - precision: 0.6440 - recall: 0.7541 - val_loss: 0.9801 - val_precision: 0.6254 - val_recall: 0.7518\n",
      "Epoch 2117/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9813 - precision: 0.6440 - recall: 0.7543 - val_loss: 0.9795 - val_precision: 0.6254 - val_recall: 0.7518\n",
      "Epoch 2118/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9807 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9789 - val_precision: 0.6254 - val_recall: 0.7518\n",
      "Epoch 2119/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9801 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9783 - val_precision: 0.6254 - val_recall: 0.7518\n",
      "Epoch 2120/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9795 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9777 - val_precision: 0.6254 - val_recall: 0.7518\n",
      "Epoch 2121/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9789 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9771 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2122/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9783 - precision: 0.6440 - recall: 0.7545 - val_loss: 0.9765 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2123/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9778 - precision: 0.6441 - recall: 0.7545 - val_loss: 0.9759 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2124/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9772 - precision: 0.6441 - recall: 0.7545 - val_loss: 0.9753 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2125/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9766 - precision: 0.6441 - recall: 0.7545 - val_loss: 0.9747 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2126/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9760 - precision: 0.6440 - recall: 0.7540 - val_loss: 0.9741 - val_precision: 0.6254 - val_recall: 0.7518\n",
      "Epoch 2127/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9754 - precision: 0.6441 - recall: 0.7545 - val_loss: 0.9736 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2128/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9748 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9730 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2129/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9743 - precision: 0.6441 - recall: 0.7544 - val_loss: 0.9724 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2130/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9737 - precision: 0.6441 - recall: 0.7543 - val_loss: 0.9718 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2131/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9731 - precision: 0.6441 - recall: 0.7543 - val_loss: 0.9712 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2132/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9725 - precision: 0.6441 - recall: 0.7544 - val_loss: 0.9707 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2133/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9720 - precision: 0.6440 - recall: 0.7540 - val_loss: 0.9701 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2134/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9714 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9695 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2135/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9708 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9690 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2136/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9703 - precision: 0.6440 - recall: 0.7540 - val_loss: 0.9684 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2137/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9697 - precision: 0.6441 - recall: 0.7543 - val_loss: 0.9678 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2138/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9692 - precision: 0.6440 - recall: 0.7539 - val_loss: 0.9673 - val_precision: 0.6256 - val_recall: 0.7521\n",
      "Epoch 2139/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9686 - precision: 0.6440 - recall: 0.7539 - val_loss: 0.9667 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2140/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9680 - precision: 0.6439 - recall: 0.7539 - val_loss: 0.9662 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2141/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9675 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9656 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2142/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9669 - precision: 0.6439 - recall: 0.7541 - val_loss: 0.9651 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2143/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9664 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9645 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2144/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9659 - precision: 0.6440 - recall: 0.7539 - val_loss: 0.9640 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2145/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9653 - precision: 0.6439 - recall: 0.7540 - val_loss: 0.9634 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2146/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9648 - precision: 0.6440 - recall: 0.7541 - val_loss: 0.9629 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2147/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9642 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9624 - val_precision: 0.6259 - val_recall: 0.7525\n",
      "Epoch 2148/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9637 - precision: 0.6439 - recall: 0.7539 - val_loss: 0.9618 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2149/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9632 - precision: 0.6440 - recall: 0.7544 - val_loss: 0.9613 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2150/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9626 - precision: 0.6438 - recall: 0.7536 - val_loss: 0.9608 - val_precision: 0.6257 - val_recall: 0.7525\n",
      "Epoch 2151/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9621 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9602 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2152/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9616 - precision: 0.6438 - recall: 0.7534 - val_loss: 0.9597 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2153/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9610 - precision: 0.6439 - recall: 0.7539 - val_loss: 0.9592 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2154/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9605 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9587 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2155/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9600 - precision: 0.6438 - recall: 0.7532 - val_loss: 0.9581 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2156/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9595 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9576 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2157/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9590 - precision: 0.6439 - recall: 0.7536 - val_loss: 0.9571 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2158/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9585 - precision: 0.6439 - recall: 0.7536 - val_loss: 0.9566 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2159/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9579 - precision: 0.6439 - recall: 0.7538 - val_loss: 0.9561 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2160/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9574 - precision: 0.6439 - recall: 0.7539 - val_loss: 0.9556 - val_precision: 0.6261 - val_recall: 0.7525\n",
      "Epoch 2161/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9569 - precision: 0.6440 - recall: 0.7539 - val_loss: 0.9551 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2162/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9564 - precision: 0.6440 - recall: 0.7536 - val_loss: 0.9545 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2163/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9559 - precision: 0.6440 - recall: 0.7531 - val_loss: 0.9540 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2164/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9554 - precision: 0.6440 - recall: 0.7531 - val_loss: 0.9535 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2165/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9549 - precision: 0.6441 - recall: 0.7531 - val_loss: 0.9530 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2166/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9544 - precision: 0.6440 - recall: 0.7532 - val_loss: 0.9525 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2167/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9539 - precision: 0.6439 - recall: 0.7532 - val_loss: 0.9520 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2168/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9534 - precision: 0.6440 - recall: 0.7534 - val_loss: 0.9516 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2169/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9529 - precision: 0.6442 - recall: 0.7532 - val_loss: 0.9511 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2170/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9524 - precision: 0.6440 - recall: 0.7532 - val_loss: 0.9506 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2171/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9519 - precision: 0.6442 - recall: 0.7532 - val_loss: 0.9501 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2172/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9515 - precision: 0.6442 - recall: 0.7534 - val_loss: 0.9496 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2173/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9510 - precision: 0.6441 - recall: 0.7534 - val_loss: 0.9491 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2174/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9505 - precision: 0.6440 - recall: 0.7532 - val_loss: 0.9486 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2175/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9500 - precision: 0.6441 - recall: 0.7534 - val_loss: 0.9482 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2176/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9495 - precision: 0.6443 - recall: 0.7531 - val_loss: 0.9477 - val_precision: 0.6262 - val_recall: 0.7521\n",
      "Epoch 2177/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9491 - precision: 0.6441 - recall: 0.7532 - val_loss: 0.9472 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2178/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9486 - precision: 0.6442 - recall: 0.7531 - val_loss: 0.9467 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2179/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9481 - precision: 0.6442 - recall: 0.7532 - val_loss: 0.9463 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2180/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9477 - precision: 0.6442 - recall: 0.7529 - val_loss: 0.9458 - val_precision: 0.6262 - val_recall: 0.7521\n",
      "Epoch 2181/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9472 - precision: 0.6441 - recall: 0.7530 - val_loss: 0.9453 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2182/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9467 - precision: 0.6441 - recall: 0.7530 - val_loss: 0.9449 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2183/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9463 - precision: 0.6442 - recall: 0.7532 - val_loss: 0.9444 - val_precision: 0.6263 - val_recall: 0.7525\n",
      "Epoch 2184/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9458 - precision: 0.6442 - recall: 0.7527 - val_loss: 0.9440 - val_precision: 0.6262 - val_recall: 0.7521\n",
      "Epoch 2185/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9454 - precision: 0.6442 - recall: 0.7527 - val_loss: 0.9435 - val_precision: 0.6262 - val_recall: 0.7521\n",
      "Epoch 2186/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9449 - precision: 0.6442 - recall: 0.7527 - val_loss: 0.9431 - val_precision: 0.6262 - val_recall: 0.7521\n",
      "Epoch 2187/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9445 - precision: 0.6441 - recall: 0.7527 - val_loss: 0.9426 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2188/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9440 - precision: 0.6441 - recall: 0.7527 - val_loss: 0.9422 - val_precision: 0.6261 - val_recall: 0.7518\n",
      "Epoch 2189/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9436 - precision: 0.6441 - recall: 0.7527 - val_loss: 0.9417 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2190/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9431 - precision: 0.6443 - recall: 0.7526 - val_loss: 0.9413 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2191/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9427 - precision: 0.6445 - recall: 0.7525 - val_loss: 0.9408 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2192/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9422 - precision: 0.6441 - recall: 0.7526 - val_loss: 0.9404 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2193/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9418 - precision: 0.6443 - recall: 0.7526 - val_loss: 0.9400 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2194/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9414 - precision: 0.6443 - recall: 0.7524 - val_loss: 0.9395 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2195/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9409 - precision: 0.6441 - recall: 0.7526 - val_loss: 0.9391 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2196/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9405 - precision: 0.6444 - recall: 0.7524 - val_loss: 0.9387 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2197/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9401 - precision: 0.6444 - recall: 0.7524 - val_loss: 0.9382 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2198/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9397 - precision: 0.6441 - recall: 0.7525 - val_loss: 0.9378 - val_precision: 0.6263 - val_recall: 0.7518\n",
      "Epoch 2199/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9392 - precision: 0.6443 - recall: 0.7524 - val_loss: 0.9374 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2200/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9388 - precision: 0.6443 - recall: 0.7524 - val_loss: 0.9370 - val_precision: 0.6261 - val_recall: 0.7514\n",
      "Epoch 2201/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9384 - precision: 0.6444 - recall: 0.7522 - val_loss: 0.9365 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2202/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9380 - precision: 0.6444 - recall: 0.7522 - val_loss: 0.9361 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2203/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9375 - precision: 0.6443 - recall: 0.7522 - val_loss: 0.9357 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2204/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9371 - precision: 0.6443 - recall: 0.7522 - val_loss: 0.9353 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2205/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9367 - precision: 0.6443 - recall: 0.7521 - val_loss: 0.9349 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2206/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9363 - precision: 0.6442 - recall: 0.7521 - val_loss: 0.9344 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2207/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9359 - precision: 0.6443 - recall: 0.7522 - val_loss: 0.9340 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2208/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9354 - precision: 0.6444 - recall: 0.7520 - val_loss: 0.9336 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2209/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9350 - precision: 0.6445 - recall: 0.7520 - val_loss: 0.9332 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2210/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9346 - precision: 0.6445 - recall: 0.7520 - val_loss: 0.9328 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2211/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9342 - precision: 0.6444 - recall: 0.7520 - val_loss: 0.9323 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2212/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9338 - precision: 0.6444 - recall: 0.7522 - val_loss: 0.9319 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2213/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9334 - precision: 0.6444 - recall: 0.7520 - val_loss: 0.9315 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2214/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9330 - precision: 0.6446 - recall: 0.7518 - val_loss: 0.9311 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2215/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9326 - precision: 0.6444 - recall: 0.7521 - val_loss: 0.9307 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2216/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9321 - precision: 0.6445 - recall: 0.7521 - val_loss: 0.9303 - val_precision: 0.6263 - val_recall: 0.7514\n",
      "Epoch 2217/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9317 - precision: 0.6445 - recall: 0.7518 - val_loss: 0.9299 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2218/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9313 - precision: 0.6446 - recall: 0.7517 - val_loss: 0.9295 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2219/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9309 - precision: 0.6446 - recall: 0.7517 - val_loss: 0.9291 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2220/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9305 - precision: 0.6447 - recall: 0.7520 - val_loss: 0.9287 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2221/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9301 - precision: 0.6447 - recall: 0.7520 - val_loss: 0.9283 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2222/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9297 - precision: 0.6447 - recall: 0.7521 - val_loss: 0.9278 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2223/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9293 - precision: 0.6447 - recall: 0.7517 - val_loss: 0.9274 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2224/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9289 - precision: 0.6446 - recall: 0.7517 - val_loss: 0.9270 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2225/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9285 - precision: 0.6446 - recall: 0.7513 - val_loss: 0.9266 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2226/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9281 - precision: 0.6447 - recall: 0.7516 - val_loss: 0.9262 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2227/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9277 - precision: 0.6447 - recall: 0.7517 - val_loss: 0.9258 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2228/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9273 - precision: 0.6446 - recall: 0.7512 - val_loss: 0.9254 - val_precision: 0.6265 - val_recall: 0.7514\n",
      "Epoch 2229/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9269 - precision: 0.6446 - recall: 0.7515 - val_loss: 0.9250 - val_precision: 0.6264 - val_recall: 0.7510\n",
      "Epoch 2230/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9265 - precision: 0.6447 - recall: 0.7515 - val_loss: 0.9246 - val_precision: 0.6264 - val_recall: 0.7510\n",
      "Epoch 2231/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9261 - precision: 0.6447 - recall: 0.7513 - val_loss: 0.9242 - val_precision: 0.6264 - val_recall: 0.7510\n",
      "Epoch 2232/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9257 - precision: 0.6447 - recall: 0.7513 - val_loss: 0.9238 - val_precision: 0.6264 - val_recall: 0.7510\n",
      "Epoch 2233/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9253 - precision: 0.6447 - recall: 0.7513 - val_loss: 0.9234 - val_precision: 0.6264 - val_recall: 0.7510\n",
      "Epoch 2234/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9249 - precision: 0.6447 - recall: 0.7513 - val_loss: 0.9230 - val_precision: 0.6264 - val_recall: 0.7510\n",
      "Epoch 2235/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9245 - precision: 0.6448 - recall: 0.7510 - val_loss: 0.9226 - val_precision: 0.6265 - val_recall: 0.7506\n",
      "Epoch 2236/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9241 - precision: 0.6449 - recall: 0.7510 - val_loss: 0.9223 - val_precision: 0.6264 - val_recall: 0.7502\n",
      "Epoch 2237/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9237 - precision: 0.6452 - recall: 0.7510 - val_loss: 0.9219 - val_precision: 0.6264 - val_recall: 0.7502\n",
      "Epoch 2238/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9233 - precision: 0.6452 - recall: 0.7510 - val_loss: 0.9215 - val_precision: 0.6264 - val_recall: 0.7502\n",
      "Epoch 2239/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9229 - precision: 0.6452 - recall: 0.7507 - val_loss: 0.9211 - val_precision: 0.6264 - val_recall: 0.7502\n",
      "Epoch 2240/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9225 - precision: 0.6452 - recall: 0.7510 - val_loss: 0.9207 - val_precision: 0.6264 - val_recall: 0.7502\n",
      "Epoch 2241/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9221 - precision: 0.6453 - recall: 0.7506 - val_loss: 0.9203 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2242/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9217 - precision: 0.6452 - recall: 0.7507 - val_loss: 0.9199 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2243/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9214 - precision: 0.6454 - recall: 0.7508 - val_loss: 0.9195 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2244/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9210 - precision: 0.6452 - recall: 0.7507 - val_loss: 0.9191 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2245/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9206 - precision: 0.6452 - recall: 0.7507 - val_loss: 0.9187 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2246/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9202 - precision: 0.6452 - recall: 0.7507 - val_loss: 0.9183 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2247/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9198 - precision: 0.6454 - recall: 0.7507 - val_loss: 0.9179 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2248/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9194 - precision: 0.6455 - recall: 0.7507 - val_loss: 0.9176 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2249/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9190 - precision: 0.6455 - recall: 0.7507 - val_loss: 0.9172 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2250/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9186 - precision: 0.6456 - recall: 0.7508 - val_loss: 0.9168 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2251/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9182 - precision: 0.6456 - recall: 0.7507 - val_loss: 0.9164 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2252/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9179 - precision: 0.6456 - recall: 0.7508 - val_loss: 0.9160 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2253/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9175 - precision: 0.6456 - recall: 0.7508 - val_loss: 0.9156 - val_precision: 0.6266 - val_recall: 0.7502\n",
      "Epoch 2254/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9171 - precision: 0.6456 - recall: 0.7508 - val_loss: 0.9152 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2255/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9167 - precision: 0.6456 - recall: 0.7507 - val_loss: 0.9149 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2256/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9163 - precision: 0.6456 - recall: 0.7508 - val_loss: 0.9145 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2257/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9159 - precision: 0.6456 - recall: 0.7508 - val_loss: 0.9141 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2258/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9156 - precision: 0.6456 - recall: 0.7507 - val_loss: 0.9137 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2259/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9152 - precision: 0.6456 - recall: 0.7506 - val_loss: 0.9133 - val_precision: 0.6263 - val_recall: 0.7494\n",
      "Epoch 2260/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9148 - precision: 0.6456 - recall: 0.7507 - val_loss: 0.9129 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2261/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9144 - precision: 0.6456 - recall: 0.7507 - val_loss: 0.9126 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2262/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9140 - precision: 0.6456 - recall: 0.7508 - val_loss: 0.9122 - val_precision: 0.6265 - val_recall: 0.7498\n",
      "Epoch 2263/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9136 - precision: 0.6456 - recall: 0.7506 - val_loss: 0.9118 - val_precision: 0.6262 - val_recall: 0.7490\n",
      "Epoch 2264/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9133 - precision: 0.6456 - recall: 0.7503 - val_loss: 0.9114 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2265/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9129 - precision: 0.6457 - recall: 0.7507 - val_loss: 0.9110 - val_precision: 0.6263 - val_recall: 0.7494\n",
      "Epoch 2266/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9125 - precision: 0.6457 - recall: 0.7504 - val_loss: 0.9106 - val_precision: 0.6263 - val_recall: 0.7494\n",
      "Epoch 2267/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9121 - precision: 0.6456 - recall: 0.7503 - val_loss: 0.9103 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2268/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9117 - precision: 0.6457 - recall: 0.7502 - val_loss: 0.9099 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2269/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9114 - precision: 0.6457 - recall: 0.7502 - val_loss: 0.9095 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2270/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9110 - precision: 0.6457 - recall: 0.7502 - val_loss: 0.9091 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2271/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9106 - precision: 0.6458 - recall: 0.7502 - val_loss: 0.9088 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2272/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9102 - precision: 0.6458 - recall: 0.7501 - val_loss: 0.9084 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2273/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9099 - precision: 0.6457 - recall: 0.7499 - val_loss: 0.9080 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2274/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9095 - precision: 0.6457 - recall: 0.7499 - val_loss: 0.9076 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2275/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9091 - precision: 0.6457 - recall: 0.7499 - val_loss: 0.9073 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2276/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9087 - precision: 0.6457 - recall: 0.7498 - val_loss: 0.9069 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2277/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9084 - precision: 0.6458 - recall: 0.7497 - val_loss: 0.9065 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2278/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9080 - precision: 0.6459 - recall: 0.7498 - val_loss: 0.9062 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2279/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9076 - precision: 0.6458 - recall: 0.7498 - val_loss: 0.9058 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2280/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9073 - precision: 0.6457 - recall: 0.7498 - val_loss: 0.9054 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2281/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9069 - precision: 0.6458 - recall: 0.7498 - val_loss: 0.9050 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2282/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9065 - precision: 0.6460 - recall: 0.7498 - val_loss: 0.9047 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2283/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9061 - precision: 0.6460 - recall: 0.7498 - val_loss: 0.9043 - val_precision: 0.6264 - val_recall: 0.7490\n",
      "Epoch 2284/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9058 - precision: 0.6460 - recall: 0.7496 - val_loss: 0.9039 - val_precision: 0.6262 - val_recall: 0.7482\n",
      "Epoch 2285/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9054 - precision: 0.6460 - recall: 0.7497 - val_loss: 0.9036 - val_precision: 0.6262 - val_recall: 0.7482\n",
      "Epoch 2286/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9050 - precision: 0.6460 - recall: 0.7497 - val_loss: 0.9032 - val_precision: 0.6262 - val_recall: 0.7482\n",
      "Epoch 2287/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9047 - precision: 0.6460 - recall: 0.7497 - val_loss: 0.9028 - val_precision: 0.6262 - val_recall: 0.7482\n",
      "Epoch 2288/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9043 - precision: 0.6460 - recall: 0.7496 - val_loss: 0.9025 - val_precision: 0.6262 - val_recall: 0.7482\n",
      "Epoch 2289/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9039 - precision: 0.6460 - recall: 0.7496 - val_loss: 0.9021 - val_precision: 0.6262 - val_recall: 0.7482\n",
      "Epoch 2290/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9036 - precision: 0.6461 - recall: 0.7494 - val_loss: 0.9017 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2291/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9032 - precision: 0.6460 - recall: 0.7496 - val_loss: 0.9014 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2292/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9028 - precision: 0.6460 - recall: 0.7494 - val_loss: 0.9010 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2293/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9025 - precision: 0.6461 - recall: 0.7494 - val_loss: 0.9006 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2294/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9021 - precision: 0.6460 - recall: 0.7493 - val_loss: 0.9003 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2295/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9018 - precision: 0.6462 - recall: 0.7492 - val_loss: 0.8999 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2296/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.9014 - precision: 0.6462 - recall: 0.7492 - val_loss: 0.8996 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2297/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9010 - precision: 0.6462 - recall: 0.7492 - val_loss: 0.8992 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2298/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.9007 - precision: 0.6462 - recall: 0.7493 - val_loss: 0.8988 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2299/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.9003 - precision: 0.6462 - recall: 0.7493 - val_loss: 0.8985 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2300/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8999 - precision: 0.6462 - recall: 0.7490 - val_loss: 0.8981 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2301/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8996 - precision: 0.6462 - recall: 0.7493 - val_loss: 0.8977 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2302/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8992 - precision: 0.6462 - recall: 0.7490 - val_loss: 0.8974 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2303/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8989 - precision: 0.6462 - recall: 0.7490 - val_loss: 0.8970 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2304/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8985 - precision: 0.6462 - recall: 0.7489 - val_loss: 0.8967 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2305/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8981 - precision: 0.6461 - recall: 0.7488 - val_loss: 0.8963 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2306/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8978 - precision: 0.6461 - recall: 0.7485 - val_loss: 0.8959 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2307/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8974 - precision: 0.6461 - recall: 0.7485 - val_loss: 0.8956 - val_precision: 0.6264 - val_recall: 0.7482\n",
      "Epoch 2308/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8971 - precision: 0.6460 - recall: 0.7482 - val_loss: 0.8952 - val_precision: 0.6263 - val_recall: 0.7475\n",
      "Epoch 2309/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8967 - precision: 0.6461 - recall: 0.7480 - val_loss: 0.8949 - val_precision: 0.6266 - val_recall: 0.7471\n",
      "Epoch 2310/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8964 - precision: 0.6461 - recall: 0.7483 - val_loss: 0.8945 - val_precision: 0.6264 - val_recall: 0.7471\n",
      "Epoch 2311/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8960 - precision: 0.6460 - recall: 0.7484 - val_loss: 0.8942 - val_precision: 0.6263 - val_recall: 0.7475\n",
      "Epoch 2312/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8957 - precision: 0.6461 - recall: 0.7483 - val_loss: 0.8938 - val_precision: 0.6264 - val_recall: 0.7471\n",
      "Epoch 2313/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8953 - precision: 0.6462 - recall: 0.7482 - val_loss: 0.8935 - val_precision: 0.6266 - val_recall: 0.7471\n",
      "Epoch 2314/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8949 - precision: 0.6463 - recall: 0.7482 - val_loss: 0.8931 - val_precision: 0.6268 - val_recall: 0.7471\n",
      "Epoch 2315/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8946 - precision: 0.6462 - recall: 0.7482 - val_loss: 0.8928 - val_precision: 0.6268 - val_recall: 0.7471\n",
      "Epoch 2316/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8942 - precision: 0.6462 - recall: 0.7478 - val_loss: 0.8924 - val_precision: 0.6266 - val_recall: 0.7463\n",
      "Epoch 2317/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8939 - precision: 0.6463 - recall: 0.7476 - val_loss: 0.8921 - val_precision: 0.6266 - val_recall: 0.7463\n",
      "Epoch 2318/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8935 - precision: 0.6463 - recall: 0.7479 - val_loss: 0.8917 - val_precision: 0.6266 - val_recall: 0.7463\n",
      "Epoch 2319/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8932 - precision: 0.6464 - recall: 0.7476 - val_loss: 0.8914 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2320/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8928 - precision: 0.6464 - recall: 0.7478 - val_loss: 0.8910 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2321/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8925 - precision: 0.6464 - recall: 0.7479 - val_loss: 0.8907 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2322/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8921 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8903 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2323/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8918 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8900 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2324/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8914 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8896 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2325/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8911 - precision: 0.6465 - recall: 0.7478 - val_loss: 0.8893 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2326/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8907 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8889 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2327/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8904 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8886 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2328/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8900 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8882 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2329/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8897 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8879 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2330/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8893 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8875 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2331/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8890 - precision: 0.6465 - recall: 0.7479 - val_loss: 0.8872 - val_precision: 0.6265 - val_recall: 0.7459\n",
      "Epoch 2332/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8887 - precision: 0.6467 - recall: 0.7479 - val_loss: 0.8868 - val_precision: 0.6263 - val_recall: 0.7455\n",
      "Epoch 2333/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8883 - precision: 0.6467 - recall: 0.7479 - val_loss: 0.8865 - val_precision: 0.6263 - val_recall: 0.7455\n",
      "Epoch 2334/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8880 - precision: 0.6465 - recall: 0.7470 - val_loss: 0.8861 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2335/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8876 - precision: 0.6466 - recall: 0.7475 - val_loss: 0.8858 - val_precision: 0.6263 - val_recall: 0.7455\n",
      "Epoch 2336/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8873 - precision: 0.6466 - recall: 0.7474 - val_loss: 0.8855 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2337/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8869 - precision: 0.6464 - recall: 0.7469 - val_loss: 0.8851 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2338/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8866 - precision: 0.6464 - recall: 0.7468 - val_loss: 0.8848 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2339/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8863 - precision: 0.6466 - recall: 0.7471 - val_loss: 0.8844 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2340/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8859 - precision: 0.6465 - recall: 0.7470 - val_loss: 0.8841 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2341/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8856 - precision: 0.6465 - recall: 0.7470 - val_loss: 0.8837 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2342/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8852 - precision: 0.6466 - recall: 0.7471 - val_loss: 0.8834 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2343/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8849 - precision: 0.6466 - recall: 0.7466 - val_loss: 0.8831 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2344/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8846 - precision: 0.6466 - recall: 0.7469 - val_loss: 0.8827 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2345/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8842 - precision: 0.6466 - recall: 0.7464 - val_loss: 0.8824 - val_precision: 0.6264 - val_recall: 0.7451\n",
      "Epoch 2346/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8839 - precision: 0.6466 - recall: 0.7468 - val_loss: 0.8820 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2347/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8835 - precision: 0.6467 - recall: 0.7468 - val_loss: 0.8817 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2348/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8832 - precision: 0.6466 - recall: 0.7469 - val_loss: 0.8814 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2349/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8829 - precision: 0.6466 - recall: 0.7469 - val_loss: 0.8810 - val_precision: 0.6262 - val_recall: 0.7451\n",
      "Epoch 2350/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8825 - precision: 0.6466 - recall: 0.7464 - val_loss: 0.8807 - val_precision: 0.6268 - val_recall: 0.7451\n",
      "Epoch 2351/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8822 - precision: 0.6466 - recall: 0.7460 - val_loss: 0.8804 - val_precision: 0.6267 - val_recall: 0.7447\n",
      "Epoch 2352/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8819 - precision: 0.6466 - recall: 0.7464 - val_loss: 0.8800 - val_precision: 0.6267 - val_recall: 0.7447\n",
      "Epoch 2353/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8815 - precision: 0.6465 - recall: 0.7461 - val_loss: 0.8797 - val_precision: 0.6267 - val_recall: 0.7447\n",
      "Epoch 2354/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8812 - precision: 0.6467 - recall: 0.7461 - val_loss: 0.8794 - val_precision: 0.6266 - val_recall: 0.7444\n",
      "Epoch 2355/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8808 - precision: 0.6466 - recall: 0.7461 - val_loss: 0.8790 - val_precision: 0.6267 - val_recall: 0.7447\n",
      "Epoch 2356/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8805 - precision: 0.6467 - recall: 0.7461 - val_loss: 0.8787 - val_precision: 0.6272 - val_recall: 0.7444\n",
      "Epoch 2357/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8802 - precision: 0.6467 - recall: 0.7460 - val_loss: 0.8784 - val_precision: 0.6271 - val_recall: 0.7440\n",
      "Epoch 2358/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8798 - precision: 0.6468 - recall: 0.7460 - val_loss: 0.8780 - val_precision: 0.6271 - val_recall: 0.7440\n",
      "Epoch 2359/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8795 - precision: 0.6469 - recall: 0.7459 - val_loss: 0.8777 - val_precision: 0.6271 - val_recall: 0.7440\n",
      "Epoch 2360/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8792 - precision: 0.6470 - recall: 0.7459 - val_loss: 0.8774 - val_precision: 0.6273 - val_recall: 0.7440\n",
      "Epoch 2361/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8789 - precision: 0.6470 - recall: 0.7460 - val_loss: 0.8770 - val_precision: 0.6273 - val_recall: 0.7440\n",
      "Epoch 2362/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8785 - precision: 0.6470 - recall: 0.7459 - val_loss: 0.8767 - val_precision: 0.6272 - val_recall: 0.7436\n",
      "Epoch 2363/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8782 - precision: 0.6470 - recall: 0.7459 - val_loss: 0.8764 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2364/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8779 - precision: 0.6470 - recall: 0.7457 - val_loss: 0.8760 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2365/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8775 - precision: 0.6469 - recall: 0.7457 - val_loss: 0.8757 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2366/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8772 - precision: 0.6470 - recall: 0.7456 - val_loss: 0.8754 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2367/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8769 - precision: 0.6469 - recall: 0.7455 - val_loss: 0.8751 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2368/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8766 - precision: 0.6469 - recall: 0.7454 - val_loss: 0.8747 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2369/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8762 - precision: 0.6470 - recall: 0.7456 - val_loss: 0.8744 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2370/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8759 - precision: 0.6469 - recall: 0.7454 - val_loss: 0.8741 - val_precision: 0.6273 - val_recall: 0.7432\n",
      "Epoch 2371/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8756 - precision: 0.6469 - recall: 0.7455 - val_loss: 0.8738 - val_precision: 0.6271 - val_recall: 0.7432\n",
      "Epoch 2372/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8752 - precision: 0.6468 - recall: 0.7452 - val_loss: 0.8734 - val_precision: 0.6275 - val_recall: 0.7432\n",
      "Epoch 2373/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8749 - precision: 0.6471 - recall: 0.7452 - val_loss: 0.8731 - val_precision: 0.6277 - val_recall: 0.7432\n",
      "Epoch 2374/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8746 - precision: 0.6469 - recall: 0.7452 - val_loss: 0.8728 - val_precision: 0.6275 - val_recall: 0.7432\n",
      "Epoch 2375/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8743 - precision: 0.6472 - recall: 0.7454 - val_loss: 0.8725 - val_precision: 0.6275 - val_recall: 0.7432\n",
      "Epoch 2376/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8739 - precision: 0.6470 - recall: 0.7451 - val_loss: 0.8721 - val_precision: 0.6275 - val_recall: 0.7428\n",
      "Epoch 2377/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8736 - precision: 0.6471 - recall: 0.7452 - val_loss: 0.8718 - val_precision: 0.6277 - val_recall: 0.7432\n",
      "Epoch 2378/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8733 - precision: 0.6471 - recall: 0.7452 - val_loss: 0.8715 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 2379/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8730 - precision: 0.6472 - recall: 0.7454 - val_loss: 0.8712 - val_precision: 0.6275 - val_recall: 0.7428\n",
      "Epoch 2380/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8727 - precision: 0.6472 - recall: 0.7451 - val_loss: 0.8708 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 2381/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8723 - precision: 0.6472 - recall: 0.7447 - val_loss: 0.8705 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 2382/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8720 - precision: 0.6472 - recall: 0.7451 - val_loss: 0.8702 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2383/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8717 - precision: 0.6472 - recall: 0.7451 - val_loss: 0.8699 - val_precision: 0.6274 - val_recall: 0.7424\n",
      "Epoch 2384/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8714 - precision: 0.6472 - recall: 0.7451 - val_loss: 0.8696 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2385/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8711 - precision: 0.6472 - recall: 0.7448 - val_loss: 0.8692 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2386/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8707 - precision: 0.6472 - recall: 0.7447 - val_loss: 0.8689 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2387/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8704 - precision: 0.6472 - recall: 0.7445 - val_loss: 0.8686 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2388/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8701 - precision: 0.6473 - recall: 0.7445 - val_loss: 0.8683 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2389/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8698 - precision: 0.6474 - recall: 0.7443 - val_loss: 0.8680 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2390/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8695 - precision: 0.6474 - recall: 0.7441 - val_loss: 0.8677 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2391/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8691 - precision: 0.6474 - recall: 0.7443 - val_loss: 0.8673 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2392/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8688 - precision: 0.6474 - recall: 0.7442 - val_loss: 0.8670 - val_precision: 0.6278 - val_recall: 0.7424\n",
      "Epoch 2393/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8685 - precision: 0.6472 - recall: 0.7442 - val_loss: 0.8667 - val_precision: 0.6276 - val_recall: 0.7424\n",
      "Epoch 2394/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8682 - precision: 0.6474 - recall: 0.7439 - val_loss: 0.8664 - val_precision: 0.6280 - val_recall: 0.7424\n",
      "Epoch 2395/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8679 - precision: 0.6473 - recall: 0.7437 - val_loss: 0.8661 - val_precision: 0.6280 - val_recall: 0.7424\n",
      "Epoch 2396/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8676 - precision: 0.6474 - recall: 0.7442 - val_loss: 0.8658 - val_precision: 0.6280 - val_recall: 0.7424\n",
      "Epoch 2397/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8673 - precision: 0.6473 - recall: 0.7438 - val_loss: 0.8655 - val_precision: 0.6280 - val_recall: 0.7424\n",
      "Epoch 2398/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8669 - precision: 0.6474 - recall: 0.7437 - val_loss: 0.8651 - val_precision: 0.6283 - val_recall: 0.7424\n",
      "Epoch 2399/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8666 - precision: 0.6475 - recall: 0.7437 - val_loss: 0.8648 - val_precision: 0.6283 - val_recall: 0.7424\n",
      "Epoch 2400/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8663 - precision: 0.6474 - recall: 0.7438 - val_loss: 0.8645 - val_precision: 0.6280 - val_recall: 0.7424\n",
      "Epoch 2401/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8660 - precision: 0.6474 - recall: 0.7433 - val_loss: 0.8642 - val_precision: 0.6283 - val_recall: 0.7424\n",
      "Epoch 2402/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8657 - precision: 0.6474 - recall: 0.7432 - val_loss: 0.8639 - val_precision: 0.6283 - val_recall: 0.7424\n",
      "Epoch 2403/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8654 - precision: 0.6474 - recall: 0.7429 - val_loss: 0.8636 - val_precision: 0.6283 - val_recall: 0.7424\n",
      "Epoch 2404/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8651 - precision: 0.6474 - recall: 0.7429 - val_loss: 0.8633 - val_precision: 0.6289 - val_recall: 0.7424\n",
      "Epoch 2405/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8648 - precision: 0.6474 - recall: 0.7429 - val_loss: 0.8630 - val_precision: 0.6287 - val_recall: 0.7424\n",
      "Epoch 2406/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8645 - precision: 0.6474 - recall: 0.7428 - val_loss: 0.8627 - val_precision: 0.6291 - val_recall: 0.7424\n",
      "Epoch 2407/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8642 - precision: 0.6474 - recall: 0.7428 - val_loss: 0.8624 - val_precision: 0.6289 - val_recall: 0.7424\n",
      "Epoch 2408/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8638 - precision: 0.6474 - recall: 0.7428 - val_loss: 0.8621 - val_precision: 0.6291 - val_recall: 0.7424\n",
      "Epoch 2409/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8635 - precision: 0.6474 - recall: 0.7429 - val_loss: 0.8617 - val_precision: 0.6289 - val_recall: 0.7424\n",
      "Epoch 2410/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8632 - precision: 0.6473 - recall: 0.7427 - val_loss: 0.8614 - val_precision: 0.6292 - val_recall: 0.7420\n",
      "Epoch 2411/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8629 - precision: 0.6474 - recall: 0.7428 - val_loss: 0.8611 - val_precision: 0.6290 - val_recall: 0.7420\n",
      "Epoch 2412/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8626 - precision: 0.6474 - recall: 0.7428 - val_loss: 0.8608 - val_precision: 0.6292 - val_recall: 0.7420\n",
      "Epoch 2413/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8623 - precision: 0.6473 - recall: 0.7424 - val_loss: 0.8605 - val_precision: 0.6292 - val_recall: 0.7420\n",
      "Epoch 2414/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8620 - precision: 0.6473 - recall: 0.7422 - val_loss: 0.8602 - val_precision: 0.6294 - val_recall: 0.7420\n",
      "Epoch 2415/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8617 - precision: 0.6472 - recall: 0.7420 - val_loss: 0.8599 - val_precision: 0.6294 - val_recall: 0.7420\n",
      "Epoch 2416/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8614 - precision: 0.6472 - recall: 0.7420 - val_loss: 0.8596 - val_precision: 0.6294 - val_recall: 0.7420\n",
      "Epoch 2417/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8611 - precision: 0.6473 - recall: 0.7423 - val_loss: 0.8593 - val_precision: 0.6292 - val_recall: 0.7420\n",
      "Epoch 2418/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8608 - precision: 0.6473 - recall: 0.7422 - val_loss: 0.8590 - val_precision: 0.6294 - val_recall: 0.7420\n",
      "Epoch 2419/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8605 - precision: 0.6474 - recall: 0.7418 - val_loss: 0.8587 - val_precision: 0.6291 - val_recall: 0.7412\n",
      "Epoch 2420/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8602 - precision: 0.6475 - recall: 0.7417 - val_loss: 0.8584 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2421/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8599 - precision: 0.6475 - recall: 0.7414 - val_loss: 0.8581 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2422/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8596 - precision: 0.6475 - recall: 0.7417 - val_loss: 0.8578 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2423/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8593 - precision: 0.6475 - recall: 0.7417 - val_loss: 0.8575 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2424/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8590 - precision: 0.6475 - recall: 0.7414 - val_loss: 0.8572 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2425/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8587 - precision: 0.6475 - recall: 0.7413 - val_loss: 0.8569 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2426/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8584 - precision: 0.6475 - recall: 0.7413 - val_loss: 0.8566 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2427/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8581 - precision: 0.6475 - recall: 0.7413 - val_loss: 0.8563 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2428/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8578 - precision: 0.6475 - recall: 0.7413 - val_loss: 0.8560 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2429/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8575 - precision: 0.6475 - recall: 0.7413 - val_loss: 0.8557 - val_precision: 0.6291 - val_recall: 0.7412\n",
      "Epoch 2430/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8572 - precision: 0.6476 - recall: 0.7411 - val_loss: 0.8554 - val_precision: 0.6291 - val_recall: 0.7412\n",
      "Epoch 2431/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8569 - precision: 0.6477 - recall: 0.7411 - val_loss: 0.8551 - val_precision: 0.6291 - val_recall: 0.7412\n",
      "Epoch 2432/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8566 - precision: 0.6477 - recall: 0.7411 - val_loss: 0.8548 - val_precision: 0.6291 - val_recall: 0.7412\n",
      "Epoch 2433/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8563 - precision: 0.6476 - recall: 0.7408 - val_loss: 0.8545 - val_precision: 0.6294 - val_recall: 0.7409\n",
      "Epoch 2434/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8560 - precision: 0.6477 - recall: 0.7406 - val_loss: 0.8542 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2435/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8557 - precision: 0.6475 - recall: 0.7409 - val_loss: 0.8539 - val_precision: 0.6291 - val_recall: 0.7412\n",
      "Epoch 2436/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8554 - precision: 0.6476 - recall: 0.7413 - val_loss: 0.8536 - val_precision: 0.6293 - val_recall: 0.7412\n",
      "Epoch 2437/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8551 - precision: 0.6476 - recall: 0.7405 - val_loss: 0.8533 - val_precision: 0.6292 - val_recall: 0.7409\n",
      "Epoch 2438/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8548 - precision: 0.6476 - recall: 0.7405 - val_loss: 0.8530 - val_precision: 0.6294 - val_recall: 0.7409\n",
      "Epoch 2439/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8545 - precision: 0.6477 - recall: 0.7405 - val_loss: 0.8528 - val_precision: 0.6293 - val_recall: 0.7405\n",
      "Epoch 2440/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8542 - precision: 0.6477 - recall: 0.7406 - val_loss: 0.8525 - val_precision: 0.6295 - val_recall: 0.7412\n",
      "Epoch 2441/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8539 - precision: 0.6477 - recall: 0.7403 - val_loss: 0.8522 - val_precision: 0.6295 - val_recall: 0.7405\n",
      "Epoch 2442/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8537 - precision: 0.6477 - recall: 0.7400 - val_loss: 0.8519 - val_precision: 0.6297 - val_recall: 0.7405\n",
      "Epoch 2443/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8534 - precision: 0.6476 - recall: 0.7399 - val_loss: 0.8516 - val_precision: 0.6299 - val_recall: 0.7405\n",
      "Epoch 2444/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8531 - precision: 0.6474 - recall: 0.7395 - val_loss: 0.8513 - val_precision: 0.6297 - val_recall: 0.7397\n",
      "Epoch 2445/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8528 - precision: 0.6475 - recall: 0.7399 - val_loss: 0.8510 - val_precision: 0.6299 - val_recall: 0.7405\n",
      "Epoch 2446/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8525 - precision: 0.6475 - recall: 0.7394 - val_loss: 0.8507 - val_precision: 0.6297 - val_recall: 0.7397\n",
      "Epoch 2447/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8522 - precision: 0.6475 - recall: 0.7391 - val_loss: 0.8504 - val_precision: 0.6295 - val_recall: 0.7385\n",
      "Epoch 2448/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8519 - precision: 0.6476 - recall: 0.7392 - val_loss: 0.8501 - val_precision: 0.6297 - val_recall: 0.7397\n",
      "Epoch 2449/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8516 - precision: 0.6476 - recall: 0.7394 - val_loss: 0.8499 - val_precision: 0.6293 - val_recall: 0.7385\n",
      "Epoch 2450/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8513 - precision: 0.6476 - recall: 0.7396 - val_loss: 0.8496 - val_precision: 0.6297 - val_recall: 0.7397\n",
      "Epoch 2451/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8510 - precision: 0.6475 - recall: 0.7392 - val_loss: 0.8493 - val_precision: 0.6294 - val_recall: 0.7389\n",
      "Epoch 2452/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8508 - precision: 0.6476 - recall: 0.7392 - val_loss: 0.8490 - val_precision: 0.6294 - val_recall: 0.7389\n",
      "Epoch 2453/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8505 - precision: 0.6476 - recall: 0.7394 - val_loss: 0.8487 - val_precision: 0.6294 - val_recall: 0.7389\n",
      "Epoch 2454/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8502 - precision: 0.6477 - recall: 0.7394 - val_loss: 0.8484 - val_precision: 0.6293 - val_recall: 0.7385\n",
      "Epoch 2455/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8499 - precision: 0.6476 - recall: 0.7390 - val_loss: 0.8481 - val_precision: 0.6293 - val_recall: 0.7385\n",
      "Epoch 2456/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8496 - precision: 0.6475 - recall: 0.7387 - val_loss: 0.8478 - val_precision: 0.6295 - val_recall: 0.7385\n",
      "Epoch 2457/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8493 - precision: 0.6475 - recall: 0.7387 - val_loss: 0.8476 - val_precision: 0.6295 - val_recall: 0.7385\n",
      "Epoch 2458/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8490 - precision: 0.6475 - recall: 0.7389 - val_loss: 0.8473 - val_precision: 0.6295 - val_recall: 0.7385\n",
      "Epoch 2459/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8488 - precision: 0.6476 - recall: 0.7391 - val_loss: 0.8470 - val_precision: 0.6295 - val_recall: 0.7385\n",
      "Epoch 2460/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8485 - precision: 0.6475 - recall: 0.7386 - val_loss: 0.8467 - val_precision: 0.6298 - val_recall: 0.7381\n",
      "Epoch 2461/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8482 - precision: 0.6475 - recall: 0.7386 - val_loss: 0.8464 - val_precision: 0.6298 - val_recall: 0.7381\n",
      "Epoch 2462/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8479 - precision: 0.6475 - recall: 0.7386 - val_loss: 0.8461 - val_precision: 0.6299 - val_recall: 0.7377\n",
      "Epoch 2463/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8476 - precision: 0.6475 - recall: 0.7385 - val_loss: 0.8459 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2464/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8473 - precision: 0.6474 - recall: 0.7385 - val_loss: 0.8456 - val_precision: 0.6299 - val_recall: 0.7377\n",
      "Epoch 2465/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8471 - precision: 0.6474 - recall: 0.7385 - val_loss: 0.8453 - val_precision: 0.6299 - val_recall: 0.7377\n",
      "Epoch 2466/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8468 - precision: 0.6475 - recall: 0.7385 - val_loss: 0.8450 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2467/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8465 - precision: 0.6474 - recall: 0.7383 - val_loss: 0.8447 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2468/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8462 - precision: 0.6474 - recall: 0.7383 - val_loss: 0.8445 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2469/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8459 - precision: 0.6475 - recall: 0.7383 - val_loss: 0.8442 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2470/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8457 - precision: 0.6476 - recall: 0.7383 - val_loss: 0.8439 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2471/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8454 - precision: 0.6475 - recall: 0.7383 - val_loss: 0.8436 - val_precision: 0.6302 - val_recall: 0.7374\n",
      "Epoch 2472/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8451 - precision: 0.6474 - recall: 0.7383 - val_loss: 0.8434 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2473/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8448 - precision: 0.6476 - recall: 0.7383 - val_loss: 0.8431 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2474/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8446 - precision: 0.6476 - recall: 0.7383 - val_loss: 0.8428 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2475/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8443 - precision: 0.6476 - recall: 0.7381 - val_loss: 0.8425 - val_precision: 0.6300 - val_recall: 0.7374\n",
      "Epoch 2476/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8440 - precision: 0.6476 - recall: 0.7382 - val_loss: 0.8422 - val_precision: 0.6299 - val_recall: 0.7370\n",
      "Epoch 2477/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8437 - precision: 0.6477 - recall: 0.7381 - val_loss: 0.8420 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2478/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8435 - precision: 0.6478 - recall: 0.7380 - val_loss: 0.8417 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2479/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8432 - precision: 0.6478 - recall: 0.7380 - val_loss: 0.8414 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2480/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8429 - precision: 0.6480 - recall: 0.7380 - val_loss: 0.8411 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2481/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8426 - precision: 0.6481 - recall: 0.7380 - val_loss: 0.8409 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2482/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8424 - precision: 0.6480 - recall: 0.7380 - val_loss: 0.8406 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2483/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8421 - precision: 0.6481 - recall: 0.7380 - val_loss: 0.8403 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2484/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8418 - precision: 0.6482 - recall: 0.7377 - val_loss: 0.8401 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2485/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8415 - precision: 0.6482 - recall: 0.7378 - val_loss: 0.8398 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2486/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8413 - precision: 0.6483 - recall: 0.7375 - val_loss: 0.8395 - val_precision: 0.6305 - val_recall: 0.7370\n",
      "Epoch 2487/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8410 - precision: 0.6482 - recall: 0.7377 - val_loss: 0.8392 - val_precision: 0.6301 - val_recall: 0.7370\n",
      "Epoch 2488/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8407 - precision: 0.6483 - recall: 0.7375 - val_loss: 0.8390 - val_precision: 0.6305 - val_recall: 0.7370\n",
      "Epoch 2489/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8405 - precision: 0.6482 - recall: 0.7376 - val_loss: 0.8387 - val_precision: 0.6305 - val_recall: 0.7370\n",
      "Epoch 2490/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8402 - precision: 0.6482 - recall: 0.7372 - val_loss: 0.8384 - val_precision: 0.6307 - val_recall: 0.7370\n",
      "Epoch 2491/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8399 - precision: 0.6482 - recall: 0.7373 - val_loss: 0.8382 - val_precision: 0.6307 - val_recall: 0.7370\n",
      "Epoch 2492/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8396 - precision: 0.6482 - recall: 0.7373 - val_loss: 0.8379 - val_precision: 0.6305 - val_recall: 0.7370\n",
      "Epoch 2493/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8394 - precision: 0.6481 - recall: 0.7368 - val_loss: 0.8376 - val_precision: 0.6310 - val_recall: 0.7366\n",
      "Epoch 2494/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8391 - precision: 0.6482 - recall: 0.7371 - val_loss: 0.8374 - val_precision: 0.6308 - val_recall: 0.7366\n",
      "Epoch 2495/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8388 - precision: 0.6483 - recall: 0.7375 - val_loss: 0.8371 - val_precision: 0.6310 - val_recall: 0.7366\n",
      "Epoch 2496/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8386 - precision: 0.6481 - recall: 0.7367 - val_loss: 0.8368 - val_precision: 0.6310 - val_recall: 0.7366\n",
      "Epoch 2497/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8383 - precision: 0.6481 - recall: 0.7367 - val_loss: 0.8366 - val_precision: 0.6310 - val_recall: 0.7366\n",
      "Epoch 2498/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8380 - precision: 0.6480 - recall: 0.7367 - val_loss: 0.8363 - val_precision: 0.6310 - val_recall: 0.7366\n",
      "Epoch 2499/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8378 - precision: 0.6481 - recall: 0.7364 - val_loss: 0.8360 - val_precision: 0.6312 - val_recall: 0.7366\n",
      "Epoch 2500/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8375 - precision: 0.6482 - recall: 0.7362 - val_loss: 0.8358 - val_precision: 0.6314 - val_recall: 0.7366\n",
      "Epoch 2501/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8372 - precision: 0.6481 - recall: 0.7363 - val_loss: 0.8355 - val_precision: 0.6313 - val_recall: 0.7362\n",
      "Epoch 2502/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8370 - precision: 0.6482 - recall: 0.7362 - val_loss: 0.8353 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2503/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8367 - precision: 0.6481 - recall: 0.7359 - val_loss: 0.8350 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2504/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8365 - precision: 0.6482 - recall: 0.7363 - val_loss: 0.8347 - val_precision: 0.6312 - val_recall: 0.7358\n",
      "Epoch 2505/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8362 - precision: 0.6481 - recall: 0.7362 - val_loss: 0.8345 - val_precision: 0.6312 - val_recall: 0.7358\n",
      "Epoch 2506/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8359 - precision: 0.6481 - recall: 0.7361 - val_loss: 0.8342 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2507/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8357 - precision: 0.6481 - recall: 0.7361 - val_loss: 0.8339 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2508/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8354 - precision: 0.6482 - recall: 0.7359 - val_loss: 0.8337 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2509/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8352 - precision: 0.6482 - recall: 0.7359 - val_loss: 0.8334 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2510/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8349 - precision: 0.6483 - recall: 0.7359 - val_loss: 0.8332 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2511/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8346 - precision: 0.6483 - recall: 0.7358 - val_loss: 0.8329 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2512/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8344 - precision: 0.6483 - recall: 0.7358 - val_loss: 0.8327 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2513/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8341 - precision: 0.6483 - recall: 0.7358 - val_loss: 0.8324 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2514/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8339 - precision: 0.6483 - recall: 0.7358 - val_loss: 0.8321 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2515/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8336 - precision: 0.6484 - recall: 0.7357 - val_loss: 0.8319 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2516/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8333 - precision: 0.6484 - recall: 0.7358 - val_loss: 0.8316 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2517/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8331 - precision: 0.6486 - recall: 0.7358 - val_loss: 0.8314 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2518/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8328 - precision: 0.6485 - recall: 0.7357 - val_loss: 0.8311 - val_precision: 0.6314 - val_recall: 0.7358\n",
      "Epoch 2519/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8326 - precision: 0.6486 - recall: 0.7357 - val_loss: 0.8309 - val_precision: 0.6313 - val_recall: 0.7354\n",
      "Epoch 2520/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8323 - precision: 0.6486 - recall: 0.7358 - val_loss: 0.8306 - val_precision: 0.6314 - val_recall: 0.7350\n",
      "Epoch 2521/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8321 - precision: 0.6486 - recall: 0.7357 - val_loss: 0.8304 - val_precision: 0.6316 - val_recall: 0.7350\n",
      "Epoch 2522/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8318 - precision: 0.6486 - recall: 0.7357 - val_loss: 0.8301 - val_precision: 0.6318 - val_recall: 0.7350\n",
      "Epoch 2523/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8316 - precision: 0.6486 - recall: 0.7357 - val_loss: 0.8299 - val_precision: 0.6316 - val_recall: 0.7346\n",
      "Epoch 2524/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8313 - precision: 0.6487 - recall: 0.7357 - val_loss: 0.8296 - val_precision: 0.6316 - val_recall: 0.7346\n",
      "Epoch 2525/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8311 - precision: 0.6487 - recall: 0.7357 - val_loss: 0.8294 - val_precision: 0.6316 - val_recall: 0.7346\n",
      "Epoch 2526/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8308 - precision: 0.6488 - recall: 0.7355 - val_loss: 0.8291 - val_precision: 0.6315 - val_recall: 0.7342\n",
      "Epoch 2527/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8306 - precision: 0.6488 - recall: 0.7354 - val_loss: 0.8289 - val_precision: 0.6317 - val_recall: 0.7342\n",
      "Epoch 2528/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8303 - precision: 0.6488 - recall: 0.7354 - val_loss: 0.8286 - val_precision: 0.6317 - val_recall: 0.7342\n",
      "Epoch 2529/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8301 - precision: 0.6487 - recall: 0.7355 - val_loss: 0.8284 - val_precision: 0.6315 - val_recall: 0.7342\n",
      "Epoch 2530/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8298 - precision: 0.6488 - recall: 0.7354 - val_loss: 0.8281 - val_precision: 0.6317 - val_recall: 0.7342\n",
      "Epoch 2531/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8296 - precision: 0.6488 - recall: 0.7354 - val_loss: 0.8279 - val_precision: 0.6317 - val_recall: 0.7342\n",
      "Epoch 2532/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8293 - precision: 0.6488 - recall: 0.7355 - val_loss: 0.8276 - val_precision: 0.6317 - val_recall: 0.7342\n",
      "Epoch 2533/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8291 - precision: 0.6487 - recall: 0.7352 - val_loss: 0.8274 - val_precision: 0.6315 - val_recall: 0.7335\n",
      "Epoch 2534/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8288 - precision: 0.6488 - recall: 0.7352 - val_loss: 0.8271 - val_precision: 0.6315 - val_recall: 0.7335\n",
      "Epoch 2535/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8286 - precision: 0.6487 - recall: 0.7352 - val_loss: 0.8269 - val_precision: 0.6316 - val_recall: 0.7339\n",
      "Epoch 2536/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8283 - precision: 0.6488 - recall: 0.7352 - val_loss: 0.8266 - val_precision: 0.6316 - val_recall: 0.7339\n",
      "Epoch 2537/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8281 - precision: 0.6487 - recall: 0.7348 - val_loss: 0.8264 - val_precision: 0.6315 - val_recall: 0.7335\n",
      "Epoch 2538/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8278 - precision: 0.6487 - recall: 0.7349 - val_loss: 0.8261 - val_precision: 0.6316 - val_recall: 0.7331\n",
      "Epoch 2539/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8276 - precision: 0.6487 - recall: 0.7348 - val_loss: 0.8259 - val_precision: 0.6314 - val_recall: 0.7331\n",
      "Epoch 2540/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8273 - precision: 0.6487 - recall: 0.7348 - val_loss: 0.8257 - val_precision: 0.6316 - val_recall: 0.7331\n",
      "Epoch 2541/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8271 - precision: 0.6488 - recall: 0.7346 - val_loss: 0.8254 - val_precision: 0.6316 - val_recall: 0.7331\n",
      "Epoch 2542/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8269 - precision: 0.6487 - recall: 0.7344 - val_loss: 0.8252 - val_precision: 0.6316 - val_recall: 0.7331\n",
      "Epoch 2543/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8266 - precision: 0.6487 - recall: 0.7346 - val_loss: 0.8249 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2544/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8264 - precision: 0.6487 - recall: 0.7344 - val_loss: 0.8247 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2545/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8261 - precision: 0.6487 - recall: 0.7346 - val_loss: 0.8244 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2546/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8259 - precision: 0.6488 - recall: 0.7344 - val_loss: 0.8242 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2547/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8257 - precision: 0.6488 - recall: 0.7344 - val_loss: 0.8240 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2548/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8254 - precision: 0.6487 - recall: 0.7343 - val_loss: 0.8237 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2549/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8252 - precision: 0.6488 - recall: 0.7341 - val_loss: 0.8235 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2550/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8249 - precision: 0.6488 - recall: 0.7341 - val_loss: 0.8233 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2551/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8247 - precision: 0.6488 - recall: 0.7341 - val_loss: 0.8230 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2552/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8245 - precision: 0.6488 - recall: 0.7341 - val_loss: 0.8228 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2553/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8242 - precision: 0.6488 - recall: 0.7341 - val_loss: 0.8225 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2554/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8240 - precision: 0.6487 - recall: 0.7340 - val_loss: 0.8223 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2555/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8238 - precision: 0.6487 - recall: 0.7340 - val_loss: 0.8221 - val_precision: 0.6320 - val_recall: 0.7331\n",
      "Epoch 2556/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8235 - precision: 0.6487 - recall: 0.7340 - val_loss: 0.8218 - val_precision: 0.6321 - val_recall: 0.7327\n",
      "Epoch 2557/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8233 - precision: 0.6487 - recall: 0.7340 - val_loss: 0.8216 - val_precision: 0.6321 - val_recall: 0.7327\n",
      "Epoch 2558/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8231 - precision: 0.6488 - recall: 0.7341 - val_loss: 0.8214 - val_precision: 0.6321 - val_recall: 0.7327\n",
      "Epoch 2559/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8228 - precision: 0.6489 - recall: 0.7338 - val_loss: 0.8211 - val_precision: 0.6318 - val_recall: 0.7319\n",
      "Epoch 2560/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8226 - precision: 0.6489 - recall: 0.7335 - val_loss: 0.8209 - val_precision: 0.6318 - val_recall: 0.7319\n",
      "Epoch 2561/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8224 - precision: 0.6489 - recall: 0.7336 - val_loss: 0.8207 - val_precision: 0.6318 - val_recall: 0.7319\n",
      "Epoch 2562/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8221 - precision: 0.6489 - recall: 0.7336 - val_loss: 0.8204 - val_precision: 0.6318 - val_recall: 0.7319\n",
      "Epoch 2563/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8219 - precision: 0.6489 - recall: 0.7336 - val_loss: 0.8202 - val_precision: 0.6318 - val_recall: 0.7319\n",
      "Epoch 2564/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8217 - precision: 0.6490 - recall: 0.7336 - val_loss: 0.8200 - val_precision: 0.6318 - val_recall: 0.7319\n",
      "Epoch 2565/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8214 - precision: 0.6490 - recall: 0.7329 - val_loss: 0.8198 - val_precision: 0.6319 - val_recall: 0.7315\n",
      "Epoch 2566/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8212 - precision: 0.6489 - recall: 0.7330 - val_loss: 0.8195 - val_precision: 0.6321 - val_recall: 0.7319\n",
      "Epoch 2567/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8210 - precision: 0.6490 - recall: 0.7330 - val_loss: 0.8193 - val_precision: 0.6319 - val_recall: 0.7315\n",
      "Epoch 2568/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8207 - precision: 0.6490 - recall: 0.7329 - val_loss: 0.8191 - val_precision: 0.6319 - val_recall: 0.7315\n",
      "Epoch 2569/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8205 - precision: 0.6489 - recall: 0.7330 - val_loss: 0.8188 - val_precision: 0.6319 - val_recall: 0.7315\n",
      "Epoch 2570/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8203 - precision: 0.6489 - recall: 0.7325 - val_loss: 0.8186 - val_precision: 0.6319 - val_recall: 0.7315\n",
      "Epoch 2571/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8201 - precision: 0.6489 - recall: 0.7327 - val_loss: 0.8184 - val_precision: 0.6319 - val_recall: 0.7315\n",
      "Epoch 2572/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8198 - precision: 0.6490 - recall: 0.7325 - val_loss: 0.8182 - val_precision: 0.6319 - val_recall: 0.7315\n",
      "Epoch 2573/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8196 - precision: 0.6490 - recall: 0.7326 - val_loss: 0.8179 - val_precision: 0.6321 - val_recall: 0.7315\n",
      "Epoch 2574/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8194 - precision: 0.6490 - recall: 0.7324 - val_loss: 0.8177 - val_precision: 0.6322 - val_recall: 0.7311\n",
      "Epoch 2575/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8192 - precision: 0.6490 - recall: 0.7325 - val_loss: 0.8175 - val_precision: 0.6320 - val_recall: 0.7311\n",
      "Epoch 2576/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8189 - precision: 0.6489 - recall: 0.7321 - val_loss: 0.8173 - val_precision: 0.6320 - val_recall: 0.7304\n",
      "Epoch 2577/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8187 - precision: 0.6490 - recall: 0.7322 - val_loss: 0.8170 - val_precision: 0.6321 - val_recall: 0.7307\n",
      "Epoch 2578/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8185 - precision: 0.6491 - recall: 0.7324 - val_loss: 0.8168 - val_precision: 0.6320 - val_recall: 0.7304\n",
      "Epoch 2579/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8183 - precision: 0.6491 - recall: 0.7325 - val_loss: 0.8166 - val_precision: 0.6320 - val_recall: 0.7304\n",
      "Epoch 2580/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8180 - precision: 0.6490 - recall: 0.7324 - val_loss: 0.8164 - val_precision: 0.6321 - val_recall: 0.7307\n",
      "Epoch 2581/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8178 - precision: 0.6492 - recall: 0.7322 - val_loss: 0.8162 - val_precision: 0.6320 - val_recall: 0.7304\n",
      "Epoch 2582/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8176 - precision: 0.6492 - recall: 0.7320 - val_loss: 0.8159 - val_precision: 0.6317 - val_recall: 0.7296\n",
      "Epoch 2583/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8174 - precision: 0.6492 - recall: 0.7320 - val_loss: 0.8157 - val_precision: 0.6319 - val_recall: 0.7300\n",
      "Epoch 2584/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8171 - precision: 0.6492 - recall: 0.7318 - val_loss: 0.8155 - val_precision: 0.6317 - val_recall: 0.7296\n",
      "Epoch 2585/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8169 - precision: 0.6493 - recall: 0.7320 - val_loss: 0.8153 - val_precision: 0.6320 - val_recall: 0.7296\n",
      "Epoch 2586/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8167 - precision: 0.6491 - recall: 0.7316 - val_loss: 0.8151 - val_precision: 0.6320 - val_recall: 0.7296\n",
      "Epoch 2587/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8165 - precision: 0.6492 - recall: 0.7315 - val_loss: 0.8148 - val_precision: 0.6320 - val_recall: 0.7296\n",
      "Epoch 2588/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8163 - precision: 0.6492 - recall: 0.7318 - val_loss: 0.8146 - val_precision: 0.6320 - val_recall: 0.7296\n",
      "Epoch 2589/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8160 - precision: 0.6492 - recall: 0.7317 - val_loss: 0.8144 - val_precision: 0.6322 - val_recall: 0.7296\n",
      "Epoch 2590/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8158 - precision: 0.6491 - recall: 0.7315 - val_loss: 0.8142 - val_precision: 0.6324 - val_recall: 0.7296\n",
      "Epoch 2591/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8156 - precision: 0.6493 - recall: 0.7310 - val_loss: 0.8140 - val_precision: 0.6324 - val_recall: 0.7296\n",
      "Epoch 2592/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8154 - precision: 0.6494 - recall: 0.7317 - val_loss: 0.8137 - val_precision: 0.6324 - val_recall: 0.7296\n",
      "Epoch 2593/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8152 - precision: 0.6493 - recall: 0.7311 - val_loss: 0.8135 - val_precision: 0.6324 - val_recall: 0.7296\n",
      "Epoch 2594/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8150 - precision: 0.6493 - recall: 0.7308 - val_loss: 0.8133 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2595/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8147 - precision: 0.6493 - recall: 0.7308 - val_loss: 0.8131 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2596/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8145 - precision: 0.6496 - recall: 0.7308 - val_loss: 0.8129 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2597/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8143 - precision: 0.6495 - recall: 0.7307 - val_loss: 0.8127 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2598/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8141 - precision: 0.6494 - recall: 0.7307 - val_loss: 0.8125 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2599/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8139 - precision: 0.6496 - recall: 0.7306 - val_loss: 0.8122 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2600/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8137 - precision: 0.6497 - recall: 0.7302 - val_loss: 0.8120 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2601/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8135 - precision: 0.6497 - recall: 0.7304 - val_loss: 0.8118 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2602/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8132 - precision: 0.6498 - recall: 0.7311 - val_loss: 0.8116 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2603/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8130 - precision: 0.6499 - recall: 0.7303 - val_loss: 0.8114 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2604/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8128 - precision: 0.6499 - recall: 0.7304 - val_loss: 0.8112 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2605/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8126 - precision: 0.6499 - recall: 0.7303 - val_loss: 0.8110 - val_precision: 0.6323 - val_recall: 0.7292\n",
      "Epoch 2606/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8124 - precision: 0.6498 - recall: 0.7302 - val_loss: 0.8108 - val_precision: 0.6321 - val_recall: 0.7288\n",
      "Epoch 2607/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8122 - precision: 0.6498 - recall: 0.7301 - val_loss: 0.8106 - val_precision: 0.6321 - val_recall: 0.7288\n",
      "Epoch 2608/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8120 - precision: 0.6499 - recall: 0.7302 - val_loss: 0.8103 - val_precision: 0.6321 - val_recall: 0.7288\n",
      "Epoch 2609/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8118 - precision: 0.6498 - recall: 0.7301 - val_loss: 0.8101 - val_precision: 0.6321 - val_recall: 0.7288\n",
      "Epoch 2610/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8115 - precision: 0.6498 - recall: 0.7299 - val_loss: 0.8099 - val_precision: 0.6321 - val_recall: 0.7288\n",
      "Epoch 2611/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8113 - precision: 0.6498 - recall: 0.7298 - val_loss: 0.8097 - val_precision: 0.6323 - val_recall: 0.7288\n",
      "Epoch 2612/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8111 - precision: 0.6498 - recall: 0.7298 - val_loss: 0.8095 - val_precision: 0.6323 - val_recall: 0.7288\n",
      "Epoch 2613/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8109 - precision: 0.6498 - recall: 0.7297 - val_loss: 0.8093 - val_precision: 0.6323 - val_recall: 0.7288\n",
      "Epoch 2614/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8107 - precision: 0.6498 - recall: 0.7296 - val_loss: 0.8091 - val_precision: 0.6323 - val_recall: 0.7288\n",
      "Epoch 2615/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8105 - precision: 0.6498 - recall: 0.7298 - val_loss: 0.8089 - val_precision: 0.6323 - val_recall: 0.7288\n",
      "Epoch 2616/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8103 - precision: 0.6498 - recall: 0.7297 - val_loss: 0.8087 - val_precision: 0.6323 - val_recall: 0.7288\n",
      "Epoch 2617/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8101 - precision: 0.6498 - recall: 0.7297 - val_loss: 0.8085 - val_precision: 0.6326 - val_recall: 0.7288\n",
      "Epoch 2618/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8099 - precision: 0.6498 - recall: 0.7296 - val_loss: 0.8083 - val_precision: 0.6326 - val_recall: 0.7288\n",
      "Epoch 2619/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8097 - precision: 0.6498 - recall: 0.7294 - val_loss: 0.8081 - val_precision: 0.6326 - val_recall: 0.7288\n",
      "Epoch 2620/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8095 - precision: 0.6498 - recall: 0.7296 - val_loss: 0.8079 - val_precision: 0.6330 - val_recall: 0.7288\n",
      "Epoch 2621/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8093 - precision: 0.6498 - recall: 0.7296 - val_loss: 0.8077 - val_precision: 0.6332 - val_recall: 0.7288\n",
      "Epoch 2622/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8091 - precision: 0.6498 - recall: 0.7296 - val_loss: 0.8075 - val_precision: 0.6330 - val_recall: 0.7288\n",
      "Epoch 2623/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8089 - precision: 0.6498 - recall: 0.7294 - val_loss: 0.8073 - val_precision: 0.6332 - val_recall: 0.7288\n",
      "Epoch 2624/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8087 - precision: 0.6497 - recall: 0.7292 - val_loss: 0.8071 - val_precision: 0.6332 - val_recall: 0.7288\n",
      "Epoch 2625/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8085 - precision: 0.6498 - recall: 0.7293 - val_loss: 0.8069 - val_precision: 0.6332 - val_recall: 0.7288\n",
      "Epoch 2626/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8083 - precision: 0.6497 - recall: 0.7292 - val_loss: 0.8067 - val_precision: 0.6332 - val_recall: 0.7288\n",
      "Epoch 2627/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8081 - precision: 0.6498 - recall: 0.7290 - val_loss: 0.8065 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2628/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8079 - precision: 0.6498 - recall: 0.7290 - val_loss: 0.8063 - val_precision: 0.6331 - val_recall: 0.7284\n",
      "Epoch 2629/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8077 - precision: 0.6498 - recall: 0.7289 - val_loss: 0.8061 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2630/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8075 - precision: 0.6497 - recall: 0.7288 - val_loss: 0.8059 - val_precision: 0.6335 - val_recall: 0.7284\n",
      "Epoch 2631/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8073 - precision: 0.6498 - recall: 0.7289 - val_loss: 0.8057 - val_precision: 0.6335 - val_recall: 0.7284\n",
      "Epoch 2632/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8071 - precision: 0.6498 - recall: 0.7289 - val_loss: 0.8055 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2633/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8069 - precision: 0.6498 - recall: 0.7289 - val_loss: 0.8053 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2634/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8067 - precision: 0.6498 - recall: 0.7289 - val_loss: 0.8051 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2635/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8065 - precision: 0.6499 - recall: 0.7289 - val_loss: 0.8049 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2636/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8063 - precision: 0.6499 - recall: 0.7289 - val_loss: 0.8047 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2637/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8061 - precision: 0.6500 - recall: 0.7289 - val_loss: 0.8045 - val_precision: 0.6335 - val_recall: 0.7284\n",
      "Epoch 2638/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8059 - precision: 0.6499 - recall: 0.7288 - val_loss: 0.8043 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2639/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8057 - precision: 0.6499 - recall: 0.7287 - val_loss: 0.8041 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2640/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8055 - precision: 0.6499 - recall: 0.7287 - val_loss: 0.8039 - val_precision: 0.6333 - val_recall: 0.7284\n",
      "Epoch 2641/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8053 - precision: 0.6499 - recall: 0.7287 - val_loss: 0.8037 - val_precision: 0.6337 - val_recall: 0.7284\n",
      "Epoch 2642/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8051 - precision: 0.6498 - recall: 0.7282 - val_loss: 0.8035 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2643/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8049 - precision: 0.6500 - recall: 0.7283 - val_loss: 0.8033 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2644/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8047 - precision: 0.6499 - recall: 0.7280 - val_loss: 0.8031 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2645/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8045 - precision: 0.6500 - recall: 0.7280 - val_loss: 0.8029 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2646/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8043 - precision: 0.6500 - recall: 0.7280 - val_loss: 0.8027 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2647/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8041 - precision: 0.6500 - recall: 0.7280 - val_loss: 0.8025 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2648/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8039 - precision: 0.6500 - recall: 0.7280 - val_loss: 0.8023 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2649/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8037 - precision: 0.6500 - recall: 0.7280 - val_loss: 0.8022 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2650/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8035 - precision: 0.6501 - recall: 0.7279 - val_loss: 0.8020 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2651/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8033 - precision: 0.6501 - recall: 0.7280 - val_loss: 0.8018 - val_precision: 0.6336 - val_recall: 0.7280\n",
      "Epoch 2652/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8031 - precision: 0.6501 - recall: 0.7279 - val_loss: 0.8016 - val_precision: 0.6335 - val_recall: 0.7276\n",
      "Epoch 2653/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8030 - precision: 0.6501 - recall: 0.7279 - val_loss: 0.8014 - val_precision: 0.6335 - val_recall: 0.7276\n",
      "Epoch 2654/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8028 - precision: 0.6501 - recall: 0.7279 - val_loss: 0.8012 - val_precision: 0.6335 - val_recall: 0.7276\n",
      "Epoch 2655/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.8026 - precision: 0.6501 - recall: 0.7279 - val_loss: 0.8010 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2656/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.8024 - precision: 0.6503 - recall: 0.7279 - val_loss: 0.8008 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2657/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8022 - precision: 0.6502 - recall: 0.7279 - val_loss: 0.8006 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2658/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8020 - precision: 0.6502 - recall: 0.7279 - val_loss: 0.8004 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2659/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8018 - precision: 0.6502 - recall: 0.7278 - val_loss: 0.8003 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2660/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8016 - precision: 0.6502 - recall: 0.7276 - val_loss: 0.8001 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2661/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.8014 - precision: 0.6502 - recall: 0.7276 - val_loss: 0.7999 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2662/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8013 - precision: 0.6502 - recall: 0.7276 - val_loss: 0.7997 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2663/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8011 - precision: 0.6504 - recall: 0.7276 - val_loss: 0.7995 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2664/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8009 - precision: 0.6502 - recall: 0.7274 - val_loss: 0.7993 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2665/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8007 - precision: 0.6503 - recall: 0.7275 - val_loss: 0.7991 - val_precision: 0.6338 - val_recall: 0.7272\n",
      "Epoch 2666/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8005 - precision: 0.6503 - recall: 0.7274 - val_loss: 0.7990 - val_precision: 0.6340 - val_recall: 0.7272\n",
      "Epoch 2667/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8003 - precision: 0.6504 - recall: 0.7273 - val_loss: 0.7988 - val_precision: 0.6340 - val_recall: 0.7272\n",
      "Epoch 2668/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8001 - precision: 0.6503 - recall: 0.7273 - val_loss: 0.7986 - val_precision: 0.6340 - val_recall: 0.7272\n",
      "Epoch 2669/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.8000 - precision: 0.6503 - recall: 0.7273 - val_loss: 0.7984 - val_precision: 0.6342 - val_recall: 0.7272\n",
      "Epoch 2670/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7998 - precision: 0.6504 - recall: 0.7273 - val_loss: 0.7982 - val_precision: 0.6342 - val_recall: 0.7272\n",
      "Epoch 2671/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7996 - precision: 0.6503 - recall: 0.7274 - val_loss: 0.7980 - val_precision: 0.6340 - val_recall: 0.7272\n",
      "Epoch 2672/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7994 - precision: 0.6505 - recall: 0.7271 - val_loss: 0.7979 - val_precision: 0.6341 - val_recall: 0.7268\n",
      "Epoch 2673/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7992 - precision: 0.6505 - recall: 0.7271 - val_loss: 0.7977 - val_precision: 0.6342 - val_recall: 0.7265\n",
      "Epoch 2674/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7991 - precision: 0.6505 - recall: 0.7271 - val_loss: 0.7975 - val_precision: 0.6344 - val_recall: 0.7265\n",
      "Epoch 2675/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7989 - precision: 0.6503 - recall: 0.7271 - val_loss: 0.7973 - val_precision: 0.6344 - val_recall: 0.7265\n",
      "Epoch 2676/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7987 - precision: 0.6503 - recall: 0.7271 - val_loss: 0.7971 - val_precision: 0.6344 - val_recall: 0.7265\n",
      "Epoch 2677/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7985 - precision: 0.6504 - recall: 0.7271 - val_loss: 0.7970 - val_precision: 0.6344 - val_recall: 0.7265\n",
      "Epoch 2678/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7983 - precision: 0.6504 - recall: 0.7270 - val_loss: 0.7968 - val_precision: 0.6344 - val_recall: 0.7265\n",
      "Epoch 2679/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7982 - precision: 0.6505 - recall: 0.7270 - val_loss: 0.7966 - val_precision: 0.6343 - val_recall: 0.7261\n",
      "Epoch 2680/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7980 - precision: 0.6505 - recall: 0.7270 - val_loss: 0.7964 - val_precision: 0.6343 - val_recall: 0.7261\n",
      "Epoch 2681/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7978 - precision: 0.6504 - recall: 0.7270 - val_loss: 0.7963 - val_precision: 0.6343 - val_recall: 0.7261\n",
      "Epoch 2682/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7976 - precision: 0.6505 - recall: 0.7265 - val_loss: 0.7961 - val_precision: 0.6343 - val_recall: 0.7261\n",
      "Epoch 2683/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7974 - precision: 0.6506 - recall: 0.7269 - val_loss: 0.7959 - val_precision: 0.6343 - val_recall: 0.7261\n",
      "Epoch 2684/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7973 - precision: 0.6504 - recall: 0.7265 - val_loss: 0.7957 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2685/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7971 - precision: 0.6506 - recall: 0.7269 - val_loss: 0.7956 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2686/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7969 - precision: 0.6505 - recall: 0.7261 - val_loss: 0.7954 - val_precision: 0.6347 - val_recall: 0.7261\n",
      "Epoch 2687/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7967 - precision: 0.6504 - recall: 0.7261 - val_loss: 0.7952 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2688/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7966 - precision: 0.6504 - recall: 0.7264 - val_loss: 0.7950 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2689/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7964 - precision: 0.6504 - recall: 0.7262 - val_loss: 0.7949 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2690/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7962 - precision: 0.6504 - recall: 0.7262 - val_loss: 0.7947 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2691/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7960 - precision: 0.6505 - recall: 0.7261 - val_loss: 0.7945 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2692/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7959 - precision: 0.6504 - recall: 0.7264 - val_loss: 0.7943 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2693/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7957 - precision: 0.6505 - recall: 0.7264 - val_loss: 0.7942 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2694/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7955 - precision: 0.6506 - recall: 0.7262 - val_loss: 0.7940 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2695/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7954 - precision: 0.6505 - recall: 0.7261 - val_loss: 0.7938 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2696/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7952 - precision: 0.6506 - recall: 0.7261 - val_loss: 0.7937 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2697/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7950 - precision: 0.6506 - recall: 0.7259 - val_loss: 0.7935 - val_precision: 0.6347 - val_recall: 0.7261\n",
      "Epoch 2698/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7948 - precision: 0.6506 - recall: 0.7264 - val_loss: 0.7933 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2699/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7947 - precision: 0.6507 - recall: 0.7262 - val_loss: 0.7932 - val_precision: 0.6346 - val_recall: 0.7257\n",
      "Epoch 2700/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7945 - precision: 0.6506 - recall: 0.7260 - val_loss: 0.7930 - val_precision: 0.6345 - val_recall: 0.7261\n",
      "Epoch 2701/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7943 - precision: 0.6507 - recall: 0.7261 - val_loss: 0.7928 - val_precision: 0.6346 - val_recall: 0.7257\n",
      "Epoch 2702/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7942 - precision: 0.6507 - recall: 0.7262 - val_loss: 0.7927 - val_precision: 0.6344 - val_recall: 0.7257\n",
      "Epoch 2703/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7940 - precision: 0.6507 - recall: 0.7261 - val_loss: 0.7925 - val_precision: 0.6346 - val_recall: 0.7257\n",
      "Epoch 2704/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7938 - precision: 0.6507 - recall: 0.7261 - val_loss: 0.7923 - val_precision: 0.6343 - val_recall: 0.7261\n",
      "Epoch 2705/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7937 - precision: 0.6507 - recall: 0.7259 - val_loss: 0.7922 - val_precision: 0.6344 - val_recall: 0.7253\n",
      "Epoch 2706/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7935 - precision: 0.6507 - recall: 0.7259 - val_loss: 0.7920 - val_precision: 0.6344 - val_recall: 0.7253\n",
      "Epoch 2707/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7933 - precision: 0.6506 - recall: 0.7255 - val_loss: 0.7918 - val_precision: 0.6344 - val_recall: 0.7253\n",
      "Epoch 2708/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7932 - precision: 0.6508 - recall: 0.7261 - val_loss: 0.7917 - val_precision: 0.6344 - val_recall: 0.7253\n",
      "Epoch 2709/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7930 - precision: 0.6507 - recall: 0.7256 - val_loss: 0.7915 - val_precision: 0.6344 - val_recall: 0.7253\n",
      "Epoch 2710/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7929 - precision: 0.6507 - recall: 0.7259 - val_loss: 0.7913 - val_precision: 0.6344 - val_recall: 0.7253\n",
      "Epoch 2711/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7927 - precision: 0.6509 - recall: 0.7252 - val_loss: 0.7912 - val_precision: 0.6343 - val_recall: 0.7249\n",
      "Epoch 2712/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7925 - precision: 0.6509 - recall: 0.7255 - val_loss: 0.7910 - val_precision: 0.6343 - val_recall: 0.7249\n",
      "Epoch 2713/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7924 - precision: 0.6510 - recall: 0.7252 - val_loss: 0.7909 - val_precision: 0.6346 - val_recall: 0.7245\n",
      "Epoch 2714/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7922 - precision: 0.6511 - recall: 0.7252 - val_loss: 0.7907 - val_precision: 0.6346 - val_recall: 0.7245\n",
      "Epoch 2715/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7920 - precision: 0.6510 - recall: 0.7251 - val_loss: 0.7905 - val_precision: 0.6346 - val_recall: 0.7245\n",
      "Epoch 2716/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7919 - precision: 0.6511 - recall: 0.7252 - val_loss: 0.7904 - val_precision: 0.6346 - val_recall: 0.7245\n",
      "Epoch 2717/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7917 - precision: 0.6510 - recall: 0.7251 - val_loss: 0.7902 - val_precision: 0.6346 - val_recall: 0.7245\n",
      "Epoch 2718/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7916 - precision: 0.6511 - recall: 0.7250 - val_loss: 0.7901 - val_precision: 0.6346 - val_recall: 0.7245\n",
      "Epoch 2719/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7914 - precision: 0.6510 - recall: 0.7247 - val_loss: 0.7899 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2720/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7912 - precision: 0.6511 - recall: 0.7250 - val_loss: 0.7898 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2721/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7911 - precision: 0.6511 - recall: 0.7254 - val_loss: 0.7896 - val_precision: 0.6346 - val_recall: 0.7245\n",
      "Epoch 2722/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7909 - precision: 0.6511 - recall: 0.7251 - val_loss: 0.7894 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2723/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7908 - precision: 0.6509 - recall: 0.7245 - val_loss: 0.7893 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2724/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7906 - precision: 0.6510 - recall: 0.7247 - val_loss: 0.7891 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2725/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7905 - precision: 0.6509 - recall: 0.7245 - val_loss: 0.7890 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2726/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7903 - precision: 0.6511 - recall: 0.7247 - val_loss: 0.7888 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2727/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7901 - precision: 0.6511 - recall: 0.7247 - val_loss: 0.7887 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2728/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7900 - precision: 0.6511 - recall: 0.7248 - val_loss: 0.7885 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2729/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7898 - precision: 0.6510 - recall: 0.7243 - val_loss: 0.7884 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2730/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7897 - precision: 0.6511 - recall: 0.7247 - val_loss: 0.7882 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2731/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7895 - precision: 0.6512 - recall: 0.7246 - val_loss: 0.7880 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2732/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7894 - precision: 0.6512 - recall: 0.7246 - val_loss: 0.7879 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2733/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7892 - precision: 0.6510 - recall: 0.7241 - val_loss: 0.7877 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2734/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7891 - precision: 0.6512 - recall: 0.7241 - val_loss: 0.7876 - val_precision: 0.6347 - val_recall: 0.7241\n",
      "Epoch 2735/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7889 - precision: 0.6514 - recall: 0.7236 - val_loss: 0.7874 - val_precision: 0.6348 - val_recall: 0.7237\n",
      "Epoch 2736/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7888 - precision: 0.6512 - recall: 0.7239 - val_loss: 0.7873 - val_precision: 0.6348 - val_recall: 0.7237\n",
      "Epoch 2737/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7886 - precision: 0.6512 - recall: 0.7241 - val_loss: 0.7871 - val_precision: 0.6346 - val_recall: 0.7237\n",
      "Epoch 2738/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7885 - precision: 0.6512 - recall: 0.7236 - val_loss: 0.7870 - val_precision: 0.6348 - val_recall: 0.7237\n",
      "Epoch 2739/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7883 - precision: 0.6514 - recall: 0.7233 - val_loss: 0.7869 - val_precision: 0.6350 - val_recall: 0.7237\n",
      "Epoch 2740/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7882 - precision: 0.6514 - recall: 0.7232 - val_loss: 0.7867 - val_precision: 0.6350 - val_recall: 0.7237\n",
      "Epoch 2741/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7880 - precision: 0.6514 - recall: 0.7233 - val_loss: 0.7866 - val_precision: 0.6350 - val_recall: 0.7237\n",
      "Epoch 2742/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7879 - precision: 0.6515 - recall: 0.7234 - val_loss: 0.7864 - val_precision: 0.6350 - val_recall: 0.7237\n",
      "Epoch 2743/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7877 - precision: 0.6515 - recall: 0.7236 - val_loss: 0.7863 - val_precision: 0.6348 - val_recall: 0.7237\n",
      "Epoch 2744/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7876 - precision: 0.6516 - recall: 0.7237 - val_loss: 0.7861 - val_precision: 0.6348 - val_recall: 0.7237\n",
      "Epoch 2745/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7874 - precision: 0.6516 - recall: 0.7237 - val_loss: 0.7860 - val_precision: 0.6350 - val_recall: 0.7237\n",
      "Epoch 2746/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7873 - precision: 0.6517 - recall: 0.7234 - val_loss: 0.7858 - val_precision: 0.6352 - val_recall: 0.7237\n",
      "Epoch 2747/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7871 - precision: 0.6517 - recall: 0.7236 - val_loss: 0.7857 - val_precision: 0.6352 - val_recall: 0.7237\n",
      "Epoch 2748/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7870 - precision: 0.6517 - recall: 0.7233 - val_loss: 0.7855 - val_precision: 0.6350 - val_recall: 0.7237\n",
      "Epoch 2749/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7868 - precision: 0.6518 - recall: 0.7233 - val_loss: 0.7854 - val_precision: 0.6353 - val_recall: 0.7233\n",
      "Epoch 2750/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7867 - precision: 0.6518 - recall: 0.7233 - val_loss: 0.7852 - val_precision: 0.6353 - val_recall: 0.7233\n",
      "Epoch 2751/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7865 - precision: 0.6518 - recall: 0.7236 - val_loss: 0.7851 - val_precision: 0.6353 - val_recall: 0.7233\n",
      "Epoch 2752/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7864 - precision: 0.6518 - recall: 0.7232 - val_loss: 0.7850 - val_precision: 0.6353 - val_recall: 0.7233\n",
      "Epoch 2753/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7863 - precision: 0.6519 - recall: 0.7236 - val_loss: 0.7848 - val_precision: 0.6353 - val_recall: 0.7233\n",
      "Epoch 2754/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7861 - precision: 0.6519 - recall: 0.7232 - val_loss: 0.7847 - val_precision: 0.6353 - val_recall: 0.7233\n",
      "Epoch 2755/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7860 - precision: 0.6519 - recall: 0.7237 - val_loss: 0.7845 - val_precision: 0.6353 - val_recall: 0.7233\n",
      "Epoch 2756/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7858 - precision: 0.6519 - recall: 0.7233 - val_loss: 0.7844 - val_precision: 0.6356 - val_recall: 0.7233\n",
      "Epoch 2757/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7857 - precision: 0.6520 - recall: 0.7232 - val_loss: 0.7843 - val_precision: 0.6356 - val_recall: 0.7233\n",
      "Epoch 2758/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7856 - precision: 0.6521 - recall: 0.7229 - val_loss: 0.7841 - val_precision: 0.6358 - val_recall: 0.7233\n",
      "Epoch 2759/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7854 - precision: 0.6520 - recall: 0.7231 - val_loss: 0.7840 - val_precision: 0.6356 - val_recall: 0.7233\n",
      "Epoch 2760/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7853 - precision: 0.6520 - recall: 0.7231 - val_loss: 0.7838 - val_precision: 0.6361 - val_recall: 0.7230\n",
      "Epoch 2761/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7851 - precision: 0.6520 - recall: 0.7231 - val_loss: 0.7837 - val_precision: 0.6359 - val_recall: 0.7230\n",
      "Epoch 2762/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7850 - precision: 0.6520 - recall: 0.7231 - val_loss: 0.7836 - val_precision: 0.6359 - val_recall: 0.7230\n",
      "Epoch 2763/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7849 - precision: 0.6522 - recall: 0.7232 - val_loss: 0.7834 - val_precision: 0.6359 - val_recall: 0.7230\n",
      "Epoch 2764/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7847 - precision: 0.6522 - recall: 0.7231 - val_loss: 0.7833 - val_precision: 0.6359 - val_recall: 0.7230\n",
      "Epoch 2765/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7846 - precision: 0.6522 - recall: 0.7229 - val_loss: 0.7831 - val_precision: 0.6359 - val_recall: 0.7230\n",
      "Epoch 2766/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7844 - precision: 0.6522 - recall: 0.7229 - val_loss: 0.7830 - val_precision: 0.6361 - val_recall: 0.7230\n",
      "Epoch 2767/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7843 - precision: 0.6523 - recall: 0.7228 - val_loss: 0.7829 - val_precision: 0.6360 - val_recall: 0.7226\n",
      "Epoch 2768/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7842 - precision: 0.6523 - recall: 0.7228 - val_loss: 0.7827 - val_precision: 0.6361 - val_recall: 0.7230\n",
      "Epoch 2769/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7840 - precision: 0.6522 - recall: 0.7229 - val_loss: 0.7826 - val_precision: 0.6361 - val_recall: 0.7230\n",
      "Epoch 2770/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7839 - precision: 0.6523 - recall: 0.7231 - val_loss: 0.7825 - val_precision: 0.6361 - val_recall: 0.7230\n",
      "Epoch 2771/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7838 - precision: 0.6524 - recall: 0.7231 - val_loss: 0.7823 - val_precision: 0.6360 - val_recall: 0.7226\n",
      "Epoch 2772/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7836 - precision: 0.6523 - recall: 0.7228 - val_loss: 0.7822 - val_precision: 0.6362 - val_recall: 0.7226\n",
      "Epoch 2773/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7835 - precision: 0.6524 - recall: 0.7231 - val_loss: 0.7821 - val_precision: 0.6362 - val_recall: 0.7226\n",
      "Epoch 2774/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7834 - precision: 0.6522 - recall: 0.7224 - val_loss: 0.7819 - val_precision: 0.6362 - val_recall: 0.7226\n",
      "Epoch 2775/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7832 - precision: 0.6523 - recall: 0.7225 - val_loss: 0.7818 - val_precision: 0.6362 - val_recall: 0.7226\n",
      "Epoch 2776/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7831 - precision: 0.6524 - recall: 0.7229 - val_loss: 0.7817 - val_precision: 0.6362 - val_recall: 0.7226\n",
      "Epoch 2777/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7830 - precision: 0.6523 - recall: 0.7228 - val_loss: 0.7815 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2778/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7828 - precision: 0.6523 - recall: 0.7227 - val_loss: 0.7814 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2779/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7827 - precision: 0.6522 - recall: 0.7220 - val_loss: 0.7813 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2780/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7826 - precision: 0.6524 - recall: 0.7227 - val_loss: 0.7811 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2781/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7824 - precision: 0.6523 - recall: 0.7222 - val_loss: 0.7810 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2782/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7823 - precision: 0.6522 - recall: 0.7220 - val_loss: 0.7809 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2783/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7822 - precision: 0.6522 - recall: 0.7217 - val_loss: 0.7808 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2784/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7820 - precision: 0.6524 - recall: 0.7219 - val_loss: 0.7806 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2785/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7819 - precision: 0.6522 - recall: 0.7220 - val_loss: 0.7805 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2786/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7818 - precision: 0.6523 - recall: 0.7217 - val_loss: 0.7804 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2787/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7816 - precision: 0.6522 - recall: 0.7211 - val_loss: 0.7802 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2788/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7815 - precision: 0.6523 - recall: 0.7211 - val_loss: 0.7801 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2789/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7814 - precision: 0.6523 - recall: 0.7213 - val_loss: 0.7800 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2790/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7813 - precision: 0.6523 - recall: 0.7214 - val_loss: 0.7799 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2791/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7811 - precision: 0.6522 - recall: 0.7210 - val_loss: 0.7797 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2792/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7810 - precision: 0.6522 - recall: 0.7210 - val_loss: 0.7796 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2793/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7809 - precision: 0.6522 - recall: 0.7210 - val_loss: 0.7795 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2794/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7807 - precision: 0.6522 - recall: 0.7210 - val_loss: 0.7794 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2795/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7806 - precision: 0.6523 - recall: 0.7210 - val_loss: 0.7792 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2796/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7805 - precision: 0.6523 - recall: 0.7209 - val_loss: 0.7791 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2797/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7804 - precision: 0.6524 - recall: 0.7210 - val_loss: 0.7790 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2798/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7802 - precision: 0.6524 - recall: 0.7209 - val_loss: 0.7789 - val_precision: 0.6366 - val_recall: 0.7226\n",
      "Epoch 2799/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7801 - precision: 0.6524 - recall: 0.7209 - val_loss: 0.7787 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2800/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7800 - precision: 0.6524 - recall: 0.7210 - val_loss: 0.7786 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2801/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7799 - precision: 0.6524 - recall: 0.7210 - val_loss: 0.7785 - val_precision: 0.6364 - val_recall: 0.7226\n",
      "Epoch 2802/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7797 - precision: 0.6524 - recall: 0.7208 - val_loss: 0.7784 - val_precision: 0.6365 - val_recall: 0.7222\n",
      "Epoch 2803/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7796 - precision: 0.6525 - recall: 0.7208 - val_loss: 0.7782 - val_precision: 0.6367 - val_recall: 0.7222\n",
      "Epoch 2804/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7795 - precision: 0.6526 - recall: 0.7208 - val_loss: 0.7781 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2805/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7794 - precision: 0.6526 - recall: 0.7208 - val_loss: 0.7780 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2806/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7792 - precision: 0.6524 - recall: 0.7208 - val_loss: 0.7779 - val_precision: 0.6367 - val_recall: 0.7222\n",
      "Epoch 2807/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7791 - precision: 0.6525 - recall: 0.7208 - val_loss: 0.7777 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2808/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7790 - precision: 0.6525 - recall: 0.7208 - val_loss: 0.7776 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2809/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7789 - precision: 0.6526 - recall: 0.7206 - val_loss: 0.7775 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2810/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7787 - precision: 0.6526 - recall: 0.7209 - val_loss: 0.7774 - val_precision: 0.6367 - val_recall: 0.7222\n",
      "Epoch 2811/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7786 - precision: 0.6525 - recall: 0.7208 - val_loss: 0.7772 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2812/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7785 - precision: 0.6526 - recall: 0.7206 - val_loss: 0.7771 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2813/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7784 - precision: 0.6525 - recall: 0.7208 - val_loss: 0.7770 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2814/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7782 - precision: 0.6525 - recall: 0.7206 - val_loss: 0.7769 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2815/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7781 - precision: 0.6526 - recall: 0.7206 - val_loss: 0.7768 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2816/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7780 - precision: 0.6525 - recall: 0.7206 - val_loss: 0.7766 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2817/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7779 - precision: 0.6526 - recall: 0.7206 - val_loss: 0.7765 - val_precision: 0.6370 - val_recall: 0.7226\n",
      "Epoch 2818/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7778 - precision: 0.6527 - recall: 0.7206 - val_loss: 0.7764 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2819/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7776 - precision: 0.6526 - recall: 0.7206 - val_loss: 0.7763 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2820/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7775 - precision: 0.6526 - recall: 0.7209 - val_loss: 0.7762 - val_precision: 0.6370 - val_recall: 0.7226\n",
      "Epoch 2821/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7774 - precision: 0.6526 - recall: 0.7208 - val_loss: 0.7760 - val_precision: 0.6370 - val_recall: 0.7226\n",
      "Epoch 2822/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7773 - precision: 0.6526 - recall: 0.7206 - val_loss: 0.7759 - val_precision: 0.6368 - val_recall: 0.7218\n",
      "Epoch 2823/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7772 - precision: 0.6527 - recall: 0.7205 - val_loss: 0.7758 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2824/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7770 - precision: 0.6527 - recall: 0.7205 - val_loss: 0.7757 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2825/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7769 - precision: 0.6528 - recall: 0.7204 - val_loss: 0.7756 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2826/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7768 - precision: 0.6527 - recall: 0.7204 - val_loss: 0.7754 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2827/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7767 - precision: 0.6529 - recall: 0.7204 - val_loss: 0.7753 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2828/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7766 - precision: 0.6529 - recall: 0.7204 - val_loss: 0.7752 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2829/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7764 - precision: 0.6529 - recall: 0.7205 - val_loss: 0.7751 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2830/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7763 - precision: 0.6528 - recall: 0.7203 - val_loss: 0.7750 - val_precision: 0.6369 - val_recall: 0.7222\n",
      "Epoch 2831/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7762 - precision: 0.6527 - recall: 0.7200 - val_loss: 0.7749 - val_precision: 0.6371 - val_recall: 0.7222\n",
      "Epoch 2832/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7761 - precision: 0.6527 - recall: 0.7200 - val_loss: 0.7747 - val_precision: 0.6369 - val_recall: 0.7214\n",
      "Epoch 2833/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7760 - precision: 0.6527 - recall: 0.7200 - val_loss: 0.7746 - val_precision: 0.6370 - val_recall: 0.7218\n",
      "Epoch 2834/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7758 - precision: 0.6527 - recall: 0.7199 - val_loss: 0.7745 - val_precision: 0.6369 - val_recall: 0.7214\n",
      "Epoch 2835/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7757 - precision: 0.6529 - recall: 0.7197 - val_loss: 0.7744 - val_precision: 0.6369 - val_recall: 0.7214\n",
      "Epoch 2836/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7756 - precision: 0.6530 - recall: 0.7197 - val_loss: 0.7743 - val_precision: 0.6369 - val_recall: 0.7214\n",
      "Epoch 2837/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7755 - precision: 0.6530 - recall: 0.7197 - val_loss: 0.7742 - val_precision: 0.6369 - val_recall: 0.7214\n",
      "Epoch 2838/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7754 - precision: 0.6530 - recall: 0.7197 - val_loss: 0.7740 - val_precision: 0.6369 - val_recall: 0.7214\n",
      "Epoch 2839/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7753 - precision: 0.6530 - recall: 0.7197 - val_loss: 0.7739 - val_precision: 0.6370 - val_recall: 0.7210\n",
      "Epoch 2840/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7751 - precision: 0.6530 - recall: 0.7197 - val_loss: 0.7738 - val_precision: 0.6370 - val_recall: 0.7210\n",
      "Epoch 2841/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7750 - precision: 0.6530 - recall: 0.7197 - val_loss: 0.7737 - val_precision: 0.6368 - val_recall: 0.7210\n",
      "Epoch 2842/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7749 - precision: 0.6530 - recall: 0.7197 - val_loss: 0.7736 - val_precision: 0.6370 - val_recall: 0.7210\n",
      "Epoch 2843/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7748 - precision: 0.6530 - recall: 0.7196 - val_loss: 0.7735 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2844/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7747 - precision: 0.6530 - recall: 0.7196 - val_loss: 0.7734 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2845/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7746 - precision: 0.6529 - recall: 0.7194 - val_loss: 0.7732 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2846/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7744 - precision: 0.6529 - recall: 0.7194 - val_loss: 0.7731 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2847/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7743 - precision: 0.6530 - recall: 0.7196 - val_loss: 0.7730 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2848/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7742 - precision: 0.6529 - recall: 0.7194 - val_loss: 0.7729 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2849/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7741 - precision: 0.6529 - recall: 0.7192 - val_loss: 0.7728 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2850/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7740 - precision: 0.6529 - recall: 0.7194 - val_loss: 0.7727 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2851/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7739 - precision: 0.6529 - recall: 0.7194 - val_loss: 0.7726 - val_precision: 0.6371 - val_recall: 0.7206\n",
      "Epoch 2852/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7738 - precision: 0.6529 - recall: 0.7195 - val_loss: 0.7725 - val_precision: 0.6369 - val_recall: 0.7206\n",
      "Epoch 2853/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7737 - precision: 0.6529 - recall: 0.7192 - val_loss: 0.7723 - val_precision: 0.6370 - val_recall: 0.7202\n",
      "Epoch 2854/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7735 - precision: 0.6529 - recall: 0.7191 - val_loss: 0.7722 - val_precision: 0.6371 - val_recall: 0.7206\n",
      "Epoch 2855/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7734 - precision: 0.6529 - recall: 0.7194 - val_loss: 0.7721 - val_precision: 0.6371 - val_recall: 0.7206\n",
      "Epoch 2856/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7733 - precision: 0.6528 - recall: 0.7191 - val_loss: 0.7720 - val_precision: 0.6370 - val_recall: 0.7202\n",
      "Epoch 2857/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7732 - precision: 0.6530 - recall: 0.7189 - val_loss: 0.7719 - val_precision: 0.6370 - val_recall: 0.7202\n",
      "Epoch 2858/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7731 - precision: 0.6529 - recall: 0.7189 - val_loss: 0.7718 - val_precision: 0.6370 - val_recall: 0.7202\n",
      "Epoch 2859/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7730 - precision: 0.6529 - recall: 0.7189 - val_loss: 0.7717 - val_precision: 0.6374 - val_recall: 0.7202\n",
      "Epoch 2860/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7729 - precision: 0.6529 - recall: 0.7189 - val_loss: 0.7716 - val_precision: 0.6372 - val_recall: 0.7202\n",
      "Epoch 2861/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7728 - precision: 0.6529 - recall: 0.7187 - val_loss: 0.7715 - val_precision: 0.6373 - val_recall: 0.7198\n",
      "Epoch 2862/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7726 - precision: 0.6530 - recall: 0.7187 - val_loss: 0.7714 - val_precision: 0.6375 - val_recall: 0.7198\n",
      "Epoch 2863/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7725 - precision: 0.6529 - recall: 0.7187 - val_loss: 0.7712 - val_precision: 0.6375 - val_recall: 0.7198\n",
      "Epoch 2864/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7724 - precision: 0.6529 - recall: 0.7187 - val_loss: 0.7711 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2865/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7723 - precision: 0.6530 - recall: 0.7186 - val_loss: 0.7710 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2866/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7722 - precision: 0.6530 - recall: 0.7186 - val_loss: 0.7709 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2867/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7721 - precision: 0.6529 - recall: 0.7185 - val_loss: 0.7708 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2868/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7720 - precision: 0.6530 - recall: 0.7183 - val_loss: 0.7707 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2869/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7719 - precision: 0.6529 - recall: 0.7185 - val_loss: 0.7706 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2870/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7718 - precision: 0.6530 - recall: 0.7183 - val_loss: 0.7705 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2871/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7717 - precision: 0.6530 - recall: 0.7183 - val_loss: 0.7704 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2872/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7715 - precision: 0.6530 - recall: 0.7183 - val_loss: 0.7703 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2873/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7714 - precision: 0.6529 - recall: 0.7182 - val_loss: 0.7702 - val_precision: 0.6377 - val_recall: 0.7198\n",
      "Epoch 2874/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7713 - precision: 0.6530 - recall: 0.7181 - val_loss: 0.7701 - val_precision: 0.6378 - val_recall: 0.7195\n",
      "Epoch 2875/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7712 - precision: 0.6530 - recall: 0.7181 - val_loss: 0.7699 - val_precision: 0.6377 - val_recall: 0.7191\n",
      "Epoch 2876/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7711 - precision: 0.6530 - recall: 0.7181 - val_loss: 0.7698 - val_precision: 0.6377 - val_recall: 0.7191\n",
      "Epoch 2877/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7710 - precision: 0.6530 - recall: 0.7181 - val_loss: 0.7697 - val_precision: 0.6378 - val_recall: 0.7195\n",
      "Epoch 2878/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7709 - precision: 0.6530 - recall: 0.7181 - val_loss: 0.7696 - val_precision: 0.6377 - val_recall: 0.7191\n",
      "Epoch 2879/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7708 - precision: 0.6530 - recall: 0.7181 - val_loss: 0.7695 - val_precision: 0.6377 - val_recall: 0.7191\n",
      "Epoch 2880/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7707 - precision: 0.6531 - recall: 0.7181 - val_loss: 0.7694 - val_precision: 0.6377 - val_recall: 0.7191\n",
      "Epoch 2881/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7706 - precision: 0.6531 - recall: 0.7181 - val_loss: 0.7693 - val_precision: 0.6377 - val_recall: 0.7191\n",
      "Epoch 2882/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7705 - precision: 0.6531 - recall: 0.7181 - val_loss: 0.7692 - val_precision: 0.6378 - val_recall: 0.7195\n",
      "Epoch 2883/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7704 - precision: 0.6531 - recall: 0.7180 - val_loss: 0.7691 - val_precision: 0.6376 - val_recall: 0.7187\n",
      "Epoch 2884/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7703 - precision: 0.6531 - recall: 0.7180 - val_loss: 0.7690 - val_precision: 0.6376 - val_recall: 0.7187\n",
      "Epoch 2885/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7701 - precision: 0.6531 - recall: 0.7180 - val_loss: 0.7689 - val_precision: 0.6376 - val_recall: 0.7187\n",
      "Epoch 2886/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7700 - precision: 0.6530 - recall: 0.7178 - val_loss: 0.7688 - val_precision: 0.6376 - val_recall: 0.7187\n",
      "Epoch 2887/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7699 - precision: 0.6531 - recall: 0.7180 - val_loss: 0.7687 - val_precision: 0.6374 - val_recall: 0.7183\n",
      "Epoch 2888/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7698 - precision: 0.6530 - recall: 0.7177 - val_loss: 0.7686 - val_precision: 0.6373 - val_recall: 0.7179\n",
      "Epoch 2889/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7697 - precision: 0.6530 - recall: 0.7178 - val_loss: 0.7685 - val_precision: 0.6375 - val_recall: 0.7179\n",
      "Epoch 2890/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7696 - precision: 0.6530 - recall: 0.7177 - val_loss: 0.7684 - val_precision: 0.6375 - val_recall: 0.7179\n",
      "Epoch 2891/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7695 - precision: 0.6528 - recall: 0.7172 - val_loss: 0.7683 - val_precision: 0.6377 - val_recall: 0.7179\n",
      "Epoch 2892/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7694 - precision: 0.6530 - recall: 0.7178 - val_loss: 0.7682 - val_precision: 0.6375 - val_recall: 0.7179\n",
      "Epoch 2893/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7693 - precision: 0.6529 - recall: 0.7173 - val_loss: 0.7681 - val_precision: 0.6375 - val_recall: 0.7179\n",
      "Epoch 2894/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7692 - precision: 0.6528 - recall: 0.7171 - val_loss: 0.7680 - val_precision: 0.6377 - val_recall: 0.7179\n",
      "Epoch 2895/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7691 - precision: 0.6529 - recall: 0.7172 - val_loss: 0.7678 - val_precision: 0.6377 - val_recall: 0.7179\n",
      "Epoch 2896/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7690 - precision: 0.6530 - recall: 0.7178 - val_loss: 0.7677 - val_precision: 0.6377 - val_recall: 0.7179\n",
      "Epoch 2897/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7689 - precision: 0.6529 - recall: 0.7171 - val_loss: 0.7676 - val_precision: 0.6377 - val_recall: 0.7179\n",
      "Epoch 2898/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7688 - precision: 0.6529 - recall: 0.7171 - val_loss: 0.7675 - val_precision: 0.6377 - val_recall: 0.7179\n",
      "Epoch 2899/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7687 - precision: 0.6528 - recall: 0.7171 - val_loss: 0.7674 - val_precision: 0.6376 - val_recall: 0.7175\n",
      "Epoch 2900/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7686 - precision: 0.6528 - recall: 0.7166 - val_loss: 0.7673 - val_precision: 0.6376 - val_recall: 0.7175\n",
      "Epoch 2901/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7685 - precision: 0.6529 - recall: 0.7167 - val_loss: 0.7672 - val_precision: 0.6376 - val_recall: 0.7175\n",
      "Epoch 2902/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7684 - precision: 0.6528 - recall: 0.7168 - val_loss: 0.7671 - val_precision: 0.6376 - val_recall: 0.7175\n",
      "Epoch 2903/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7683 - precision: 0.6527 - recall: 0.7167 - val_loss: 0.7670 - val_precision: 0.6376 - val_recall: 0.7175\n",
      "Epoch 2904/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7682 - precision: 0.6527 - recall: 0.7167 - val_loss: 0.7669 - val_precision: 0.6376 - val_recall: 0.7175\n",
      "Epoch 2905/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7681 - precision: 0.6528 - recall: 0.7168 - val_loss: 0.7668 - val_precision: 0.6377 - val_recall: 0.7179\n",
      "Epoch 2906/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7680 - precision: 0.6527 - recall: 0.7167 - val_loss: 0.7667 - val_precision: 0.6375 - val_recall: 0.7171\n",
      "Epoch 2907/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7679 - precision: 0.6528 - recall: 0.7167 - val_loss: 0.7666 - val_precision: 0.6375 - val_recall: 0.7171\n",
      "Epoch 2908/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7678 - precision: 0.6528 - recall: 0.7167 - val_loss: 0.7665 - val_precision: 0.6375 - val_recall: 0.7171\n",
      "Epoch 2909/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7676 - precision: 0.6529 - recall: 0.7167 - val_loss: 0.7664 - val_precision: 0.6377 - val_recall: 0.7171\n",
      "Epoch 2910/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7675 - precision: 0.6528 - recall: 0.7167 - val_loss: 0.7663 - val_precision: 0.6377 - val_recall: 0.7171\n",
      "Epoch 2911/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7674 - precision: 0.6529 - recall: 0.7166 - val_loss: 0.7662 - val_precision: 0.6377 - val_recall: 0.7171\n",
      "Epoch 2912/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7673 - precision: 0.6528 - recall: 0.7167 - val_loss: 0.7661 - val_precision: 0.6378 - val_recall: 0.7175\n",
      "Epoch 2913/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7672 - precision: 0.6529 - recall: 0.7166 - val_loss: 0.7660 - val_precision: 0.6378 - val_recall: 0.7175\n",
      "Epoch 2914/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7671 - precision: 0.6531 - recall: 0.7166 - val_loss: 0.7659 - val_precision: 0.6378 - val_recall: 0.7175\n",
      "Epoch 2915/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7670 - precision: 0.6531 - recall: 0.7167 - val_loss: 0.7658 - val_precision: 0.6378 - val_recall: 0.7175\n",
      "Epoch 2916/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7669 - precision: 0.6532 - recall: 0.7166 - val_loss: 0.7657 - val_precision: 0.6383 - val_recall: 0.7175\n",
      "Epoch 2917/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7668 - precision: 0.6532 - recall: 0.7166 - val_loss: 0.7656 - val_precision: 0.6381 - val_recall: 0.7175\n",
      "Epoch 2918/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7667 - precision: 0.6534 - recall: 0.7166 - val_loss: 0.7655 - val_precision: 0.6383 - val_recall: 0.7175\n",
      "Epoch 2919/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7666 - precision: 0.6534 - recall: 0.7166 - val_loss: 0.7654 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2920/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7665 - precision: 0.6534 - recall: 0.7166 - val_loss: 0.7653 - val_precision: 0.6383 - val_recall: 0.7175\n",
      "Epoch 2921/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7664 - precision: 0.6534 - recall: 0.7167 - val_loss: 0.7652 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2922/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7663 - precision: 0.6533 - recall: 0.7162 - val_loss: 0.7651 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2923/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7662 - precision: 0.6532 - recall: 0.7161 - val_loss: 0.7651 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2924/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7661 - precision: 0.6533 - recall: 0.7161 - val_loss: 0.7649 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2925/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7661 - precision: 0.6533 - recall: 0.7159 - val_loss: 0.7649 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2926/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7660 - precision: 0.6533 - recall: 0.7159 - val_loss: 0.7648 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2927/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7659 - precision: 0.6533 - recall: 0.7159 - val_loss: 0.7647 - val_precision: 0.6385 - val_recall: 0.7175\n",
      "Epoch 2928/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7658 - precision: 0.6533 - recall: 0.7158 - val_loss: 0.7646 - val_precision: 0.6384 - val_recall: 0.7171\n",
      "Epoch 2929/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7657 - precision: 0.6533 - recall: 0.7159 - val_loss: 0.7645 - val_precision: 0.6384 - val_recall: 0.7171\n",
      "Epoch 2930/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7656 - precision: 0.6533 - recall: 0.7158 - val_loss: 0.7644 - val_precision: 0.6384 - val_recall: 0.7171\n",
      "Epoch 2931/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7655 - precision: 0.6534 - recall: 0.7157 - val_loss: 0.7643 - val_precision: 0.6383 - val_recall: 0.7167\n",
      "Epoch 2932/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7654 - precision: 0.6536 - recall: 0.7157 - val_loss: 0.7642 - val_precision: 0.6383 - val_recall: 0.7167\n",
      "Epoch 2933/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7653 - precision: 0.6535 - recall: 0.7155 - val_loss: 0.7641 - val_precision: 0.6383 - val_recall: 0.7167\n",
      "Epoch 2934/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7652 - precision: 0.6535 - recall: 0.7157 - val_loss: 0.7640 - val_precision: 0.6383 - val_recall: 0.7167\n",
      "Epoch 2935/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7651 - precision: 0.6536 - recall: 0.7155 - val_loss: 0.7639 - val_precision: 0.6383 - val_recall: 0.7167\n",
      "Epoch 2936/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7650 - precision: 0.6536 - recall: 0.7157 - val_loss: 0.7638 - val_precision: 0.6383 - val_recall: 0.7167\n",
      "Epoch 2937/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7649 - precision: 0.6535 - recall: 0.7155 - val_loss: 0.7637 - val_precision: 0.6381 - val_recall: 0.7163\n",
      "Epoch 2938/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7648 - precision: 0.6535 - recall: 0.7155 - val_loss: 0.7636 - val_precision: 0.6381 - val_recall: 0.7163\n",
      "Epoch 2939/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7647 - precision: 0.6536 - recall: 0.7155 - val_loss: 0.7635 - val_precision: 0.6381 - val_recall: 0.7163\n",
      "Epoch 2940/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7646 - precision: 0.6535 - recall: 0.7155 - val_loss: 0.7634 - val_precision: 0.6383 - val_recall: 0.7163\n",
      "Epoch 2941/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7645 - precision: 0.6536 - recall: 0.7155 - val_loss: 0.7633 - val_precision: 0.6383 - val_recall: 0.7163\n",
      "Epoch 2942/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7644 - precision: 0.6535 - recall: 0.7155 - val_loss: 0.7632 - val_precision: 0.6383 - val_recall: 0.7163\n",
      "Epoch 2943/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7643 - precision: 0.6535 - recall: 0.7153 - val_loss: 0.7632 - val_precision: 0.6383 - val_recall: 0.7163\n",
      "Epoch 2944/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7642 - precision: 0.6536 - recall: 0.7155 - val_loss: 0.7631 - val_precision: 0.6383 - val_recall: 0.7163\n",
      "Epoch 2945/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7641 - precision: 0.6536 - recall: 0.7154 - val_loss: 0.7630 - val_precision: 0.6383 - val_recall: 0.7163\n",
      "Epoch 2946/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7640 - precision: 0.6536 - recall: 0.7157 - val_loss: 0.7629 - val_precision: 0.6383 - val_recall: 0.7163\n",
      "Epoch 2947/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7639 - precision: 0.6535 - recall: 0.7153 - val_loss: 0.7628 - val_precision: 0.6386 - val_recall: 0.7163\n",
      "Epoch 2948/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7638 - precision: 0.6536 - recall: 0.7154 - val_loss: 0.7627 - val_precision: 0.6386 - val_recall: 0.7163\n",
      "Epoch 2949/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7638 - precision: 0.6536 - recall: 0.7154 - val_loss: 0.7626 - val_precision: 0.6386 - val_recall: 0.7163\n",
      "Epoch 2950/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7637 - precision: 0.6536 - recall: 0.7153 - val_loss: 0.7625 - val_precision: 0.6386 - val_recall: 0.7163\n",
      "Epoch 2951/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7636 - precision: 0.6536 - recall: 0.7153 - val_loss: 0.7624 - val_precision: 0.6388 - val_recall: 0.7163\n",
      "Epoch 2952/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7635 - precision: 0.6536 - recall: 0.7153 - val_loss: 0.7623 - val_precision: 0.6386 - val_recall: 0.7163\n",
      "Epoch 2953/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7634 - precision: 0.6537 - recall: 0.7153 - val_loss: 0.7622 - val_precision: 0.6387 - val_recall: 0.7160\n",
      "Epoch 2954/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7633 - precision: 0.6537 - recall: 0.7153 - val_loss: 0.7621 - val_precision: 0.6387 - val_recall: 0.7160\n",
      "Epoch 2955/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7632 - precision: 0.6537 - recall: 0.7153 - val_loss: 0.7621 - val_precision: 0.6387 - val_recall: 0.7160\n",
      "Epoch 2956/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7631 - precision: 0.6536 - recall: 0.7152 - val_loss: 0.7620 - val_precision: 0.6387 - val_recall: 0.7160\n",
      "Epoch 2957/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7630 - precision: 0.6536 - recall: 0.7149 - val_loss: 0.7619 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2958/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7629 - precision: 0.6536 - recall: 0.7149 - val_loss: 0.7618 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2959/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7628 - precision: 0.6537 - recall: 0.7150 - val_loss: 0.7617 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2960/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7627 - precision: 0.6536 - recall: 0.7148 - val_loss: 0.7616 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2961/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7626 - precision: 0.6535 - recall: 0.7146 - val_loss: 0.7615 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2962/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7626 - precision: 0.6536 - recall: 0.7146 - val_loss: 0.7614 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2963/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7625 - precision: 0.6536 - recall: 0.7145 - val_loss: 0.7613 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2964/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7624 - precision: 0.6536 - recall: 0.7146 - val_loss: 0.7612 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2965/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7623 - precision: 0.6537 - recall: 0.7144 - val_loss: 0.7612 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2966/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7622 - precision: 0.6537 - recall: 0.7144 - val_loss: 0.7611 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2967/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7621 - precision: 0.6536 - recall: 0.7143 - val_loss: 0.7610 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2968/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7620 - precision: 0.6536 - recall: 0.7140 - val_loss: 0.7609 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2969/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7619 - precision: 0.6537 - recall: 0.7144 - val_loss: 0.7608 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2970/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7618 - precision: 0.6537 - recall: 0.7143 - val_loss: 0.7607 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2971/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7617 - precision: 0.6538 - recall: 0.7140 - val_loss: 0.7606 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2972/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7617 - precision: 0.6539 - recall: 0.7140 - val_loss: 0.7605 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2973/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7616 - precision: 0.6539 - recall: 0.7140 - val_loss: 0.7604 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2974/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7615 - precision: 0.6538 - recall: 0.7140 - val_loss: 0.7604 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2975/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7614 - precision: 0.6539 - recall: 0.7141 - val_loss: 0.7603 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2976/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7613 - precision: 0.6539 - recall: 0.7140 - val_loss: 0.7602 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2977/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7612 - precision: 0.6540 - recall: 0.7140 - val_loss: 0.7601 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2978/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7611 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7600 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2979/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7610 - precision: 0.6540 - recall: 0.7140 - val_loss: 0.7599 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2980/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7609 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7598 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2981/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7609 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7597 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2982/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7608 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7597 - val_precision: 0.6389 - val_recall: 0.7152\n",
      "Epoch 2983/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7607 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7596 - val_precision: 0.6389 - val_recall: 0.7160\n",
      "Epoch 2984/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7606 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7595 - val_precision: 0.6389 - val_recall: 0.7152\n",
      "Epoch 2985/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7605 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7594 - val_precision: 0.6389 - val_recall: 0.7152\n",
      "Epoch 2986/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7604 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7593 - val_precision: 0.6390 - val_recall: 0.7156\n",
      "Epoch 2987/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7603 - precision: 0.6541 - recall: 0.7141 - val_loss: 0.7592 - val_precision: 0.6391 - val_recall: 0.7152\n",
      "Epoch 2988/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7602 - precision: 0.6542 - recall: 0.7143 - val_loss: 0.7592 - val_precision: 0.6391 - val_recall: 0.7152\n",
      "Epoch 2989/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7602 - precision: 0.6543 - recall: 0.7140 - val_loss: 0.7591 - val_precision: 0.6391 - val_recall: 0.7152\n",
      "Epoch 2990/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7601 - precision: 0.6542 - recall: 0.7140 - val_loss: 0.7590 - val_precision: 0.6389 - val_recall: 0.7152\n",
      "Epoch 2991/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7600 - precision: 0.6543 - recall: 0.7141 - val_loss: 0.7589 - val_precision: 0.6391 - val_recall: 0.7152\n",
      "Epoch 2992/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7599 - precision: 0.6542 - recall: 0.7141 - val_loss: 0.7588 - val_precision: 0.6393 - val_recall: 0.7152\n",
      "Epoch 2993/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7598 - precision: 0.6544 - recall: 0.7140 - val_loss: 0.7587 - val_precision: 0.6393 - val_recall: 0.7152\n",
      "Epoch 2994/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7597 - precision: 0.6543 - recall: 0.7141 - val_loss: 0.7586 - val_precision: 0.6393 - val_recall: 0.7152\n",
      "Epoch 2995/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7596 - precision: 0.6544 - recall: 0.7140 - val_loss: 0.7586 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 2996/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7596 - precision: 0.6544 - recall: 0.7140 - val_loss: 0.7585 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 2997/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7595 - precision: 0.6544 - recall: 0.7141 - val_loss: 0.7584 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 2998/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7594 - precision: 0.6544 - recall: 0.7138 - val_loss: 0.7583 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 2999/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7593 - precision: 0.6545 - recall: 0.7141 - val_loss: 0.7582 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3000/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7592 - precision: 0.6545 - recall: 0.7139 - val_loss: 0.7582 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3001/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7591 - precision: 0.6546 - recall: 0.7140 - val_loss: 0.7581 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3002/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7591 - precision: 0.6546 - recall: 0.7138 - val_loss: 0.7580 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3003/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7590 - precision: 0.6546 - recall: 0.7138 - val_loss: 0.7579 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3004/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7589 - precision: 0.6546 - recall: 0.7139 - val_loss: 0.7578 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3005/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7588 - precision: 0.6546 - recall: 0.7136 - val_loss: 0.7577 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3006/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7587 - precision: 0.6545 - recall: 0.7139 - val_loss: 0.7577 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3007/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7586 - precision: 0.6546 - recall: 0.7138 - val_loss: 0.7576 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3008/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7586 - precision: 0.6547 - recall: 0.7135 - val_loss: 0.7575 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3009/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7585 - precision: 0.6547 - recall: 0.7136 - val_loss: 0.7574 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3010/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7584 - precision: 0.6547 - recall: 0.7135 - val_loss: 0.7573 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3011/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7583 - precision: 0.6547 - recall: 0.7138 - val_loss: 0.7572 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3012/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7582 - precision: 0.6547 - recall: 0.7138 - val_loss: 0.7572 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3013/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7581 - precision: 0.6547 - recall: 0.7138 - val_loss: 0.7571 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3014/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7581 - precision: 0.6546 - recall: 0.7135 - val_loss: 0.7570 - val_precision: 0.6391 - val_recall: 0.7144\n",
      "Epoch 3015/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7580 - precision: 0.6547 - recall: 0.7134 - val_loss: 0.7569 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3016/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7579 - precision: 0.6546 - recall: 0.7136 - val_loss: 0.7568 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3017/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7578 - precision: 0.6547 - recall: 0.7136 - val_loss: 0.7568 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3018/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7577 - precision: 0.6547 - recall: 0.7134 - val_loss: 0.7567 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3019/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7577 - precision: 0.6548 - recall: 0.7130 - val_loss: 0.7566 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3020/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7576 - precision: 0.6548 - recall: 0.7129 - val_loss: 0.7565 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3021/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7575 - precision: 0.6549 - recall: 0.7131 - val_loss: 0.7564 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3022/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7574 - precision: 0.6549 - recall: 0.7129 - val_loss: 0.7564 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3023/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7573 - precision: 0.6548 - recall: 0.7126 - val_loss: 0.7563 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3024/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7573 - precision: 0.6549 - recall: 0.7126 - val_loss: 0.7562 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3025/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7572 - precision: 0.6549 - recall: 0.7129 - val_loss: 0.7561 - val_precision: 0.6389 - val_recall: 0.7140\n",
      "Epoch 3026/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7571 - precision: 0.6550 - recall: 0.7129 - val_loss: 0.7561 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3027/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7570 - precision: 0.6549 - recall: 0.7129 - val_loss: 0.7560 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3028/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7569 - precision: 0.6548 - recall: 0.7122 - val_loss: 0.7559 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3029/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7569 - precision: 0.6547 - recall: 0.7121 - val_loss: 0.7558 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3030/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7568 - precision: 0.6547 - recall: 0.7120 - val_loss: 0.7557 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3031/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7567 - precision: 0.6547 - recall: 0.7120 - val_loss: 0.7557 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3032/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7566 - precision: 0.6548 - recall: 0.7124 - val_loss: 0.7556 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3033/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7565 - precision: 0.6548 - recall: 0.7117 - val_loss: 0.7555 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3034/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7565 - precision: 0.6548 - recall: 0.7120 - val_loss: 0.7554 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3035/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7564 - precision: 0.6548 - recall: 0.7118 - val_loss: 0.7554 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3036/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7563 - precision: 0.6546 - recall: 0.7113 - val_loss: 0.7553 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3037/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7562 - precision: 0.6546 - recall: 0.7113 - val_loss: 0.7552 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3038/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7562 - precision: 0.6547 - recall: 0.7112 - val_loss: 0.7551 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3039/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7561 - precision: 0.6548 - recall: 0.7111 - val_loss: 0.7551 - val_precision: 0.6390 - val_recall: 0.7136\n",
      "Epoch 3040/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7560 - precision: 0.6548 - recall: 0.7111 - val_loss: 0.7550 - val_precision: 0.6392 - val_recall: 0.7140\n",
      "Epoch 3041/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7559 - precision: 0.6548 - recall: 0.7111 - val_loss: 0.7549 - val_precision: 0.6390 - val_recall: 0.7136\n",
      "Epoch 3042/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7558 - precision: 0.6548 - recall: 0.7111 - val_loss: 0.7548 - val_precision: 0.6390 - val_recall: 0.7136\n",
      "Epoch 3043/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7558 - precision: 0.6548 - recall: 0.7111 - val_loss: 0.7548 - val_precision: 0.6390 - val_recall: 0.7136\n",
      "Epoch 3044/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7557 - precision: 0.6549 - recall: 0.7111 - val_loss: 0.7547 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3045/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7556 - precision: 0.6548 - recall: 0.7111 - val_loss: 0.7546 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3046/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7555 - precision: 0.6548 - recall: 0.7108 - val_loss: 0.7545 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3047/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7555 - precision: 0.6549 - recall: 0.7110 - val_loss: 0.7545 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3048/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7554 - precision: 0.6548 - recall: 0.7110 - val_loss: 0.7544 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3049/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7553 - precision: 0.6549 - recall: 0.7107 - val_loss: 0.7543 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3050/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7553 - precision: 0.6548 - recall: 0.7107 - val_loss: 0.7543 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3051/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7552 - precision: 0.6548 - recall: 0.7106 - val_loss: 0.7542 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3052/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7551 - precision: 0.6549 - recall: 0.7110 - val_loss: 0.7541 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3053/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7550 - precision: 0.6550 - recall: 0.7110 - val_loss: 0.7540 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3054/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7550 - precision: 0.6548 - recall: 0.7106 - val_loss: 0.7540 - val_precision: 0.6391 - val_recall: 0.7132\n",
      "Epoch 3055/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7549 - precision: 0.6549 - recall: 0.7108 - val_loss: 0.7539 - val_precision: 0.6392 - val_recall: 0.7136\n",
      "Epoch 3056/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7548 - precision: 0.6549 - recall: 0.7107 - val_loss: 0.7538 - val_precision: 0.6391 - val_recall: 0.7132\n",
      "Epoch 3057/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7547 - precision: 0.6550 - recall: 0.7107 - val_loss: 0.7538 - val_precision: 0.6391 - val_recall: 0.7132\n",
      "Epoch 3058/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7547 - precision: 0.6549 - recall: 0.7106 - val_loss: 0.7537 - val_precision: 0.6391 - val_recall: 0.7132\n",
      "Epoch 3059/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7546 - precision: 0.6550 - recall: 0.7107 - val_loss: 0.7536 - val_precision: 0.6391 - val_recall: 0.7132\n",
      "Epoch 3060/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7545 - precision: 0.6550 - recall: 0.7107 - val_loss: 0.7535 - val_precision: 0.6391 - val_recall: 0.7132\n",
      "Epoch 3061/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7544 - precision: 0.6550 - recall: 0.7107 - val_loss: 0.7535 - val_precision: 0.6391 - val_recall: 0.7132\n",
      "Epoch 3062/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7544 - precision: 0.6550 - recall: 0.7106 - val_loss: 0.7534 - val_precision: 0.6392 - val_recall: 0.7128\n",
      "Epoch 3063/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7543 - precision: 0.6550 - recall: 0.7104 - val_loss: 0.7533 - val_precision: 0.6392 - val_recall: 0.7128\n",
      "Epoch 3064/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7542 - precision: 0.6550 - recall: 0.7104 - val_loss: 0.7533 - val_precision: 0.6394 - val_recall: 0.7128\n",
      "Epoch 3065/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7542 - precision: 0.6550 - recall: 0.7104 - val_loss: 0.7532 - val_precision: 0.6393 - val_recall: 0.7125\n",
      "Epoch 3066/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7541 - precision: 0.6552 - recall: 0.7104 - val_loss: 0.7531 - val_precision: 0.6393 - val_recall: 0.7125\n",
      "Epoch 3067/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7540 - precision: 0.6550 - recall: 0.7104 - val_loss: 0.7530 - val_precision: 0.6394 - val_recall: 0.7128\n",
      "Epoch 3068/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7539 - precision: 0.6553 - recall: 0.7103 - val_loss: 0.7530 - val_precision: 0.6393 - val_recall: 0.7125\n",
      "Epoch 3069/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7539 - precision: 0.6553 - recall: 0.7104 - val_loss: 0.7529 - val_precision: 0.6393 - val_recall: 0.7125\n",
      "Epoch 3070/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7538 - precision: 0.6552 - recall: 0.7103 - val_loss: 0.7528 - val_precision: 0.6392 - val_recall: 0.7121\n",
      "Epoch 3071/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7537 - precision: 0.6552 - recall: 0.7104 - val_loss: 0.7528 - val_precision: 0.6392 - val_recall: 0.7121\n",
      "Epoch 3072/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7537 - precision: 0.6553 - recall: 0.7104 - val_loss: 0.7527 - val_precision: 0.6393 - val_recall: 0.7125\n",
      "Epoch 3073/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7536 - precision: 0.6552 - recall: 0.7104 - val_loss: 0.7526 - val_precision: 0.6392 - val_recall: 0.7121\n",
      "Epoch 3074/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7535 - precision: 0.6553 - recall: 0.7103 - val_loss: 0.7526 - val_precision: 0.6392 - val_recall: 0.7121\n",
      "Epoch 3075/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7535 - precision: 0.6553 - recall: 0.7106 - val_loss: 0.7525 - val_precision: 0.6391 - val_recall: 0.7117\n",
      "Epoch 3076/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7534 - precision: 0.6554 - recall: 0.7106 - val_loss: 0.7524 - val_precision: 0.6391 - val_recall: 0.7117\n",
      "Epoch 3077/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7533 - precision: 0.6554 - recall: 0.7103 - val_loss: 0.7524 - val_precision: 0.6391 - val_recall: 0.7117\n",
      "Epoch 3078/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7532 - precision: 0.6554 - recall: 0.7103 - val_loss: 0.7523 - val_precision: 0.6393 - val_recall: 0.7117\n",
      "Epoch 3079/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7532 - precision: 0.6553 - recall: 0.7103 - val_loss: 0.7522 - val_precision: 0.6393 - val_recall: 0.7117\n",
      "Epoch 3080/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7531 - precision: 0.6554 - recall: 0.7104 - val_loss: 0.7522 - val_precision: 0.6393 - val_recall: 0.7117\n",
      "Epoch 3081/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7530 - precision: 0.6553 - recall: 0.7099 - val_loss: 0.7521 - val_precision: 0.6393 - val_recall: 0.7117\n",
      "Epoch 3082/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7530 - precision: 0.6554 - recall: 0.7103 - val_loss: 0.7520 - val_precision: 0.6393 - val_recall: 0.7117\n",
      "Epoch 3083/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7529 - precision: 0.6554 - recall: 0.7102 - val_loss: 0.7520 - val_precision: 0.6397 - val_recall: 0.7117\n",
      "Epoch 3084/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7528 - precision: 0.6554 - recall: 0.7102 - val_loss: 0.7519 - val_precision: 0.6397 - val_recall: 0.7117\n",
      "Epoch 3085/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7528 - precision: 0.6554 - recall: 0.7099 - val_loss: 0.7518 - val_precision: 0.6396 - val_recall: 0.7113\n",
      "Epoch 3086/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7527 - precision: 0.6554 - recall: 0.7098 - val_loss: 0.7518 - val_precision: 0.6398 - val_recall: 0.7113\n",
      "Epoch 3087/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7526 - precision: 0.6554 - recall: 0.7099 - val_loss: 0.7517 - val_precision: 0.6397 - val_recall: 0.7117\n",
      "Epoch 3088/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7526 - precision: 0.6555 - recall: 0.7097 - val_loss: 0.7516 - val_precision: 0.6396 - val_recall: 0.7105\n",
      "Epoch 3089/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7525 - precision: 0.6554 - recall: 0.7098 - val_loss: 0.7516 - val_precision: 0.6396 - val_recall: 0.7105\n",
      "Epoch 3090/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7524 - precision: 0.6555 - recall: 0.7098 - val_loss: 0.7515 - val_precision: 0.6396 - val_recall: 0.7105\n",
      "Epoch 3091/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7524 - precision: 0.6555 - recall: 0.7099 - val_loss: 0.7514 - val_precision: 0.6395 - val_recall: 0.7101\n",
      "Epoch 3092/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7523 - precision: 0.6554 - recall: 0.7099 - val_loss: 0.7514 - val_precision: 0.6395 - val_recall: 0.7101\n",
      "Epoch 3093/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7522 - precision: 0.6555 - recall: 0.7097 - val_loss: 0.7513 - val_precision: 0.6395 - val_recall: 0.7101\n",
      "Epoch 3094/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7522 - precision: 0.6555 - recall: 0.7097 - val_loss: 0.7512 - val_precision: 0.6395 - val_recall: 0.7101\n",
      "Epoch 3095/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7521 - precision: 0.6556 - recall: 0.7098 - val_loss: 0.7512 - val_precision: 0.6395 - val_recall: 0.7101\n",
      "Epoch 3096/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7520 - precision: 0.6556 - recall: 0.7099 - val_loss: 0.7511 - val_precision: 0.6395 - val_recall: 0.7101\n",
      "Epoch 3097/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7520 - precision: 0.6556 - recall: 0.7097 - val_loss: 0.7511 - val_precision: 0.6397 - val_recall: 0.7101\n",
      "Epoch 3098/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7519 - precision: 0.6556 - recall: 0.7099 - val_loss: 0.7510 - val_precision: 0.6395 - val_recall: 0.7101\n",
      "Epoch 3099/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7518 - precision: 0.6557 - recall: 0.7099 - val_loss: 0.7509 - val_precision: 0.6397 - val_recall: 0.7101\n",
      "Epoch 3100/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7518 - precision: 0.6556 - recall: 0.7092 - val_loss: 0.7509 - val_precision: 0.6399 - val_recall: 0.7101\n",
      "Epoch 3101/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7517 - precision: 0.6557 - recall: 0.7093 - val_loss: 0.7508 - val_precision: 0.6399 - val_recall: 0.7101\n",
      "Epoch 3102/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7517 - precision: 0.6557 - recall: 0.7090 - val_loss: 0.7507 - val_precision: 0.6399 - val_recall: 0.7101\n",
      "Epoch 3103/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7516 - precision: 0.6558 - recall: 0.7094 - val_loss: 0.7507 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3104/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7515 - precision: 0.6558 - recall: 0.7093 - val_loss: 0.7506 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3105/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7515 - precision: 0.6558 - recall: 0.7093 - val_loss: 0.7506 - val_precision: 0.6399 - val_recall: 0.7101\n",
      "Epoch 3106/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7514 - precision: 0.6557 - recall: 0.7090 - val_loss: 0.7505 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3107/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7513 - precision: 0.6556 - recall: 0.7089 - val_loss: 0.7504 - val_precision: 0.6402 - val_recall: 0.7097\n",
      "Epoch 3108/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7513 - precision: 0.6557 - recall: 0.7089 - val_loss: 0.7504 - val_precision: 0.6402 - val_recall: 0.7097\n",
      "Epoch 3109/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7512 - precision: 0.6558 - recall: 0.7094 - val_loss: 0.7503 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3110/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7511 - precision: 0.6557 - recall: 0.7092 - val_loss: 0.7502 - val_precision: 0.6400 - val_recall: 0.7097\n",
      "Epoch 3111/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7511 - precision: 0.6557 - recall: 0.7090 - val_loss: 0.7502 - val_precision: 0.6400 - val_recall: 0.7097\n",
      "Epoch 3112/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7510 - precision: 0.6558 - recall: 0.7093 - val_loss: 0.7501 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3113/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7510 - precision: 0.6557 - recall: 0.7092 - val_loss: 0.7501 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3114/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7509 - precision: 0.6558 - recall: 0.7092 - val_loss: 0.7500 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3115/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7508 - precision: 0.6557 - recall: 0.7090 - val_loss: 0.7499 - val_precision: 0.6404 - val_recall: 0.7101\n",
      "Epoch 3116/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7508 - precision: 0.6558 - recall: 0.7093 - val_loss: 0.7499 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3117/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7507 - precision: 0.6558 - recall: 0.7093 - val_loss: 0.7498 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3118/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7506 - precision: 0.6557 - recall: 0.7090 - val_loss: 0.7498 - val_precision: 0.6401 - val_recall: 0.7101\n",
      "Epoch 3119/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7506 - precision: 0.6557 - recall: 0.7088 - val_loss: 0.7497 - val_precision: 0.6408 - val_recall: 0.7101\n",
      "Epoch 3120/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7505 - precision: 0.6557 - recall: 0.7088 - val_loss: 0.7496 - val_precision: 0.6406 - val_recall: 0.7101\n",
      "Epoch 3121/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7505 - precision: 0.6558 - recall: 0.7089 - val_loss: 0.7496 - val_precision: 0.6408 - val_recall: 0.7101\n",
      "Epoch 3122/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7504 - precision: 0.6558 - recall: 0.7089 - val_loss: 0.7495 - val_precision: 0.6408 - val_recall: 0.7101\n",
      "Epoch 3123/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7503 - precision: 0.6558 - recall: 0.7089 - val_loss: 0.7494 - val_precision: 0.6408 - val_recall: 0.7101\n",
      "Epoch 3124/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7503 - precision: 0.6558 - recall: 0.7090 - val_loss: 0.7494 - val_precision: 0.6408 - val_recall: 0.7101\n",
      "Epoch 3125/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7502 - precision: 0.6557 - recall: 0.7087 - val_loss: 0.7493 - val_precision: 0.6410 - val_recall: 0.7101\n",
      "Epoch 3126/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7501 - precision: 0.6558 - recall: 0.7087 - val_loss: 0.7493 - val_precision: 0.6410 - val_recall: 0.7101\n",
      "Epoch 3127/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7501 - precision: 0.6559 - recall: 0.7089 - val_loss: 0.7492 - val_precision: 0.6410 - val_recall: 0.7101\n",
      "Epoch 3128/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7500 - precision: 0.6558 - recall: 0.7088 - val_loss: 0.7491 - val_precision: 0.6410 - val_recall: 0.7101\n",
      "Epoch 3129/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7500 - precision: 0.6559 - recall: 0.7089 - val_loss: 0.7491 - val_precision: 0.6410 - val_recall: 0.7101\n",
      "Epoch 3130/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7499 - precision: 0.6559 - recall: 0.7089 - val_loss: 0.7490 - val_precision: 0.6413 - val_recall: 0.7101\n",
      "Epoch 3131/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7498 - precision: 0.6558 - recall: 0.7084 - val_loss: 0.7490 - val_precision: 0.6415 - val_recall: 0.7101\n",
      "Epoch 3132/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7498 - precision: 0.6557 - recall: 0.7082 - val_loss: 0.7489 - val_precision: 0.6415 - val_recall: 0.7101\n",
      "Epoch 3133/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7497 - precision: 0.6559 - recall: 0.7087 - val_loss: 0.7488 - val_precision: 0.6415 - val_recall: 0.7101\n",
      "Epoch 3134/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7497 - precision: 0.6558 - recall: 0.7084 - val_loss: 0.7488 - val_precision: 0.6415 - val_recall: 0.7101\n",
      "Epoch 3135/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7496 - precision: 0.6559 - recall: 0.7089 - val_loss: 0.7487 - val_precision: 0.6415 - val_recall: 0.7101\n",
      "Epoch 3136/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7495 - precision: 0.6558 - recall: 0.7087 - val_loss: 0.7487 - val_precision: 0.6415 - val_recall: 0.7101\n",
      "Epoch 3137/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7495 - precision: 0.6558 - recall: 0.7083 - val_loss: 0.7486 - val_precision: 0.6414 - val_recall: 0.7093\n",
      "Epoch 3138/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7494 - precision: 0.6558 - recall: 0.7084 - val_loss: 0.7485 - val_precision: 0.6414 - val_recall: 0.7097\n",
      "Epoch 3139/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7493 - precision: 0.6557 - recall: 0.7083 - val_loss: 0.7485 - val_precision: 0.6414 - val_recall: 0.7093\n",
      "Epoch 3140/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7493 - precision: 0.6558 - recall: 0.7082 - val_loss: 0.7484 - val_precision: 0.6414 - val_recall: 0.7093\n",
      "Epoch 3141/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7492 - precision: 0.6558 - recall: 0.7076 - val_loss: 0.7484 - val_precision: 0.6414 - val_recall: 0.7093\n",
      "Epoch 3142/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7492 - precision: 0.6558 - recall: 0.7079 - val_loss: 0.7483 - val_precision: 0.6414 - val_recall: 0.7093\n",
      "Epoch 3143/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7491 - precision: 0.6558 - recall: 0.7075 - val_loss: 0.7483 - val_precision: 0.6414 - val_recall: 0.7093\n",
      "Epoch 3144/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7490 - precision: 0.6558 - recall: 0.7078 - val_loss: 0.7482 - val_precision: 0.6414 - val_recall: 0.7093\n",
      "Epoch 3145/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7490 - precision: 0.6560 - recall: 0.7075 - val_loss: 0.7481 - val_precision: 0.6417 - val_recall: 0.7093\n",
      "Epoch 3146/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7489 - precision: 0.6560 - recall: 0.7076 - val_loss: 0.7481 - val_precision: 0.6417 - val_recall: 0.7093\n",
      "Epoch 3147/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7489 - precision: 0.6560 - recall: 0.7074 - val_loss: 0.7480 - val_precision: 0.6417 - val_recall: 0.7093\n",
      "Epoch 3148/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7488 - precision: 0.6560 - recall: 0.7075 - val_loss: 0.7480 - val_precision: 0.6417 - val_recall: 0.7093\n",
      "Epoch 3149/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7487 - precision: 0.6560 - recall: 0.7074 - val_loss: 0.7479 - val_precision: 0.6415 - val_recall: 0.7089\n",
      "Epoch 3150/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7487 - precision: 0.6560 - recall: 0.7074 - val_loss: 0.7478 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3151/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7486 - precision: 0.6560 - recall: 0.7074 - val_loss: 0.7478 - val_precision: 0.6417 - val_recall: 0.7093\n",
      "Epoch 3152/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7486 - precision: 0.6562 - recall: 0.7074 - val_loss: 0.7477 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3153/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7485 - precision: 0.6562 - recall: 0.7074 - val_loss: 0.7477 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3154/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7484 - precision: 0.6561 - recall: 0.7073 - val_loss: 0.7476 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3155/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7484 - precision: 0.6561 - recall: 0.7073 - val_loss: 0.7475 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3156/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7483 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7475 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3157/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7483 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7474 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3158/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7482 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7474 - val_precision: 0.6414 - val_recall: 0.7086\n",
      "Epoch 3159/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7481 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7473 - val_precision: 0.6416 - val_recall: 0.7086\n",
      "Epoch 3160/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7481 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7473 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3161/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7480 - precision: 0.6560 - recall: 0.7071 - val_loss: 0.7472 - val_precision: 0.6415 - val_recall: 0.7089\n",
      "Epoch 3162/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7480 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7471 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3163/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7479 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7471 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3164/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7478 - precision: 0.6561 - recall: 0.7070 - val_loss: 0.7470 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3165/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7478 - precision: 0.6562 - recall: 0.7071 - val_loss: 0.7470 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3166/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7477 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7469 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3167/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7477 - precision: 0.6561 - recall: 0.7071 - val_loss: 0.7468 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3168/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7476 - precision: 0.6563 - recall: 0.7070 - val_loss: 0.7468 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3169/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7475 - precision: 0.6562 - recall: 0.7070 - val_loss: 0.7467 - val_precision: 0.6418 - val_recall: 0.7089\n",
      "Epoch 3170/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7475 - precision: 0.6562 - recall: 0.7071 - val_loss: 0.7467 - val_precision: 0.6416 - val_recall: 0.7086\n",
      "Epoch 3171/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7474 - precision: 0.6562 - recall: 0.7070 - val_loss: 0.7466 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3172/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7474 - precision: 0.6562 - recall: 0.7071 - val_loss: 0.7466 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3173/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7473 - precision: 0.6562 - recall: 0.7069 - val_loss: 0.7465 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3174/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7472 - precision: 0.6562 - recall: 0.7069 - val_loss: 0.7464 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3175/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7472 - precision: 0.6562 - recall: 0.7070 - val_loss: 0.7464 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3176/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7471 - precision: 0.6561 - recall: 0.7066 - val_loss: 0.7463 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3177/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7471 - precision: 0.6562 - recall: 0.7068 - val_loss: 0.7463 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3178/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7470 - precision: 0.6562 - recall: 0.7068 - val_loss: 0.7462 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3179/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7469 - precision: 0.6562 - recall: 0.7068 - val_loss: 0.7462 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3180/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7469 - precision: 0.6562 - recall: 0.7068 - val_loss: 0.7461 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3181/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7468 - precision: 0.6562 - recall: 0.7068 - val_loss: 0.7460 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3182/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7468 - precision: 0.6563 - recall: 0.7068 - val_loss: 0.7460 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3183/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7467 - precision: 0.6564 - recall: 0.7066 - val_loss: 0.7459 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3184/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7467 - precision: 0.6564 - recall: 0.7068 - val_loss: 0.7459 - val_precision: 0.6415 - val_recall: 0.7082\n",
      "Epoch 3185/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7466 - precision: 0.6563 - recall: 0.7065 - val_loss: 0.7458 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3186/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7465 - precision: 0.6564 - recall: 0.7066 - val_loss: 0.7458 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3187/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7465 - precision: 0.6564 - recall: 0.7068 - val_loss: 0.7457 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3188/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7464 - precision: 0.6564 - recall: 0.7068 - val_loss: 0.7456 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3189/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7464 - precision: 0.6564 - recall: 0.7064 - val_loss: 0.7456 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3190/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7463 - precision: 0.6564 - recall: 0.7064 - val_loss: 0.7455 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3191/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7462 - precision: 0.6566 - recall: 0.7065 - val_loss: 0.7455 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3192/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7462 - precision: 0.6564 - recall: 0.7066 - val_loss: 0.7454 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3193/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7461 - precision: 0.6564 - recall: 0.7066 - val_loss: 0.7454 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3194/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7461 - precision: 0.6566 - recall: 0.7065 - val_loss: 0.7453 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3195/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7460 - precision: 0.6564 - recall: 0.7066 - val_loss: 0.7452 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3196/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7460 - precision: 0.6566 - recall: 0.7065 - val_loss: 0.7452 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3197/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7459 - precision: 0.6566 - recall: 0.7065 - val_loss: 0.7451 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3198/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7458 - precision: 0.6566 - recall: 0.7065 - val_loss: 0.7451 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3199/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7458 - precision: 0.6565 - recall: 0.7066 - val_loss: 0.7450 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3200/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7457 - precision: 0.6566 - recall: 0.7064 - val_loss: 0.7450 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3201/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7457 - precision: 0.6566 - recall: 0.7065 - val_loss: 0.7449 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3202/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7456 - precision: 0.6566 - recall: 0.7064 - val_loss: 0.7448 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3203/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7455 - precision: 0.6565 - recall: 0.7064 - val_loss: 0.7448 - val_precision: 0.6417 - val_recall: 0.7082\n",
      "Epoch 3204/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7455 - precision: 0.6566 - recall: 0.7064 - val_loss: 0.7447 - val_precision: 0.6416 - val_recall: 0.7078\n",
      "Epoch 3205/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7454 - precision: 0.6567 - recall: 0.7064 - val_loss: 0.7447 - val_precision: 0.6416 - val_recall: 0.7078\n",
      "Epoch 3206/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7454 - precision: 0.6567 - recall: 0.7060 - val_loss: 0.7446 - val_precision: 0.6416 - val_recall: 0.7078\n",
      "Epoch 3207/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7453 - precision: 0.6566 - recall: 0.7060 - val_loss: 0.7446 - val_precision: 0.6416 - val_recall: 0.7078\n",
      "Epoch 3208/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7453 - precision: 0.6567 - recall: 0.7060 - val_loss: 0.7445 - val_precision: 0.6416 - val_recall: 0.7078\n",
      "Epoch 3209/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7452 - precision: 0.6566 - recall: 0.7062 - val_loss: 0.7444 - val_precision: 0.6416 - val_recall: 0.7078\n",
      "Epoch 3210/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7451 - precision: 0.6568 - recall: 0.7059 - val_loss: 0.7444 - val_precision: 0.6415 - val_recall: 0.7074\n",
      "Epoch 3211/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7451 - precision: 0.6568 - recall: 0.7061 - val_loss: 0.7443 - val_precision: 0.6415 - val_recall: 0.7074\n",
      "Epoch 3212/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7450 - precision: 0.6568 - recall: 0.7061 - val_loss: 0.7443 - val_precision: 0.6415 - val_recall: 0.7074\n",
      "Epoch 3213/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7450 - precision: 0.6567 - recall: 0.7059 - val_loss: 0.7442 - val_precision: 0.6415 - val_recall: 0.7074\n",
      "Epoch 3214/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7449 - precision: 0.6567 - recall: 0.7059 - val_loss: 0.7442 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3215/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7448 - precision: 0.6568 - recall: 0.7061 - val_loss: 0.7441 - val_precision: 0.6417 - val_recall: 0.7074\n",
      "Epoch 3216/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7448 - precision: 0.6567 - recall: 0.7059 - val_loss: 0.7441 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3217/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7447 - precision: 0.6567 - recall: 0.7054 - val_loss: 0.7440 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3218/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7447 - precision: 0.6567 - recall: 0.7055 - val_loss: 0.7439 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3219/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7446 - precision: 0.6567 - recall: 0.7055 - val_loss: 0.7439 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3220/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7446 - precision: 0.6567 - recall: 0.7054 - val_loss: 0.7438 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3221/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7445 - precision: 0.6567 - recall: 0.7054 - val_loss: 0.7438 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3222/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7444 - precision: 0.6567 - recall: 0.7052 - val_loss: 0.7437 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3223/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7444 - precision: 0.6567 - recall: 0.7054 - val_loss: 0.7437 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3224/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7443 - precision: 0.6567 - recall: 0.7054 - val_loss: 0.7436 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3225/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7443 - precision: 0.6567 - recall: 0.7052 - val_loss: 0.7435 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3226/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7442 - precision: 0.6567 - recall: 0.7051 - val_loss: 0.7435 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3227/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7442 - precision: 0.6566 - recall: 0.7050 - val_loss: 0.7434 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3228/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7441 - precision: 0.6567 - recall: 0.7048 - val_loss: 0.7434 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3229/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7440 - precision: 0.6566 - recall: 0.7050 - val_loss: 0.7433 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3230/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7440 - precision: 0.6569 - recall: 0.7050 - val_loss: 0.7433 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3231/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7439 - precision: 0.6570 - recall: 0.7048 - val_loss: 0.7432 - val_precision: 0.6417 - val_recall: 0.7066\n",
      "Epoch 3232/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7439 - precision: 0.6569 - recall: 0.7046 - val_loss: 0.7432 - val_precision: 0.6418 - val_recall: 0.7070\n",
      "Epoch 3233/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7438 - precision: 0.6567 - recall: 0.7048 - val_loss: 0.7431 - val_precision: 0.6418 - val_recall: 0.7070\n",
      "Epoch 3234/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7438 - precision: 0.6569 - recall: 0.7046 - val_loss: 0.7431 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3235/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7437 - precision: 0.6568 - recall: 0.7048 - val_loss: 0.7430 - val_precision: 0.6416 - val_recall: 0.7070\n",
      "Epoch 3236/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7436 - precision: 0.6570 - recall: 0.7046 - val_loss: 0.7429 - val_precision: 0.6419 - val_recall: 0.7066\n",
      "Epoch 3237/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7436 - precision: 0.6570 - recall: 0.7047 - val_loss: 0.7429 - val_precision: 0.6419 - val_recall: 0.7066\n",
      "Epoch 3238/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7435 - precision: 0.6572 - recall: 0.7045 - val_loss: 0.7428 - val_precision: 0.6419 - val_recall: 0.7066\n",
      "Epoch 3239/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7435 - precision: 0.6567 - recall: 0.7048 - val_loss: 0.7428 - val_precision: 0.6419 - val_recall: 0.7066\n",
      "Epoch 3240/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7434 - precision: 0.6570 - recall: 0.7048 - val_loss: 0.7427 - val_precision: 0.6420 - val_recall: 0.7070\n",
      "Epoch 3241/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7434 - precision: 0.6570 - recall: 0.7048 - val_loss: 0.7427 - val_precision: 0.6420 - val_recall: 0.7070\n",
      "Epoch 3242/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7433 - precision: 0.6570 - recall: 0.7048 - val_loss: 0.7426 - val_precision: 0.6420 - val_recall: 0.7070\n",
      "Epoch 3243/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7432 - precision: 0.6570 - recall: 0.7047 - val_loss: 0.7426 - val_precision: 0.6421 - val_recall: 0.7066\n",
      "Epoch 3244/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7432 - precision: 0.6570 - recall: 0.7048 - val_loss: 0.7425 - val_precision: 0.6419 - val_recall: 0.7066\n",
      "Epoch 3245/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7431 - precision: 0.6570 - recall: 0.7047 - val_loss: 0.7424 - val_precision: 0.6419 - val_recall: 0.7066\n",
      "Epoch 3246/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7431 - precision: 0.6568 - recall: 0.7048 - val_loss: 0.7424 - val_precision: 0.6419 - val_recall: 0.7066\n",
      "Epoch 3247/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7430 - precision: 0.6570 - recall: 0.7046 - val_loss: 0.7423 - val_precision: 0.6421 - val_recall: 0.7066\n",
      "Epoch 3248/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7430 - precision: 0.6569 - recall: 0.7047 - val_loss: 0.7423 - val_precision: 0.6420 - val_recall: 0.7070\n",
      "Epoch 3249/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7429 - precision: 0.6570 - recall: 0.7045 - val_loss: 0.7422 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3250/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7429 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7422 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3251/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7428 - precision: 0.6572 - recall: 0.7043 - val_loss: 0.7421 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3252/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7427 - precision: 0.6572 - recall: 0.7045 - val_loss: 0.7421 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3253/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7427 - precision: 0.6573 - recall: 0.7043 - val_loss: 0.7420 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3254/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7426 - precision: 0.6572 - recall: 0.7042 - val_loss: 0.7420 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3255/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7426 - precision: 0.6572 - recall: 0.7045 - val_loss: 0.7419 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3256/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7425 - precision: 0.6572 - recall: 0.7045 - val_loss: 0.7418 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3257/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7425 - precision: 0.6572 - recall: 0.7045 - val_loss: 0.7418 - val_precision: 0.6426 - val_recall: 0.7066\n",
      "Epoch 3258/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7424 - precision: 0.6572 - recall: 0.7045 - val_loss: 0.7417 - val_precision: 0.6425 - val_recall: 0.7062\n",
      "Epoch 3259/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7424 - precision: 0.6573 - recall: 0.7045 - val_loss: 0.7417 - val_precision: 0.6425 - val_recall: 0.7062\n",
      "Epoch 3260/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7423 - precision: 0.6574 - recall: 0.7042 - val_loss: 0.7416 - val_precision: 0.6422 - val_recall: 0.7054\n",
      "Epoch 3261/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7422 - precision: 0.6573 - recall: 0.7042 - val_loss: 0.7416 - val_precision: 0.6424 - val_recall: 0.7058\n",
      "Epoch 3262/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7422 - precision: 0.6574 - recall: 0.7045 - val_loss: 0.7415 - val_precision: 0.6425 - val_recall: 0.7062\n",
      "Epoch 3263/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7421 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7415 - val_precision: 0.6424 - val_recall: 0.7058\n",
      "Epoch 3264/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7421 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7414 - val_precision: 0.6424 - val_recall: 0.7058\n",
      "Epoch 3265/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7420 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7414 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3266/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7420 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7413 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3267/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7419 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7413 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3268/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7419 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7412 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3269/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7418 - precision: 0.6573 - recall: 0.7041 - val_loss: 0.7412 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3270/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7418 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7411 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3271/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7417 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7410 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3272/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7416 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7410 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3273/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7416 - precision: 0.6573 - recall: 0.7042 - val_loss: 0.7409 - val_precision: 0.6427 - val_recall: 0.7054\n",
      "Epoch 3274/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7415 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7409 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3275/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7415 - precision: 0.6573 - recall: 0.7042 - val_loss: 0.7408 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3276/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7414 - precision: 0.6573 - recall: 0.7042 - val_loss: 0.7408 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3277/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7414 - precision: 0.6574 - recall: 0.7041 - val_loss: 0.7407 - val_precision: 0.6426 - val_recall: 0.7051\n",
      "Epoch 3278/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7413 - precision: 0.6574 - recall: 0.7043 - val_loss: 0.7407 - val_precision: 0.6422 - val_recall: 0.7054\n",
      "Epoch 3279/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7413 - precision: 0.6573 - recall: 0.7039 - val_loss: 0.7406 - val_precision: 0.6426 - val_recall: 0.7051\n",
      "Epoch 3280/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7412 - precision: 0.6574 - recall: 0.7041 - val_loss: 0.7406 - val_precision: 0.6422 - val_recall: 0.7054\n",
      "Epoch 3281/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7412 - precision: 0.6574 - recall: 0.7042 - val_loss: 0.7405 - val_precision: 0.6425 - val_recall: 0.7054\n",
      "Epoch 3282/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7411 - precision: 0.6573 - recall: 0.7038 - val_loss: 0.7405 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3283/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7410 - precision: 0.6574 - recall: 0.7037 - val_loss: 0.7404 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3284/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7410 - precision: 0.6574 - recall: 0.7038 - val_loss: 0.7403 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3285/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7409 - precision: 0.6575 - recall: 0.7039 - val_loss: 0.7403 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3286/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7409 - precision: 0.6574 - recall: 0.7041 - val_loss: 0.7402 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3287/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7408 - precision: 0.6574 - recall: 0.7037 - val_loss: 0.7402 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3288/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7408 - precision: 0.6574 - recall: 0.7037 - val_loss: 0.7401 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3289/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7407 - precision: 0.6575 - recall: 0.7039 - val_loss: 0.7401 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3290/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7407 - precision: 0.6575 - recall: 0.7037 - val_loss: 0.7400 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3291/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7406 - precision: 0.6575 - recall: 0.7041 - val_loss: 0.7400 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3292/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7406 - precision: 0.6576 - recall: 0.7037 - val_loss: 0.7399 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3293/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7405 - precision: 0.6575 - recall: 0.7037 - val_loss: 0.7399 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3294/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7405 - precision: 0.6577 - recall: 0.7041 - val_loss: 0.7398 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3295/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7404 - precision: 0.6577 - recall: 0.7042 - val_loss: 0.7398 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3296/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7404 - precision: 0.6576 - recall: 0.7037 - val_loss: 0.7397 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3297/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7403 - precision: 0.6576 - recall: 0.7033 - val_loss: 0.7397 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3298/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7402 - precision: 0.6576 - recall: 0.7033 - val_loss: 0.7396 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3299/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7402 - precision: 0.6576 - recall: 0.7034 - val_loss: 0.7396 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3300/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7401 - precision: 0.6577 - recall: 0.7033 - val_loss: 0.7395 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3301/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7401 - precision: 0.6576 - recall: 0.7033 - val_loss: 0.7395 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3302/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7400 - precision: 0.6576 - recall: 0.7033 - val_loss: 0.7394 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3303/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7400 - precision: 0.6576 - recall: 0.7034 - val_loss: 0.7394 - val_precision: 0.6423 - val_recall: 0.7051\n",
      "Epoch 3304/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7399 - precision: 0.6577 - recall: 0.7036 - val_loss: 0.7393 - val_precision: 0.6426 - val_recall: 0.7051\n",
      "Epoch 3305/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7399 - precision: 0.6577 - recall: 0.7033 - val_loss: 0.7393 - val_precision: 0.6426 - val_recall: 0.7051\n",
      "Epoch 3306/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7398 - precision: 0.6577 - recall: 0.7033 - val_loss: 0.7392 - val_precision: 0.6426 - val_recall: 0.7051\n",
      "Epoch 3307/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7398 - precision: 0.6578 - recall: 0.7034 - val_loss: 0.7392 - val_precision: 0.6426 - val_recall: 0.7051\n",
      "Epoch 3308/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7397 - precision: 0.6577 - recall: 0.7033 - val_loss: 0.7391 - val_precision: 0.6425 - val_recall: 0.7043\n",
      "Epoch 3309/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7397 - precision: 0.6579 - recall: 0.7032 - val_loss: 0.7391 - val_precision: 0.6423 - val_recall: 0.7043\n",
      "Epoch 3310/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7396 - precision: 0.6578 - recall: 0.7032 - val_loss: 0.7390 - val_precision: 0.6423 - val_recall: 0.7043\n",
      "Epoch 3311/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7396 - precision: 0.6577 - recall: 0.7034 - val_loss: 0.7389 - val_precision: 0.6423 - val_recall: 0.7043\n",
      "Epoch 3312/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7395 - precision: 0.6580 - recall: 0.7025 - val_loss: 0.7389 - val_precision: 0.6424 - val_recall: 0.7039\n",
      "Epoch 3313/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7394 - precision: 0.6581 - recall: 0.7024 - val_loss: 0.7389 - val_precision: 0.6426 - val_recall: 0.7039\n",
      "Epoch 3314/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7394 - precision: 0.6581 - recall: 0.7025 - val_loss: 0.7388 - val_precision: 0.6426 - val_recall: 0.7039\n",
      "Epoch 3315/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7393 - precision: 0.6580 - recall: 0.7025 - val_loss: 0.7388 - val_precision: 0.6426 - val_recall: 0.7039\n",
      "Epoch 3316/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7393 - precision: 0.6581 - recall: 0.7024 - val_loss: 0.7387 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3317/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7392 - precision: 0.6581 - recall: 0.7024 - val_loss: 0.7387 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3318/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7392 - precision: 0.6579 - recall: 0.7027 - val_loss: 0.7386 - val_precision: 0.6426 - val_recall: 0.7039\n",
      "Epoch 3319/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7391 - precision: 0.6581 - recall: 0.7024 - val_loss: 0.7385 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3320/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7391 - precision: 0.6580 - recall: 0.7024 - val_loss: 0.7385 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3321/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7390 - precision: 0.6580 - recall: 0.7025 - val_loss: 0.7384 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3322/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7390 - precision: 0.6581 - recall: 0.7027 - val_loss: 0.7384 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3323/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7389 - precision: 0.6580 - recall: 0.7024 - val_loss: 0.7383 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3324/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7389 - precision: 0.6581 - recall: 0.7028 - val_loss: 0.7383 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3325/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7388 - precision: 0.6581 - recall: 0.7022 - val_loss: 0.7382 - val_precision: 0.6431 - val_recall: 0.7039\n",
      "Epoch 3326/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7388 - precision: 0.6580 - recall: 0.7025 - val_loss: 0.7382 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3327/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7387 - precision: 0.6581 - recall: 0.7028 - val_loss: 0.7381 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3328/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7387 - precision: 0.6581 - recall: 0.7028 - val_loss: 0.7381 - val_precision: 0.6429 - val_recall: 0.7039\n",
      "Epoch 3329/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7386 - precision: 0.6581 - recall: 0.7022 - val_loss: 0.7380 - val_precision: 0.6432 - val_recall: 0.7035\n",
      "Epoch 3330/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7386 - precision: 0.6581 - recall: 0.7019 - val_loss: 0.7380 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3331/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7385 - precision: 0.6581 - recall: 0.7019 - val_loss: 0.7379 - val_precision: 0.6432 - val_recall: 0.7035\n",
      "Epoch 3332/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7384 - precision: 0.6581 - recall: 0.7019 - val_loss: 0.7379 - val_precision: 0.6432 - val_recall: 0.7035\n",
      "Epoch 3333/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7384 - precision: 0.6581 - recall: 0.7019 - val_loss: 0.7378 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3334/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7383 - precision: 0.6583 - recall: 0.7024 - val_loss: 0.7378 - val_precision: 0.6432 - val_recall: 0.7035\n",
      "Epoch 3335/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7383 - precision: 0.6582 - recall: 0.7020 - val_loss: 0.7377 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3336/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7382 - precision: 0.6583 - recall: 0.7023 - val_loss: 0.7377 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3337/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7382 - precision: 0.6583 - recall: 0.7020 - val_loss: 0.7376 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3338/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7381 - precision: 0.6583 - recall: 0.7020 - val_loss: 0.7376 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3339/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7381 - precision: 0.6582 - recall: 0.7015 - val_loss: 0.7375 - val_precision: 0.6433 - val_recall: 0.7031\n",
      "Epoch 3340/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7380 - precision: 0.6583 - recall: 0.7020 - val_loss: 0.7375 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3341/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7380 - precision: 0.6583 - recall: 0.7020 - val_loss: 0.7374 - val_precision: 0.6433 - val_recall: 0.7031\n",
      "Epoch 3342/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7379 - precision: 0.6585 - recall: 0.7027 - val_loss: 0.7374 - val_precision: 0.6434 - val_recall: 0.7035\n",
      "Epoch 3343/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7379 - precision: 0.6583 - recall: 0.7017 - val_loss: 0.7373 - val_precision: 0.6433 - val_recall: 0.7031\n",
      "Epoch 3344/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7378 - precision: 0.6584 - recall: 0.7018 - val_loss: 0.7373 - val_precision: 0.6433 - val_recall: 0.7031\n",
      "Epoch 3345/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7378 - precision: 0.6586 - recall: 0.7024 - val_loss: 0.7372 - val_precision: 0.6433 - val_recall: 0.7031\n",
      "Epoch 3346/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7377 - precision: 0.6585 - recall: 0.7020 - val_loss: 0.7372 - val_precision: 0.6433 - val_recall: 0.7031\n",
      "Epoch 3347/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7377 - precision: 0.6586 - recall: 0.7024 - val_loss: 0.7371 - val_precision: 0.6433 - val_recall: 0.7031\n",
      "Epoch 3348/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7376 - precision: 0.6586 - recall: 0.7020 - val_loss: 0.7371 - val_precision: 0.6432 - val_recall: 0.7027\n",
      "Epoch 3349/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7376 - precision: 0.6586 - recall: 0.7022 - val_loss: 0.7370 - val_precision: 0.6432 - val_recall: 0.7027\n",
      "Epoch 3350/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7375 - precision: 0.6585 - recall: 0.7014 - val_loss: 0.7370 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3351/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7375 - precision: 0.6586 - recall: 0.7022 - val_loss: 0.7369 - val_precision: 0.6432 - val_recall: 0.7027\n",
      "Epoch 3352/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7374 - precision: 0.6585 - recall: 0.7019 - val_loss: 0.7369 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3353/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7374 - precision: 0.6587 - recall: 0.7020 - val_loss: 0.7368 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3354/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7373 - precision: 0.6587 - recall: 0.7022 - val_loss: 0.7368 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3355/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7373 - precision: 0.6587 - recall: 0.7025 - val_loss: 0.7367 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3356/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7372 - precision: 0.6587 - recall: 0.7023 - val_loss: 0.7367 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3357/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7372 - precision: 0.6589 - recall: 0.7024 - val_loss: 0.7366 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3358/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7371 - precision: 0.6588 - recall: 0.7020 - val_loss: 0.7366 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3359/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7371 - precision: 0.6588 - recall: 0.7018 - val_loss: 0.7365 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3360/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7370 - precision: 0.6589 - recall: 0.7022 - val_loss: 0.7365 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3361/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7369 - precision: 0.6589 - recall: 0.7022 - val_loss: 0.7364 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3362/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7369 - precision: 0.6589 - recall: 0.7019 - val_loss: 0.7364 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3363/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7368 - precision: 0.6589 - recall: 0.7020 - val_loss: 0.7363 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3364/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7368 - precision: 0.6589 - recall: 0.7022 - val_loss: 0.7363 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3365/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7367 - precision: 0.6589 - recall: 0.7017 - val_loss: 0.7362 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3366/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7367 - precision: 0.6589 - recall: 0.7020 - val_loss: 0.7362 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3367/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7366 - precision: 0.6590 - recall: 0.7023 - val_loss: 0.7361 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3368/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7366 - precision: 0.6590 - recall: 0.7022 - val_loss: 0.7361 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3369/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7365 - precision: 0.6589 - recall: 0.7020 - val_loss: 0.7360 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3370/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7365 - precision: 0.6591 - recall: 0.7020 - val_loss: 0.7360 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3371/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7364 - precision: 0.6591 - recall: 0.7018 - val_loss: 0.7359 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3372/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7364 - precision: 0.6591 - recall: 0.7018 - val_loss: 0.7359 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3373/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7363 - precision: 0.6591 - recall: 0.7020 - val_loss: 0.7358 - val_precision: 0.6433 - val_recall: 0.7023\n",
      "Epoch 3374/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7363 - precision: 0.6589 - recall: 0.7017 - val_loss: 0.7358 - val_precision: 0.6434 - val_recall: 0.7019\n",
      "Epoch 3375/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7362 - precision: 0.6590 - recall: 0.7015 - val_loss: 0.7357 - val_precision: 0.6434 - val_recall: 0.7019\n",
      "Epoch 3376/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7362 - precision: 0.6591 - recall: 0.7019 - val_loss: 0.7357 - val_precision: 0.6434 - val_recall: 0.7019\n",
      "Epoch 3377/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7361 - precision: 0.6590 - recall: 0.7019 - val_loss: 0.7356 - val_precision: 0.6434 - val_recall: 0.7019\n",
      "Epoch 3378/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7361 - precision: 0.6590 - recall: 0.7018 - val_loss: 0.7356 - val_precision: 0.6434 - val_recall: 0.7019\n",
      "Epoch 3379/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7360 - precision: 0.6591 - recall: 0.7019 - val_loss: 0.7355 - val_precision: 0.6436 - val_recall: 0.7019\n",
      "Epoch 3380/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7360 - precision: 0.6590 - recall: 0.7019 - val_loss: 0.7355 - val_precision: 0.6436 - val_recall: 0.7019\n",
      "Epoch 3381/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7359 - precision: 0.6590 - recall: 0.7015 - val_loss: 0.7354 - val_precision: 0.6434 - val_recall: 0.7019\n",
      "Epoch 3382/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7359 - precision: 0.6591 - recall: 0.7018 - val_loss: 0.7354 - val_precision: 0.6434 - val_recall: 0.7019\n",
      "Epoch 3383/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7358 - precision: 0.6590 - recall: 0.7015 - val_loss: 0.7353 - val_precision: 0.6436 - val_recall: 0.7019\n",
      "Epoch 3384/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7358 - precision: 0.6590 - recall: 0.7015 - val_loss: 0.7353 - val_precision: 0.6436 - val_recall: 0.7019\n",
      "Epoch 3385/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7357 - precision: 0.6591 - recall: 0.7014 - val_loss: 0.7352 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3386/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7357 - precision: 0.6590 - recall: 0.7015 - val_loss: 0.7352 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3387/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7356 - precision: 0.6592 - recall: 0.7014 - val_loss: 0.7352 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3388/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7356 - precision: 0.6592 - recall: 0.7013 - val_loss: 0.7351 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3389/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7355 - precision: 0.6592 - recall: 0.7013 - val_loss: 0.7351 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3390/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7355 - precision: 0.6590 - recall: 0.7013 - val_loss: 0.7350 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3391/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7354 - precision: 0.6591 - recall: 0.7014 - val_loss: 0.7350 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3392/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7354 - precision: 0.6592 - recall: 0.7014 - val_loss: 0.7349 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3393/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7353 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7349 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3394/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7353 - precision: 0.6593 - recall: 0.7011 - val_loss: 0.7348 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3395/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7352 - precision: 0.6592 - recall: 0.7009 - val_loss: 0.7348 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3396/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7352 - precision: 0.6590 - recall: 0.7003 - val_loss: 0.7347 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3397/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7351 - precision: 0.6591 - recall: 0.7004 - val_loss: 0.7347 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3398/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7351 - precision: 0.6591 - recall: 0.7005 - val_loss: 0.7346 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3399/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7350 - precision: 0.6592 - recall: 0.7008 - val_loss: 0.7346 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3400/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7350 - precision: 0.6593 - recall: 0.7011 - val_loss: 0.7345 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3401/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7349 - precision: 0.6591 - recall: 0.7005 - val_loss: 0.7345 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3402/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7349 - precision: 0.6591 - recall: 0.7003 - val_loss: 0.7344 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3403/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7348 - precision: 0.6592 - recall: 0.7004 - val_loss: 0.7344 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3404/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7348 - precision: 0.6591 - recall: 0.7003 - val_loss: 0.7343 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3405/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7347 - precision: 0.6592 - recall: 0.7004 - val_loss: 0.7343 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3406/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7347 - precision: 0.6592 - recall: 0.7004 - val_loss: 0.7342 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3407/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7346 - precision: 0.6592 - recall: 0.7003 - val_loss: 0.7342 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3408/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7346 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7341 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3409/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7345 - precision: 0.6592 - recall: 0.7004 - val_loss: 0.7341 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3410/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7345 - precision: 0.6594 - recall: 0.7010 - val_loss: 0.7340 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3411/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7344 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7340 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3412/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7344 - precision: 0.6593 - recall: 0.7008 - val_loss: 0.7339 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3413/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7343 - precision: 0.6594 - recall: 0.7008 - val_loss: 0.7339 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3414/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7343 - precision: 0.6593 - recall: 0.7006 - val_loss: 0.7338 - val_precision: 0.6438 - val_recall: 0.7019\n",
      "Epoch 3415/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7342 - precision: 0.6594 - recall: 0.7008 - val_loss: 0.7338 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3416/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7342 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7338 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3417/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7341 - precision: 0.6593 - recall: 0.7008 - val_loss: 0.7337 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3418/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7341 - precision: 0.6593 - recall: 0.7008 - val_loss: 0.7337 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3419/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7340 - precision: 0.6593 - recall: 0.7009 - val_loss: 0.7336 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3420/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7340 - precision: 0.6593 - recall: 0.7008 - val_loss: 0.7336 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3421/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7339 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7335 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3422/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7339 - precision: 0.6593 - recall: 0.7008 - val_loss: 0.7335 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3423/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7338 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7334 - val_precision: 0.6437 - val_recall: 0.7016\n",
      "Epoch 3424/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7338 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7334 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3425/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7337 - precision: 0.6592 - recall: 0.7006 - val_loss: 0.7333 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3426/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7337 - precision: 0.6593 - recall: 0.7004 - val_loss: 0.7333 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3427/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7336 - precision: 0.6593 - recall: 0.7006 - val_loss: 0.7332 - val_precision: 0.6441 - val_recall: 0.7019\n",
      "Epoch 3428/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7336 - precision: 0.6594 - recall: 0.7006 - val_loss: 0.7332 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3429/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7336 - precision: 0.6594 - recall: 0.7006 - val_loss: 0.7331 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3430/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7335 - precision: 0.6593 - recall: 0.7000 - val_loss: 0.7331 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3431/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7335 - precision: 0.6594 - recall: 0.7006 - val_loss: 0.7330 - val_precision: 0.6441 - val_recall: 0.7019\n",
      "Epoch 3432/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7334 - precision: 0.6593 - recall: 0.7003 - val_loss: 0.7330 - val_precision: 0.6441 - val_recall: 0.7019\n",
      "Epoch 3433/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7334 - precision: 0.6594 - recall: 0.7006 - val_loss: 0.7329 - val_precision: 0.6441 - val_recall: 0.7019\n",
      "Epoch 3434/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7333 - precision: 0.6593 - recall: 0.7001 - val_loss: 0.7329 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3435/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7333 - precision: 0.6592 - recall: 0.6999 - val_loss: 0.7329 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3436/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7332 - precision: 0.6592 - recall: 0.6999 - val_loss: 0.7328 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3437/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7332 - precision: 0.6593 - recall: 0.6997 - val_loss: 0.7328 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3438/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7331 - precision: 0.6593 - recall: 0.6999 - val_loss: 0.7327 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3439/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7331 - precision: 0.6593 - recall: 0.7000 - val_loss: 0.7327 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3440/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7330 - precision: 0.6593 - recall: 0.7000 - val_loss: 0.7326 - val_precision: 0.6441 - val_recall: 0.7019\n",
      "Epoch 3441/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7330 - precision: 0.6593 - recall: 0.7003 - val_loss: 0.7326 - val_precision: 0.6441 - val_recall: 0.7019\n",
      "Epoch 3442/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7329 - precision: 0.6592 - recall: 0.7000 - val_loss: 0.7325 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3443/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7329 - precision: 0.6592 - recall: 0.7001 - val_loss: 0.7325 - val_precision: 0.6441 - val_recall: 0.7019\n",
      "Epoch 3444/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7328 - precision: 0.6594 - recall: 0.7000 - val_loss: 0.7324 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3445/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7328 - precision: 0.6593 - recall: 0.7000 - val_loss: 0.7324 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3446/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7327 - precision: 0.6593 - recall: 0.7001 - val_loss: 0.7323 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3447/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7327 - precision: 0.6591 - recall: 0.6999 - val_loss: 0.7323 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3448/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7326 - precision: 0.6591 - recall: 0.6999 - val_loss: 0.7322 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3449/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7326 - precision: 0.6593 - recall: 0.6999 - val_loss: 0.7322 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3450/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7325 - precision: 0.6592 - recall: 0.6999 - val_loss: 0.7321 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3451/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7325 - precision: 0.6591 - recall: 0.6999 - val_loss: 0.7321 - val_precision: 0.6439 - val_recall: 0.7016\n",
      "Epoch 3452/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7324 - precision: 0.6591 - recall: 0.6999 - val_loss: 0.7321 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3453/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7324 - precision: 0.6591 - recall: 0.6999 - val_loss: 0.7320 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3454/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7323 - precision: 0.6591 - recall: 0.6999 - val_loss: 0.7320 - val_precision: 0.6438 - val_recall: 0.7012\n",
      "Epoch 3455/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7323 - precision: 0.6592 - recall: 0.7000 - val_loss: 0.7319 - val_precision: 0.6437 - val_recall: 0.7008\n",
      "Epoch 3456/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7322 - precision: 0.6592 - recall: 0.6999 - val_loss: 0.7319 - val_precision: 0.6437 - val_recall: 0.7008\n",
      "Epoch 3457/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7322 - precision: 0.6593 - recall: 0.7000 - val_loss: 0.7318 - val_precision: 0.6437 - val_recall: 0.7008\n",
      "Epoch 3458/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7322 - precision: 0.6593 - recall: 0.6999 - val_loss: 0.7318 - val_precision: 0.6435 - val_recall: 0.7004\n",
      "Epoch 3459/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7321 - precision: 0.6594 - recall: 0.6996 - val_loss: 0.7317 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3460/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7321 - precision: 0.6594 - recall: 0.6999 - val_loss: 0.7317 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3461/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7320 - precision: 0.6595 - recall: 0.6995 - val_loss: 0.7316 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3462/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7320 - precision: 0.6596 - recall: 0.6992 - val_loss: 0.7316 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3463/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7319 - precision: 0.6596 - recall: 0.6992 - val_loss: 0.7315 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3464/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7319 - precision: 0.6593 - recall: 0.6992 - val_loss: 0.7315 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3465/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7318 - precision: 0.6595 - recall: 0.6994 - val_loss: 0.7315 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3466/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7318 - precision: 0.6595 - recall: 0.6994 - val_loss: 0.7314 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3467/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7317 - precision: 0.6595 - recall: 0.6992 - val_loss: 0.7314 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3468/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7317 - precision: 0.6596 - recall: 0.6992 - val_loss: 0.7313 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3469/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7316 - precision: 0.6596 - recall: 0.6992 - val_loss: 0.7313 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3470/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7316 - precision: 0.6595 - recall: 0.6992 - val_loss: 0.7312 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3471/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7315 - precision: 0.6595 - recall: 0.6991 - val_loss: 0.7312 - val_precision: 0.6438 - val_recall: 0.7004\n",
      "Epoch 3472/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7315 - precision: 0.6596 - recall: 0.6991 - val_loss: 0.7311 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3473/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7314 - precision: 0.6597 - recall: 0.6990 - val_loss: 0.7311 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3474/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7314 - precision: 0.6596 - recall: 0.6989 - val_loss: 0.7310 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3475/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7313 - precision: 0.6596 - recall: 0.6989 - val_loss: 0.7310 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3476/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7313 - precision: 0.6596 - recall: 0.6989 - val_loss: 0.7309 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3477/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7312 - precision: 0.6596 - recall: 0.6989 - val_loss: 0.7309 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3478/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7312 - precision: 0.6595 - recall: 0.6989 - val_loss: 0.7308 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3479/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7312 - precision: 0.6596 - recall: 0.6991 - val_loss: 0.7308 - val_precision: 0.6440 - val_recall: 0.7004\n",
      "Epoch 3480/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7311 - precision: 0.6597 - recall: 0.6989 - val_loss: 0.7308 - val_precision: 0.6439 - val_recall: 0.7000\n",
      "Epoch 3481/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7311 - precision: 0.6597 - recall: 0.6987 - val_loss: 0.7307 - val_precision: 0.6439 - val_recall: 0.7000\n",
      "Epoch 3482/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7310 - precision: 0.6596 - recall: 0.6986 - val_loss: 0.7307 - val_precision: 0.6441 - val_recall: 0.7000\n",
      "Epoch 3483/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7310 - precision: 0.6596 - recall: 0.6986 - val_loss: 0.7306 - val_precision: 0.6439 - val_recall: 0.7000\n",
      "Epoch 3484/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7309 - precision: 0.6595 - recall: 0.6987 - val_loss: 0.7306 - val_precision: 0.6439 - val_recall: 0.7000\n",
      "Epoch 3485/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7309 - precision: 0.6597 - recall: 0.6986 - val_loss: 0.7305 - val_precision: 0.6441 - val_recall: 0.7000\n",
      "Epoch 3486/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7308 - precision: 0.6596 - recall: 0.6985 - val_loss: 0.7305 - val_precision: 0.6441 - val_recall: 0.7000\n",
      "Epoch 3487/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7308 - precision: 0.6597 - recall: 0.6986 - val_loss: 0.7304 - val_precision: 0.6441 - val_recall: 0.7000\n",
      "Epoch 3488/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7307 - precision: 0.6596 - recall: 0.6986 - val_loss: 0.7304 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3489/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7307 - precision: 0.6597 - recall: 0.6983 - val_loss: 0.7303 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3490/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7306 - precision: 0.6596 - recall: 0.6981 - val_loss: 0.7303 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3491/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7306 - precision: 0.6596 - recall: 0.6982 - val_loss: 0.7303 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3492/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7305 - precision: 0.6596 - recall: 0.6985 - val_loss: 0.7302 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3493/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7305 - precision: 0.6596 - recall: 0.6981 - val_loss: 0.7302 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3494/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7304 - precision: 0.6596 - recall: 0.6983 - val_loss: 0.7301 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3495/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7304 - precision: 0.6597 - recall: 0.6983 - val_loss: 0.7301 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3496/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7304 - precision: 0.6596 - recall: 0.6983 - val_loss: 0.7300 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3497/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7303 - precision: 0.6596 - recall: 0.6985 - val_loss: 0.7300 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3498/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7303 - precision: 0.6597 - recall: 0.6985 - val_loss: 0.7299 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3499/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7302 - precision: 0.6596 - recall: 0.6981 - val_loss: 0.7299 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3500/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7302 - precision: 0.6596 - recall: 0.6983 - val_loss: 0.7298 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3501/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7301 - precision: 0.6597 - recall: 0.6983 - val_loss: 0.7298 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3502/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7301 - precision: 0.6595 - recall: 0.6980 - val_loss: 0.7297 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3503/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7300 - precision: 0.6595 - recall: 0.6978 - val_loss: 0.7297 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3504/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7300 - precision: 0.6596 - recall: 0.6982 - val_loss: 0.7297 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3505/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7299 - precision: 0.6596 - recall: 0.6978 - val_loss: 0.7296 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3506/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7299 - precision: 0.6595 - recall: 0.6980 - val_loss: 0.7296 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3507/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7298 - precision: 0.6595 - recall: 0.6981 - val_loss: 0.7295 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3508/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7298 - precision: 0.6594 - recall: 0.6978 - val_loss: 0.7295 - val_precision: 0.6440 - val_recall: 0.6996\n",
      "Epoch 3509/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7298 - precision: 0.6594 - recall: 0.6978 - val_loss: 0.7294 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3510/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7297 - precision: 0.6595 - recall: 0.6978 - val_loss: 0.7294 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3511/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7297 - precision: 0.6594 - recall: 0.6978 - val_loss: 0.7293 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3512/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7296 - precision: 0.6595 - recall: 0.6978 - val_loss: 0.7293 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3513/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7296 - precision: 0.6597 - recall: 0.6978 - val_loss: 0.7293 - val_precision: 0.6442 - val_recall: 0.6996\n",
      "Epoch 3514/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7295 - precision: 0.6595 - recall: 0.6976 - val_loss: 0.7292 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3515/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7295 - precision: 0.6595 - recall: 0.6976 - val_loss: 0.7292 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3516/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7294 - precision: 0.6595 - recall: 0.6976 - val_loss: 0.7291 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3517/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7294 - precision: 0.6596 - recall: 0.6980 - val_loss: 0.7291 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3518/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7293 - precision: 0.6596 - recall: 0.6980 - val_loss: 0.7290 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3519/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7293 - precision: 0.6596 - recall: 0.6978 - val_loss: 0.7290 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3520/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7293 - precision: 0.6596 - recall: 0.6978 - val_loss: 0.7289 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3521/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7292 - precision: 0.6596 - recall: 0.6980 - val_loss: 0.7289 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3522/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7292 - precision: 0.6594 - recall: 0.6973 - val_loss: 0.7289 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3523/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7291 - precision: 0.6596 - recall: 0.6977 - val_loss: 0.7288 - val_precision: 0.6444 - val_recall: 0.6996\n",
      "Epoch 3524/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7291 - precision: 0.6594 - recall: 0.6973 - val_loss: 0.7288 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3525/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7290 - precision: 0.6594 - recall: 0.6973 - val_loss: 0.7287 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3526/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7290 - precision: 0.6595 - recall: 0.6975 - val_loss: 0.7287 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3527/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7289 - precision: 0.6594 - recall: 0.6972 - val_loss: 0.7286 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3528/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7289 - precision: 0.6594 - recall: 0.6973 - val_loss: 0.7286 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3529/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7288 - precision: 0.6595 - recall: 0.6976 - val_loss: 0.7285 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3530/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7288 - precision: 0.6595 - recall: 0.6976 - val_loss: 0.7285 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3531/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7288 - precision: 0.6594 - recall: 0.6972 - val_loss: 0.7285 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3532/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7287 - precision: 0.6594 - recall: 0.6972 - val_loss: 0.7284 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3533/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7287 - precision: 0.6594 - recall: 0.6973 - val_loss: 0.7284 - val_precision: 0.6449 - val_recall: 0.6996\n",
      "Epoch 3534/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7286 - precision: 0.6594 - recall: 0.6972 - val_loss: 0.7283 - val_precision: 0.6448 - val_recall: 0.6992\n",
      "Epoch 3535/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7286 - precision: 0.6594 - recall: 0.6971 - val_loss: 0.7283 - val_precision: 0.6448 - val_recall: 0.6992\n",
      "Epoch 3536/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7285 - precision: 0.6594 - recall: 0.6972 - val_loss: 0.7282 - val_precision: 0.6448 - val_recall: 0.6992\n",
      "Epoch 3537/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7285 - precision: 0.6594 - recall: 0.6972 - val_loss: 0.7282 - val_precision: 0.6448 - val_recall: 0.6992\n",
      "Epoch 3538/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7284 - precision: 0.6594 - recall: 0.6971 - val_loss: 0.7282 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3539/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7284 - precision: 0.6594 - recall: 0.6971 - val_loss: 0.7281 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3540/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7283 - precision: 0.6593 - recall: 0.6967 - val_loss: 0.7281 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3541/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7283 - precision: 0.6594 - recall: 0.6971 - val_loss: 0.7280 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3542/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7283 - precision: 0.6594 - recall: 0.6969 - val_loss: 0.7280 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3543/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7282 - precision: 0.6594 - recall: 0.6969 - val_loss: 0.7279 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3544/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7282 - precision: 0.6594 - recall: 0.6969 - val_loss: 0.7279 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3545/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7281 - precision: 0.6593 - recall: 0.6966 - val_loss: 0.7278 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3546/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7281 - precision: 0.6593 - recall: 0.6969 - val_loss: 0.7278 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3547/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7280 - precision: 0.6594 - recall: 0.6969 - val_loss: 0.7278 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3548/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7280 - precision: 0.6593 - recall: 0.6966 - val_loss: 0.7277 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3549/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7279 - precision: 0.6594 - recall: 0.6968 - val_loss: 0.7277 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3550/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7279 - precision: 0.6594 - recall: 0.6967 - val_loss: 0.7276 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3551/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7279 - precision: 0.6594 - recall: 0.6966 - val_loss: 0.7276 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3552/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7278 - precision: 0.6592 - recall: 0.6962 - val_loss: 0.7275 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3553/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7278 - precision: 0.6594 - recall: 0.6967 - val_loss: 0.7275 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3554/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7277 - precision: 0.6593 - recall: 0.6963 - val_loss: 0.7275 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3555/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7277 - precision: 0.6593 - recall: 0.6962 - val_loss: 0.7274 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3556/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7276 - precision: 0.6594 - recall: 0.6964 - val_loss: 0.7274 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3557/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7276 - precision: 0.6594 - recall: 0.6964 - val_loss: 0.7273 - val_precision: 0.6449 - val_recall: 0.6988\n",
      "Epoch 3558/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7275 - precision: 0.6593 - recall: 0.6962 - val_loss: 0.7273 - val_precision: 0.6450 - val_recall: 0.6984\n",
      "Epoch 3559/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7275 - precision: 0.6594 - recall: 0.6962 - val_loss: 0.7272 - val_precision: 0.6447 - val_recall: 0.6977\n",
      "Epoch 3560/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7275 - precision: 0.6594 - recall: 0.6962 - val_loss: 0.7272 - val_precision: 0.6450 - val_recall: 0.6984\n",
      "Epoch 3561/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7274 - precision: 0.6594 - recall: 0.6963 - val_loss: 0.7272 - val_precision: 0.6449 - val_recall: 0.6981\n",
      "Epoch 3562/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7274 - precision: 0.6594 - recall: 0.6963 - val_loss: 0.7271 - val_precision: 0.6450 - val_recall: 0.6984\n",
      "Epoch 3563/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7273 - precision: 0.6594 - recall: 0.6962 - val_loss: 0.7271 - val_precision: 0.6450 - val_recall: 0.6984\n",
      "Epoch 3564/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7273 - precision: 0.6594 - recall: 0.6959 - val_loss: 0.7270 - val_precision: 0.6450 - val_recall: 0.6977\n",
      "Epoch 3565/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7272 - precision: 0.6594 - recall: 0.6963 - val_loss: 0.7270 - val_precision: 0.6450 - val_recall: 0.6984\n",
      "Epoch 3566/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7272 - precision: 0.6595 - recall: 0.6962 - val_loss: 0.7269 - val_precision: 0.6449 - val_recall: 0.6981\n",
      "Epoch 3567/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7271 - precision: 0.6595 - recall: 0.6962 - val_loss: 0.7269 - val_precision: 0.6450 - val_recall: 0.6977\n",
      "Epoch 3568/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7271 - precision: 0.6595 - recall: 0.6962 - val_loss: 0.7269 - val_precision: 0.6450 - val_recall: 0.6977\n",
      "Epoch 3569/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7271 - precision: 0.6595 - recall: 0.6962 - val_loss: 0.7268 - val_precision: 0.6450 - val_recall: 0.6977\n",
      "Epoch 3570/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7270 - precision: 0.6594 - recall: 0.6961 - val_loss: 0.7268 - val_precision: 0.6452 - val_recall: 0.6977\n",
      "Epoch 3571/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7270 - precision: 0.6595 - recall: 0.6962 - val_loss: 0.7267 - val_precision: 0.6452 - val_recall: 0.6977\n",
      "Epoch 3572/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7269 - precision: 0.6595 - recall: 0.6962 - val_loss: 0.7267 - val_precision: 0.6450 - val_recall: 0.6977\n",
      "Epoch 3573/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7269 - precision: 0.6595 - recall: 0.6962 - val_loss: 0.7266 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3574/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7268 - precision: 0.6596 - recall: 0.6961 - val_loss: 0.7266 - val_precision: 0.6452 - val_recall: 0.6977\n",
      "Epoch 3575/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7268 - precision: 0.6597 - recall: 0.6958 - val_loss: 0.7266 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3576/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7268 - precision: 0.6597 - recall: 0.6962 - val_loss: 0.7265 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3577/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7267 - precision: 0.6596 - recall: 0.6959 - val_loss: 0.7265 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3578/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7267 - precision: 0.6597 - recall: 0.6958 - val_loss: 0.7264 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3579/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7266 - precision: 0.6597 - recall: 0.6958 - val_loss: 0.7264 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3580/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7266 - precision: 0.6597 - recall: 0.6958 - val_loss: 0.7264 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3581/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7265 - precision: 0.6596 - recall: 0.6957 - val_loss: 0.7263 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3582/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7265 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7263 - val_precision: 0.6454 - val_recall: 0.6977\n",
      "Epoch 3583/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7265 - precision: 0.6597 - recall: 0.6958 - val_loss: 0.7262 - val_precision: 0.6452 - val_recall: 0.6977\n",
      "Epoch 3584/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7264 - precision: 0.6596 - recall: 0.6957 - val_loss: 0.7262 - val_precision: 0.6452 - val_recall: 0.6977\n",
      "Epoch 3585/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7264 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7261 - val_precision: 0.6452 - val_recall: 0.6977\n",
      "Epoch 3586/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7263 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7261 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3587/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7263 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7261 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3588/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7262 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7260 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3589/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7262 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7260 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3590/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7261 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7259 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3591/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7261 - precision: 0.6597 - recall: 0.6955 - val_loss: 0.7259 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3592/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7261 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7259 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3593/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7260 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7258 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3594/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7260 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7258 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3595/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7259 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7257 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3596/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7259 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7257 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3597/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7258 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7256 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3598/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7258 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7256 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3599/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7258 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7256 - val_precision: 0.6457 - val_recall: 0.6977\n",
      "Epoch 3600/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7257 - precision: 0.6597 - recall: 0.6954 - val_loss: 0.7255 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3601/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7257 - precision: 0.6598 - recall: 0.6953 - val_loss: 0.7255 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3602/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7256 - precision: 0.6599 - recall: 0.6953 - val_loss: 0.7254 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3603/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7256 - precision: 0.6599 - recall: 0.6953 - val_loss: 0.7254 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3604/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7256 - precision: 0.6598 - recall: 0.6954 - val_loss: 0.7254 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3605/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7255 - precision: 0.6599 - recall: 0.6954 - val_loss: 0.7253 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3606/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7255 - precision: 0.6599 - recall: 0.6953 - val_loss: 0.7253 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3607/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7254 - precision: 0.6599 - recall: 0.6953 - val_loss: 0.7252 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3608/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7254 - precision: 0.6599 - recall: 0.6954 - val_loss: 0.7252 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3609/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7253 - precision: 0.6599 - recall: 0.6954 - val_loss: 0.7251 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3610/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7253 - precision: 0.6599 - recall: 0.6954 - val_loss: 0.7251 - val_precision: 0.6461 - val_recall: 0.6977\n",
      "Epoch 3611/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7253 - precision: 0.6599 - recall: 0.6954 - val_loss: 0.7251 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3612/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7252 - precision: 0.6599 - recall: 0.6953 - val_loss: 0.7250 - val_precision: 0.6460 - val_recall: 0.6973\n",
      "Epoch 3613/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7252 - precision: 0.6599 - recall: 0.6954 - val_loss: 0.7250 - val_precision: 0.6461 - val_recall: 0.6977\n",
      "Epoch 3614/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7251 - precision: 0.6599 - recall: 0.6955 - val_loss: 0.7249 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3615/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7251 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7249 - val_precision: 0.6460 - val_recall: 0.6973\n",
      "Epoch 3616/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7250 - precision: 0.6601 - recall: 0.6953 - val_loss: 0.7249 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3617/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7250 - precision: 0.6600 - recall: 0.6950 - val_loss: 0.7248 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3618/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7250 - precision: 0.6600 - recall: 0.6952 - val_loss: 0.7248 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3619/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7249 - precision: 0.6600 - recall: 0.6950 - val_loss: 0.7247 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3620/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7249 - precision: 0.6601 - recall: 0.6950 - val_loss: 0.7247 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3621/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7248 - precision: 0.6598 - recall: 0.6950 - val_loss: 0.7247 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3622/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7248 - precision: 0.6601 - recall: 0.6950 - val_loss: 0.7246 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3623/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7247 - precision: 0.6599 - recall: 0.6953 - val_loss: 0.7246 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3624/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7247 - precision: 0.6597 - recall: 0.6952 - val_loss: 0.7245 - val_precision: 0.6459 - val_recall: 0.6977\n",
      "Epoch 3625/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7247 - precision: 0.6597 - recall: 0.6952 - val_loss: 0.7245 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3626/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7246 - precision: 0.6601 - recall: 0.6952 - val_loss: 0.7245 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3627/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7246 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7244 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3628/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7245 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7244 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3629/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7245 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7243 - val_precision: 0.6458 - val_recall: 0.6973\n",
      "Epoch 3630/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7245 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7243 - val_precision: 0.6462 - val_recall: 0.6973\n",
      "Epoch 3631/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7244 - precision: 0.6599 - recall: 0.6950 - val_loss: 0.7243 - val_precision: 0.6462 - val_recall: 0.6973\n",
      "Epoch 3632/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7244 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7242 - val_precision: 0.6462 - val_recall: 0.6973\n",
      "Epoch 3633/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7243 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7242 - val_precision: 0.6462 - val_recall: 0.6973\n",
      "Epoch 3634/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7243 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7241 - val_precision: 0.6462 - val_recall: 0.6973\n",
      "Epoch 3635/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7242 - precision: 0.6599 - recall: 0.6950 - val_loss: 0.7241 - val_precision: 0.6465 - val_recall: 0.6973\n",
      "Epoch 3636/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7242 - precision: 0.6600 - recall: 0.6949 - val_loss: 0.7241 - val_precision: 0.6465 - val_recall: 0.6973\n",
      "Epoch 3637/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7242 - precision: 0.6599 - recall: 0.6949 - val_loss: 0.7240 - val_precision: 0.6465 - val_recall: 0.6973\n",
      "Epoch 3638/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7241 - precision: 0.6599 - recall: 0.6949 - val_loss: 0.7240 - val_precision: 0.6465 - val_recall: 0.6973\n",
      "Epoch 3639/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7241 - precision: 0.6599 - recall: 0.6949 - val_loss: 0.7239 - val_precision: 0.6463 - val_recall: 0.6969\n",
      "Epoch 3640/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7240 - precision: 0.6599 - recall: 0.6952 - val_loss: 0.7239 - val_precision: 0.6465 - val_recall: 0.6973\n",
      "Epoch 3641/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7240 - precision: 0.6599 - recall: 0.6948 - val_loss: 0.7239 - val_precision: 0.6463 - val_recall: 0.6969\n",
      "Epoch 3642/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7240 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7238 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3643/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7239 - precision: 0.6599 - recall: 0.6949 - val_loss: 0.7238 - val_precision: 0.6463 - val_recall: 0.6969\n",
      "Epoch 3644/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7239 - precision: 0.6600 - recall: 0.6946 - val_loss: 0.7237 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3645/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7238 - precision: 0.6601 - recall: 0.6946 - val_loss: 0.7237 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3646/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7238 - precision: 0.6601 - recall: 0.6948 - val_loss: 0.7237 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3647/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7238 - precision: 0.6601 - recall: 0.6946 - val_loss: 0.7236 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3648/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7237 - precision: 0.6601 - recall: 0.6949 - val_loss: 0.7236 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3649/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7237 - precision: 0.6601 - recall: 0.6946 - val_loss: 0.7235 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3650/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7236 - precision: 0.6600 - recall: 0.6945 - val_loss: 0.7235 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3651/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7236 - precision: 0.6600 - recall: 0.6945 - val_loss: 0.7235 - val_precision: 0.6462 - val_recall: 0.6965\n",
      "Epoch 3652/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7236 - precision: 0.6600 - recall: 0.6945 - val_loss: 0.7234 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3653/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7235 - precision: 0.6600 - recall: 0.6945 - val_loss: 0.7234 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3654/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7235 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7233 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3655/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7234 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7233 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3656/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7234 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7233 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3657/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7234 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7232 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3658/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7233 - precision: 0.6601 - recall: 0.6948 - val_loss: 0.7232 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3659/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7233 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7231 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3660/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7232 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7231 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3661/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7232 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7231 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3662/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7232 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7230 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3663/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7231 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7230 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3664/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7231 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7230 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3665/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7230 - precision: 0.6602 - recall: 0.6944 - val_loss: 0.7229 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3666/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7230 - precision: 0.6601 - recall: 0.6945 - val_loss: 0.7229 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3667/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7229 - precision: 0.6602 - recall: 0.6946 - val_loss: 0.7228 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3668/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7229 - precision: 0.6600 - recall: 0.6943 - val_loss: 0.7228 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3669/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7229 - precision: 0.6602 - recall: 0.6946 - val_loss: 0.7228 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3670/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7228 - precision: 0.6602 - recall: 0.6946 - val_loss: 0.7227 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3671/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7228 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7227 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3672/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7227 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7226 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3673/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7227 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7226 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3674/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7227 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7226 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3675/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7226 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7225 - val_precision: 0.6464 - val_recall: 0.6965\n",
      "Epoch 3676/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7226 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7225 - val_precision: 0.6467 - val_recall: 0.6965\n",
      "Epoch 3677/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7225 - precision: 0.6600 - recall: 0.6943 - val_loss: 0.7225 - val_precision: 0.6467 - val_recall: 0.6965\n",
      "Epoch 3678/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7225 - precision: 0.6601 - recall: 0.6944 - val_loss: 0.7224 - val_precision: 0.6467 - val_recall: 0.6965\n",
      "Epoch 3679/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7225 - precision: 0.6601 - recall: 0.6943 - val_loss: 0.7224 - val_precision: 0.6467 - val_recall: 0.6965\n",
      "Epoch 3680/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7224 - precision: 0.6601 - recall: 0.6943 - val_loss: 0.7223 - val_precision: 0.6469 - val_recall: 0.6965\n",
      "Epoch 3681/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7224 - precision: 0.6599 - recall: 0.6938 - val_loss: 0.7223 - val_precision: 0.6473 - val_recall: 0.6961\n",
      "Epoch 3682/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7223 - precision: 0.6601 - recall: 0.6943 - val_loss: 0.7223 - val_precision: 0.6467 - val_recall: 0.6965\n",
      "Epoch 3683/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7223 - precision: 0.6601 - recall: 0.6941 - val_loss: 0.7222 - val_precision: 0.6475 - val_recall: 0.6961\n",
      "Epoch 3684/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7223 - precision: 0.6600 - recall: 0.6939 - val_loss: 0.7222 - val_precision: 0.6475 - val_recall: 0.6961\n",
      "Epoch 3685/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7222 - precision: 0.6600 - recall: 0.6938 - val_loss: 0.7221 - val_precision: 0.6475 - val_recall: 0.6961\n",
      "Epoch 3686/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7222 - precision: 0.6600 - recall: 0.6938 - val_loss: 0.7221 - val_precision: 0.6475 - val_recall: 0.6961\n",
      "Epoch 3687/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7221 - precision: 0.6600 - recall: 0.6936 - val_loss: 0.7221 - val_precision: 0.6475 - val_recall: 0.6961\n",
      "Epoch 3688/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7221 - precision: 0.6601 - recall: 0.6940 - val_loss: 0.7220 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3689/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7221 - precision: 0.6601 - recall: 0.6936 - val_loss: 0.7220 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3690/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7220 - precision: 0.6600 - recall: 0.6938 - val_loss: 0.7220 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3691/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7220 - precision: 0.6602 - recall: 0.6935 - val_loss: 0.7219 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3692/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7220 - precision: 0.6602 - recall: 0.6936 - val_loss: 0.7219 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3693/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7219 - precision: 0.6602 - recall: 0.6935 - val_loss: 0.7218 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3694/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7219 - precision: 0.6601 - recall: 0.6935 - val_loss: 0.7218 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3695/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7218 - precision: 0.6602 - recall: 0.6936 - val_loss: 0.7218 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3696/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7218 - precision: 0.6601 - recall: 0.6934 - val_loss: 0.7217 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3697/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7218 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7217 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3698/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7217 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7217 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3699/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7217 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7216 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3700/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7216 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7216 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3701/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7216 - precision: 0.6602 - recall: 0.6935 - val_loss: 0.7215 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3702/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7216 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7215 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3703/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7215 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7215 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3704/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7215 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7214 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3705/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7214 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7214 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3706/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7214 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7214 - val_precision: 0.6476 - val_recall: 0.6957\n",
      "Epoch 3707/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7214 - precision: 0.6602 - recall: 0.6934 - val_loss: 0.7213 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3708/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7213 - precision: 0.6602 - recall: 0.6936 - val_loss: 0.7213 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3709/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7213 - precision: 0.6602 - recall: 0.6935 - val_loss: 0.7212 - val_precision: 0.6477 - val_recall: 0.6961\n",
      "Epoch 3710/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7212 - precision: 0.6603 - recall: 0.6931 - val_loss: 0.7212 - val_precision: 0.6478 - val_recall: 0.6957\n",
      "Epoch 3711/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7212 - precision: 0.6604 - recall: 0.6934 - val_loss: 0.7212 - val_precision: 0.6481 - val_recall: 0.6957\n",
      "Epoch 3712/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7212 - precision: 0.6603 - recall: 0.6931 - val_loss: 0.7211 - val_precision: 0.6480 - val_recall: 0.6961\n",
      "Epoch 3713/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7211 - precision: 0.6603 - recall: 0.6934 - val_loss: 0.7211 - val_precision: 0.6481 - val_recall: 0.6957\n",
      "Epoch 3714/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7211 - precision: 0.6603 - recall: 0.6934 - val_loss: 0.7210 - val_precision: 0.6479 - val_recall: 0.6953\n",
      "Epoch 3715/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7211 - precision: 0.6604 - recall: 0.6932 - val_loss: 0.7210 - val_precision: 0.6479 - val_recall: 0.6953\n",
      "Epoch 3716/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7210 - precision: 0.6603 - recall: 0.6934 - val_loss: 0.7210 - val_precision: 0.6479 - val_recall: 0.6953\n",
      "Epoch 3717/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7210 - precision: 0.6605 - recall: 0.6939 - val_loss: 0.7209 - val_precision: 0.6479 - val_recall: 0.6953\n",
      "Epoch 3718/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7209 - precision: 0.6605 - recall: 0.6936 - val_loss: 0.7209 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3719/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7209 - precision: 0.6604 - recall: 0.6935 - val_loss: 0.7209 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3720/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7209 - precision: 0.6607 - recall: 0.6935 - val_loss: 0.7208 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3721/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7208 - precision: 0.6605 - recall: 0.6934 - val_loss: 0.7208 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3722/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7208 - precision: 0.6604 - recall: 0.6935 - val_loss: 0.7208 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3723/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7207 - precision: 0.6605 - recall: 0.6938 - val_loss: 0.7207 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3724/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7207 - precision: 0.6606 - recall: 0.6936 - val_loss: 0.7207 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3725/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7207 - precision: 0.6607 - recall: 0.6938 - val_loss: 0.7206 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3726/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7206 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7206 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3727/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7206 - precision: 0.6607 - recall: 0.6939 - val_loss: 0.7206 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3728/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7206 - precision: 0.6605 - recall: 0.6938 - val_loss: 0.7205 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3729/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7205 - precision: 0.6606 - recall: 0.6939 - val_loss: 0.7205 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3730/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7205 - precision: 0.6606 - recall: 0.6936 - val_loss: 0.7205 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3731/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7204 - precision: 0.6606 - recall: 0.6938 - val_loss: 0.7204 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3732/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7204 - precision: 0.6606 - recall: 0.6936 - val_loss: 0.7204 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3733/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7204 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7203 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3734/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7203 - precision: 0.6606 - recall: 0.6936 - val_loss: 0.7203 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3735/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7203 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7203 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3736/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7203 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7202 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3737/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7202 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7202 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3738/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7202 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7202 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3739/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7201 - precision: 0.6605 - recall: 0.6935 - val_loss: 0.7201 - val_precision: 0.6478 - val_recall: 0.6949\n",
      "Epoch 3740/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7201 - precision: 0.6605 - recall: 0.6935 - val_loss: 0.7201 - val_precision: 0.6480 - val_recall: 0.6949\n",
      "Epoch 3741/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7201 - precision: 0.6606 - recall: 0.6934 - val_loss: 0.7201 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3742/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7200 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7200 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3743/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7200 - precision: 0.6606 - recall: 0.6935 - val_loss: 0.7200 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3744/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7200 - precision: 0.6605 - recall: 0.6935 - val_loss: 0.7199 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3745/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7199 - precision: 0.6605 - recall: 0.6935 - val_loss: 0.7199 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3746/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7199 - precision: 0.6605 - recall: 0.6935 - val_loss: 0.7199 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3747/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7198 - precision: 0.6607 - recall: 0.6934 - val_loss: 0.7198 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3748/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7198 - precision: 0.6606 - recall: 0.6934 - val_loss: 0.7198 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3749/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7198 - precision: 0.6607 - recall: 0.6935 - val_loss: 0.7198 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3750/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7197 - precision: 0.6607 - recall: 0.6934 - val_loss: 0.7197 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3751/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7197 - precision: 0.6607 - recall: 0.6934 - val_loss: 0.7197 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3752/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7197 - precision: 0.6607 - recall: 0.6934 - val_loss: 0.7197 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3753/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7196 - precision: 0.6607 - recall: 0.6934 - val_loss: 0.7196 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3754/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7196 - precision: 0.6607 - recall: 0.6934 - val_loss: 0.7196 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3755/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7195 - precision: 0.6606 - recall: 0.6934 - val_loss: 0.7195 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3756/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7195 - precision: 0.6607 - recall: 0.6935 - val_loss: 0.7195 - val_precision: 0.6479 - val_recall: 0.6946\n",
      "Epoch 3757/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7195 - precision: 0.6607 - recall: 0.6932 - val_loss: 0.7195 - val_precision: 0.6480 - val_recall: 0.6942\n",
      "Epoch 3758/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7194 - precision: 0.6607 - recall: 0.6932 - val_loss: 0.7194 - val_precision: 0.6481 - val_recall: 0.6946\n",
      "Epoch 3759/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7194 - precision: 0.6606 - recall: 0.6932 - val_loss: 0.7194 - val_precision: 0.6480 - val_recall: 0.6942\n",
      "Epoch 3760/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7194 - precision: 0.6607 - recall: 0.6932 - val_loss: 0.7194 - val_precision: 0.6480 - val_recall: 0.6942\n",
      "Epoch 3761/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7193 - precision: 0.6606 - recall: 0.6932 - val_loss: 0.7193 - val_precision: 0.6480 - val_recall: 0.6942\n",
      "Epoch 3762/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7193 - precision: 0.6606 - recall: 0.6932 - val_loss: 0.7193 - val_precision: 0.6480 - val_recall: 0.6942\n",
      "Epoch 3763/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7192 - precision: 0.6607 - recall: 0.6932 - val_loss: 0.7193 - val_precision: 0.6480 - val_recall: 0.6942\n",
      "Epoch 3764/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7192 - precision: 0.6610 - recall: 0.6932 - val_loss: 0.7192 - val_precision: 0.6480 - val_recall: 0.6942\n",
      "Epoch 3765/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7192 - precision: 0.6610 - recall: 0.6932 - val_loss: 0.7192 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3766/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7191 - precision: 0.6608 - recall: 0.6932 - val_loss: 0.7192 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3767/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7191 - precision: 0.6607 - recall: 0.6934 - val_loss: 0.7191 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3768/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7191 - precision: 0.6608 - recall: 0.6932 - val_loss: 0.7191 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3769/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7190 - precision: 0.6608 - recall: 0.6934 - val_loss: 0.7190 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3770/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7190 - precision: 0.6609 - recall: 0.6931 - val_loss: 0.7190 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3771/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7190 - precision: 0.6609 - recall: 0.6934 - val_loss: 0.7190 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3772/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7189 - precision: 0.6609 - recall: 0.6931 - val_loss: 0.7189 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3773/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7189 - precision: 0.6608 - recall: 0.6932 - val_loss: 0.7189 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3774/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7188 - precision: 0.6610 - recall: 0.6931 - val_loss: 0.7189 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3775/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7188 - precision: 0.6610 - recall: 0.6929 - val_loss: 0.7188 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3776/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7188 - precision: 0.6609 - recall: 0.6930 - val_loss: 0.7188 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3777/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7187 - precision: 0.6610 - recall: 0.6929 - val_loss: 0.7188 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3778/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7187 - precision: 0.6610 - recall: 0.6929 - val_loss: 0.7187 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3779/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7187 - precision: 0.6608 - recall: 0.6930 - val_loss: 0.7187 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3780/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7186 - precision: 0.6610 - recall: 0.6930 - val_loss: 0.7187 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3781/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7186 - precision: 0.6610 - recall: 0.6930 - val_loss: 0.7186 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3782/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7185 - precision: 0.6610 - recall: 0.6930 - val_loss: 0.7186 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3783/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7185 - precision: 0.6610 - recall: 0.6930 - val_loss: 0.7185 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3784/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7185 - precision: 0.6611 - recall: 0.6929 - val_loss: 0.7185 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3785/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7184 - precision: 0.6613 - recall: 0.6929 - val_loss: 0.7185 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3786/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7184 - precision: 0.6613 - recall: 0.6929 - val_loss: 0.7184 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3787/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7184 - precision: 0.6611 - recall: 0.6929 - val_loss: 0.7184 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3788/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7183 - precision: 0.6613 - recall: 0.6929 - val_loss: 0.7184 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3789/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7183 - precision: 0.6612 - recall: 0.6929 - val_loss: 0.7183 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3790/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7183 - precision: 0.6613 - recall: 0.6927 - val_loss: 0.7183 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3791/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7182 - precision: 0.6613 - recall: 0.6929 - val_loss: 0.7183 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3792/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7182 - precision: 0.6612 - recall: 0.6929 - val_loss: 0.7182 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3793/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7181 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7182 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3794/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7181 - precision: 0.6613 - recall: 0.6927 - val_loss: 0.7182 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3795/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7181 - precision: 0.6614 - recall: 0.6929 - val_loss: 0.7181 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3796/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7180 - precision: 0.6613 - recall: 0.6927 - val_loss: 0.7181 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3797/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7180 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7181 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3798/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7180 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7180 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3799/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7179 - precision: 0.6612 - recall: 0.6926 - val_loss: 0.7180 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3800/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7179 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7180 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3801/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7179 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7179 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3802/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7178 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7179 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3803/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7178 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7179 - val_precision: 0.6478 - val_recall: 0.6934\n",
      "Epoch 3804/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7178 - precision: 0.6612 - recall: 0.6925 - val_loss: 0.7178 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3805/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7177 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7178 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3806/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7177 - precision: 0.6613 - recall: 0.6925 - val_loss: 0.7177 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3807/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7176 - precision: 0.6614 - recall: 0.6926 - val_loss: 0.7177 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3808/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7176 - precision: 0.6613 - recall: 0.6926 - val_loss: 0.7177 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3809/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7176 - precision: 0.6613 - recall: 0.6925 - val_loss: 0.7176 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3810/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7175 - precision: 0.6614 - recall: 0.6925 - val_loss: 0.7176 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3811/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7175 - precision: 0.6614 - recall: 0.6925 - val_loss: 0.7176 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3812/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7175 - precision: 0.6614 - recall: 0.6925 - val_loss: 0.7175 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3813/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7174 - precision: 0.6613 - recall: 0.6925 - val_loss: 0.7175 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3814/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7174 - precision: 0.6613 - recall: 0.6925 - val_loss: 0.7175 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3815/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7174 - precision: 0.6613 - recall: 0.6925 - val_loss: 0.7174 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3816/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7173 - precision: 0.6614 - recall: 0.6926 - val_loss: 0.7174 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3817/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7173 - precision: 0.6614 - recall: 0.6925 - val_loss: 0.7174 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3818/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7173 - precision: 0.6613 - recall: 0.6925 - val_loss: 0.7173 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3819/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7172 - precision: 0.6614 - recall: 0.6922 - val_loss: 0.7173 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3820/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7172 - precision: 0.6614 - recall: 0.6924 - val_loss: 0.7173 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3821/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7172 - precision: 0.6614 - recall: 0.6922 - val_loss: 0.7172 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3822/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7171 - precision: 0.6614 - recall: 0.6924 - val_loss: 0.7172 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3823/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7171 - precision: 0.6614 - recall: 0.6924 - val_loss: 0.7172 - val_precision: 0.6479 - val_recall: 0.6938\n",
      "Epoch 3824/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7171 - precision: 0.6614 - recall: 0.6924 - val_loss: 0.7171 - val_precision: 0.6481 - val_recall: 0.6938\n",
      "Epoch 3825/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7170 - precision: 0.6614 - recall: 0.6924 - val_loss: 0.7171 - val_precision: 0.6481 - val_recall: 0.6938\n",
      "Epoch 3826/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7170 - precision: 0.6614 - recall: 0.6924 - val_loss: 0.7171 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3827/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7169 - precision: 0.6614 - recall: 0.6924 - val_loss: 0.7170 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3828/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7169 - precision: 0.6616 - recall: 0.6921 - val_loss: 0.7170 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3829/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7169 - precision: 0.6616 - recall: 0.6922 - val_loss: 0.7170 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3830/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7168 - precision: 0.6615 - recall: 0.6922 - val_loss: 0.7169 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3831/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7168 - precision: 0.6615 - recall: 0.6922 - val_loss: 0.7169 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3832/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7168 - precision: 0.6616 - recall: 0.6921 - val_loss: 0.7169 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3833/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7167 - precision: 0.6616 - recall: 0.6922 - val_loss: 0.7168 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3834/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7167 - precision: 0.6616 - recall: 0.6922 - val_loss: 0.7168 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3835/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7167 - precision: 0.6616 - recall: 0.6922 - val_loss: 0.7168 - val_precision: 0.6481 - val_recall: 0.6938\n",
      "Epoch 3836/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7166 - precision: 0.6616 - recall: 0.6922 - val_loss: 0.7167 - val_precision: 0.6481 - val_recall: 0.6938\n",
      "Epoch 3837/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7166 - precision: 0.6616 - recall: 0.6922 - val_loss: 0.7167 - val_precision: 0.6481 - val_recall: 0.6938\n",
      "Epoch 3838/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7166 - precision: 0.6618 - recall: 0.6921 - val_loss: 0.7167 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3839/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7165 - precision: 0.6618 - recall: 0.6921 - val_loss: 0.7166 - val_precision: 0.6484 - val_recall: 0.6938\n",
      "Epoch 3840/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7165 - precision: 0.6617 - recall: 0.6921 - val_loss: 0.7166 - val_precision: 0.6481 - val_recall: 0.6938\n",
      "Epoch 3841/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7165 - precision: 0.6617 - recall: 0.6921 - val_loss: 0.7166 - val_precision: 0.6488 - val_recall: 0.6938\n",
      "Epoch 3842/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7164 - precision: 0.6617 - recall: 0.6920 - val_loss: 0.7165 - val_precision: 0.6488 - val_recall: 0.6938\n",
      "Epoch 3843/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7164 - precision: 0.6617 - recall: 0.6920 - val_loss: 0.7165 - val_precision: 0.6488 - val_recall: 0.6938\n",
      "Epoch 3844/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7164 - precision: 0.6617 - recall: 0.6920 - val_loss: 0.7165 - val_precision: 0.6488 - val_recall: 0.6938\n",
      "Epoch 3845/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7163 - precision: 0.6617 - recall: 0.6921 - val_loss: 0.7164 - val_precision: 0.6486 - val_recall: 0.6938\n",
      "Epoch 3846/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7163 - precision: 0.6617 - recall: 0.6918 - val_loss: 0.7164 - val_precision: 0.6488 - val_recall: 0.6938\n",
      "Epoch 3847/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7163 - precision: 0.6617 - recall: 0.6920 - val_loss: 0.7164 - val_precision: 0.6488 - val_recall: 0.6938\n",
      "Epoch 3848/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7162 - precision: 0.6617 - recall: 0.6921 - val_loss: 0.7163 - val_precision: 0.6486 - val_recall: 0.6938\n",
      "Epoch 3849/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7162 - precision: 0.6616 - recall: 0.6920 - val_loss: 0.7163 - val_precision: 0.6486 - val_recall: 0.6938\n",
      "Epoch 3850/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7162 - precision: 0.6617 - recall: 0.6922 - val_loss: 0.7163 - val_precision: 0.6486 - val_recall: 0.6938\n",
      "Epoch 3851/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7161 - precision: 0.6616 - recall: 0.6920 - val_loss: 0.7162 - val_precision: 0.6486 - val_recall: 0.6938\n",
      "Epoch 3852/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7161 - precision: 0.6619 - recall: 0.6917 - val_loss: 0.7162 - val_precision: 0.6493 - val_recall: 0.6938\n",
      "Epoch 3853/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7161 - precision: 0.6618 - recall: 0.6918 - val_loss: 0.7162 - val_precision: 0.6491 - val_recall: 0.6938\n",
      "Epoch 3854/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7160 - precision: 0.6618 - recall: 0.6917 - val_loss: 0.7161 - val_precision: 0.6493 - val_recall: 0.6938\n",
      "Epoch 3855/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7160 - precision: 0.6616 - recall: 0.6917 - val_loss: 0.7161 - val_precision: 0.6490 - val_recall: 0.6942\n",
      "Epoch 3856/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7160 - precision: 0.6618 - recall: 0.6920 - val_loss: 0.7161 - val_precision: 0.6491 - val_recall: 0.6938\n",
      "Epoch 3857/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7159 - precision: 0.6618 - recall: 0.6916 - val_loss: 0.7160 - val_precision: 0.6493 - val_recall: 0.6938\n",
      "Epoch 3858/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7159 - precision: 0.6618 - recall: 0.6917 - val_loss: 0.7160 - val_precision: 0.6494 - val_recall: 0.6942\n",
      "Epoch 3859/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7159 - precision: 0.6618 - recall: 0.6918 - val_loss: 0.7160 - val_precision: 0.6494 - val_recall: 0.6942\n",
      "Epoch 3860/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7158 - precision: 0.6619 - recall: 0.6916 - val_loss: 0.7159 - val_precision: 0.6494 - val_recall: 0.6942\n",
      "Epoch 3861/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7158 - precision: 0.6620 - recall: 0.6913 - val_loss: 0.7159 - val_precision: 0.6494 - val_recall: 0.6942\n",
      "Epoch 3862/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7158 - precision: 0.6618 - recall: 0.6917 - val_loss: 0.7159 - val_precision: 0.6494 - val_recall: 0.6942\n",
      "Epoch 3863/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7157 - precision: 0.6619 - recall: 0.6915 - val_loss: 0.7158 - val_precision: 0.6493 - val_recall: 0.6938\n",
      "Epoch 3864/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7157 - precision: 0.6618 - recall: 0.6916 - val_loss: 0.7158 - val_precision: 0.6494 - val_recall: 0.6942\n",
      "Epoch 3865/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7157 - precision: 0.6619 - recall: 0.6916 - val_loss: 0.7158 - val_precision: 0.6493 - val_recall: 0.6938\n",
      "Epoch 3866/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7156 - precision: 0.6619 - recall: 0.6915 - val_loss: 0.7157 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3867/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7156 - precision: 0.6618 - recall: 0.6916 - val_loss: 0.7157 - val_precision: 0.6493 - val_recall: 0.6938\n",
      "Epoch 3868/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7155 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7157 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3869/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7155 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7156 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3870/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7155 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7156 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3871/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7154 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7156 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3872/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7154 - precision: 0.6621 - recall: 0.6915 - val_loss: 0.7156 - val_precision: 0.6497 - val_recall: 0.6934\n",
      "Epoch 3873/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7154 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7155 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3874/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7154 - precision: 0.6619 - recall: 0.6915 - val_loss: 0.7155 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3875/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7153 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7155 - val_precision: 0.6494 - val_recall: 0.6934\n",
      "Epoch 3876/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7153 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7154 - val_precision: 0.6497 - val_recall: 0.6934\n",
      "Epoch 3877/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7152 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7154 - val_precision: 0.6497 - val_recall: 0.6934\n",
      "Epoch 3878/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7152 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7154 - val_precision: 0.6497 - val_recall: 0.6934\n",
      "Epoch 3879/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7152 - precision: 0.6621 - recall: 0.6913 - val_loss: 0.7153 - val_precision: 0.6499 - val_recall: 0.6934\n",
      "Epoch 3880/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7152 - precision: 0.6621 - recall: 0.6913 - val_loss: 0.7153 - val_precision: 0.6498 - val_recall: 0.6930\n",
      "Epoch 3881/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7151 - precision: 0.6621 - recall: 0.6913 - val_loss: 0.7153 - val_precision: 0.6497 - val_recall: 0.6934\n",
      "Epoch 3882/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7151 - precision: 0.6620 - recall: 0.6913 - val_loss: 0.7152 - val_precision: 0.6498 - val_recall: 0.6930\n",
      "Epoch 3883/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7151 - precision: 0.6621 - recall: 0.6915 - val_loss: 0.7152 - val_precision: 0.6498 - val_recall: 0.6930\n",
      "Epoch 3884/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7150 - precision: 0.6620 - recall: 0.6915 - val_loss: 0.7152 - val_precision: 0.6496 - val_recall: 0.6926\n",
      "Epoch 3885/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7150 - precision: 0.6621 - recall: 0.6913 - val_loss: 0.7151 - val_precision: 0.6496 - val_recall: 0.6926\n",
      "Epoch 3886/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7150 - precision: 0.6622 - recall: 0.6915 - val_loss: 0.7151 - val_precision: 0.6496 - val_recall: 0.6926\n",
      "Epoch 3887/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7149 - precision: 0.6621 - recall: 0.6915 - val_loss: 0.7151 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3888/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7149 - precision: 0.6622 - recall: 0.6913 - val_loss: 0.7150 - val_precision: 0.6496 - val_recall: 0.6926\n",
      "Epoch 3889/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7149 - precision: 0.6622 - recall: 0.6915 - val_loss: 0.7150 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3890/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7148 - precision: 0.6622 - recall: 0.6916 - val_loss: 0.7150 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3891/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7148 - precision: 0.6621 - recall: 0.6915 - val_loss: 0.7149 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3892/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7148 - precision: 0.6622 - recall: 0.6916 - val_loss: 0.7149 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3893/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7147 - precision: 0.6623 - recall: 0.6916 - val_loss: 0.7149 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3894/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7147 - precision: 0.6624 - recall: 0.6916 - val_loss: 0.7149 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3895/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7147 - precision: 0.6624 - recall: 0.6915 - val_loss: 0.7148 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3896/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7146 - precision: 0.6623 - recall: 0.6916 - val_loss: 0.7148 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3897/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7146 - precision: 0.6624 - recall: 0.6916 - val_loss: 0.7148 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3898/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7146 - precision: 0.6624 - recall: 0.6916 - val_loss: 0.7147 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3899/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7145 - precision: 0.6624 - recall: 0.6913 - val_loss: 0.7147 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3900/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7145 - precision: 0.6623 - recall: 0.6916 - val_loss: 0.7147 - val_precision: 0.6497 - val_recall: 0.6922\n",
      "Epoch 3901/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7145 - precision: 0.6624 - recall: 0.6916 - val_loss: 0.7146 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3902/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7144 - precision: 0.6624 - recall: 0.6915 - val_loss: 0.7146 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3903/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7144 - precision: 0.6624 - recall: 0.6918 - val_loss: 0.7146 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3904/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7144 - precision: 0.6623 - recall: 0.6912 - val_loss: 0.7145 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3905/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7143 - precision: 0.6624 - recall: 0.6912 - val_loss: 0.7145 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3906/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7143 - precision: 0.6624 - recall: 0.6913 - val_loss: 0.7145 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3907/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7143 - precision: 0.6623 - recall: 0.6911 - val_loss: 0.7144 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3908/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7142 - precision: 0.6623 - recall: 0.6910 - val_loss: 0.7144 - val_precision: 0.6500 - val_recall: 0.6922\n",
      "Epoch 3909/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7142 - precision: 0.6624 - recall: 0.6916 - val_loss: 0.7144 - val_precision: 0.6501 - val_recall: 0.6926\n",
      "Epoch 3910/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7142 - precision: 0.6623 - recall: 0.6913 - val_loss: 0.7143 - val_precision: 0.6501 - val_recall: 0.6926\n",
      "Epoch 3911/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7141 - precision: 0.6624 - recall: 0.6915 - val_loss: 0.7143 - val_precision: 0.6501 - val_recall: 0.6926\n",
      "Epoch 3912/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7141 - precision: 0.6624 - recall: 0.6915 - val_loss: 0.7143 - val_precision: 0.6501 - val_recall: 0.6926\n",
      "Epoch 3913/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7141 - precision: 0.6623 - recall: 0.6915 - val_loss: 0.7143 - val_precision: 0.6505 - val_recall: 0.6930\n",
      "Epoch 3914/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7140 - precision: 0.6623 - recall: 0.6913 - val_loss: 0.7142 - val_precision: 0.6503 - val_recall: 0.6926\n",
      "Epoch 3915/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7140 - precision: 0.6623 - recall: 0.6913 - val_loss: 0.7142 - val_precision: 0.6505 - val_recall: 0.6930\n",
      "Epoch 3916/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7140 - precision: 0.6624 - recall: 0.6915 - val_loss: 0.7142 - val_precision: 0.6505 - val_recall: 0.6930\n",
      "Epoch 3917/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7140 - precision: 0.6623 - recall: 0.6912 - val_loss: 0.7141 - val_precision: 0.6505 - val_recall: 0.6930\n",
      "Epoch 3918/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7139 - precision: 0.6624 - recall: 0.6913 - val_loss: 0.7141 - val_precision: 0.6505 - val_recall: 0.6930\n",
      "Epoch 3919/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7139 - precision: 0.6623 - recall: 0.6913 - val_loss: 0.7141 - val_precision: 0.6505 - val_recall: 0.6930\n",
      "Epoch 3920/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7139 - precision: 0.6624 - recall: 0.6913 - val_loss: 0.7140 - val_precision: 0.6507 - val_recall: 0.6930\n",
      "Epoch 3921/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7138 - precision: 0.6623 - recall: 0.6913 - val_loss: 0.7140 - val_precision: 0.6507 - val_recall: 0.6930\n",
      "Epoch 3922/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7138 - precision: 0.6624 - recall: 0.6911 - val_loss: 0.7140 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3923/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7138 - precision: 0.6624 - recall: 0.6912 - val_loss: 0.7140 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3924/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7137 - precision: 0.6624 - recall: 0.6910 - val_loss: 0.7139 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3925/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7137 - precision: 0.6624 - recall: 0.6910 - val_loss: 0.7139 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3926/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7137 - precision: 0.6624 - recall: 0.6912 - val_loss: 0.7139 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3927/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7136 - precision: 0.6623 - recall: 0.6911 - val_loss: 0.7138 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3928/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7136 - precision: 0.6624 - recall: 0.6908 - val_loss: 0.7138 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3929/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7136 - precision: 0.6624 - recall: 0.6910 - val_loss: 0.7138 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3930/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7135 - precision: 0.6624 - recall: 0.6912 - val_loss: 0.7137 - val_precision: 0.6506 - val_recall: 0.6926\n",
      "Epoch 3931/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7135 - precision: 0.6624 - recall: 0.6910 - val_loss: 0.7137 - val_precision: 0.6508 - val_recall: 0.6926\n",
      "Epoch 3932/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7135 - precision: 0.6623 - recall: 0.6910 - val_loss: 0.7137 - val_precision: 0.6508 - val_recall: 0.6926\n",
      "Epoch 3933/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7134 - precision: 0.6624 - recall: 0.6910 - val_loss: 0.7136 - val_precision: 0.6508 - val_recall: 0.6926\n",
      "Epoch 3934/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7134 - precision: 0.6624 - recall: 0.6907 - val_loss: 0.7136 - val_precision: 0.6508 - val_recall: 0.6926\n",
      "Epoch 3935/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7134 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7136 - val_precision: 0.6508 - val_recall: 0.6926\n",
      "Epoch 3936/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7134 - precision: 0.6622 - recall: 0.6906 - val_loss: 0.7136 - val_precision: 0.6508 - val_recall: 0.6926\n",
      "Epoch 3937/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7133 - precision: 0.6623 - recall: 0.6907 - val_loss: 0.7135 - val_precision: 0.6508 - val_recall: 0.6926\n",
      "Epoch 3938/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7133 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7135 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3939/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7133 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7135 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3940/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7132 - precision: 0.6621 - recall: 0.6904 - val_loss: 0.7134 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3941/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7132 - precision: 0.6622 - recall: 0.6906 - val_loss: 0.7134 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3942/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7132 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7134 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3943/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7131 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7133 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3944/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7131 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7133 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3945/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7131 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7133 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3946/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7130 - precision: 0.6623 - recall: 0.6902 - val_loss: 0.7133 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3947/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7130 - precision: 0.6623 - recall: 0.6902 - val_loss: 0.7132 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3948/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7130 - precision: 0.6623 - recall: 0.6904 - val_loss: 0.7132 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3949/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7129 - precision: 0.6622 - recall: 0.6903 - val_loss: 0.7132 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3950/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7129 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7131 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3951/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7129 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7131 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3952/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7129 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7131 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3953/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7128 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7130 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3954/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7128 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7130 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3955/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7128 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7130 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3956/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7127 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7130 - val_precision: 0.6507 - val_recall: 0.6922\n",
      "Epoch 3957/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7127 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7129 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3958/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7127 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7129 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3959/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7126 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7129 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3960/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7126 - precision: 0.6621 - recall: 0.6899 - val_loss: 0.7128 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3961/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7126 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7128 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3962/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7125 - precision: 0.6621 - recall: 0.6898 - val_loss: 0.7128 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3963/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7125 - precision: 0.6621 - recall: 0.6899 - val_loss: 0.7127 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3964/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7125 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7127 - val_precision: 0.6509 - val_recall: 0.6922\n",
      "Epoch 3965/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7125 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7127 - val_precision: 0.6508 - val_recall: 0.6918\n",
      "Epoch 3966/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7124 - precision: 0.6621 - recall: 0.6899 - val_loss: 0.7127 - val_precision: 0.6508 - val_recall: 0.6918\n",
      "Epoch 3967/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7124 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7126 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3968/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7124 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7126 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3969/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7123 - precision: 0.6621 - recall: 0.6898 - val_loss: 0.7126 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3970/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7123 - precision: 0.6621 - recall: 0.6901 - val_loss: 0.7125 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3971/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7123 - precision: 0.6622 - recall: 0.6899 - val_loss: 0.7125 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3972/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7122 - precision: 0.6621 - recall: 0.6903 - val_loss: 0.7125 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3973/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7122 - precision: 0.6622 - recall: 0.6902 - val_loss: 0.7124 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3974/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7122 - precision: 0.6623 - recall: 0.6902 - val_loss: 0.7124 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3975/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7121 - precision: 0.6621 - recall: 0.6899 - val_loss: 0.7124 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3976/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7121 - precision: 0.6623 - recall: 0.6903 - val_loss: 0.7124 - val_precision: 0.6510 - val_recall: 0.6918\n",
      "Epoch 3977/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7121 - precision: 0.6623 - recall: 0.6899 - val_loss: 0.7123 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3978/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7121 - precision: 0.6623 - recall: 0.6901 - val_loss: 0.7123 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3979/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7120 - precision: 0.6625 - recall: 0.6901 - val_loss: 0.7123 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3980/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7120 - precision: 0.6623 - recall: 0.6902 - val_loss: 0.7122 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3981/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7120 - precision: 0.6622 - recall: 0.6901 - val_loss: 0.7122 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3982/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7119 - precision: 0.6623 - recall: 0.6897 - val_loss: 0.7122 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3983/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7119 - precision: 0.6624 - recall: 0.6898 - val_loss: 0.7122 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3984/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7119 - precision: 0.6623 - recall: 0.6902 - val_loss: 0.7121 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3985/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7118 - precision: 0.6622 - recall: 0.6901 - val_loss: 0.7121 - val_precision: 0.6514 - val_recall: 0.6922\n",
      "Epoch 3986/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7118 - precision: 0.6623 - recall: 0.6902 - val_loss: 0.7121 - val_precision: 0.6514 - val_recall: 0.6922\n",
      "Epoch 3987/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7118 - precision: 0.6623 - recall: 0.6901 - val_loss: 0.7120 - val_precision: 0.6514 - val_recall: 0.6922\n",
      "Epoch 3988/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7117 - precision: 0.6623 - recall: 0.6898 - val_loss: 0.7120 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3989/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7117 - precision: 0.6623 - recall: 0.6897 - val_loss: 0.7120 - val_precision: 0.6512 - val_recall: 0.6914\n",
      "Epoch 3990/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7117 - precision: 0.6623 - recall: 0.6897 - val_loss: 0.7119 - val_precision: 0.6512 - val_recall: 0.6914\n",
      "Epoch 3991/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7117 - precision: 0.6623 - recall: 0.6897 - val_loss: 0.7119 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3992/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7116 - precision: 0.6623 - recall: 0.6897 - val_loss: 0.7119 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3993/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7116 - precision: 0.6624 - recall: 0.6896 - val_loss: 0.7119 - val_precision: 0.6512 - val_recall: 0.6914\n",
      "Epoch 3994/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7116 - precision: 0.6624 - recall: 0.6898 - val_loss: 0.7118 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3995/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7115 - precision: 0.6625 - recall: 0.6898 - val_loss: 0.7118 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3996/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7115 - precision: 0.6625 - recall: 0.6897 - val_loss: 0.7118 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3997/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7115 - precision: 0.6625 - recall: 0.6898 - val_loss: 0.7117 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3998/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7114 - precision: 0.6625 - recall: 0.6898 - val_loss: 0.7117 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 3999/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7114 - precision: 0.6625 - recall: 0.6898 - val_loss: 0.7117 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4000/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7114 - precision: 0.6625 - recall: 0.6901 - val_loss: 0.7116 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4001/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7114 - precision: 0.6625 - recall: 0.6901 - val_loss: 0.7116 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4002/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7113 - precision: 0.6625 - recall: 0.6902 - val_loss: 0.7116 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4003/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7113 - precision: 0.6625 - recall: 0.6902 - val_loss: 0.7116 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4004/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7113 - precision: 0.6625 - recall: 0.6902 - val_loss: 0.7115 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4005/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7112 - precision: 0.6625 - recall: 0.6901 - val_loss: 0.7115 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4006/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7112 - precision: 0.6625 - recall: 0.6901 - val_loss: 0.7115 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4007/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7112 - precision: 0.6626 - recall: 0.6903 - val_loss: 0.7114 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4008/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7111 - precision: 0.6625 - recall: 0.6902 - val_loss: 0.7114 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4009/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7111 - precision: 0.6625 - recall: 0.6903 - val_loss: 0.7114 - val_precision: 0.6513 - val_recall: 0.6918\n",
      "Epoch 4010/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7111 - precision: 0.6626 - recall: 0.6903 - val_loss: 0.7114 - val_precision: 0.6515 - val_recall: 0.6918\n",
      "Epoch 4011/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7111 - precision: 0.6625 - recall: 0.6902 - val_loss: 0.7113 - val_precision: 0.6515 - val_recall: 0.6918\n",
      "Epoch 4012/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7110 - precision: 0.6625 - recall: 0.6901 - val_loss: 0.7113 - val_precision: 0.6514 - val_recall: 0.6914\n",
      "Epoch 4013/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7110 - precision: 0.6627 - recall: 0.6901 - val_loss: 0.7113 - val_precision: 0.6514 - val_recall: 0.6914\n",
      "Epoch 4014/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7110 - precision: 0.6627 - recall: 0.6899 - val_loss: 0.7112 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4015/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7109 - precision: 0.6627 - recall: 0.6903 - val_loss: 0.7112 - val_precision: 0.6514 - val_recall: 0.6914\n",
      "Epoch 4016/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7109 - precision: 0.6627 - recall: 0.6899 - val_loss: 0.7112 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4017/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7109 - precision: 0.6627 - recall: 0.6904 - val_loss: 0.7112 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4018/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7109 - precision: 0.6626 - recall: 0.6901 - val_loss: 0.7111 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4019/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7108 - precision: 0.6626 - recall: 0.6904 - val_loss: 0.7111 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4020/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7108 - precision: 0.6627 - recall: 0.6906 - val_loss: 0.7111 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4021/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7108 - precision: 0.6627 - recall: 0.6904 - val_loss: 0.7110 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4022/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7107 - precision: 0.6627 - recall: 0.6902 - val_loss: 0.7110 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4023/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7107 - precision: 0.6627 - recall: 0.6901 - val_loss: 0.7110 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4024/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7107 - precision: 0.6626 - recall: 0.6901 - val_loss: 0.7110 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4025/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7106 - precision: 0.6627 - recall: 0.6907 - val_loss: 0.7109 - val_precision: 0.6513 - val_recall: 0.6911\n",
      "Epoch 4026/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7106 - precision: 0.6628 - recall: 0.6903 - val_loss: 0.7109 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4027/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7106 - precision: 0.6627 - recall: 0.6903 - val_loss: 0.7109 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4028/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7106 - precision: 0.6626 - recall: 0.6903 - val_loss: 0.7109 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4029/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7105 - precision: 0.6626 - recall: 0.6903 - val_loss: 0.7108 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4030/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7105 - precision: 0.6627 - recall: 0.6903 - val_loss: 0.7108 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4031/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7105 - precision: 0.6626 - recall: 0.6906 - val_loss: 0.7108 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4032/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7104 - precision: 0.6627 - recall: 0.6906 - val_loss: 0.7107 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4033/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7104 - precision: 0.6627 - recall: 0.6904 - val_loss: 0.7107 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4034/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7104 - precision: 0.6626 - recall: 0.6908 - val_loss: 0.7107 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4035/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7104 - precision: 0.6628 - recall: 0.6906 - val_loss: 0.7107 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4036/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7103 - precision: 0.6628 - recall: 0.6907 - val_loss: 0.7106 - val_precision: 0.6511 - val_recall: 0.6907\n",
      "Epoch 4037/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7103 - precision: 0.6629 - recall: 0.6906 - val_loss: 0.7106 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4038/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7103 - precision: 0.6630 - recall: 0.6903 - val_loss: 0.7106 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4039/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7102 - precision: 0.6630 - recall: 0.6904 - val_loss: 0.7105 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4040/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7102 - precision: 0.6628 - recall: 0.6907 - val_loss: 0.7105 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4041/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7102 - precision: 0.6630 - recall: 0.6907 - val_loss: 0.7105 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4042/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7102 - precision: 0.6629 - recall: 0.6908 - val_loss: 0.7105 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4043/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7101 - precision: 0.6630 - recall: 0.6906 - val_loss: 0.7104 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4044/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7101 - precision: 0.6629 - recall: 0.6906 - val_loss: 0.7104 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4045/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7101 - precision: 0.6629 - recall: 0.6907 - val_loss: 0.7104 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4046/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7100 - precision: 0.6630 - recall: 0.6908 - val_loss: 0.7103 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4047/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7100 - precision: 0.6629 - recall: 0.6908 - val_loss: 0.7103 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4048/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7100 - precision: 0.6630 - recall: 0.6908 - val_loss: 0.7103 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4049/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7100 - precision: 0.6630 - recall: 0.6906 - val_loss: 0.7103 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4050/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7099 - precision: 0.6628 - recall: 0.6904 - val_loss: 0.7102 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4051/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7099 - precision: 0.6629 - recall: 0.6901 - val_loss: 0.7102 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4052/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7099 - precision: 0.6630 - recall: 0.6902 - val_loss: 0.7102 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4053/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7099 - precision: 0.6629 - recall: 0.6903 - val_loss: 0.7102 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4054/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7098 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7101 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4055/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7098 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7101 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4056/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7098 - precision: 0.6629 - recall: 0.6903 - val_loss: 0.7101 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4057/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7097 - precision: 0.6629 - recall: 0.6903 - val_loss: 0.7101 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4058/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7097 - precision: 0.6630 - recall: 0.6903 - val_loss: 0.7100 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4059/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7097 - precision: 0.6629 - recall: 0.6903 - val_loss: 0.7100 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4060/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7097 - precision: 0.6629 - recall: 0.6901 - val_loss: 0.7100 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4061/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7096 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7099 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4062/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7096 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7099 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4063/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7096 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7099 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4064/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7095 - precision: 0.6629 - recall: 0.6901 - val_loss: 0.7099 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4065/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7095 - precision: 0.6628 - recall: 0.6901 - val_loss: 0.7098 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4066/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7095 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7098 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4067/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7095 - precision: 0.6629 - recall: 0.6901 - val_loss: 0.7098 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4068/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7094 - precision: 0.6628 - recall: 0.6901 - val_loss: 0.7098 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4069/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7094 - precision: 0.6628 - recall: 0.6899 - val_loss: 0.7097 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4070/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7094 - precision: 0.6629 - recall: 0.6901 - val_loss: 0.7097 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4071/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7094 - precision: 0.6628 - recall: 0.6901 - val_loss: 0.7097 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4072/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7093 - precision: 0.6629 - recall: 0.6902 - val_loss: 0.7097 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4073/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7093 - precision: 0.6629 - recall: 0.6901 - val_loss: 0.7096 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4074/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7093 - precision: 0.6629 - recall: 0.6903 - val_loss: 0.7096 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4075/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7092 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7096 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4076/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7092 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7095 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4077/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7092 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7095 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4078/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7092 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7095 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4079/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7091 - precision: 0.6629 - recall: 0.6902 - val_loss: 0.7095 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4080/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7091 - precision: 0.6630 - recall: 0.6902 - val_loss: 0.7094 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4081/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7091 - precision: 0.6630 - recall: 0.6902 - val_loss: 0.7094 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4082/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7091 - precision: 0.6630 - recall: 0.6901 - val_loss: 0.7094 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4083/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7090 - precision: 0.6630 - recall: 0.6902 - val_loss: 0.7094 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4084/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7090 - precision: 0.6629 - recall: 0.6901 - val_loss: 0.7093 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4085/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7090 - precision: 0.6629 - recall: 0.6902 - val_loss: 0.7093 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4086/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7089 - precision: 0.6629 - recall: 0.6902 - val_loss: 0.7093 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4087/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7089 - precision: 0.6629 - recall: 0.6902 - val_loss: 0.7093 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4088/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7089 - precision: 0.6629 - recall: 0.6902 - val_loss: 0.7092 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4089/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7089 - precision: 0.6630 - recall: 0.6903 - val_loss: 0.7092 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4090/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7088 - precision: 0.6630 - recall: 0.6899 - val_loss: 0.7092 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4091/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7088 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7092 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4092/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7088 - precision: 0.6628 - recall: 0.6899 - val_loss: 0.7091 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4093/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7088 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7091 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4094/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7087 - precision: 0.6629 - recall: 0.6898 - val_loss: 0.7091 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4095/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7087 - precision: 0.6629 - recall: 0.6898 - val_loss: 0.7091 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4096/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7087 - precision: 0.6629 - recall: 0.6898 - val_loss: 0.7090 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4097/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7086 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7090 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4098/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7086 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7090 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4099/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7086 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7089 - val_precision: 0.6514 - val_recall: 0.6907\n",
      "Epoch 4100/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7086 - precision: 0.6630 - recall: 0.6896 - val_loss: 0.7089 - val_precision: 0.6512 - val_recall: 0.6903\n",
      "Epoch 4101/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7085 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7089 - val_precision: 0.6515 - val_recall: 0.6903\n",
      "Epoch 4102/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7085 - precision: 0.6629 - recall: 0.6899 - val_loss: 0.7089 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4103/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7085 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7088 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4104/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7085 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7088 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4105/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7084 - precision: 0.6630 - recall: 0.6897 - val_loss: 0.7088 - val_precision: 0.6516 - val_recall: 0.6907\n",
      "Epoch 4106/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7084 - precision: 0.6630 - recall: 0.6899 - val_loss: 0.7088 - val_precision: 0.6517 - val_recall: 0.6911\n",
      "Epoch 4107/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7084 - precision: 0.6630 - recall: 0.6897 - val_loss: 0.7087 - val_precision: 0.6519 - val_recall: 0.6907\n",
      "Epoch 4108/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7084 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7087 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4109/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7083 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7087 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4110/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7083 - precision: 0.6630 - recall: 0.6899 - val_loss: 0.7087 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4111/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7083 - precision: 0.6630 - recall: 0.6902 - val_loss: 0.7086 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4112/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7082 - precision: 0.6630 - recall: 0.6901 - val_loss: 0.7086 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4113/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7082 - precision: 0.6630 - recall: 0.6901 - val_loss: 0.7086 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4114/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7082 - precision: 0.6631 - recall: 0.6899 - val_loss: 0.7086 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4115/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7082 - precision: 0.6630 - recall: 0.6901 - val_loss: 0.7085 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4116/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7081 - precision: 0.6632 - recall: 0.6898 - val_loss: 0.7085 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4117/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7081 - precision: 0.6630 - recall: 0.6901 - val_loss: 0.7085 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4118/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7081 - precision: 0.6628 - recall: 0.6902 - val_loss: 0.7084 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4119/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7081 - precision: 0.6628 - recall: 0.6899 - val_loss: 0.7084 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4120/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7080 - precision: 0.6629 - recall: 0.6899 - val_loss: 0.7084 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4121/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7080 - precision: 0.6629 - recall: 0.6899 - val_loss: 0.7084 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4122/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7080 - precision: 0.6629 - recall: 0.6899 - val_loss: 0.7084 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4123/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7080 - precision: 0.6628 - recall: 0.6899 - val_loss: 0.7083 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4124/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7079 - precision: 0.6629 - recall: 0.6898 - val_loss: 0.7083 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4125/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7079 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7083 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4126/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7079 - precision: 0.6628 - recall: 0.6897 - val_loss: 0.7083 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4127/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7079 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7082 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4128/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7078 - precision: 0.6630 - recall: 0.6897 - val_loss: 0.7082 - val_precision: 0.6520 - val_recall: 0.6911\n",
      "Epoch 4129/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7078 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7082 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4130/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7078 - precision: 0.6628 - recall: 0.6897 - val_loss: 0.7082 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4131/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7078 - precision: 0.6630 - recall: 0.6897 - val_loss: 0.7081 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4132/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7077 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7081 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4133/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7077 - precision: 0.6632 - recall: 0.6897 - val_loss: 0.7081 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4134/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7077 - precision: 0.6630 - recall: 0.6899 - val_loss: 0.7080 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4135/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7077 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7080 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4136/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7076 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7080 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4137/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7076 - precision: 0.6631 - recall: 0.6898 - val_loss: 0.7080 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4138/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7076 - precision: 0.6632 - recall: 0.6898 - val_loss: 0.7080 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4139/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7076 - precision: 0.6631 - recall: 0.6898 - val_loss: 0.7079 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4140/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7075 - precision: 0.6632 - recall: 0.6898 - val_loss: 0.7079 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4141/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7075 - precision: 0.6632 - recall: 0.6898 - val_loss: 0.7079 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4142/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7075 - precision: 0.6631 - recall: 0.6898 - val_loss: 0.7078 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4143/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7075 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7078 - val_precision: 0.6516 - val_recall: 0.6914\n",
      "Epoch 4144/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7074 - precision: 0.6631 - recall: 0.6898 - val_loss: 0.7078 - val_precision: 0.6516 - val_recall: 0.6914\n",
      "Epoch 4145/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7074 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7078 - val_precision: 0.6516 - val_recall: 0.6914\n",
      "Epoch 4146/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7074 - precision: 0.6632 - recall: 0.6898 - val_loss: 0.7077 - val_precision: 0.6516 - val_recall: 0.6914\n",
      "Epoch 4147/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7073 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7077 - val_precision: 0.6516 - val_recall: 0.6914\n",
      "Epoch 4148/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7073 - precision: 0.6630 - recall: 0.6899 - val_loss: 0.7077 - val_precision: 0.6516 - val_recall: 0.6914\n",
      "Epoch 4149/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7073 - precision: 0.6630 - recall: 0.6899 - val_loss: 0.7077 - val_precision: 0.6516 - val_recall: 0.6914\n",
      "Epoch 4150/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7073 - precision: 0.6632 - recall: 0.6897 - val_loss: 0.7077 - val_precision: 0.6517 - val_recall: 0.6911\n",
      "Epoch 4151/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7072 - precision: 0.6632 - recall: 0.6896 - val_loss: 0.7076 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4152/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7072 - precision: 0.6632 - recall: 0.6897 - val_loss: 0.7076 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4153/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7072 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7076 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4154/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7072 - precision: 0.6629 - recall: 0.6897 - val_loss: 0.7075 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4155/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7071 - precision: 0.6631 - recall: 0.6898 - val_loss: 0.7075 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4156/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7071 - precision: 0.6632 - recall: 0.6897 - val_loss: 0.7075 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4157/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7071 - precision: 0.6631 - recall: 0.6897 - val_loss: 0.7075 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4158/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7071 - precision: 0.6630 - recall: 0.6897 - val_loss: 0.7074 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4159/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7070 - precision: 0.6632 - recall: 0.6897 - val_loss: 0.7074 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4160/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7070 - precision: 0.6632 - recall: 0.6898 - val_loss: 0.7074 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4161/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7070 - precision: 0.6632 - recall: 0.6897 - val_loss: 0.7074 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4162/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7070 - precision: 0.6630 - recall: 0.6898 - val_loss: 0.7073 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4163/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7069 - precision: 0.6633 - recall: 0.6896 - val_loss: 0.7073 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4164/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7069 - precision: 0.6633 - recall: 0.6894 - val_loss: 0.7073 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4165/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7069 - precision: 0.6634 - recall: 0.6896 - val_loss: 0.7073 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4166/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7069 - precision: 0.6633 - recall: 0.6894 - val_loss: 0.7073 - val_precision: 0.6519 - val_recall: 0.6914\n",
      "Epoch 4167/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7068 - precision: 0.6634 - recall: 0.6898 - val_loss: 0.7072 - val_precision: 0.6523 - val_recall: 0.6926\n",
      "Epoch 4168/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7068 - precision: 0.6634 - recall: 0.6897 - val_loss: 0.7072 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4169/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7068 - precision: 0.6634 - recall: 0.6898 - val_loss: 0.7072 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4170/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7068 - precision: 0.6634 - recall: 0.6897 - val_loss: 0.7072 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4171/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7068 - precision: 0.6634 - recall: 0.6896 - val_loss: 0.7071 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4172/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7067 - precision: 0.6633 - recall: 0.6897 - val_loss: 0.7071 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4173/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7067 - precision: 0.6635 - recall: 0.6897 - val_loss: 0.7071 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4174/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7067 - precision: 0.6635 - recall: 0.6897 - val_loss: 0.7071 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4175/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7067 - precision: 0.6635 - recall: 0.6897 - val_loss: 0.7070 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4176/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7066 - precision: 0.6634 - recall: 0.6896 - val_loss: 0.7070 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4177/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7066 - precision: 0.6635 - recall: 0.6894 - val_loss: 0.7070 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4178/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7066 - precision: 0.6633 - recall: 0.6897 - val_loss: 0.7070 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4179/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7066 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7070 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4180/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7065 - precision: 0.6635 - recall: 0.6896 - val_loss: 0.7069 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4181/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7065 - precision: 0.6635 - recall: 0.6896 - val_loss: 0.7069 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4182/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7065 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7069 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4183/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7065 - precision: 0.6635 - recall: 0.6896 - val_loss: 0.7069 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4184/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7064 - precision: 0.6634 - recall: 0.6896 - val_loss: 0.7068 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4185/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7064 - precision: 0.6635 - recall: 0.6897 - val_loss: 0.7068 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4186/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7064 - precision: 0.6634 - recall: 0.6896 - val_loss: 0.7068 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4187/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7064 - precision: 0.6635 - recall: 0.6897 - val_loss: 0.7068 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4188/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7063 - precision: 0.6635 - recall: 0.6897 - val_loss: 0.7067 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4189/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7063 - precision: 0.6635 - recall: 0.6898 - val_loss: 0.7067 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4190/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7063 - precision: 0.6635 - recall: 0.6897 - val_loss: 0.7067 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4191/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7063 - precision: 0.6635 - recall: 0.6898 - val_loss: 0.7067 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4192/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7062 - precision: 0.6635 - recall: 0.6898 - val_loss: 0.7066 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4193/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7062 - precision: 0.6635 - recall: 0.6898 - val_loss: 0.7066 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4194/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7062 - precision: 0.6636 - recall: 0.6896 - val_loss: 0.7066 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4195/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7062 - precision: 0.6636 - recall: 0.6898 - val_loss: 0.7066 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4196/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7061 - precision: 0.6636 - recall: 0.6897 - val_loss: 0.7065 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4197/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7061 - precision: 0.6636 - recall: 0.6897 - val_loss: 0.7065 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4198/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7061 - precision: 0.6636 - recall: 0.6896 - val_loss: 0.7065 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4199/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7061 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7065 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4200/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7061 - precision: 0.6636 - recall: 0.6897 - val_loss: 0.7065 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4201/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7060 - precision: 0.6636 - recall: 0.6897 - val_loss: 0.7064 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4202/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7060 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7064 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4203/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7060 - precision: 0.6636 - recall: 0.6896 - val_loss: 0.7064 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4204/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7060 - precision: 0.6637 - recall: 0.6896 - val_loss: 0.7064 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4205/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7059 - precision: 0.6637 - recall: 0.6896 - val_loss: 0.7063 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4206/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7059 - precision: 0.6636 - recall: 0.6896 - val_loss: 0.7063 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4207/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7059 - precision: 0.6636 - recall: 0.6896 - val_loss: 0.7063 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4208/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7059 - precision: 0.6637 - recall: 0.6896 - val_loss: 0.7063 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4209/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7058 - precision: 0.6637 - recall: 0.6896 - val_loss: 0.7063 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4210/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7058 - precision: 0.6637 - recall: 0.6896 - val_loss: 0.7062 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4211/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7058 - precision: 0.6637 - recall: 0.6896 - val_loss: 0.7062 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4212/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7058 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7062 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4213/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7058 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7062 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4214/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7057 - precision: 0.6636 - recall: 0.6893 - val_loss: 0.7061 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4215/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7057 - precision: 0.6638 - recall: 0.6893 - val_loss: 0.7061 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4216/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7057 - precision: 0.6637 - recall: 0.6893 - val_loss: 0.7061 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4217/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7057 - precision: 0.6637 - recall: 0.6890 - val_loss: 0.7061 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4218/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7056 - precision: 0.6636 - recall: 0.6892 - val_loss: 0.7061 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4219/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7056 - precision: 0.6637 - recall: 0.6892 - val_loss: 0.7060 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4220/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7056 - precision: 0.6638 - recall: 0.6893 - val_loss: 0.7060 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4221/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7056 - precision: 0.6637 - recall: 0.6893 - val_loss: 0.7060 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4222/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7055 - precision: 0.6637 - recall: 0.6896 - val_loss: 0.7060 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4223/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7055 - precision: 0.6637 - recall: 0.6894 - val_loss: 0.7059 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4224/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7055 - precision: 0.6636 - recall: 0.6896 - val_loss: 0.7059 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4225/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7055 - precision: 0.6637 - recall: 0.6894 - val_loss: 0.7059 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4226/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7055 - precision: 0.6637 - recall: 0.6897 - val_loss: 0.7059 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4227/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7054 - precision: 0.6638 - recall: 0.6893 - val_loss: 0.7059 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4228/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7054 - precision: 0.6637 - recall: 0.6893 - val_loss: 0.7058 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4229/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7054 - precision: 0.6636 - recall: 0.6897 - val_loss: 0.7058 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4230/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7054 - precision: 0.6637 - recall: 0.6894 - val_loss: 0.7058 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4231/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7053 - precision: 0.6637 - recall: 0.6893 - val_loss: 0.7058 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4232/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7053 - precision: 0.6637 - recall: 0.6893 - val_loss: 0.7057 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4233/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7053 - precision: 0.6637 - recall: 0.6893 - val_loss: 0.7057 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4234/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7053 - precision: 0.6637 - recall: 0.6894 - val_loss: 0.7057 - val_precision: 0.6523 - val_recall: 0.6914\n",
      "Epoch 4235/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7052 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7057 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4236/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7052 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7056 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4237/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7052 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7056 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4238/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7052 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7056 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4239/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7052 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7056 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4240/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7051 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7056 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4241/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7051 - precision: 0.6636 - recall: 0.6894 - val_loss: 0.7055 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4242/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7051 - precision: 0.6637 - recall: 0.6894 - val_loss: 0.7055 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4243/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7051 - precision: 0.6637 - recall: 0.6894 - val_loss: 0.7055 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4244/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7050 - precision: 0.6639 - recall: 0.6894 - val_loss: 0.7055 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4245/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7050 - precision: 0.6638 - recall: 0.6894 - val_loss: 0.7055 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4246/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7050 - precision: 0.6637 - recall: 0.6894 - val_loss: 0.7054 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4247/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7050 - precision: 0.6640 - recall: 0.6894 - val_loss: 0.7054 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4248/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7050 - precision: 0.6639 - recall: 0.6892 - val_loss: 0.7054 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4249/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7049 - precision: 0.6640 - recall: 0.6897 - val_loss: 0.7054 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4250/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7049 - precision: 0.6640 - recall: 0.6894 - val_loss: 0.7053 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4251/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7049 - precision: 0.6640 - recall: 0.6896 - val_loss: 0.7053 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4252/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7049 - precision: 0.6641 - recall: 0.6897 - val_loss: 0.7053 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4253/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7048 - precision: 0.6641 - recall: 0.6897 - val_loss: 0.7053 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4254/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7048 - precision: 0.6640 - recall: 0.6893 - val_loss: 0.7053 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4255/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7048 - precision: 0.6641 - recall: 0.6896 - val_loss: 0.7052 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4256/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7048 - precision: 0.6640 - recall: 0.6892 - val_loss: 0.7052 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4257/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7048 - precision: 0.6640 - recall: 0.6894 - val_loss: 0.7052 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4258/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7047 - precision: 0.6640 - recall: 0.6892 - val_loss: 0.7052 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4259/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7047 - precision: 0.6641 - recall: 0.6894 - val_loss: 0.7052 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4260/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7047 - precision: 0.6640 - recall: 0.6890 - val_loss: 0.7051 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4261/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7047 - precision: 0.6640 - recall: 0.6889 - val_loss: 0.7051 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4262/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7047 - precision: 0.6640 - recall: 0.6892 - val_loss: 0.7051 - val_precision: 0.6526 - val_recall: 0.6922\n",
      "Epoch 4263/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7046 - precision: 0.6641 - recall: 0.6887 - val_loss: 0.7051 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4264/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7046 - precision: 0.6641 - recall: 0.6890 - val_loss: 0.7050 - val_precision: 0.6526 - val_recall: 0.6922\n",
      "Epoch 4265/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7046 - precision: 0.6640 - recall: 0.6894 - val_loss: 0.7050 - val_precision: 0.6526 - val_recall: 0.6922\n",
      "Epoch 4266/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7046 - precision: 0.6642 - recall: 0.6888 - val_loss: 0.7050 - val_precision: 0.6526 - val_recall: 0.6922\n",
      "Epoch 4267/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7045 - precision: 0.6641 - recall: 0.6890 - val_loss: 0.7050 - val_precision: 0.6524 - val_recall: 0.6922\n",
      "Epoch 4268/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7045 - precision: 0.6641 - recall: 0.6889 - val_loss: 0.7050 - val_precision: 0.6526 - val_recall: 0.6922\n",
      "Epoch 4269/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7045 - precision: 0.6641 - recall: 0.6889 - val_loss: 0.7049 - val_precision: 0.6524 - val_recall: 0.6922\n",
      "Epoch 4270/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7045 - precision: 0.6641 - recall: 0.6890 - val_loss: 0.7049 - val_precision: 0.6524 - val_recall: 0.6922\n",
      "Epoch 4271/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7045 - precision: 0.6640 - recall: 0.6892 - val_loss: 0.7049 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4272/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7044 - precision: 0.6642 - recall: 0.6890 - val_loss: 0.7049 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4273/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7044 - precision: 0.6641 - recall: 0.6893 - val_loss: 0.7049 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4274/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7044 - precision: 0.6641 - recall: 0.6887 - val_loss: 0.7048 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4275/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7044 - precision: 0.6641 - recall: 0.6893 - val_loss: 0.7048 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4276/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7044 - precision: 0.6642 - recall: 0.6890 - val_loss: 0.7048 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4277/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7043 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7048 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4278/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7043 - precision: 0.6642 - recall: 0.6893 - val_loss: 0.7047 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4279/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7043 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7047 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4280/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7043 - precision: 0.6644 - recall: 0.6894 - val_loss: 0.7047 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4281/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7042 - precision: 0.6642 - recall: 0.6887 - val_loss: 0.7047 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4282/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7042 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7047 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4283/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7042 - precision: 0.6641 - recall: 0.6887 - val_loss: 0.7047 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4284/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7042 - precision: 0.6643 - recall: 0.6889 - val_loss: 0.7046 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4285/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7042 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7046 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4286/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7041 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7046 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4287/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7041 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7046 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4288/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7041 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7046 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4289/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7041 - precision: 0.6642 - recall: 0.6888 - val_loss: 0.7045 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4290/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7041 - precision: 0.6642 - recall: 0.6889 - val_loss: 0.7045 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4291/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7040 - precision: 0.6642 - recall: 0.6888 - val_loss: 0.7045 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4292/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7040 - precision: 0.6643 - recall: 0.6892 - val_loss: 0.7045 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4293/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7040 - precision: 0.6643 - recall: 0.6892 - val_loss: 0.7044 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4294/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7040 - precision: 0.6643 - recall: 0.6892 - val_loss: 0.7044 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4295/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7040 - precision: 0.6643 - recall: 0.6889 - val_loss: 0.7044 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4296/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7039 - precision: 0.6642 - recall: 0.6889 - val_loss: 0.7044 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4297/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7039 - precision: 0.6642 - recall: 0.6888 - val_loss: 0.7044 - val_precision: 0.6520 - val_recall: 0.6918\n",
      "Epoch 4298/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7039 - precision: 0.6642 - recall: 0.6890 - val_loss: 0.7043 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4299/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7039 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7043 - val_precision: 0.6521 - val_recall: 0.6922\n",
      "Epoch 4300/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7039 - precision: 0.6643 - recall: 0.6889 - val_loss: 0.7043 - val_precision: 0.6521 - val_recall: 0.6914\n",
      "Epoch 4301/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7038 - precision: 0.6642 - recall: 0.6889 - val_loss: 0.7043 - val_precision: 0.6524 - val_recall: 0.6922\n",
      "Epoch 4302/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7038 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7043 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4303/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7038 - precision: 0.6642 - recall: 0.6889 - val_loss: 0.7043 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4304/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7038 - precision: 0.6643 - recall: 0.6889 - val_loss: 0.7042 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4305/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7038 - precision: 0.6643 - recall: 0.6889 - val_loss: 0.7042 - val_precision: 0.6522 - val_recall: 0.6918\n",
      "Epoch 4306/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7037 - precision: 0.6643 - recall: 0.6889 - val_loss: 0.7042 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4307/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7037 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7042 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4308/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7037 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7042 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4309/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7037 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7041 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4310/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7037 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7041 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4311/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7036 - precision: 0.6641 - recall: 0.6884 - val_loss: 0.7041 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4312/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7036 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7041 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4313/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7036 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7041 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4314/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7036 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7041 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4315/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7036 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7040 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4316/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7035 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7040 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4317/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7035 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7040 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4318/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7035 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7040 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4319/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7035 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7040 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4320/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7035 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7039 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4321/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7034 - precision: 0.6642 - recall: 0.6889 - val_loss: 0.7039 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4322/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7034 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7039 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4323/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7034 - precision: 0.6644 - recall: 0.6889 - val_loss: 0.7039 - val_precision: 0.6525 - val_recall: 0.6918\n",
      "Epoch 4324/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7034 - precision: 0.6642 - recall: 0.6883 - val_loss: 0.7039 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4325/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7034 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7038 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4326/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7033 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7038 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4327/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7033 - precision: 0.6643 - recall: 0.6885 - val_loss: 0.7038 - val_precision: 0.6526 - val_recall: 0.6914\n",
      "Epoch 4328/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7033 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7038 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4329/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7033 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7038 - val_precision: 0.6526 - val_recall: 0.6914\n",
      "Epoch 4330/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7033 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7038 - val_precision: 0.6526 - val_recall: 0.6914\n",
      "Epoch 4331/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7033 - precision: 0.6643 - recall: 0.6884 - val_loss: 0.7037 - val_precision: 0.6526 - val_recall: 0.6914\n",
      "Epoch 4332/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7032 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7037 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4333/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7032 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7037 - val_precision: 0.6526 - val_recall: 0.6914\n",
      "Epoch 4334/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7032 - precision: 0.6644 - recall: 0.6889 - val_loss: 0.7037 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4335/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7032 - precision: 0.6644 - recall: 0.6889 - val_loss: 0.7037 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4336/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7032 - precision: 0.6644 - recall: 0.6889 - val_loss: 0.7037 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4337/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7031 - precision: 0.6645 - recall: 0.6892 - val_loss: 0.7036 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4338/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7031 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7036 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4339/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7031 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7036 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4340/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7031 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7036 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4341/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7031 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7036 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4342/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7030 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7035 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4343/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7030 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7035 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4344/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7030 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7035 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4345/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7030 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7035 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4346/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7030 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7035 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4347/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7030 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7035 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4348/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7029 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7034 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4349/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7029 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7034 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4350/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7029 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7034 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4351/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7029 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7034 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4352/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7029 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7034 - val_precision: 0.6527 - val_recall: 0.6918\n",
      "Epoch 4353/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7028 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7034 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4354/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7028 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7033 - val_precision: 0.6530 - val_recall: 0.6918\n",
      "Epoch 4355/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7028 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7033 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4356/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7028 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7033 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4357/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7028 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7033 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4358/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7028 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7033 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4359/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7027 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7032 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4360/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7027 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7032 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4361/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7027 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7032 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4362/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7027 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7032 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4363/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7027 - precision: 0.6644 - recall: 0.6892 - val_loss: 0.7032 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4364/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7027 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7032 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4365/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7026 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7032 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4366/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7026 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7031 - val_precision: 0.6526 - val_recall: 0.6907\n",
      "Epoch 4367/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7026 - precision: 0.6645 - recall: 0.6889 - val_loss: 0.7031 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4368/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7026 - precision: 0.6645 - recall: 0.6887 - val_loss: 0.7031 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4369/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7026 - precision: 0.6644 - recall: 0.6889 - val_loss: 0.7031 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4370/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7025 - precision: 0.6643 - recall: 0.6888 - val_loss: 0.7031 - val_precision: 0.6528 - val_recall: 0.6914\n",
      "Epoch 4371/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7025 - precision: 0.6644 - recall: 0.6889 - val_loss: 0.7030 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4372/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7025 - precision: 0.6643 - recall: 0.6889 - val_loss: 0.7030 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4373/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7025 - precision: 0.6643 - recall: 0.6892 - val_loss: 0.7030 - val_precision: 0.6526 - val_recall: 0.6914\n",
      "Epoch 4374/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7025 - precision: 0.6643 - recall: 0.6890 - val_loss: 0.7030 - val_precision: 0.6526 - val_recall: 0.6907\n",
      "Epoch 4375/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7025 - precision: 0.6645 - recall: 0.6892 - val_loss: 0.7030 - val_precision: 0.6525 - val_recall: 0.6911\n",
      "Epoch 4376/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7024 - precision: 0.6644 - recall: 0.6890 - val_loss: 0.7030 - val_precision: 0.6523 - val_recall: 0.6907\n",
      "Epoch 4377/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7024 - precision: 0.6643 - recall: 0.6887 - val_loss: 0.7029 - val_precision: 0.6523 - val_recall: 0.6907\n",
      "Epoch 4378/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7024 - precision: 0.6645 - recall: 0.6892 - val_loss: 0.7029 - val_precision: 0.6525 - val_recall: 0.6911\n",
      "Epoch 4379/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7024 - precision: 0.6645 - recall: 0.6892 - val_loss: 0.7029 - val_precision: 0.6523 - val_recall: 0.6907\n",
      "Epoch 4380/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7024 - precision: 0.6644 - recall: 0.6887 - val_loss: 0.7029 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4381/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7024 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7029 - val_precision: 0.6522 - val_recall: 0.6903\n",
      "Epoch 4382/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7023 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7029 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4383/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7023 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7029 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4384/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7023 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7028 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4385/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7023 - precision: 0.6643 - recall: 0.6884 - val_loss: 0.7028 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4386/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7023 - precision: 0.6644 - recall: 0.6888 - val_loss: 0.7028 - val_precision: 0.6526 - val_recall: 0.6907\n",
      "Epoch 4387/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7023 - precision: 0.6645 - recall: 0.6885 - val_loss: 0.7028 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4388/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7022 - precision: 0.6645 - recall: 0.6885 - val_loss: 0.7028 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4389/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7022 - precision: 0.6645 - recall: 0.6885 - val_loss: 0.7028 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4390/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7022 - precision: 0.6645 - recall: 0.6890 - val_loss: 0.7027 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4391/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7022 - precision: 0.6646 - recall: 0.6885 - val_loss: 0.7027 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4392/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7022 - precision: 0.6645 - recall: 0.6888 - val_loss: 0.7027 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4393/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7022 - precision: 0.6647 - recall: 0.6887 - val_loss: 0.7027 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4394/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7021 - precision: 0.6646 - recall: 0.6887 - val_loss: 0.7027 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4395/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7021 - precision: 0.6646 - recall: 0.6887 - val_loss: 0.7027 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4396/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7021 - precision: 0.6647 - recall: 0.6888 - val_loss: 0.7026 - val_precision: 0.6526 - val_recall: 0.6907\n",
      "Epoch 4397/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7021 - precision: 0.6648 - recall: 0.6888 - val_loss: 0.7026 - val_precision: 0.6526 - val_recall: 0.6907\n",
      "Epoch 4398/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7021 - precision: 0.6648 - recall: 0.6889 - val_loss: 0.7026 - val_precision: 0.6527 - val_recall: 0.6911\n",
      "Epoch 4399/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7021 - precision: 0.6649 - recall: 0.6889 - val_loss: 0.7026 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4400/5000\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7020 - precision: 0.6649 - recall: 0.6889 - val_loss: 0.7026 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4401/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7020 - precision: 0.6648 - recall: 0.6890 - val_loss: 0.7026 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4402/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7020 - precision: 0.6648 - recall: 0.6890 - val_loss: 0.7025 - val_precision: 0.6526 - val_recall: 0.6907\n",
      "Epoch 4403/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7020 - precision: 0.6649 - recall: 0.6885 - val_loss: 0.7025 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4404/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7020 - precision: 0.6648 - recall: 0.6892 - val_loss: 0.7025 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4405/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.7020 - precision: 0.6648 - recall: 0.6890 - val_loss: 0.7025 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4406/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7019 - precision: 0.6648 - recall: 0.6890 - val_loss: 0.7025 - val_precision: 0.6524 - val_recall: 0.6903\n",
      "Epoch 4407/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7019 - precision: 0.6649 - recall: 0.6889 - val_loss: 0.7025 - val_precision: 0.6527 - val_recall: 0.6903\n",
      "Epoch 4408/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7019 - precision: 0.6649 - recall: 0.6888 - val_loss: 0.7025 - val_precision: 0.6527 - val_recall: 0.6903\n",
      "Epoch 4409/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7019 - precision: 0.6649 - recall: 0.6890 - val_loss: 0.7024 - val_precision: 0.6527 - val_recall: 0.6903\n",
      "Epoch 4410/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7019 - precision: 0.6647 - recall: 0.6890 - val_loss: 0.7024 - val_precision: 0.6527 - val_recall: 0.6903\n",
      "Epoch 4411/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7019 - precision: 0.6648 - recall: 0.6890 - val_loss: 0.7024 - val_precision: 0.6528 - val_recall: 0.6907\n",
      "Epoch 4412/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7018 - precision: 0.6649 - recall: 0.6893 - val_loss: 0.7024 - val_precision: 0.6528 - val_recall: 0.6907\n",
      "Epoch 4413/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7018 - precision: 0.6648 - recall: 0.6896 - val_loss: 0.7024 - val_precision: 0.6528 - val_recall: 0.6907\n",
      "Epoch 4414/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7018 - precision: 0.6650 - recall: 0.6890 - val_loss: 0.7024 - val_precision: 0.6528 - val_recall: 0.6907\n",
      "Epoch 4415/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7018 - precision: 0.6649 - recall: 0.6888 - val_loss: 0.7023 - val_precision: 0.6531 - val_recall: 0.6907\n",
      "Epoch 4416/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7018 - precision: 0.6651 - recall: 0.6893 - val_loss: 0.7023 - val_precision: 0.6528 - val_recall: 0.6907\n",
      "Epoch 4417/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7018 - precision: 0.6649 - recall: 0.6888 - val_loss: 0.7023 - val_precision: 0.6528 - val_recall: 0.6907\n",
      "Epoch 4418/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7018 - precision: 0.6649 - recall: 0.6888 - val_loss: 0.7023 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4419/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7017 - precision: 0.6649 - recall: 0.6888 - val_loss: 0.7023 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4420/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7017 - precision: 0.6650 - recall: 0.6890 - val_loss: 0.7023 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4421/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7017 - precision: 0.6650 - recall: 0.6890 - val_loss: 0.7022 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4422/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7017 - precision: 0.6650 - recall: 0.6890 - val_loss: 0.7022 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4423/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7017 - precision: 0.6650 - recall: 0.6890 - val_loss: 0.7022 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4424/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7017 - precision: 0.6651 - recall: 0.6893 - val_loss: 0.7022 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4425/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7016 - precision: 0.6651 - recall: 0.6897 - val_loss: 0.7022 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4426/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7016 - precision: 0.6650 - recall: 0.6892 - val_loss: 0.7022 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4427/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7016 - precision: 0.6649 - recall: 0.6890 - val_loss: 0.7022 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4428/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7016 - precision: 0.6650 - recall: 0.6887 - val_loss: 0.7021 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4429/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7016 - precision: 0.6651 - recall: 0.6890 - val_loss: 0.7021 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4430/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7016 - precision: 0.6652 - recall: 0.6888 - val_loss: 0.7021 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4431/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7015 - precision: 0.6652 - recall: 0.6892 - val_loss: 0.7021 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4432/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7015 - precision: 0.6652 - recall: 0.6893 - val_loss: 0.7021 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4433/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7015 - precision: 0.6650 - recall: 0.6890 - val_loss: 0.7021 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4434/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7015 - precision: 0.6652 - recall: 0.6887 - val_loss: 0.7020 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4435/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7015 - precision: 0.6653 - recall: 0.6889 - val_loss: 0.7020 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4436/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7015 - precision: 0.6652 - recall: 0.6889 - val_loss: 0.7020 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4437/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7014 - precision: 0.6652 - recall: 0.6887 - val_loss: 0.7020 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4438/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7014 - precision: 0.6653 - recall: 0.6887 - val_loss: 0.7020 - val_precision: 0.6535 - val_recall: 0.6907\n",
      "Epoch 4439/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7014 - precision: 0.6651 - recall: 0.6888 - val_loss: 0.7020 - val_precision: 0.6535 - val_recall: 0.6907\n",
      "Epoch 4440/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7014 - precision: 0.6652 - recall: 0.6888 - val_loss: 0.7020 - val_precision: 0.6533 - val_recall: 0.6907\n",
      "Epoch 4441/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7014 - precision: 0.6652 - recall: 0.6889 - val_loss: 0.7019 - val_precision: 0.6535 - val_recall: 0.6907\n",
      "Epoch 4442/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7014 - precision: 0.6651 - recall: 0.6889 - val_loss: 0.7019 - val_precision: 0.6535 - val_recall: 0.6907\n",
      "Epoch 4443/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7013 - precision: 0.6652 - recall: 0.6887 - val_loss: 0.7019 - val_precision: 0.6536 - val_recall: 0.6903\n",
      "Epoch 4444/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7013 - precision: 0.6651 - recall: 0.6888 - val_loss: 0.7019 - val_precision: 0.6535 - val_recall: 0.6907\n",
      "Epoch 4445/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7013 - precision: 0.6652 - recall: 0.6889 - val_loss: 0.7019 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4446/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7013 - precision: 0.6651 - recall: 0.6885 - val_loss: 0.7019 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4447/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7013 - precision: 0.6651 - recall: 0.6888 - val_loss: 0.7019 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4448/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7013 - precision: 0.6652 - recall: 0.6890 - val_loss: 0.7018 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4449/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7013 - precision: 0.6651 - recall: 0.6888 - val_loss: 0.7018 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4450/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7012 - precision: 0.6651 - recall: 0.6888 - val_loss: 0.7018 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4451/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7012 - precision: 0.6651 - recall: 0.6887 - val_loss: 0.7018 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4452/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7012 - precision: 0.6652 - recall: 0.6889 - val_loss: 0.7018 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4453/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7012 - precision: 0.6653 - recall: 0.6892 - val_loss: 0.7018 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4454/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7012 - precision: 0.6650 - recall: 0.6884 - val_loss: 0.7017 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4455/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7012 - precision: 0.6651 - recall: 0.6888 - val_loss: 0.7017 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4456/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7011 - precision: 0.6652 - recall: 0.6890 - val_loss: 0.7017 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4457/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7011 - precision: 0.6652 - recall: 0.6890 - val_loss: 0.7017 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4458/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7011 - precision: 0.6651 - recall: 0.6884 - val_loss: 0.7017 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4459/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7011 - precision: 0.6652 - recall: 0.6887 - val_loss: 0.7017 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4460/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7011 - precision: 0.6651 - recall: 0.6885 - val_loss: 0.7017 - val_precision: 0.6536 - val_recall: 0.6903\n",
      "Epoch 4461/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7011 - precision: 0.6651 - recall: 0.6887 - val_loss: 0.7016 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4462/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7010 - precision: 0.6652 - recall: 0.6888 - val_loss: 0.7016 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4463/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7010 - precision: 0.6652 - recall: 0.6888 - val_loss: 0.7016 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4464/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7010 - precision: 0.6652 - recall: 0.6887 - val_loss: 0.7016 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4465/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7010 - precision: 0.6651 - recall: 0.6887 - val_loss: 0.7016 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4466/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7010 - precision: 0.6652 - recall: 0.6887 - val_loss: 0.7015 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4467/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7010 - precision: 0.6653 - recall: 0.6889 - val_loss: 0.7015 - val_precision: 0.6537 - val_recall: 0.6911\n",
      "Epoch 4468/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7009 - precision: 0.6653 - recall: 0.6888 - val_loss: 0.7015 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4469/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7009 - precision: 0.6654 - recall: 0.6889 - val_loss: 0.7015 - val_precision: 0.6536 - val_recall: 0.6903\n",
      "Epoch 4470/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7009 - precision: 0.6653 - recall: 0.6885 - val_loss: 0.7015 - val_precision: 0.6539 - val_recall: 0.6903\n",
      "Epoch 4471/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7009 - precision: 0.6654 - recall: 0.6889 - val_loss: 0.7015 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4472/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7009 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7015 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4473/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7009 - precision: 0.6653 - recall: 0.6888 - val_loss: 0.7014 - val_precision: 0.6538 - val_recall: 0.6907\n",
      "Epoch 4474/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7009 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7014 - val_precision: 0.6535 - val_recall: 0.6899\n",
      "Epoch 4475/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7008 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7014 - val_precision: 0.6536 - val_recall: 0.6903\n",
      "Epoch 4476/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7008 - precision: 0.6654 - recall: 0.6889 - val_loss: 0.7014 - val_precision: 0.6536 - val_recall: 0.6903\n",
      "Epoch 4477/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7008 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7014 - val_precision: 0.6539 - val_recall: 0.6903\n",
      "Epoch 4478/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7008 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7014 - val_precision: 0.6540 - val_recall: 0.6907\n",
      "Epoch 4479/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7008 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7014 - val_precision: 0.6540 - val_recall: 0.6907\n",
      "Epoch 4480/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7008 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7013 - val_precision: 0.6540 - val_recall: 0.6907\n",
      "Epoch 4481/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7007 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7013 - val_precision: 0.6539 - val_recall: 0.6903\n",
      "Epoch 4482/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7007 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7013 - val_precision: 0.6539 - val_recall: 0.6903\n",
      "Epoch 4483/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7007 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7013 - val_precision: 0.6540 - val_recall: 0.6907\n",
      "Epoch 4484/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7007 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7013 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4485/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7007 - precision: 0.6653 - recall: 0.6888 - val_loss: 0.7013 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4486/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7007 - precision: 0.6653 - recall: 0.6888 - val_loss: 0.7012 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4487/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7007 - precision: 0.6653 - recall: 0.6888 - val_loss: 0.7012 - val_precision: 0.6539 - val_recall: 0.6903\n",
      "Epoch 4488/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7006 - precision: 0.6655 - recall: 0.6885 - val_loss: 0.7012 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4489/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7006 - precision: 0.6652 - recall: 0.6888 - val_loss: 0.7012 - val_precision: 0.6544 - val_recall: 0.6918\n",
      "Epoch 4490/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7006 - precision: 0.6653 - recall: 0.6888 - val_loss: 0.7012 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4491/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7006 - precision: 0.6652 - recall: 0.6887 - val_loss: 0.7012 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4492/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7006 - precision: 0.6652 - recall: 0.6885 - val_loss: 0.7012 - val_precision: 0.6540 - val_recall: 0.6907\n",
      "Epoch 4493/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7006 - precision: 0.6653 - recall: 0.6884 - val_loss: 0.7011 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4494/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7005 - precision: 0.6653 - recall: 0.6885 - val_loss: 0.7011 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4495/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7005 - precision: 0.6652 - recall: 0.6883 - val_loss: 0.7011 - val_precision: 0.6540 - val_recall: 0.6907\n",
      "Epoch 4496/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7005 - precision: 0.6653 - recall: 0.6885 - val_loss: 0.7011 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4497/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7005 - precision: 0.6654 - recall: 0.6889 - val_loss: 0.7011 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4498/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7005 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7011 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4499/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7005 - precision: 0.6655 - recall: 0.6892 - val_loss: 0.7010 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4500/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7004 - precision: 0.6655 - recall: 0.6890 - val_loss: 0.7010 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4501/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7004 - precision: 0.6654 - recall: 0.6892 - val_loss: 0.7010 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4502/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7004 - precision: 0.6655 - recall: 0.6892 - val_loss: 0.7010 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4503/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7004 - precision: 0.6655 - recall: 0.6892 - val_loss: 0.7010 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4504/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7004 - precision: 0.6654 - recall: 0.6889 - val_loss: 0.7010 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4505/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7004 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7010 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4506/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7004 - precision: 0.6654 - recall: 0.6892 - val_loss: 0.7009 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4507/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7003 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7009 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4508/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7003 - precision: 0.6654 - recall: 0.6887 - val_loss: 0.7009 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4509/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7003 - precision: 0.6655 - recall: 0.6885 - val_loss: 0.7009 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4510/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7003 - precision: 0.6654 - recall: 0.6890 - val_loss: 0.7009 - val_precision: 0.6544 - val_recall: 0.6918\n",
      "Epoch 4511/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7003 - precision: 0.6655 - recall: 0.6888 - val_loss: 0.7009 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4512/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7003 - precision: 0.6654 - recall: 0.6892 - val_loss: 0.7008 - val_precision: 0.6544 - val_recall: 0.6918\n",
      "Epoch 4513/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7002 - precision: 0.6653 - recall: 0.6888 - val_loss: 0.7008 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4514/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7002 - precision: 0.6654 - recall: 0.6888 - val_loss: 0.7008 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4515/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7002 - precision: 0.6656 - recall: 0.6885 - val_loss: 0.7008 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4516/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7002 - precision: 0.6654 - recall: 0.6882 - val_loss: 0.7008 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4517/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7002 - precision: 0.6656 - recall: 0.6884 - val_loss: 0.7008 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4518/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7002 - precision: 0.6656 - recall: 0.6885 - val_loss: 0.7008 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4519/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7002 - precision: 0.6656 - recall: 0.6884 - val_loss: 0.7008 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4520/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7001 - precision: 0.6656 - recall: 0.6888 - val_loss: 0.7007 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4521/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7001 - precision: 0.6654 - recall: 0.6889 - val_loss: 0.7007 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4522/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7001 - precision: 0.6656 - recall: 0.6890 - val_loss: 0.7007 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4523/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.7001 - precision: 0.6656 - recall: 0.6887 - val_loss: 0.7007 - val_precision: 0.6540 - val_recall: 0.6907\n",
      "Epoch 4524/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7001 - precision: 0.6656 - recall: 0.6890 - val_loss: 0.7007 - val_precision: 0.6543 - val_recall: 0.6914\n",
      "Epoch 4525/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7001 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7007 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4526/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7000 - precision: 0.6655 - recall: 0.6890 - val_loss: 0.7006 - val_precision: 0.6544 - val_recall: 0.6918\n",
      "Epoch 4527/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7000 - precision: 0.6658 - recall: 0.6890 - val_loss: 0.7006 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4528/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7000 - precision: 0.6656 - recall: 0.6888 - val_loss: 0.7006 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4529/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7000 - precision: 0.6656 - recall: 0.6890 - val_loss: 0.7006 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4530/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7000 - precision: 0.6657 - recall: 0.6890 - val_loss: 0.7006 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4531/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7000 - precision: 0.6658 - recall: 0.6890 - val_loss: 0.7006 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4532/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.7000 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7006 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4533/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6999 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7005 - val_precision: 0.6541 - val_recall: 0.6911\n",
      "Epoch 4534/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6999 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7005 - val_precision: 0.6539 - val_recall: 0.6911\n",
      "Epoch 4535/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6999 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7005 - val_precision: 0.6544 - val_recall: 0.6911\n",
      "Epoch 4536/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6999 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7005 - val_precision: 0.6544 - val_recall: 0.6911\n",
      "Epoch 4537/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6999 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7005 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4538/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6999 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7005 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4539/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6999 - precision: 0.6659 - recall: 0.6887 - val_loss: 0.7005 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4540/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6998 - precision: 0.6659 - recall: 0.6889 - val_loss: 0.7004 - val_precision: 0.6544 - val_recall: 0.6911\n",
      "Epoch 4541/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6998 - precision: 0.6658 - recall: 0.6889 - val_loss: 0.7004 - val_precision: 0.6544 - val_recall: 0.6911\n",
      "Epoch 4542/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6998 - precision: 0.6660 - recall: 0.6890 - val_loss: 0.7004 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4543/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6998 - precision: 0.6660 - recall: 0.6892 - val_loss: 0.7004 - val_precision: 0.6544 - val_recall: 0.6911\n",
      "Epoch 4544/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6998 - precision: 0.6661 - recall: 0.6890 - val_loss: 0.7004 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4545/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6998 - precision: 0.6661 - recall: 0.6892 - val_loss: 0.7004 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4546/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6997 - precision: 0.6660 - recall: 0.6889 - val_loss: 0.7004 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4547/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6997 - precision: 0.6661 - recall: 0.6890 - val_loss: 0.7003 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4548/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6997 - precision: 0.6661 - recall: 0.6892 - val_loss: 0.7003 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4549/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6997 - precision: 0.6661 - recall: 0.6890 - val_loss: 0.7003 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4550/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6997 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7003 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4551/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6997 - precision: 0.6661 - recall: 0.6887 - val_loss: 0.7003 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4552/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6997 - precision: 0.6660 - recall: 0.6889 - val_loss: 0.7003 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4553/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6996 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7003 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4554/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6996 - precision: 0.6660 - recall: 0.6889 - val_loss: 0.7002 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4555/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6996 - precision: 0.6660 - recall: 0.6889 - val_loss: 0.7002 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4556/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6996 - precision: 0.6661 - recall: 0.6890 - val_loss: 0.7002 - val_precision: 0.6544 - val_recall: 0.6911\n",
      "Epoch 4557/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6996 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7002 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4558/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6996 - precision: 0.6661 - recall: 0.6888 - val_loss: 0.7002 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4559/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6995 - precision: 0.6659 - recall: 0.6888 - val_loss: 0.7002 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4560/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6995 - precision: 0.6660 - recall: 0.6887 - val_loss: 0.7002 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4561/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6995 - precision: 0.6659 - recall: 0.6889 - val_loss: 0.7001 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4562/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6995 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7001 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4563/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6995 - precision: 0.6660 - recall: 0.6893 - val_loss: 0.7001 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4564/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6995 - precision: 0.6661 - recall: 0.6888 - val_loss: 0.7001 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4565/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6995 - precision: 0.6660 - recall: 0.6887 - val_loss: 0.7001 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4566/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6994 - precision: 0.6661 - recall: 0.6888 - val_loss: 0.7001 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4567/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6994 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7001 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4568/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6994 - precision: 0.6661 - recall: 0.6888 - val_loss: 0.7000 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4569/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6994 - precision: 0.6661 - recall: 0.6888 - val_loss: 0.7000 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4570/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6994 - precision: 0.6661 - recall: 0.6892 - val_loss: 0.7000 - val_precision: 0.6546 - val_recall: 0.6911\n",
      "Epoch 4571/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6994 - precision: 0.6661 - recall: 0.6888 - val_loss: 0.7000 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4572/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6994 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7000 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4573/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6993 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7000 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4574/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6993 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.7000 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4575/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6993 - precision: 0.6661 - recall: 0.6889 - val_loss: 0.6999 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4576/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6993 - precision: 0.6662 - recall: 0.6889 - val_loss: 0.6999 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4577/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6993 - precision: 0.6662 - recall: 0.6889 - val_loss: 0.6999 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4578/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6993 - precision: 0.6663 - recall: 0.6892 - val_loss: 0.6999 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4579/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6993 - precision: 0.6662 - recall: 0.6889 - val_loss: 0.6999 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4580/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6992 - precision: 0.6662 - recall: 0.6890 - val_loss: 0.6999 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4581/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6992 - precision: 0.6662 - recall: 0.6889 - val_loss: 0.6999 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4582/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6992 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6998 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4583/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6992 - precision: 0.6663 - recall: 0.6892 - val_loss: 0.6998 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4584/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6992 - precision: 0.6662 - recall: 0.6892 - val_loss: 0.6998 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4585/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6992 - precision: 0.6661 - recall: 0.6893 - val_loss: 0.6998 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4586/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6991 - precision: 0.6662 - recall: 0.6893 - val_loss: 0.6998 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4587/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6991 - precision: 0.6661 - recall: 0.6892 - val_loss: 0.6998 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4588/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6991 - precision: 0.6661 - recall: 0.6893 - val_loss: 0.6998 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4589/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6991 - precision: 0.6662 - recall: 0.6893 - val_loss: 0.6997 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4590/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6991 - precision: 0.6662 - recall: 0.6893 - val_loss: 0.6997 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4591/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6991 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6997 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4592/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6991 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6997 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4593/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6990 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6997 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4594/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6990 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6997 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4595/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6990 - precision: 0.6664 - recall: 0.6896 - val_loss: 0.6997 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4596/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6990 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6996 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4597/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6990 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6996 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4598/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6990 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6996 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4599/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6990 - precision: 0.6665 - recall: 0.6897 - val_loss: 0.6996 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4600/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6989 - precision: 0.6665 - recall: 0.6897 - val_loss: 0.6996 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4601/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6989 - precision: 0.6665 - recall: 0.6896 - val_loss: 0.6996 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4602/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6989 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6996 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4603/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6989 - precision: 0.6664 - recall: 0.6892 - val_loss: 0.6995 - val_precision: 0.6554 - val_recall: 0.6911\n",
      "Epoch 4604/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6989 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6995 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4605/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6989 - precision: 0.6665 - recall: 0.6897 - val_loss: 0.6995 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4606/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6989 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6995 - val_precision: 0.6549 - val_recall: 0.6911\n",
      "Epoch 4607/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6988 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6995 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4608/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6988 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6995 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4609/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6988 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6995 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4610/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6988 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6994 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4611/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6988 - precision: 0.6663 - recall: 0.6892 - val_loss: 0.6994 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4612/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6988 - precision: 0.6665 - recall: 0.6893 - val_loss: 0.6994 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4613/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6987 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6994 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4614/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6987 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6994 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4615/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6987 - precision: 0.6665 - recall: 0.6893 - val_loss: 0.6994 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4616/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6987 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6994 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4617/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6987 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6993 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4618/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6987 - precision: 0.6663 - recall: 0.6892 - val_loss: 0.6993 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4619/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6987 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6993 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4620/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6986 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6993 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4621/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6986 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6993 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4622/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6986 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6993 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4623/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6986 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6993 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4624/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6986 - precision: 0.6663 - recall: 0.6892 - val_loss: 0.6992 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4625/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6986 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6992 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4626/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6986 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6992 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4627/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6985 - precision: 0.6662 - recall: 0.6890 - val_loss: 0.6992 - val_precision: 0.6551 - val_recall: 0.6911\n",
      "Epoch 4628/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6985 - precision: 0.6663 - recall: 0.6894 - val_loss: 0.6992 - val_precision: 0.6554 - val_recall: 0.6911\n",
      "Epoch 4629/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6985 - precision: 0.6662 - recall: 0.6893 - val_loss: 0.6992 - val_precision: 0.6554 - val_recall: 0.6911\n",
      "Epoch 4630/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6985 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6992 - val_precision: 0.6554 - val_recall: 0.6911\n",
      "Epoch 4631/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6985 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6991 - val_precision: 0.6554 - val_recall: 0.6911\n",
      "Epoch 4632/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6985 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6991 - val_precision: 0.6554 - val_recall: 0.6911\n",
      "Epoch 4633/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6985 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6991 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4634/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6984 - precision: 0.6663 - recall: 0.6893 - val_loss: 0.6991 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4635/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6984 - precision: 0.6664 - recall: 0.6892 - val_loss: 0.6991 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4636/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6984 - precision: 0.6665 - recall: 0.6893 - val_loss: 0.6991 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4637/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6984 - precision: 0.6664 - recall: 0.6890 - val_loss: 0.6991 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4638/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6984 - precision: 0.6664 - recall: 0.6890 - val_loss: 0.6990 - val_precision: 0.6555 - val_recall: 0.6907\n",
      "Epoch 4639/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6984 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6990 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4640/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6983 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6990 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4641/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6983 - precision: 0.6665 - recall: 0.6893 - val_loss: 0.6990 - val_precision: 0.6555 - val_recall: 0.6907\n",
      "Epoch 4642/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6983 - precision: 0.6664 - recall: 0.6894 - val_loss: 0.6990 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4643/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6983 - precision: 0.6664 - recall: 0.6892 - val_loss: 0.6990 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4644/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6983 - precision: 0.6662 - recall: 0.6894 - val_loss: 0.6990 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4645/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6983 - precision: 0.6666 - recall: 0.6894 - val_loss: 0.6989 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4646/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6983 - precision: 0.6666 - recall: 0.6893 - val_loss: 0.6989 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4647/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6982 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6989 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4648/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6982 - precision: 0.6665 - recall: 0.6893 - val_loss: 0.6989 - val_precision: 0.6556 - val_recall: 0.6911\n",
      "Epoch 4649/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6982 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6989 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4650/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6982 - precision: 0.6664 - recall: 0.6892 - val_loss: 0.6989 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4651/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6982 - precision: 0.6665 - recall: 0.6893 - val_loss: 0.6989 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4652/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6982 - precision: 0.6664 - recall: 0.6893 - val_loss: 0.6988 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4653/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6982 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6988 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4654/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6981 - precision: 0.6666 - recall: 0.6892 - val_loss: 0.6988 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4655/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6981 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6988 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4656/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6981 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6988 - val_precision: 0.6555 - val_recall: 0.6914\n",
      "Epoch 4657/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6981 - precision: 0.6666 - recall: 0.6890 - val_loss: 0.6988 - val_precision: 0.6555 - val_recall: 0.6914\n",
      "Epoch 4658/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6981 - precision: 0.6664 - recall: 0.6892 - val_loss: 0.6987 - val_precision: 0.6555 - val_recall: 0.6914\n",
      "Epoch 4659/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6981 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6987 - val_precision: 0.6555 - val_recall: 0.6914\n",
      "Epoch 4660/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6981 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6987 - val_precision: 0.6555 - val_recall: 0.6914\n",
      "Epoch 4661/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6980 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6987 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4662/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6980 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6987 - val_precision: 0.6557 - val_recall: 0.6914\n",
      "Epoch 4663/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6980 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6987 - val_precision: 0.6560 - val_recall: 0.6914\n",
      "Epoch 4664/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6980 - precision: 0.6666 - recall: 0.6892 - val_loss: 0.6987 - val_precision: 0.6558 - val_recall: 0.6911\n",
      "Epoch 4665/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6980 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6986 - val_precision: 0.6556 - val_recall: 0.6918\n",
      "Epoch 4666/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6980 - precision: 0.6663 - recall: 0.6892 - val_loss: 0.6986 - val_precision: 0.6560 - val_recall: 0.6914\n",
      "Epoch 4667/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6980 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6986 - val_precision: 0.6560 - val_recall: 0.6914\n",
      "Epoch 4668/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6979 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6986 - val_precision: 0.6560 - val_recall: 0.6914\n",
      "Epoch 4669/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6979 - precision: 0.6664 - recall: 0.6889 - val_loss: 0.6986 - val_precision: 0.6560 - val_recall: 0.6914\n",
      "Epoch 4670/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6979 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6986 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4671/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6979 - precision: 0.6664 - recall: 0.6889 - val_loss: 0.6986 - val_precision: 0.6560 - val_recall: 0.6914\n",
      "Epoch 4672/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6979 - precision: 0.6665 - recall: 0.6888 - val_loss: 0.6986 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4673/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6979 - precision: 0.6665 - recall: 0.6888 - val_loss: 0.6986 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4674/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6979 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6985 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4675/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6978 - precision: 0.6666 - recall: 0.6885 - val_loss: 0.6985 - val_precision: 0.6564 - val_recall: 0.6914\n",
      "Epoch 4676/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6978 - precision: 0.6664 - recall: 0.6887 - val_loss: 0.6985 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4677/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6978 - precision: 0.6665 - recall: 0.6888 - val_loss: 0.6985 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4678/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6978 - precision: 0.6665 - recall: 0.6888 - val_loss: 0.6985 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4679/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6978 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6985 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4680/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6978 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6984 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4681/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6978 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6984 - val_precision: 0.6562 - val_recall: 0.6914\n",
      "Epoch 4682/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6977 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6984 - val_precision: 0.6564 - val_recall: 0.6914\n",
      "Epoch 4683/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6977 - precision: 0.6668 - recall: 0.6888 - val_loss: 0.6984 - val_precision: 0.6564 - val_recall: 0.6914\n",
      "Epoch 4684/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6977 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6984 - val_precision: 0.6564 - val_recall: 0.6914\n",
      "Epoch 4685/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6977 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6984 - val_precision: 0.6564 - val_recall: 0.6914\n",
      "Epoch 4686/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6977 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6984 - val_precision: 0.6564 - val_recall: 0.6914\n",
      "Epoch 4687/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6977 - precision: 0.6665 - recall: 0.6889 - val_loss: 0.6983 - val_precision: 0.6564 - val_recall: 0.6914\n",
      "Epoch 4688/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6977 - precision: 0.6667 - recall: 0.6887 - val_loss: 0.6983 - val_precision: 0.6567 - val_recall: 0.6914\n",
      "Epoch 4689/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6976 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6983 - val_precision: 0.6567 - val_recall: 0.6914\n",
      "Epoch 4690/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6976 - precision: 0.6666 - recall: 0.6887 - val_loss: 0.6983 - val_precision: 0.6569 - val_recall: 0.6914\n",
      "Epoch 4691/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6976 - precision: 0.6666 - recall: 0.6887 - val_loss: 0.6983 - val_precision: 0.6572 - val_recall: 0.6914\n",
      "Epoch 4692/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6976 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6983 - val_precision: 0.6572 - val_recall: 0.6914\n",
      "Epoch 4693/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6976 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6983 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4694/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6976 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4695/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6976 - precision: 0.6667 - recall: 0.6887 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4696/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6975 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4697/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6975 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4698/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6975 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4699/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6975 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4700/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6975 - precision: 0.6668 - recall: 0.6888 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4701/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6975 - precision: 0.6667 - recall: 0.6887 - val_loss: 0.6982 - val_precision: 0.6573 - val_recall: 0.6918\n",
      "Epoch 4702/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6975 - precision: 0.6666 - recall: 0.6890 - val_loss: 0.6981 - val_precision: 0.6574 - val_recall: 0.6922\n",
      "Epoch 4703/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6974 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6981 - val_precision: 0.6574 - val_recall: 0.6922\n",
      "Epoch 4704/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6974 - precision: 0.6666 - recall: 0.6889 - val_loss: 0.6981 - val_precision: 0.6574 - val_recall: 0.6922\n",
      "Epoch 4705/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6974 - precision: 0.6666 - recall: 0.6889 - val_loss: 0.6981 - val_precision: 0.6574 - val_recall: 0.6922\n",
      "Epoch 4706/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6974 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6981 - val_precision: 0.6574 - val_recall: 0.6922\n",
      "Epoch 4707/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6974 - precision: 0.6669 - recall: 0.6888 - val_loss: 0.6981 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4708/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6974 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6981 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4709/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6974 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6980 - val_precision: 0.6574 - val_recall: 0.6922\n",
      "Epoch 4710/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6973 - precision: 0.6666 - recall: 0.6890 - val_loss: 0.6980 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4711/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6973 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6980 - val_precision: 0.6578 - val_recall: 0.6926\n",
      "Epoch 4712/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6973 - precision: 0.6665 - recall: 0.6890 - val_loss: 0.6980 - val_precision: 0.6578 - val_recall: 0.6926\n",
      "Epoch 4713/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6973 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6980 - val_precision: 0.6574 - val_recall: 0.6930\n",
      "Epoch 4714/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6973 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6980 - val_precision: 0.6578 - val_recall: 0.6926\n",
      "Epoch 4715/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6973 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6979 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4716/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6973 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6979 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4717/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6972 - precision: 0.6664 - recall: 0.6890 - val_loss: 0.6979 - val_precision: 0.6578 - val_recall: 0.6934\n",
      "Epoch 4718/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6972 - precision: 0.6668 - recall: 0.6888 - val_loss: 0.6979 - val_precision: 0.6576 - val_recall: 0.6926\n",
      "Epoch 4719/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6972 - precision: 0.6666 - recall: 0.6889 - val_loss: 0.6979 - val_precision: 0.6578 - val_recall: 0.6934\n",
      "Epoch 4720/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6972 - precision: 0.6666 - recall: 0.6889 - val_loss: 0.6979 - val_precision: 0.6578 - val_recall: 0.6934\n",
      "Epoch 4721/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6972 - precision: 0.6665 - recall: 0.6888 - val_loss: 0.6979 - val_precision: 0.6578 - val_recall: 0.6934\n",
      "Epoch 4722/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6972 - precision: 0.6665 - recall: 0.6888 - val_loss: 0.6979 - val_precision: 0.6578 - val_recall: 0.6934\n",
      "Epoch 4723/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6972 - precision: 0.6665 - recall: 0.6888 - val_loss: 0.6978 - val_precision: 0.6579 - val_recall: 0.6930\n",
      "Epoch 4724/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6971 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6978 - val_precision: 0.6579 - val_recall: 0.6930\n",
      "Epoch 4725/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6971 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6978 - val_precision: 0.6579 - val_recall: 0.6930\n",
      "Epoch 4726/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6971 - precision: 0.6666 - recall: 0.6888 - val_loss: 0.6978 - val_precision: 0.6579 - val_recall: 0.6930\n",
      "Epoch 4727/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6971 - precision: 0.6668 - recall: 0.6888 - val_loss: 0.6978 - val_precision: 0.6579 - val_recall: 0.6930\n",
      "Epoch 4728/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6971 - precision: 0.6669 - recall: 0.6888 - val_loss: 0.6978 - val_precision: 0.6579 - val_recall: 0.6930\n",
      "Epoch 4729/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6971 - precision: 0.6667 - recall: 0.6888 - val_loss: 0.6978 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4730/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6971 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6977 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4731/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6970 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6977 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4732/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6970 - precision: 0.6667 - recall: 0.6889 - val_loss: 0.6977 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4733/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6970 - precision: 0.6669 - recall: 0.6889 - val_loss: 0.6977 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4734/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6970 - precision: 0.6668 - recall: 0.6889 - val_loss: 0.6977 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4735/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6970 - precision: 0.6669 - recall: 0.6889 - val_loss: 0.6977 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4736/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6970 - precision: 0.6668 - recall: 0.6889 - val_loss: 0.6977 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4737/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6970 - precision: 0.6668 - recall: 0.6889 - val_loss: 0.6976 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4738/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6969 - precision: 0.6669 - recall: 0.6890 - val_loss: 0.6976 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4739/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6969 - precision: 0.6668 - recall: 0.6889 - val_loss: 0.6976 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4740/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6969 - precision: 0.6669 - recall: 0.6890 - val_loss: 0.6976 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4741/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6969 - precision: 0.6670 - recall: 0.6889 - val_loss: 0.6976 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4742/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6969 - precision: 0.6670 - recall: 0.6890 - val_loss: 0.6976 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4743/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6969 - precision: 0.6670 - recall: 0.6890 - val_loss: 0.6976 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4744/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6969 - precision: 0.6670 - recall: 0.6890 - val_loss: 0.6975 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4745/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6968 - precision: 0.6670 - recall: 0.6890 - val_loss: 0.6975 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4746/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6968 - precision: 0.6671 - recall: 0.6889 - val_loss: 0.6975 - val_precision: 0.6578 - val_recall: 0.6926\n",
      "Epoch 4747/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6968 - precision: 0.6671 - recall: 0.6890 - val_loss: 0.6975 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4748/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6968 - precision: 0.6671 - recall: 0.6890 - val_loss: 0.6975 - val_precision: 0.6577 - val_recall: 0.6930\n",
      "Epoch 4749/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6968 - precision: 0.6672 - recall: 0.6890 - val_loss: 0.6975 - val_precision: 0.6578 - val_recall: 0.6926\n",
      "Epoch 4750/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6968 - precision: 0.6672 - recall: 0.6890 - val_loss: 0.6975 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4751/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6968 - precision: 0.6671 - recall: 0.6890 - val_loss: 0.6975 - val_precision: 0.6578 - val_recall: 0.6926\n",
      "Epoch 4752/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6967 - precision: 0.6670 - recall: 0.6890 - val_loss: 0.6974 - val_precision: 0.6578 - val_recall: 0.6926\n",
      "Epoch 4753/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6967 - precision: 0.6671 - recall: 0.6887 - val_loss: 0.6974 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4754/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6967 - precision: 0.6670 - recall: 0.6888 - val_loss: 0.6974 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4755/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6967 - precision: 0.6671 - recall: 0.6888 - val_loss: 0.6974 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4756/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6967 - precision: 0.6670 - recall: 0.6888 - val_loss: 0.6974 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4757/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6967 - precision: 0.6671 - recall: 0.6889 - val_loss: 0.6974 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4758/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6967 - precision: 0.6670 - recall: 0.6890 - val_loss: 0.6974 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4759/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6967 - precision: 0.6670 - recall: 0.6887 - val_loss: 0.6974 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4760/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6966 - precision: 0.6670 - recall: 0.6888 - val_loss: 0.6973 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4761/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6966 - precision: 0.6671 - recall: 0.6889 - val_loss: 0.6973 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4762/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6966 - precision: 0.6670 - recall: 0.6888 - val_loss: 0.6973 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4763/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6966 - precision: 0.6671 - recall: 0.6890 - val_loss: 0.6973 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4764/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6966 - precision: 0.6670 - recall: 0.6890 - val_loss: 0.6973 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4765/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6966 - precision: 0.6671 - recall: 0.6885 - val_loss: 0.6973 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4766/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6966 - precision: 0.6672 - recall: 0.6885 - val_loss: 0.6973 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4767/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6965 - precision: 0.6670 - recall: 0.6888 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4768/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6965 - precision: 0.6671 - recall: 0.6887 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4769/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6965 - precision: 0.6671 - recall: 0.6883 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4770/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6965 - precision: 0.6672 - recall: 0.6884 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4771/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6965 - precision: 0.6673 - recall: 0.6885 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4772/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6965 - precision: 0.6672 - recall: 0.6885 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4773/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6965 - precision: 0.6674 - recall: 0.6885 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4774/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6964 - precision: 0.6674 - recall: 0.6882 - val_loss: 0.6972 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4775/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6964 - precision: 0.6672 - recall: 0.6889 - val_loss: 0.6971 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4776/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6964 - precision: 0.6671 - recall: 0.6887 - val_loss: 0.6971 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4777/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6964 - precision: 0.6673 - recall: 0.6884 - val_loss: 0.6971 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4778/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6964 - precision: 0.6672 - recall: 0.6885 - val_loss: 0.6971 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4779/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6964 - precision: 0.6675 - recall: 0.6884 - val_loss: 0.6971 - val_precision: 0.6575 - val_recall: 0.6918\n",
      "Epoch 4780/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6964 - precision: 0.6674 - recall: 0.6885 - val_loss: 0.6971 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4781/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6963 - precision: 0.6675 - recall: 0.6883 - val_loss: 0.6971 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4782/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6963 - precision: 0.6675 - recall: 0.6883 - val_loss: 0.6970 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4783/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6963 - precision: 0.6675 - recall: 0.6884 - val_loss: 0.6970 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4784/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6963 - precision: 0.6676 - recall: 0.6882 - val_loss: 0.6970 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4785/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6963 - precision: 0.6673 - recall: 0.6887 - val_loss: 0.6970 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4786/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6963 - precision: 0.6675 - recall: 0.6885 - val_loss: 0.6970 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4787/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6963 - precision: 0.6675 - recall: 0.6887 - val_loss: 0.6970 - val_precision: 0.6579 - val_recall: 0.6922\n",
      "Epoch 4788/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6962 - precision: 0.6674 - recall: 0.6888 - val_loss: 0.6970 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4789/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6962 - precision: 0.6675 - recall: 0.6888 - val_loss: 0.6969 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4790/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6962 - precision: 0.6677 - recall: 0.6889 - val_loss: 0.6969 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4791/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6962 - precision: 0.6675 - recall: 0.6890 - val_loss: 0.6969 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4792/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6962 - precision: 0.6674 - recall: 0.6893 - val_loss: 0.6969 - val_precision: 0.6577 - val_recall: 0.6922\n",
      "Epoch 4793/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6962 - precision: 0.6676 - recall: 0.6890 - val_loss: 0.6969 - val_precision: 0.6579 - val_recall: 0.6922\n",
      "Epoch 4794/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6962 - precision: 0.6677 - recall: 0.6889 - val_loss: 0.6969 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4795/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6961 - precision: 0.6676 - recall: 0.6892 - val_loss: 0.6969 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4796/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6961 - precision: 0.6675 - recall: 0.6885 - val_loss: 0.6969 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4797/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6961 - precision: 0.6676 - recall: 0.6888 - val_loss: 0.6968 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4798/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6961 - precision: 0.6675 - recall: 0.6885 - val_loss: 0.6968 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4799/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6961 - precision: 0.6674 - recall: 0.6884 - val_loss: 0.6968 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4800/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6961 - precision: 0.6675 - recall: 0.6887 - val_loss: 0.6968 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4801/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6961 - precision: 0.6675 - recall: 0.6884 - val_loss: 0.6968 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4802/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6961 - precision: 0.6675 - recall: 0.6882 - val_loss: 0.6968 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4803/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6960 - precision: 0.6674 - recall: 0.6883 - val_loss: 0.6968 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4804/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6960 - precision: 0.6675 - recall: 0.6885 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4805/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6960 - precision: 0.6675 - recall: 0.6884 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4806/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6960 - precision: 0.6676 - recall: 0.6888 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4807/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6960 - precision: 0.6675 - recall: 0.6885 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4808/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6960 - precision: 0.6675 - recall: 0.6884 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4809/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6960 - precision: 0.6677 - recall: 0.6892 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4810/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6959 - precision: 0.6676 - recall: 0.6888 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4811/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6959 - precision: 0.6675 - recall: 0.6882 - val_loss: 0.6967 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4812/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6959 - precision: 0.6675 - recall: 0.6883 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4813/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6959 - precision: 0.6675 - recall: 0.6882 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4814/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6959 - precision: 0.6675 - recall: 0.6884 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4815/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6959 - precision: 0.6675 - recall: 0.6882 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4816/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6959 - precision: 0.6675 - recall: 0.6885 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4817/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6958 - precision: 0.6675 - recall: 0.6882 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4818/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6958 - precision: 0.6675 - recall: 0.6883 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4819/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6958 - precision: 0.6674 - recall: 0.6884 - val_loss: 0.6966 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4820/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6958 - precision: 0.6674 - recall: 0.6883 - val_loss: 0.6965 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4821/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6958 - precision: 0.6674 - recall: 0.6884 - val_loss: 0.6965 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4822/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6958 - precision: 0.6674 - recall: 0.6888 - val_loss: 0.6965 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4823/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6958 - precision: 0.6675 - recall: 0.6882 - val_loss: 0.6965 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4824/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6957 - precision: 0.6675 - recall: 0.6883 - val_loss: 0.6965 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4825/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6957 - precision: 0.6674 - recall: 0.6885 - val_loss: 0.6965 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4826/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6957 - precision: 0.6676 - recall: 0.6884 - val_loss: 0.6965 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4827/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6957 - precision: 0.6674 - recall: 0.6888 - val_loss: 0.6964 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4828/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6957 - precision: 0.6673 - recall: 0.6887 - val_loss: 0.6964 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4829/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6957 - precision: 0.6674 - recall: 0.6885 - val_loss: 0.6964 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4830/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6957 - precision: 0.6675 - recall: 0.6885 - val_loss: 0.6964 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4831/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6957 - precision: 0.6675 - recall: 0.6887 - val_loss: 0.6964 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4832/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6956 - precision: 0.6674 - recall: 0.6888 - val_loss: 0.6964 - val_precision: 0.6583 - val_recall: 0.6926\n",
      "Epoch 4833/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6956 - precision: 0.6674 - recall: 0.6885 - val_loss: 0.6964 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4834/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6956 - precision: 0.6674 - recall: 0.6888 - val_loss: 0.6964 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4835/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6956 - precision: 0.6674 - recall: 0.6888 - val_loss: 0.6963 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4836/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6956 - precision: 0.6676 - recall: 0.6888 - val_loss: 0.6963 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4837/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6956 - precision: 0.6676 - recall: 0.6892 - val_loss: 0.6963 - val_precision: 0.6582 - val_recall: 0.6922\n",
      "Epoch 4838/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6956 - precision: 0.6677 - recall: 0.6888 - val_loss: 0.6963 - val_precision: 0.6584 - val_recall: 0.6922\n",
      "Epoch 4839/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6955 - precision: 0.6679 - recall: 0.6887 - val_loss: 0.6963 - val_precision: 0.6584 - val_recall: 0.6922\n",
      "Epoch 4840/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6955 - precision: 0.6678 - recall: 0.6889 - val_loss: 0.6963 - val_precision: 0.6584 - val_recall: 0.6922\n",
      "Epoch 4841/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6955 - precision: 0.6679 - recall: 0.6885 - val_loss: 0.6963 - val_precision: 0.6586 - val_recall: 0.6922\n",
      "Epoch 4842/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6955 - precision: 0.6679 - recall: 0.6888 - val_loss: 0.6963 - val_precision: 0.6586 - val_recall: 0.6922\n",
      "Epoch 4843/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6955 - precision: 0.6678 - recall: 0.6892 - val_loss: 0.6962 - val_precision: 0.6584 - val_recall: 0.6922\n",
      "Epoch 4844/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6955 - precision: 0.6679 - recall: 0.6890 - val_loss: 0.6962 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4845/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6955 - precision: 0.6679 - recall: 0.6888 - val_loss: 0.6962 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4846/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6955 - precision: 0.6679 - recall: 0.6888 - val_loss: 0.6962 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4847/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6954 - precision: 0.6679 - recall: 0.6889 - val_loss: 0.6962 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4848/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6954 - precision: 0.6679 - recall: 0.6888 - val_loss: 0.6962 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4849/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6954 - precision: 0.6679 - recall: 0.6889 - val_loss: 0.6962 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4850/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6954 - precision: 0.6679 - recall: 0.6888 - val_loss: 0.6962 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4851/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6954 - precision: 0.6679 - recall: 0.6888 - val_loss: 0.6961 - val_precision: 0.6589 - val_recall: 0.6922\n",
      "Epoch 4852/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6954 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6961 - val_precision: 0.6590 - val_recall: 0.6926\n",
      "Epoch 4853/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6954 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6961 - val_precision: 0.6590 - val_recall: 0.6926\n",
      "Epoch 4854/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6953 - precision: 0.6680 - recall: 0.6888 - val_loss: 0.6961 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4855/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6953 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6961 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4856/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6953 - precision: 0.6681 - recall: 0.6890 - val_loss: 0.6961 - val_precision: 0.6590 - val_recall: 0.6926\n",
      "Epoch 4857/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6953 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6961 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4858/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6953 - precision: 0.6681 - recall: 0.6890 - val_loss: 0.6960 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4859/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6953 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6960 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4860/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6953 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6960 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4861/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6952 - precision: 0.6681 - recall: 0.6890 - val_loss: 0.6960 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4862/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6952 - precision: 0.6681 - recall: 0.6890 - val_loss: 0.6960 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4863/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6952 - precision: 0.6681 - recall: 0.6890 - val_loss: 0.6960 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4864/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6952 - precision: 0.6681 - recall: 0.6890 - val_loss: 0.6960 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4865/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6952 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6959 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4866/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6952 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6959 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4867/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6952 - precision: 0.6679 - recall: 0.6888 - val_loss: 0.6959 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4868/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6952 - precision: 0.6681 - recall: 0.6892 - val_loss: 0.6959 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4869/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6951 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6959 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4870/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6951 - precision: 0.6680 - recall: 0.6890 - val_loss: 0.6959 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4871/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6951 - precision: 0.6683 - recall: 0.6888 - val_loss: 0.6959 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4872/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6951 - precision: 0.6684 - recall: 0.6888 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4873/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6951 - precision: 0.6683 - recall: 0.6888 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4874/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6951 - precision: 0.6684 - recall: 0.6889 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4875/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6951 - precision: 0.6683 - recall: 0.6889 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4876/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6950 - precision: 0.6683 - recall: 0.6889 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4877/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6950 - precision: 0.6684 - recall: 0.6890 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4878/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6950 - precision: 0.6684 - recall: 0.6889 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4879/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6950 - precision: 0.6682 - recall: 0.6887 - val_loss: 0.6958 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4880/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6950 - precision: 0.6683 - recall: 0.6889 - val_loss: 0.6957 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4881/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6950 - precision: 0.6683 - recall: 0.6889 - val_loss: 0.6957 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4882/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6950 - precision: 0.6683 - recall: 0.6889 - val_loss: 0.6957 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4883/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6950 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6957 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4884/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6949 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6957 - val_precision: 0.6593 - val_recall: 0.6926\n",
      "Epoch 4885/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6949 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6957 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4886/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6949 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6957 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4887/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6949 - precision: 0.6681 - recall: 0.6889 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4888/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6949 - precision: 0.6681 - recall: 0.6889 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4889/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6949 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4890/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6949 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4891/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6948 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4892/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6948 - precision: 0.6681 - recall: 0.6889 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4893/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6948 - precision: 0.6683 - recall: 0.6889 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4894/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6948 - precision: 0.6681 - recall: 0.6889 - val_loss: 0.6956 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4895/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6948 - precision: 0.6681 - recall: 0.6890 - val_loss: 0.6955 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4896/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6948 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6955 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4897/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6948 - precision: 0.6683 - recall: 0.6888 - val_loss: 0.6955 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4898/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6948 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6955 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4899/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6947 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6955 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4900/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6947 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6955 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4901/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6947 - precision: 0.6681 - recall: 0.6888 - val_loss: 0.6955 - val_precision: 0.6591 - val_recall: 0.6922\n",
      "Epoch 4902/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6947 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6955 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4903/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6947 - precision: 0.6681 - recall: 0.6887 - val_loss: 0.6954 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4904/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6947 - precision: 0.6683 - recall: 0.6888 - val_loss: 0.6954 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4905/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6947 - precision: 0.6683 - recall: 0.6888 - val_loss: 0.6954 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4906/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6946 - precision: 0.6683 - recall: 0.6889 - val_loss: 0.6954 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4907/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6946 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6954 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4908/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6946 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6954 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4909/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6946 - precision: 0.6682 - recall: 0.6888 - val_loss: 0.6954 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4910/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6946 - precision: 0.6683 - recall: 0.6893 - val_loss: 0.6953 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4911/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6946 - precision: 0.6683 - recall: 0.6890 - val_loss: 0.6953 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4912/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6946 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6953 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4913/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6946 - precision: 0.6682 - recall: 0.6892 - val_loss: 0.6953 - val_precision: 0.6588 - val_recall: 0.6918\n",
      "Epoch 4914/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6945 - precision: 0.6683 - recall: 0.6890 - val_loss: 0.6953 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4915/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6945 - precision: 0.6682 - recall: 0.6889 - val_loss: 0.6953 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4916/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6945 - precision: 0.6683 - recall: 0.6890 - val_loss: 0.6953 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4917/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6945 - precision: 0.6684 - recall: 0.6890 - val_loss: 0.6953 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4918/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6945 - precision: 0.6683 - recall: 0.6890 - val_loss: 0.6953 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4919/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6945 - precision: 0.6683 - recall: 0.6890 - val_loss: 0.6952 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4920/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6945 - precision: 0.6683 - recall: 0.6892 - val_loss: 0.6952 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4921/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6945 - precision: 0.6684 - recall: 0.6893 - val_loss: 0.6952 - val_precision: 0.6588 - val_recall: 0.6918\n",
      "Epoch 4922/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6944 - precision: 0.6683 - recall: 0.6890 - val_loss: 0.6952 - val_precision: 0.6588 - val_recall: 0.6918\n",
      "Epoch 4923/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6944 - precision: 0.6683 - recall: 0.6892 - val_loss: 0.6952 - val_precision: 0.6588 - val_recall: 0.6918\n",
      "Epoch 4924/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6944 - precision: 0.6683 - recall: 0.6892 - val_loss: 0.6952 - val_precision: 0.6586 - val_recall: 0.6914\n",
      "Epoch 4925/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6944 - precision: 0.6683 - recall: 0.6892 - val_loss: 0.6951 - val_precision: 0.6588 - val_recall: 0.6918\n",
      "Epoch 4926/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6944 - precision: 0.6685 - recall: 0.6894 - val_loss: 0.6951 - val_precision: 0.6586 - val_recall: 0.6914\n",
      "Epoch 4927/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6944 - precision: 0.6684 - recall: 0.6896 - val_loss: 0.6951 - val_precision: 0.6586 - val_recall: 0.6914\n",
      "Epoch 4928/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6944 - precision: 0.6684 - recall: 0.6896 - val_loss: 0.6951 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4929/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6943 - precision: 0.6685 - recall: 0.6894 - val_loss: 0.6951 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4930/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6943 - precision: 0.6684 - recall: 0.6893 - val_loss: 0.6951 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4931/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6943 - precision: 0.6685 - recall: 0.6894 - val_loss: 0.6951 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4932/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6943 - precision: 0.6685 - recall: 0.6894 - val_loss: 0.6951 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4933/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6943 - precision: 0.6685 - recall: 0.6893 - val_loss: 0.6951 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4934/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6943 - precision: 0.6685 - recall: 0.6893 - val_loss: 0.6950 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4935/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6943 - precision: 0.6686 - recall: 0.6892 - val_loss: 0.6950 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4936/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6943 - precision: 0.6684 - recall: 0.6896 - val_loss: 0.6950 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4937/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6942 - precision: 0.6685 - recall: 0.6894 - val_loss: 0.6950 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4938/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6942 - precision: 0.6684 - recall: 0.6893 - val_loss: 0.6950 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4939/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6942 - precision: 0.6685 - recall: 0.6894 - val_loss: 0.6950 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4940/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6942 - precision: 0.6684 - recall: 0.6893 - val_loss: 0.6950 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4941/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6942 - precision: 0.6686 - recall: 0.6896 - val_loss: 0.6949 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4942/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6942 - precision: 0.6685 - recall: 0.6897 - val_loss: 0.6949 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4943/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6942 - precision: 0.6686 - recall: 0.6894 - val_loss: 0.6949 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4944/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6942 - precision: 0.6686 - recall: 0.6896 - val_loss: 0.6949 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4945/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6941 - precision: 0.6685 - recall: 0.6898 - val_loss: 0.6949 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4946/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6941 - precision: 0.6684 - recall: 0.6896 - val_loss: 0.6949 - val_precision: 0.6583 - val_recall: 0.6911\n",
      "Epoch 4947/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6941 - precision: 0.6685 - recall: 0.6898 - val_loss: 0.6949 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4948/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6941 - precision: 0.6685 - recall: 0.6898 - val_loss: 0.6949 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4949/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6941 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6948 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4950/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6941 - precision: 0.6686 - recall: 0.6894 - val_loss: 0.6948 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4951/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6941 - precision: 0.6685 - recall: 0.6896 - val_loss: 0.6948 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4952/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6941 - precision: 0.6684 - recall: 0.6894 - val_loss: 0.6948 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4953/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6940 - precision: 0.6684 - recall: 0.6898 - val_loss: 0.6948 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4954/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6940 - precision: 0.6683 - recall: 0.6894 - val_loss: 0.6948 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4955/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6940 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6948 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4956/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6940 - precision: 0.6685 - recall: 0.6899 - val_loss: 0.6947 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4957/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6940 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6947 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4958/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6940 - precision: 0.6685 - recall: 0.6896 - val_loss: 0.6947 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4959/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6940 - precision: 0.6685 - recall: 0.6898 - val_loss: 0.6947 - val_precision: 0.6583 - val_recall: 0.6911\n",
      "Epoch 4960/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6896 - val_loss: 0.6947 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4961/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6947 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4962/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6899 - val_loss: 0.6947 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4963/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6898 - val_loss: 0.6947 - val_precision: 0.6583 - val_recall: 0.6911\n",
      "Epoch 4964/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6899 - val_loss: 0.6947 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4965/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6899 - val_loss: 0.6946 - val_precision: 0.6584 - val_recall: 0.6914\n",
      "Epoch 4966/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6946 - val_precision: 0.6586 - val_recall: 0.6914\n",
      "Epoch 4967/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6939 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6946 - val_precision: 0.6586 - val_recall: 0.6914\n",
      "Epoch 4968/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6938 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6946 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4969/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6938 - precision: 0.6685 - recall: 0.6898 - val_loss: 0.6946 - val_precision: 0.6588 - val_recall: 0.6918\n",
      "Epoch 4970/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6938 - precision: 0.6687 - recall: 0.6897 - val_loss: 0.6946 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4971/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6938 - precision: 0.6687 - recall: 0.6897 - val_loss: 0.6946 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4972/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6938 - precision: 0.6687 - recall: 0.6897 - val_loss: 0.6946 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4973/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6938 - precision: 0.6685 - recall: 0.6897 - val_loss: 0.6945 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4974/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6938 - precision: 0.6687 - recall: 0.6897 - val_loss: 0.6945 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4975/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6938 - precision: 0.6686 - recall: 0.6898 - val_loss: 0.6945 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4976/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6937 - precision: 0.6684 - recall: 0.6903 - val_loss: 0.6945 - val_precision: 0.6586 - val_recall: 0.6914\n",
      "Epoch 4977/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6937 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6945 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4978/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6937 - precision: 0.6687 - recall: 0.6896 - val_loss: 0.6945 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4979/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6937 - precision: 0.6688 - recall: 0.6896 - val_loss: 0.6945 - val_precision: 0.6585 - val_recall: 0.6911\n",
      "Epoch 4980/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6937 - precision: 0.6688 - recall: 0.6896 - val_loss: 0.6945 - val_precision: 0.6586 - val_recall: 0.6914\n",
      "Epoch 4981/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6937 - precision: 0.6687 - recall: 0.6896 - val_loss: 0.6945 - val_precision: 0.6588 - val_recall: 0.6911\n",
      "Epoch 4982/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6937 - precision: 0.6687 - recall: 0.6894 - val_loss: 0.6944 - val_precision: 0.6588 - val_recall: 0.6911\n",
      "Epoch 4983/5000\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6937 - precision: 0.6687 - recall: 0.6894 - val_loss: 0.6944 - val_precision: 0.6588 - val_recall: 0.6911\n",
      "Epoch 4984/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6936 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6944 - val_precision: 0.6588 - val_recall: 0.6911\n",
      "Epoch 4985/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6936 - precision: 0.6687 - recall: 0.6892 - val_loss: 0.6944 - val_precision: 0.6588 - val_recall: 0.6911\n",
      "Epoch 4986/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6936 - precision: 0.6687 - recall: 0.6897 - val_loss: 0.6944 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4987/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6936 - precision: 0.6687 - recall: 0.6896 - val_loss: 0.6944 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4988/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6936 - precision: 0.6686 - recall: 0.6893 - val_loss: 0.6944 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4989/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6936 - precision: 0.6687 - recall: 0.6892 - val_loss: 0.6944 - val_precision: 0.6588 - val_recall: 0.6911\n",
      "Epoch 4990/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6936 - precision: 0.6688 - recall: 0.6896 - val_loss: 0.6943 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4991/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6936 - precision: 0.6686 - recall: 0.6896 - val_loss: 0.6943 - val_precision: 0.6589 - val_recall: 0.6914\n",
      "Epoch 4992/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6935 - precision: 0.6686 - recall: 0.6896 - val_loss: 0.6943 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4993/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6935 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6943 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4994/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6935 - precision: 0.6685 - recall: 0.6893 - val_loss: 0.6943 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4995/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6935 - precision: 0.6685 - recall: 0.6896 - val_loss: 0.6943 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4996/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6935 - precision: 0.6686 - recall: 0.6894 - val_loss: 0.6943 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4997/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6935 - precision: 0.6686 - recall: 0.6897 - val_loss: 0.6943 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4998/5000\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.6935 - precision: 0.6685 - recall: 0.6897 - val_loss: 0.6942 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 4999/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6935 - precision: 0.6687 - recall: 0.6896 - val_loss: 0.6942 - val_precision: 0.6590 - val_recall: 0.6918\n",
      "Epoch 5000/5000\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.6934 - precision: 0.6685 - recall: 0.6898 - val_loss: 0.6942 - val_precision: 0.6590 - val_recall: 0.6918\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Set the weight initializer function\n",
    "initializer=GlorotUniform(seed=315)\n",
    "\n",
    "# Set-up the L1L2 for the dense layers\n",
    "regularizer=L1L2(l1=l1, l2=l2)\n",
    "\n",
    "# Define the model layers in order\n",
    "nn_model=Sequential([\n",
    "    Dense(128, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(256, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(256, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(256, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(128, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(64, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(32, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(16, kernel_regularizer=regularizer, activation='relu', kernel_initializer=initializer),\n",
    "    Dense(1, activation='sigmoid', kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "nn_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    metrics=[Precision(name='precision'), Recall(name='recall')]\n",
    ")\n",
    "\n",
    "# Calculate class weighting\n",
    "pos_examples=sum(training_labels_df['efs'])\n",
    "neg_examples=len(training_labels_df['efs']) - pos_examples\n",
    "neg_class_weight=(1 / neg_examples) * (len(training_labels_df['efs']) / 2.0)\n",
    "pos_class_weight=(1 / pos_examples) * (len(training_labels_df['efs']) / 2.0)\n",
    "\n",
    "# Do the training run\n",
    "training_results=nn_model.fit(\n",
    "    training_features_df,\n",
    "    training_labels_df['efs'],\n",
    "    batch_size=256,\n",
    "    validation_split=0.25,\n",
    "    epochs=5000,\n",
    "    # steps_per_epoch=steps_per_epoch,\n",
    "    # validation_steps=validation_steps,\n",
    "    verbose=True,\n",
    "    class_weight={0: neg_class_weight, 1: pos_class_weight}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKMAAAErCAYAAAACIUADAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAvBtJREFUeJzs3XdYU9cbwPFv2BtcIOIA9144fmoVN26p1m1d1Vr3qHXUuq2jVotV62irqNW6tbauOmsdde86wD1xAgKykvv7IyUawwoCAXk/z8MjOffce9+ENjd57znvUSmKoiCEEEIIIYQQQgghRAYwM3UAQgghhBBCCCGEECL7kGSUEEIIIYQQQgghhMgwkowSQgghhBBCCCGEEBlGklFCCCGEEEIIIYQQIsNIMkoIIYQQQgghhBBCZBhJRgkhhBBCCCGEEEKIDCPJKCGEEEIIIYQQQgiRYSQZJYQQQgghhBBCCCEyjCSjhBBCCCGEEEIIIUSGkWSUEEII8Z7y9PSkR48eJjt/jx498PT01GsLDw+nd+/e5M2bF5VKxdChQ7l16xYqlYqAgACTxJmWEnrOKTVx4kRUKlXaBiSEEEIIkQlJMkoIIYTIYq5fv07fvn0pXLgwNjY2ODk5UatWLebOncurV69MHV6Spk2bRkBAAP369WPlypV8/PHHGXr+Bw8eMHHiRM6ePZuh5xVCCCGEEK+pFEVRTB2EEEIIIVJm27ZttGvXDmtra7p160bZsmWJiYnh0KFDbNy4kR49erBkyRJAOzKqbt26JhtxFBsbi0ajwdraWtf2v//9DwsLCw4dOqRrUxSF6OhoLC0tMTc3T9eYTp48SdWqVVm2bFm6jBpL6DmnVFxcHHFxcdjY2KR5XEIIIYQQmYmFqQMQQgghRMrcvHmTjh07UqhQIfbt24e7u7tu24ABAwgKCmLbtm0mjFCfpaWlQdvjx48pXbq0XptKpUrTBExERAT29vZpcqzIyEjs7OxS3D+h55xSFhYWWFi8nx/N4uLi0Gg0WFlZmToUIYQQQmQCMk1PCCGEyCK++eYbwsPD+fnnn/USUfGKFi3KkCFDEt3/+fPnjBgxgnLlyuHg4ICTkxNNmzbl3LlzBn3nzZtHmTJlsLOzI0eOHFSpUoXVq1frtr98+ZKhQ4fi6emJtbU1rq6uNGrUiNOnT+v6vFk/6cCBA6hUKm7evMm2bdtQqVSoVCpu3bqVaM2oK1eu8NFHH5EzZ05sbGyoUqUKW7du1esTEBCASqXir7/+on///ri6upI/f/4En/+BAweoWrUqAD179tTFEH/eunXrUrZsWU6dOkWdOnWws7Pjyy+/BOC3336jefPm5MuXD2tra4oUKcKUKVNQq9V653i7ZlT8c/v2229ZsmQJRYoUwdramqpVq3LixAm9fROqGaVSqRg4cCBbtmyhbNmyWFtbU6ZMGXbu3Jng86tSpQo2NjYUKVKExYsXG1WH6tixYzRr1owcOXJgb29P+fLlmTt3rm573bp1qVu3rsF+ST1nf39/3XM+c+YMFhYWTJo0yeAYV69eRaVSMX/+fF1bSEgIQ4cOpUCBAlhbW1O0aFFmzpyJRqPR23fNmjV4e3vj6OiIk5MT5cqV04tbCCGEEJnP+3n7TQghhHgP/f777xQuXJiaNWumav8bN26wZcsW2rVrh5eXF8HBwSxevBgfHx/+/fdf8uXLB8CPP/7I4MGD+eijjxgyZAhRUVGcP3+eY8eO0blzZwA+++wzNmzYwMCBAyldujTPnj3j0KFDXL58mcqVKxucu1SpUqxcuZJhw4aRP39+Pv/8cwDy5MnDkydPDPpfunSJWrVq4eHhwejRo7G3t2fdunX4+fmxceNGPvzwQ73+/fv3J0+ePIwfP56IiIgEn3+pUqWYPHky48eP59NPP6V27doAeq/ns2fPaNq0KR07dqRr1664ubkB2qSXg4MDw4cPx8HBgX379jF+/HjCwsKYNWtWsq/96tWrefnyJX379kWlUvHNN9/Qpk0bbty4kexoqkOHDrFp0yb69++Po6Mj33//PW3btuXOnTvkypULgDNnztCkSRPc3d2ZNGkSarWayZMnkydPnmRjA9i9ezctWrTA3d2dIUOGkDdvXi5fvswff/yRZIIzKcuWLSMqKopPP/0Ua2tr3N3d8fHxYd26dUyYMEGv79q1azE3N6ddu3aAdkSaj48P9+/fp2/fvhQsWJAjR44wZswYHj58iL+/vy7uTp060aBBA2bOnAnA5cuXOXz4cKrjFkIIIUQGUIQQQgiR6YWGhiqA0rp16xTvU6hQIaV79+66x1FRUYpardbrc/PmTcXa2lqZPHmyrq1169ZKmTJlkjy2s7OzMmDAgCT7dO/eXSlUqJBBTM2bNzeIAVCWLVuma2vQoIFSrlw5JSoqStem0WiUmjVrKsWKFdO1LVu2TAGUDz74QImLi0syHkVRlBMnThicK56Pj48CKIsWLTLYFhkZadDWt29fxc7OTi/Gt59z/HPLlSuX8vz5c137b7/9pgDK77//rmubMGGC8vZHM0CxsrJSgoKCdG3nzp1TAGXevHm6tpYtWyp2dnbK/fv3dW2BgYGKhYWFwTHfFhcXp3h5eSmFChVSXrx4obdNo9Hofvfx8VF8fHwM9k/sOTs5OSmPHz/W67t48WIFUC5cuKDXXrp0aaV+/fq6x1OmTFHs7e2Va9eu6fUbPXq0Ym5urty5c0dRFEUZMmSI4uTklKK/vRBCCCEyD5mmJ4QQQmQBYWFhADg6Oqb6GNbW1piZaS/9arWaZ8+e4eDgQIkSJfSm17m4uHDv3j2DaWRvcnFx4dixYzx48CDV8STm+fPn7Nu3j/bt2/Py5UuePn3K06dPefbsGb6+vgQGBnL//n29ffr06ZMmxc+tra3p2bOnQbutra3u9/iYateuTWRkJFeuXEn2uB06dCBHjhy6x/Gjsm7cuJHsvg0bNqRIkSK6x+XLl8fJyUm3r1qtZs+ePfj5+elGt4F22mbTpk2TPf6ZM2e4efMmQ4cOxcXFRW9bSqf4JaRt27YGI7PatGmDhYUFa9eu1bVdvHiRf//9lw4dOuja1q9fT+3atcmRI4fu7//06VMaNmyIWq3m4MGDgPa/w4iICHbv3p3qOIUQQgiR8SQZJYQQQmQBTk5OgDYRkloajYbvvvuOYsWKYW1tTe7cucmTJw/nz58nNDRU12/UqFE4ODhQrVo1ihUrxoABAzh8+LDesb755hsuXrxIgQIFqFatGhMnTkxRYiUlgoKCUBSFcePGkSdPHr2f+Oldjx8/1tvHy8srTc7t4eGRYJHtS5cu8eGHH+Ls7IyTkxN58uSha9euAHqvXWIKFiyo9zg+MfXixQuj943fP37fx48f8+rVK4oWLWrQL6G2t12/fh2AsmXLJtvXGAn9TXLnzk2DBg1Yt26drm3t2rVYWFjQpk0bXVtgYCA7d+40+Ps3bNgQeP3379+/P8WLF6dp06bkz5+fXr16JVhPSwghhBCZi9SMEkIIIbIAJycn8uXLx8WLF1N9jGnTpjFu3Dh69erFlClTyJkzJ2ZmZgwdOlSvKHSpUqW4evUqf/zxBzt37mTjxo388MMPjB8/Xld8un379tSuXZvNmzfz559/MmvWLGbOnMmmTZtSNBonKfGxjBgxAl9f3wT7vJ1keXPk0rtI6DghISH4+Pjg5OTE5MmTKVKkCDY2Npw+fZpRo0YZFNROSGKjthRFSdd905JKpUrwnG8XcY+X2N+kY8eO9OzZk7Nnz1KxYkXWrVtHgwYNyJ07t66PRqOhUaNGjBw5MsFjFC9eHABXV1fOnj3Lrl272LFjBzt27GDZsmV069aN5cuXG/sUhRBCCJFBJBklhBBCZBEtWrRgyZIlHD16lBo1ahi9/4YNG6hXrx4///yzXntISIheIgDA3t6eDh060KFDB2JiYmjTpg1ff/01Y8aMwcbGBgB3d3f69+9P//79efz4MZUrV+brr79+52RU4cKFAbC0tNSNhEkrqZl2duDAAZ49e8amTZuoU6eOrv3mzZtpGVqqubq6YmNjQ1BQkMG2hNreFj8F8OLFi0m+3jly5Ehw9Nvt27eNiBb8/Pzo27evbqretWvXGDNmjEFM4eHhKfr7W1lZ0bJlS1q2bIlGo6F///4sXryYcePGpWhkmBBCCCEynkzTE0IIIbKIkSNHYm9vT+/evQkODjbYfv369SSXtDc3NzcY2bJ+/XqD+kvPnj3Te2xlZUXp0qVRFIXY2FjUarXB1DRXV1fy5ctHdHS0sU/LgKurK3Xr1mXx4sU8fPjQYHtCq++llL29PaBNwKVU/MikN1+7mJgYfvjhh1THkZbMzc1p2LAhW7Zs0avhFRQUxI4dO5Ldv3Llynh5eeHv72/wurz5nIsUKcKVK1f0Xv9z584ZTOFMjouLC76+vqxbt441a9ZgZWWFn5+fXp/27dtz9OhRdu3aZbB/SEgIcXFxgOF/q2ZmZpQvXx4gTf5bFEIIIUT6kJFRQgghRBZRpEgRVq9eTYcOHShVqhTdunWjbNmyxMTEcOTIEdavX0+PHj0S3b9FixZMnjyZnj17UrNmTS5cuMCqVat0I5HiNW7cmLx581KrVi3c3Ny4fPky8+fPp3nz5jg6OhISEkL+/Pn56KOPqFChAg4ODuzZs4cTJ04we/bsNHmuCxYs4IMPPqBcuXL06dOHwoULExwczNGjR7l37x7nzp1L1XGLFCmCi4sLixYtwtHREXt7e6pXr55kzamaNWuSI0cOunfvzuDBg1GpVKxcuTLDp8klZeLEifz555/UqlWLfv36oVarmT9/PmXLluXs2bNJ7mtmZsbChQtp2bIlFStWpGfPnri7u3PlyhUuXbqkSwj16tWLOXPm4OvryyeffMLjx49ZtGgRZcqU0RXYT6kOHTrQtWtXfvjhB3x9fQ0Kp3/xxRds3bqVFi1a0KNHD7y9vYmIiODChQts2LCBW7dukTt3bnr37s3z58+pX78++fPn5/bt28ybN4+KFStSqlQpo2ISQgghRMaRZJQQQgiRhbRq1Yrz588za9YsfvvtNxYuXIi1tTXly5dn9uzZ9OnTJ9F9v/zySyIiIli9ejVr166lcuXKbNu2jdGjR+v169u3L6tWrWLOnDmEh4eTP39+Bg8ezFdffQWAnZ0d/fv3588//2TTpk1oNBqKFi3KDz/8QL9+/dLkeZYuXZqTJ08yadIkAgICePbsGa6urlSqVInx48en+riWlpYsX76cMWPG8NlnnxEXF8eyZcuSTEblypWLP/74g88//5yvvvqKHDly0LVrVxo0aJBoTauM5u3tzY4dOxgxYgTjxo2jQIECTJ48mcuXL6dotT9fX1/279/PpEmTmD17NhqNhiJFiuj991SqVClWrFjB+PHjGT58OKVLl2blypWsXr2aAwcOGBVvq1atsLW15eXLl3qr6MWzs7Pjr7/+Ytq0aaxfv54VK1bg5ORE8eLFmTRpEs7OzgB07dqVJUuW8MMPPxASEkLevHnp0KEDEydO1K0cKYQQQojMR6Vkptt6QgghhBAizfj5+XHp0iUCAwNNHYoQQgghhI7cMhJCCCGEeA+8evVK73FgYCDbt2+nbt26pglICCGEECIRMjJKCCGEEOI94O7uTo8ePShcuDC3b99m4cKFREdHc+bMGYoVK2bq8IQQQgghdKRmlBBCCCHEe6BJkyb8+uuvPHr0CGtra2rUqMG0adMkESWEEEKITEdGRgkhhBBCCCGEEEKIDCM1o4QQQgghhBBCCCFEhpFklBBCCCGEEEIIIYTIMJKMEkIIIYQQQgghhBAZRpJRQgghhBBCCCGEECLDSDJKCCGEEEIIIYQQQmQYSUYJIYQQQgghhBBCiAwjySghhBBCCCGEEEIIkWEkGSWEEEIIIYQQQgghMowko4QQQgghhBBCCCFEhpFklBBCCCGEEEIIIYTIMJKMEkIIIYQQQgghhBAZRpJRQgghhBBCCCGEECLDSDJKCCGEEEIIIYQQQmQYSUYJIYQQQgghhBBCiAwjySghhBBCCCGEEEIIkWEkGSWEEEIIIYQQQgghMowko4QQQgghhBBCCCFEhpFklBBCCCGEEEIIIYTIMJKMEkIIIYQQQgghhBAZRpJRQgghhBBCCCGEECLDSDJKCCGEEEIIIYQQQmQYSUYJIYQQQgghhBBCiAwjySghhBBCCCGEEEIIkWEkGSVSTaVSMXHiRFOHIYQQQrxXevTogaenp1H7HDhwAJVKxYEDB9IlJiGEENnD29/xAgICUKlU3Lp1y2QxifeTJKOETvwbzZs/rq6u1KtXjx07dpg6PJEBpk2bxpYtW0wdhhBCZLi3r4E2NjYUL16cgQMHEhwcbOrwhBBCvCfevt5YWFjg4eFBjx49uH//vqnDEyLDWJg6AJH5TJ48GS8vLxRFITg4mICAAJo1a8bvv/9OixYtdP1evXqFhYX8J/Q+mTZtGh999BF+fn6mDkUIIUwi/hoYFRXFoUOHWLhwIdu3b+fixYvY2dllSAw//vgjGo3GqH3q1KnDq1evsLKySqeohBBCpKU3rzf//PMPAQEBHDp0iIsXL2JjY2Pq8IRId5JJEAaaNm1KlSpVdI8/+eQT3Nzc+PXXX/WSUaZ4k1QUhaioKGxtbTP83ACRkZEZ9mUks4uIiMDe3t7UYQghRJp68xrYu3dvcuXKxZw5c/jtt9/o1KmTQf/0eC+0tLQ0eh8zMzP58iKEEFnI29eb3LlzM3PmTLZu3Ur79u1NHJ0Q6U+m6Ylkubi4YGtrazAK6u35xBMnTkSlUhEUFESPHj1wcXHB2dmZnj17EhkZqbfvsmXLqF+/Pq6urlhbW1O6dGkWLlxocG5PT09atGjBrl27qFKlCra2tixevBgfHx8qVKiQYLwlSpTA19c32ee1Y8cOfHx8cHR0xMnJiapVq7J69Wrd9rp161K2bFlOnTpFnTp1sLOz48svvwTg8ePHuiSdjY0NFSpUYPny5QbnWLNmDd7e3rpzlCtXjrlz5+q2x8bGMmnSJIoVK4aNjQ25cuXigw8+YPfu3cnGD3Ds2DGaNGmCs7MzdnZ2+Pj4cPjwYb0+Kf27qFQqIiIiWL58uW7YcI8ePfSO8e+//9K5c2dy5MjBBx98AEBcXBxTpkyhSJEiWFtb4+npyZdffkl0dLReHPF/yz///JOKFStiY2ND6dKl2bRpk67PjRs3UKlUfPfddwbP9ciRI6hUKn799dcUvTZCCJEW6tevD8DNmzfp0aMHDg4OXL9+nWbNmuHo6EiXLl0A0Gg0+Pv7U6ZMGWxsbHBzc6Nv3768ePHC4JjJXX8SqhmV3PUksZpR69evx9vbG1tbW3Lnzk3Xrl0NpoHEP6/79+/j5+eHg4MDefLkYcSIEajV6nd5+YQQQqRQ7dq1Abh+/bqu7cqVK3z00UfkzJkTGxsbqlSpwtatWw32DQkJYdiwYXh6emJtbU3+/Pnp1q0bT58+BSAmJobx48fj7e2Ns7Mz9vb21K5dm/3792fMkxMiAZKMEgZCQ0N5+vQpT5484dKlS/Tr14/w8HC6du2aov3bt2/Py5cvmT59Ou3btycgIIBJkybp9Vm4cCGFChXiyy+/ZPbs2RQoUID+/fuzYMECg+NdvXqVTp060ahRI+bOnUvFihX5+OOPOX/+PBcvXtTre+LECa5du5ZsrAEBATRv3pznz58zZswYZsyYQcWKFdm5c6dev2fPntG0aVMqVqyIv78/9erV49WrV9StW5eVK1fSpUsXZs2ahbOzMz169ND7YrB79246depEjhw5mDlzJjNmzKBu3bp6yaKJEycyadIk6tWrx/z58xk7diwFCxbk9OnTyb7O+/bto06dOoSFhTFhwgSmTZtGSEgI9evX5/jx4wb9k/u7rFy5Emtra2rXrs3KlStZuXIlffv21TtGu3btiIyMZNq0afTp0wfQ3skZP348lStX5rvvvsPHx4fp06fTsWNHgxgCAwPp0KEDTZs2Zfr06VhYWNCuXTtd8q1w4cLUqlWLVatWGey7atUqHB0dad26dbKvjRBCpJX4LwW5cuUCtAl4X19fXF1d+fbbb2nbti0Affv25YsvvqBWrVrMnTuXnj17smrVKnx9fYmNjdUdL6XXnzel5HqSkICAANq3b4+5uTnTp0+nT58+bNq0iQ8++ICQkBC9vmq1Gl9fX3LlysW3336Lj48Ps2fPZsmSJal52YQQQhgpvkB4jhw5ALh06RL/+9//uHz5MqNHj2b27NnY29vj5+fH5s2bdfuFh4dTu3Zt5s2bR+PGjZk7dy6fffYZV65c4d69ewCEhYXx008/UbduXWbOnMnEiRN58uQJvr6+nD17NqOfqhBaihD/WbZsmQIY/FhbWysBAQEG/QFlwoQJuscTJkxQAKVXr156/T788EMlV65cem2RkZEGx/P19VUKFy6s11aoUCEFUHbu3KnXHhISotjY2CijRo3Sax88eLBib2+vhIeHJ/o8Q0JCFEdHR6V69erKq1ev9LZpNBrd7z4+PgqgLFq0SK+Pv7+/Aii//PKLri0mJkapUaOG4uDgoISFhSmKoihDhgxRnJyclLi4uERjqVChgtK8efNEtydGo9EoxYoVU3x9ffVijoyMVLy8vJRGjRrp2oz5u9jb2yvdu3c3OF/8MTp16qTXfvbsWQVQevfurdc+YsQIBVD27duna4v/W27cuFHXFhoaqri7uyuVKlXStS1evFgBlMuXL+vaYmJilNy5cycYmxBCpIX4a+CePXuUJ0+eKHfv3lXWrFmj5MqVS7G1tVXu3bundO/eXQGU0aNH6+37999/K4CyatUqvfadO3fqtaf0+tO9e3elUKFCuscpuZ7s379fAZT9+/criqJ933R1dVXKli2rd64//vhDAZTx48frnQ9QJk+erHfMSpUqKd7e3km8akIIIYyV0PVmw4YNSp48eRRra2vl7t27iqIoSoMGDZRy5copUVFRun01Go1Ss2ZNpVixYrq28ePHK4CyadMmg3PFX1vi4uKU6OhovW0vXrxQ3NzcDL4jvP0dLz7emzdvvutTF0KPjIwSBhYsWMDu3bvZvXs3v/zyC/Xq1aN3795606mS8tlnn+k9rl27Ns+ePSMsLEzX9mbNp/iRWD4+Pty4cYPQ0FC9/b28vAym3Tk7O9O6dWt+/fVXFEUBtHd1165di5+fX5L1O3bv3s3Lly8ZPXq0QX0NlUql99ja2pqePXvqtW3fvp28efPq1Q6xtLRk8ODBhIeH89dffwHa6Y0RERFJTrlzcXHh0qVLBAYGJtonIWfPniUwMJDOnTvz7Nkznj59ytOnT4mIiKBBgwYcPHjQoPhtSv4uyXn7GNu3bwdg+PDheu2ff/45ANu2bdNrz5cvHx9++KHusZOTE926dePMmTM8evQI0I7gsrGx0RsdtWvXLp4+fZri0XlCCJFaDRs2JE+ePBQoUICOHTvi4ODA5s2b8fDw0PXp16+f3j7r16/H2dmZRo0a6d6Pnz59ire3Nw4ODrppEMZcf96UkuvJ206ePMnjx4/p37+/3rmaN29OyZIlDd6fIeHrxI0bN1J8TiGEECn35vXmo48+wt7enq1bt5I/f36eP3/Ovn37dDMb4q8rz549w9fXl8DAQN2U640bN1KhQgW9z9jx4q8t5ubmugUuNBoNz58/Jy4ujipVqqRoRoYQ6UEKmAsD1apV0ytg3qlTJypVqsTAgQNp0aJFsiv1FCxYUO9x/FDTFy9e4OTkBMDhw4eZMGECR48eNagnFRoairOzs+6xl5dXgufp1q0ba9eu5e+//6ZOnTrs2bOH4OBgPv744yTji59yUbZs2ST7AXh4eBg839u3b1OsWDHMzPRzuaVKldJtB+jfvz/r1q2jadOmeHh40LhxY9q3b0+TJk10+0yePJnWrVtTvHhxypYtS5MmTfj4448pX748oF2x8O3kXN68eXXJq+7duycae2hoqO61h5T9XZLz9t/i9u3bmJmZUbRoUYMYXVxcdK9FvKJFixp84SpevDigHZocv1/Lli1ZvXo1U6ZMAbRT9Dw8PHS1W4QQIr0sWLCA4sWLY2FhgZubGyVKlNB7v7ewsCB//vx6+wQGBhIaGoqrq2uCx3z8+DFg3PXnTSm5nrwt/v23RIkSBttKlizJoUOH9NpsbGzIkyePXluOHDkSrHklhBDi3cVfb0JDQ1m6dCkHDx7E2toagKCgIBRFYdy4cYwbNy7B/R8/foyHhwfXr1/XTRlPyvLly5k9ezZXrlzRmz6e2HctIdKbJKNEsszMzKhXrx5z584lMDCQMmXKJNnf3Nw8wfb4EUzXr1+nQYMGlCxZkjlz5lCgQAGsrKzYvn073333ncGInsRWzvP19cXNzY1ffvmFOnXq8Msvv5A3b14aNmyYimeZsHdZtc/V1ZWzZ8+ya9cuduzYwY4dO1i2bBndunXTFTuvU6cO169f57fffuPPP//kp59+4rvvvmPRokX07t2btWvXGozMUhRF9xrNmjWLihUrJnh+BwcHvcfJ/V1SIrHXI6k7+qnRrVs31q9fz5EjRyhXrhxbt26lf//+BglAIYRIa2/fkHmbtbW1wXuRRqPB1dU1wXp3gEGSx1gpuZ68q8SuEUIIIdLHm9cbPz8/PvjgAzp37szVq1d1n/VHjBiR6MJMb98MTsovv/xCjx498PPz44svvsDV1VVXT/DNgulCZCRJRokUiYuLA7QF8t7V77//TnR0NFu3btUbrWPsag7m5uZ07tyZgIAAZs6cyZYtW+jTp0+yH6iLFCkCwMWLF416E49XqFAhzp8/j0aj0ftCcuXKFd32eFZWVrRs2ZKWLVui0Wjo378/ixcvZty4cbpz58yZk549e9KzZ0/Cw8OpU6cOEydOpHfv3vj6+iY4LSP+OTg5OaVp8s3YpFKhQoXQaDQEBgbqRoYBBAcHExISovdawOu7PG+e59q1awB6K0c1adKEPHnysGrVKqpXr05kZGSyI96EEMJUihQpwp49e6hVq1aSNzHe5fqTkuvJm+Lff69evWowqvTq1asG789CCCFMJz4xFL+oUa9evQBtKZDkPusXKVLEYFGnt23YsIHChQuzadMmvc/hEyZMePfghUglGWYgkhUbG8uff/6JlZWVXsIhteKTRW+OyAkNDWXZsmVGH+vjjz/mxYsX9O3bN8Ur/jVu3BhHR0emT59OVFSU3raUjBJq1qwZjx49Yu3atbq2uLg45s2bh4ODAz4+PoB2Jb43mZmZ6abfRUdHJ9jHwcGBokWL6ra7u7vTsGFDvR8Ab29vihQpwrfffptggvDJkyfJPo+E2NvbG6ywlJRmzZoB4O/vr9c+Z84cQFub5E0PHjzQW/0jLCyMFStWULFiRfLmzatrt7CwoFOnTqxbt46AgADKlSune+2EECKzad++PWq1Wje1+E1xcXG699XUXn9Scj15W5UqVXB1dWXRokV6fXbs2MHly5cN3p+FEEKYVt26dalWrRr+/v44OTlRt25dFi9ezMOHDw36vvlZv23btpw7d07vM3a8+GtLQt+/jh07xtGjR9P6aQiRYjIyShjYsWOHbpTP48ePWb16NYGBgYwePTrFtYWS0rhxY90d3vgk0o8//oirq2uCb7ZJqVSpEmXLlmX9+vWUKlWKypUrJ7uPk5MT3333Hb1796Zq1ap07tyZHDlycO7cOSIjI5Od8vDpp5+yePFievTowalTp/D09GTDhg0cPnwYf39/HB0dAejduzfPnz+nfv365M+fn9u3bzNv3jwqVqyoS+qVLl2aunXr4u3tTc6cOTl58iQbNmxg4MCBScZgZmbGTz/9RNOmTSlTpgw9e/bEw8OD+/fvs3//fpycnPj9999T+Cq+5u3tzZ49e5gzZw758uXDy8uL6tWrJ9q/QoUKdO/enSVLlhASEoKPjw/Hjx9n+fLl+Pn5Ua9ePb3+xYsX55NPPuHEiRO4ubmxdOlSgoODE0xEduvWje+//579+/czc+ZMo5+LEEJkFB8fH/r27cv06dM5e/YsjRs3xtLSksDAQNavX8/cuXP56KOPUn39Scn15G2WlpbMnDmTnj174uPjQ6dOnQgODmbu3Ll4enoybNiw9HxJhBBCpMIXX3xBu3btCAgIYMGCBXzwwQeUK1eOPn36ULhwYYKDgzl69Cj37t3j3Llzun02bNhAu3bt6NWrF97e3jx//pytW7eyaNEiKlSoQIsWLdi0aRMffvghzZs35+bNmyxatIjSpUunycwXIVLFRKv4iUwoftnON39sbGyUihUrKgsXLtRbdlpRDJf9nDBhggIoT548SfC4by4HunXrVqV8+fKKjY2N4unpqcycOVNZunSpQb9ChQopzZs3TzLub775RgGUadOmGfV8t27dqtSsWVOxtbVVnJyclGrVqim//vqrbruPj49SpkyZBPcNDg5WevbsqeTOnVuxsrJSypUrpyxbtkyvz4YNG5TGjRsrrq6uipWVlVKwYEGlb9++ysOHD3V9pk6dqlSrVk1xcXFRbG1tlZIlSypff/21EhMTk6LncObMGaVNmzZKrly5FGtra6VQoUJK+/btlb179+r6GPN3uXLlilKnTh3F1tZWAZTu3bsneQxFUZTY2Fhl0qRJipeXl2JpaakUKFBAGTNmjN4ytIry+m+5a9cupXz58oq1tbVSsmRJZf369Yk+vzJlyihmZmbKvXv3UvR6CCFEasW/J544cSLRPt27d1fs7e0T3b5kyRLF29tbsbW1VRwdHZVy5copI0eOVB48eKDXL7nrT/fu3ZVChQrpHqfkerJ//34FUPbv3693rrVr1yqVKlVSrK2tlZw5cypdunQxeE9N7HnFv/cLIYRIO0ldb9RqtVKkSBGlSJEiSlxcnHL9+nWlW7duSt68eRVLS0vFw8NDadGihbJhwwa9/Z49e6YMHDhQ8fDwUKysrJT8+fMr3bt3V54+faooiqJoNBpl2rRpSqFChRRra2ulUqVKyh9//GFwvVEUw+94CX1nECItqBTFiOrFQmRCc+fOZdiwYdy6dctgxTiReXh6elK2bFn++OOPFO9TqVIlcubMyd69e9MxMiGEEEIIIYQQGUlqRoksTVEUfv75Z3x8fCQR9Z45efIkZ8+epVu3bqYORQghhBBCCCFEGpKaUSJLioiIYOvWrezfv58LFy7w22+/mTokkUYuXrzIqVOnmD17Nu7u7nTo0MHUIQkhhBBCCCGESEOSjBJZ0pMnT+jcuTMuLi58+eWXtGrVytQhiTSyYcMGJk+eTIkSJfj111+xsbExdUhCCCGEEEIIIdKQ1IwSQgghhBBCCCGEEBlGakYJIYQQQgghhBBCiAwjySghhBBCCCGEEEIIkWHe+5pRGo2GBw8e4OjoiEqlMnU4QgiRIRRF4eXLl+TLlw8zM7nvYCy5dgghsiO5drw7uX4IIbKj1Fw/3vtk1IMHDyhQoICpwxBCCJO4e/cu+fPnN3UYWY5cO4QQ2ZlcO1JPrh9CiOzMmOvHe5+McnR0BLQvipOTk4mjEUKIjBEWFkaBAgV074HCOHLtEEJkR3LteHdy/RBCZEepuX6898mo+OGxTk5OckEQQmQ7MkUgdeTaIYTIzuTakXpy/RBCZGfGXD9kMrgQQgghhBBCCCGEyDCSjBJCCCGEEEIIIYQQGUaSUUIIIYQQQgghhBAiw7z3NaNSSq1WExsbq9cWEhqCk4MTZuaSs8tKLC0tMTc3N3UYQgghhBBCCCGESEC2T0YpisKjR48ICQnRa496+RwrdQTBNrmxsrE1TXAi1VxcXMibN68U4BRCCCHEeydOreGzX05Tt0Qectpb0X/VaYM+hfPYs+/zuhkfnEgXao2C2bGFqHaN0Tb0Owp/zQSPylBriGmDE0KIVMj2yaj4RJSrqyt2dna65EXkM0vs1GFEquywy+Np2iBFiimKQmRkJI8fPwbA3d3dxBEJIYQQQryb60/CeRYeQ+E89lSZukfXvudycKL73HgSQWRMHHZW2f7jfpYXHh1HxQnbCLIZ87pxYQ3tv/9ugeJNIE8Jk8QmhBCpla2vTmq1WpeIypUrl942s1zuWD1/ibXyilgVWFnbmChKYSxbW+1ItsePH+Pq6ipT9oQQQgiR5TwIeUXNGftSvb9XbnviNEoaRiRMpeyEXeywGpt4h2OLoelMMLfMuKCEEOIdZetkVHyNKDs7O4NtVjb2vFLZYssrYkIfY+VaMKPDE+8g/m8aGxsrySghhBBCZCovo2Lpvfwkx24+p16JPOy/+sToY3SqVpDetb1QAYXzOKR9kCJTePIymm7muyhldjfxTid/hrOr4KvER8oJIURmk62TUfESqyuk2OeB8DvYxL5ArfaQpEYWIrWihBBCCJFZRMbEUXr8rgS3pTQR5d+hIreeRVDM1ZHm5aUMQXZRbdpublov12srG/UTdczOc13Jxy7r0drGuCiY6EyFqCXUr1SCOe0ryOdhIUSmJsmoJNg65iQm/AFWqjjCQ5/gkDOvqUMSQgghhBCZVFhULOUn/plmx7s6tQnWFnIzNDurkiMaIl8/9omeQzh2bNf8L8H+52w+xfPMajafuU/g102xlFXBhRCZlEmTUQcPHmTWrFmcOnWKhw8fsnnzZvz8/HTbFUVhwoQJ/Pjjj4SEhFCrVi0WLlxIsWLFMiQ+lUpFrHVOrKIfYxH1DEVxe2/vMHh6ejJ06FCGDh2aov4HDhygXr16vHjxAhcXl3SNTQghhBAiM4hTa4jTKFhbmHHvxSvWn7qHjaUZt55GsO7kvRQfJ38OW37qXoWieRyIUWuIjtWQw94qHSMXWVVJi4evH5T2Y3vr7jx+GU0+FxtKfLUTz6jVfGa+ldGWa3TdXHhJCI4UG7uDi5N8cbCW8QdCiMzHpO9MERERVKhQgV69etGmTRuD7d988w3ff/89y5cvx8vLi3HjxuHr68u///6LjU3GFBS3cXZFE/wEG1UMkeGh2Dm6ZMh5E5NcMmzChAlMnDjR6OOeOHECe3v7FPevWbMmDx8+xNnZ2ehzCSGEEEJkBTFxGnZcfMiWM/dTVdfpTcMaFmdwg6IGn+UszM2wkzyUSECsWoPVs8tgCeGFm+LQfjn2gNd/yaUNn9Xgo0VH8e4ymbiYBlhs6QPAWZu+eEatBrTFzyUhJYTIjIx+V9q/fz/16tVLk5M3bdqUpk2bJrhNURT8/f356quvaN26NQArVqzAzc2NLVu20LFjxzSJITnmFpZEWDhhrw5FiXgCJk5GPXz4+u7I2rVrGT9+PFevXtW1OTi8LmCpKApqtRoLi+T/zHny5DEqDisrK/LmlWmLQgghhMh6FEVBrVGwMDdDURTiNAqnbr9g0+l7Ro1wSsiOIbUp4eaImdn7OZpeZJwTt54zzvIXAOzsHQ22V/HMya0Zzf971B4OzYKn1wCoa3aGA5pKgDYhNaZpSfr6FMmQuIUQIiWMnkTcpEkTihQpwtSpU7l7N4lVHd7RzZs3efToEQ0bNtS1OTs7U716dY4ePZpu502IpZMbAHbqcGKiozL03G/Lmzev7sfZ2RmVSqV7fOXKFRwdHdmxYwfe3t5YW1tz6NAhrl+/TuvWrXFzc8PBwYGqVauyZ88eveN6enri7++ve6xSqfjpp5/48MMPsbOzo1ixYmzdulW3/cCBA6hUKkJCQgAICAjAxcWFXbt2UapUKRwcHGjSpIle8iwuLo7Bgwfj4uJCrly5GDVqFN27d9ebmimEEEII8a7i1BoiY+J4GPqKmDgNAM/Co/nr2hM8R2/Da8x2io7dofu92NgddFzyT4oSUfVLujKmaUlmfVSe8xMbc2tGcwK/bsrN6c24NaM5pdydJBEl0sTjsGjd72YPzyW/Q7/X35F+LnNeb9P0HVfwHL2N3f/KintCiMzB6GTU/fv3GThwIBs2bKBw4cL4+vqybt06YmJi0jSwR48eAeDm5qbX7ubmptuWkOjoaMLCwvR+UkpRFCJj4gx+4syteRZnzas4DSFPHyXY511/FEVJ3QuVgNGjRzNjxgwuX75M+fLlCQ8Pp1mzZuzdu5czZ87QpEkTWrZsyZ07d5I8zqRJk2jfvj3nz5+nWbNmdOnShefPnyfaPzIykm+//ZaVK1dy8OBB7ty5w4gRI3TbZ86cyapVq1i2bBmHDx8mLCyMLVu2pNXTFkJkYQsWLMDT0xMbGxuqV6/O8ePHk+wfEhLCgAEDcHd3x9ramuLFi7N9+3a9Pvfv36dr167kypULW1tbypUrx8mTJ9PzaQghTOhlVCz/m7YXz9HbKDp2B6XH76LG9H0U/0qbdPKeuofuS5N+b3nbwHpF+WPQB2wfXJvLk5twa0ZzlvaoSl+fIrSrUgAnG0sALM3N3tu6osJ0njx/8fpB+xXJ72D+ejaEeeAugqb6GnTps+IkUbHqtAhPCCHeidHT9HLnzs2wYcMYNmwYp0+fZtmyZfTv35/+/fvTuXNnPvnkEypUqJAesabI9OnTmTRpUqr2fRWrTnTZ3dceAZdSdfyk/DvZFzurtJnLPXnyZBo1aqR7nDNnTr2/yZQpU9i8eTNbt25l4MCBiR6nR48edOrUCYBp06bx/fffc/z4cZo0aZJg/9jYWBYtWkSRItohwAMHDmTy5Mm67fPmzWPMmDF8+OGHAMyfP9/gy6MQIvtZu3Ytw4cPZ9GiRVSvXh1/f398fX25evUqrq6uBv1jYmJo1KgRrq6ubNiwAQ8PD27fvq23mMKLFy+oVasW9erVY8eOHeTJk4fAwEBy5MiRgc9MCJGe4tQamn9/iKvBL1N9jKZl85LD3goXW0ui4zRceRTG5NZlyedsi62VrGKX2S1YsIBZs2bx6NEjKlSowLx586hWrVqi/f39/Vm4cCF37twhd+7cfPTRR0yfPl2vFq2xx0xPr55qbxzHmNlhlaeE0ftbHP2eWzOGczjoKV1+OqZrLzlu5xvT+4QQwjTeKftRuXJl8ubNS65cuZgxYwZLly7lhx9+oEaNGixatIgyZcqk+tjx9YiCg4Nxd3fXtQcHB1OxYsVE9xszZgzDhw/XPQ4LC6NAgQKpjiMrqlKlit7j8PBwJk6cyLZt23j48CFxcXG8evUq2ZFR5cuX1/1ub2+Pk5MTjx8/TrS/nZ2dLhEF4O7urusfGhpKcHCw3sXc3Nwcb29vNBqNUc9PCPF+mTNnDn369KFnz54ALFq0iG3btrF06VJGjx5t0H/p0qU8f/6cI0eOYGmpHZXg6emp12fmzJkUKFCAZcuW6dq8vLzS70kIIdKdWqPQY9lx/g58mqL+o5uWJJ+LLZfuh3LuXgj/3HjO8l7V8CluXJ1MkTkZeyNj9erVjB49mqVLl1KzZk2uXbtGjx49UKlUzJkzJ1XHTG+xIfcBeGXrhlVKR94NOQdz/7sJvXcS1B5OraK5uTWjOZ6jt+m6xf9er0QelvU0TbJNCJG9pSoZFRsby2+//cbSpUvZvXs3VapUYf78+XTq1IknT57w1Vdf0a5dO/79999UB+bl5UXevHnZu3evLvkUFhbGsWPH6NevX6L7WVtbY21tnapz2lqa8+9kw+Gs8SKePcA+5glRWGGdt2SaDse2tUy7u29vr4o3YsQIdu/ezbfffkvRokWxtbXlo48+SnZqZfyXvHgqlSrJxFFC/dNy+qEQ4v0TExPDqVOnGDNmjK7NzMyMhg0bJlofcOvWrdSoUYMBAwbw22+/kSdPHjp37syoUaMwNzfX9fH19aVdu3b89ddfeHh40L9/f/r06ZMhz0sIkXrXgl/S+LuDRu/Xorw7n/kUoUw+J73PaK0q5EvL8EQmYeyNjCNHjlCrVi06d+4MaG9idOrUiWPHjqX6mOnN7OUDAOIc3JPp+YYcnpC3PDz6r2bUT42g104wM+fMuEZUmrJbr/v+q9o6auNblOZRWBRLDt6gdcV8zO1YKY2ehRBCJMzoZNSgQYP49ddfURSFjz/+mG+++YayZcvqttvb2/Ptt9+SL1/yF/7w8HCCgoJ0j2/evMnZs2fJmTMnBQsWZOjQoUydOpVixYrh5eXFuHHjyJcvX7oVvFapVElOlbPO444q+Dl2qjgiYyKwM/HKeil1+PBhevTooZseFx4ezq1btzI0BmdnZ9zc3Dhx4gR16tQBQK1Wc/r06SRHugkh3m9Pnz5FrVYnWB/wypUrCe5z48YN9u3bR5cuXdi+fTtBQUH079+f2NhYJkyYoOuzcOFChg8fzpdffsmJEycYPHgwVlZWdO/e3eCY0dHRREe/LhRrTL1BIUTiFEVhw6l7rD5+hzN3QtL8+B9W8uC7DhXT/LiZXtAe0GjAOT/kKQlmRpeBzdJScyOjZs2a/PLLLxw/fpxq1apx48YNtm/fzscff5zqY0L6Xj+sI7V1cs2cPYzbsfvvMLOQ9vd7x2HbcGjhTw57KxqWcmPPZcMi5pP/eD2I4LezD4iO1bDoY+9Uxy6EEMkxOhn177//Mm/ePNq0aZPoCKTcuXOzf//+ZI918uRJ6tWrp3scP72ue/fuBAQEMHLkSCIiIvj0008JCQnhgw8+YOfOnXrzujOSuYUlEZbO2MeFoIQ/hiySjCpWrBibNm2iZcuWqFQqxo0bZ5KpcYMGDWL69OkULVqUkiVLMm/ePF68eCEFP4UQRtFoNLi6urJkyRLddN/79+8za9YsXTJKo9FQpUoVpk2bBkClSpW4ePEiixYtSjAZ9S71BoUQhvZdCaZXQNovGDCicXEG1CuavT87THROuL3TGrBygOUt3ugbmjExZbDU3Mjo3LkzT58+5YMPPkBRFOLi4vjss8/48ssvU31MSL/rR6xaQ4nYy2AO1jnzG7ezrQuYW4P6vyTZqQDtD/BTxa4oU78jPE5FuYl/JnqInZce4Tl6G+s/q0GVQjmy9/9zQoh0YXQyau/evckf1MICHx+fZPvVrVs3yWlcKpWKyZMn6xXBNjVLJzd4HoK9EkHUq0hsbO1MHVKy5syZQ69evahZsya5c+dm1KhRJrnrP2rUKB49ekS3bt0wNzfn008/xdfXVzetRgiR/eTOnRtzc3OCg/Xv0gYHB+tqB77N3d0dS0tLvfeOUqVK8ejRI2JiYrCyssLd3Z3SpUvr7VeqVCk2btyY4DGl3qAQaWPxX9eZviPxL+7JaVUhHwPqFaVATltUqLJvEfGYSIh9Bfa5tI///Q2u7YKzqxLf59eOGRNbFnXgwAGmTZvGDz/8QPXq1QkKCmLIkCFMmTKFcePGpfq46XX9uPU0ggbmZwCwjUtFkf5xj+Hsr7DlM/32s7+gOvsLjm1/5pbNJwDUiJqHu+oZL3DkpqI/JbDdotejwvwq5sNfpu8JIdJIqmpGXb16lXnz5nH58mVA+wF/0KBBlChh/CoPWY2VjR2RZvbYaSKICwsGW9MVxO3Rowc9evTQPU4suefp6cm+ffv02gYMGKD3+O1pewkdJyQkJNFzvR0LgJ+fn14fCwsL5s2bx7x58wDtyIVSpUrRvn37BJ+fEOL9Z2Vlhbe3N3v37tVNwdZoNOzduzfR1T5r1arF6tWr0Wg0mP03NeXatWu4u7tjZWWl63P16lW9/a5du0ahQoUSPOa71BsUIjsLfRXLrouP+OfmMzadvp9gn8al3fDvWFFXCkFRFBllkZiYCJiWwhpXYx/BsyBY9EHC27sknHx/H6TmRsa4ceP4+OOP6d27NwDlypXTzcAYO3Zsqo4J6Xf9ePnsoe53VakWSfRMQsVO4JgXVvoZbtv4ie7XozaD9DbtaXOe3qsvGuyy5ewDDl9/xomxDVMXjxBCvMHoCeYbN26kbNmynDp1igoVKlChQgVOnz5N2bJlE73j/L4xc9AO37WLCyU2Nuki4OK127dv8+OPP3Lt2jUuXLhAv379uHnzpq6QpBAiexo+fDg//vgjy5cv5/Lly/Tr14+IiAhdAdlu3brp1fDo168fz58/Z8iQIVy7do1t27Yxbdo0vST7sGHD+Oeff5g2bRpBQUGsXr2aJUuWGCTihRDGi4pVM/63i3iO3kaFSX8ycuP5BBNRO4fW5taM5izpVkWvJqckohKhKK9XQUuKe0UYdgksbSFvOe1UvAkh0H4FlPkQBp7SthV7fxMGb97IiBd/I6NGjRoJ7hMZGam7gREvfoStoiipOma6ii9ADlCkXuL9klOknva/h4mhUDJlSa2Gm8pz63/b6e/jabDtycto6s5KvhyLEEIkx+iRUSNHjmTMmDEGU+cmTJjAyJEjadu2bZoFl1nZ2DsRHWaNtSqaiJDHWOYxch53NmVmZkZAQAAjRoxAURTKli3Lnj17KFWqlKlDE0KYUIcOHXjy5Anjx4/n0aNHVKxYkZ07d+rqdty5c0fvC0SBAgXYtWsXw4YNo3z58nh4eDBkyBBGjRql61O1alU2b96su155eXnh7+9Ply5dMvz5CfE+eBoezYBVpzl283myfY992QA3J9PU98yyFAUmuei3NZwExxZD5W7w+F9oMl1bsDwhKhWUbq39ySaGDx9O9+7dqVKlCtWqVcPf39/gRoaHhwfTp08HoGXLlsyZM4dKlSrppumNGzeOli1b6pJSyR0zI+UJXJf2B+24CkLugv9/i0+5FISQOwn3PfsLI/mFkW/8r/yXujzdY0dz61kknqO3cXN6M0kuCyFSTaUkVbQpAXZ2dpw/f56iRYvqtQcGBlKhQgUiIyPTNMB3FRYWhrOzM6GhoTg5Oelti4qK4ubNm3h5eRldFD0y9Al2EfeIxRwztzJS9yiTeZe/rRDvg6Te+0Ty5PUT2V1oZCwVJide3PhtN6Y1w8xMvpQaJfI5qMxer3oWzz4PfBGU8D7pLKu9982fP59Zs2bpbmR8//33VK9eHdCWlPD09CQgIACAuLg4vv76a1auXMn9+/fJkycPLVu25Ouvv8bFxSVFx0yJtHoN/149ndrXZhClssVmwqNUHydBIXfhyRUo2lCbyIwX/gS+LZr4fv+pETWPh2jrmZ0b3xhnO8u0jU8IkeWk5r3P6GRUs2bNaNeuncEdgmXLlrFmzRp27dplzOHSXXoloxSNhrhHl7AkjnCbfDjkdEt+J5FhJBklsrus9oUis5HXT2Q3sWoNvQJO8Hfg0xT1/75TJVpVSGFtI6GlKLDtczj5c9L9RgSCg2vGxPQWee97d2n1Gk4Z259xlqvYoq6J35QdaRhhClzaAusNV559U9GoFcT9N8km6OumWJgbXf1FCPEeSc17n9HT9Fq1asWoUaM4deoU//vf/wD4559/WL9+PZMmTWLr1q16fd9XKjMzYqxzYhn9GIuopyiKqwxTFUIIIUSW0++XU+y4mPTIi2qeORnVtCTehXJkUFTvicPfw24jVmobeRPscqZfPCLLcCAKgBgzE6zcXcYPyoTqt23+DM79qnu40WoiH8ZMRoMZRcfukNGRQgijGZ2M6t+/PwA//PADP/zwQ4LbQFucUq1Wv2N4mZuNsyvqx0+wIYaIlyHYO8kHNCGEEEJkbjFxGr7e9i/Lj95Ost/OobUpmVdGxxjtxW2YWz7l/T87DHnLpl88IksqmyMOwqFUEU9Th6L14SJo8R0sqQdPLlPB7AY3bLpyRlOUD2MmU/jL7dya0dzUUQohshCjk1EajSY94siSzC0sibBwwT7uBaqIxyDJKCGEEEJkIhtP3ePz9edS1HdR18o0Lp1XRjekVOh9bfHnA9PAKT80ngqzCie/X+99kN87/eMTWZqF5hUA5jYOJo7kDZa28NnfMCW3rqmSWRC/Wk6lU+xXdPnpH1b1/p8JAxRCZCVGJ6OEPitnN5SnL7AjkqjICGzs7E0dkhBCCCGyqV/+uc1XWy4atU//ukX4wreElBt4eE5bUNzJA7b0g9B72uLOLoXg5SO4fzLp/c+tTri91y4o+D+IjQJzSzCTRW9E8sJfhoE52Ng5mjoUfeaWMPwKrGgFT68BUMP8X75Q1jArqCPPI2LIaW9l4iCFEFlBqpJRf/31F99++y2XL18GoHTp0nzxxRfUrl07TYPLCiytbYk0d8BOE05c2COwK2LqkIQQQgiRDa09cSfFiajRTUvymU82+8yijgN1tPYLtGtpiH0FFjZw8y9Y3T7x/R5dMP5cY4PB8q0FVN5+LEQi4tQaGptpk5/Odpnwvxsndxh4Al7cgrkVABhgsZXVcQ2oPGW3TNcTQqSI0cmoX375hZ49e9KmTRsGDx4MwOHDh2nQoAEBAQF07tw5zYPM7Myd8kJIEHbqMKKjo7C2zoQXjTfUrVuXihUr4u/vD4CnpydDhw5l6NChie6jUqnYvHkzfn5+73TutDqOEEIIIbT891zDf09ggtt+7l6FBqWy8Yq/kc+1o5oW1ni345RpA4//hSdXXrflLAztloNrKZjpCTHhUKUX+E6XxJN4Jy+j4sihigPA5VXStd1MKocn9Duq+//rsM0QPKNWceNJOIXzZKLphUKITMnoZNTXX3/NN998w7Bhw3RtgwcPZs6cOUyZMiVbJqOs7Rx5FWqLLa+ICX2Etatnup2rZcuWxMbGsnPnToNtf//9N3Xq1OHcuXOUL5/ywpknTpzA3j5tpxdOnDiRLVu2cPbsWb32hw8fkiOH1NYSQggh3kVSCahzExrjbGuZwRFlQhOdjd+n0RR4FghFGkBhH7ByBPM3Pi7Hj64yt9JOV4r35f13j1eI/4S+iiX+07J5qRYmjSVZbqXBszbc+hsAH7PzDFuXg98G1DJxYEKIzM7oZNSNGzdo2bKlQXurVq348ssv0ySorEjl6AZht7CLDSE2NgZLy/SZK/3JJ5/Qtm1b7t27R/78+fW2LVu2jCpVqhiViALIkydPWoaYpLx582bYuYQQQoj3RUhkDHW/PUBIZGyS/U591TB7J6KiQmFGwcS3F64LxZvA2dVQuRt4eGtHNkWFga0LWFgnfXxzC/3klBDpICwqlgjFGntVNDjnT34HU+vxhy75+7PlLIrerYBGo8hiCEKIJJkZu0OBAgXYu3evQfuePXsoUKBAmgSVFdnYuxCNNeYqhaiQ4HQ7T4sWLciTJw8BAQF67eHh4axfvx4/Pz86deqEh4cHdnZ2lCtXjl9//TXJY3p6euqm7AEEBgZSp04dbGxsKF26NLt37zbYZ9SoURQvXhw7OzsKFy7MuHHjiI3VfkAOCAhg0qRJnDt3DpVKhUql0sWrUqnYsmWL7jgXLlygfv362NrakitXLj799FPCw8N123v06IGfnx/ffvst7u7u5MqViwEDBujOJYQQQryvQl/F8iIiBs/R26g4eXeiiahWFfJxZUoTbs1oTi6HZJIp77MfaiaciBp6Eb58CBNDodtv8L9+2hXBqvUBj8raFcIc3ZJPRAmRQSIiIrWJKADbLDKjIKd2JUkLlQZrYhi+7qxp4xFCZHpG39r5/PPPGTx4MGfPnqVmzZqAtmZUQEAAc+fOTfMAM5SiQGxkqndXWzlARAi2MfeJs3fCwsKIl9fSTrtiSzIsLCzo1q0bAQEBjB07Vrfyzfr161Gr1XTt2pX169czatQonJyc2LZtGx9//DFFihShWrVqyR5fo9HQpk0b3NzcOHbsGKGhoQnWknJ0dCQgIIB8+fJx4cIF+vTpg6OjIyNHjqRDhw5cvHiRnTt3smfPHgCcnQ2HykdERODr60uNGjU4ceIEjx8/pnfv3gwcOFAv2bZ//37c3d3Zv38/QUFBdOjQgYoVK9KnT59kn48QQgiRldx7EcmuS8FM+ePfRPtYmZsx9cOytK+SfW8CGvhnITy+pN9WtBF0XgdmRt97FcKkoiJCXj+wdjJZHEb5eLOumPloi1+ZdLY7/h0rmTgoIURmZnQyql+/fuTNm5fZs2ezbt06AEqVKsXatWtp3bp1mgeYoWIjYVq+VO9u99+/qRq8/eUDsEpZ3aZevXoxa9Ys/vrrL+rWrQtop+i1bduWQoUKMWLECF3fQYMGsWvXLtatW5eiZNSePXu4cuUKu3btIl8+7Wsxbdo0mjZtqtfvq6++0v3u6enJiBEjWLNmDSNHjsTW1hYHBwcsLCySnJa3evVqoqKiWLFiha5m1fz582nZsiUzZ87EzU1bcDVHjhzMnz8fc3NzSpYsSfPmzdm7d68ko4QQQmRpiqKgUeBQ0FO2n3/Ig9BX/B34NNH+eZ1s+OfLBhkYYSYStBdWfQSKRr89fzUIfwQhd163lWsHbX/K2PiESEMxkaEARKussc4q00JzeOp+7Wmxi0lx3fh83Tlmt69gupiEEJmaUe9ucXFxTJs2jV69enHo0KH0ikkko2TJktSsWZOlS5dSt25dgoKC+Pvvv5k8eTJqtZpp06axbt067t+/T0xMDNHR0djZ2SV/YODy5csUKFBAl4gCqFHDcAWatWvX8v3333P9+nXCw8OJi4vDycm4OzeXL1+mQoUKesXTa9WqhUaj4erVq7pkVJkyZTA3N9f1cXd358KFVCyzLIQQQmQCp++8oM0PR5Ltl9fJhp+6V6FMPifdSOhs6a9vYP/XCW+7d9ywTRJRIouLjdAmo6LM7MlSk0ebzoIdXwDQ1/wPFp9uKckoIUSijEpGWVhY8M0339CtW7f0ise0LO20I5TegUajRh18GUvUhNu64+DimvJzG+GTTz5h0KBBLFiwgGXLllGkSBF8fHyYOXMmc+fOxd/fn3LlymFvb8/QoUOJiYlJxbNJ2NGjR+nSpQuTJk3C19cXZ2dn1qxZw+zZs9PsHG+ytNQvxKpSqdBoNIn0FkIIITIXRVG4H/KKD2buT1H/L3xL8HGNQjjZZONC5IoC67tD0D6Ieam/zbM23DsJca+gVCuwcYZcRaBiF3BI4ecuITIxTVQYANHmDiaOxEjVP9Ulo8ZY/spGdR1eRsXimJ3fy4QQiTJ63GeDBg3466+/8PT0TIdwTEylSvFUucSYAa8c8mMZ/RjLuEgUS7t0uZvZvn17hgwZwurVq1mxYgX9+vVDpVJx+PBhWrduTdeuXQFtDahr165RunTpFB23VKlS3L17l4cPH+Lu7g7AP//8o9fnyJEjFCpUiLFjx+rabt++rdfHysoKtVqd7LkCAgKIiIjQjY46fPgwZmZmlChRIkXxCiGEEJmRoij8HfiUXgEniNMoifbrXqMQTcq6U7mQC6GRsUTHaSiQ07gbVO+VsIcwp2TC27zqQPffMzYeIUxA+S8ZFWPxbt9LTKL3PvipPgAnbfrhOdGJWzNamDgoIURmZHQyqmnTpowePZoLFy7g7e2tN8UKoFWrVmkWXFZl6+KGOvgp1sQQHvYcB+dcaX4OBwcHOnTowJgxYwgLC6NHjx4AFCtWjA0bNnDkyBFy5MjBnDlzCA4OTnEyqmHDhhQvXpzu3bsza9YswsLC9JJO8ee4c+cOa9asoWrVqmzbto3Nmzfr9fH09OTmzZucPXuW/Pnz4+joiLW1/kDjLl26MGHCBLp3787EiRN58uQJgwYN4uOPP9ZN0RNCCPH+O3bjGWM2XWDLwFrvxWigOLWGomN3JNnn2tSmWFnoF9Z2dTJPpPd7LvolaNQws1AiHVRQrDF0WpOhYQlhKqr/RgPGZsVkVH5vvYe3bLpw9dE9SuR1NFFAQojMyuhkVP/+/QGYM2eOwTaVSpXsaJjswMzcggjLHNjHPsM8IhjFKWe6jI765JNP+Pnnn2nWrJmuxtNXX33FjRs38PX1xc7Ojk8//RQ/Pz9CQ0NTFruZGZs3b+aTTz6hWrVqeHp68v3339OkSRNdn1atWjFs2DAGDhxIdHQ0zZs3Z9y4cUycOFHXp23btmzatIl69eoREhLCsmXLdAmzeHZ2duzatYshQ4ZQtWpV7OzsaNu2bYL/bQkhhHi/vIiIISImjr4rT3HpgXYUQPmJfwLw98h61P5GO6VtbLNSfPKBF2ZmmbtmkqIo/Hr8Ll9uTrim4eKPvfmgaG7srbNIMeKMEPEMfqgOEU8S7zMiCBzyZFxMQmQCZtHhAMRZZNEEzhfXYVYR3cOYHz5AmXgGlaxsKYR4g0pRlMTHjpuYWq1m4sSJ/PLLLzx69Ih8+fLRo0cPvvrqqxQnd8LCwnB2diY0NNSgwHZUVBQ3b97Ey8sLGxubtI09NgbV438xUylEOBTC3ilnmh5fJC09/7ZCZAVJvfeJ5Mnrl/Yehr6ixvR9qd5/3+c+rDt5j3wuNvhV8jDpCKqzd0PwW3A42X6F89iz7/O66R9QZhZyF67vhWdBcGReyvbp/gd41U7fuESC5L3v3aXFa7jth5E0f7yYy24tKdXvlzSOMIPExcDUtxLJE1N2c1wIkfWk5r3P6NtzK1asoEOHDgZTrmJiYlizZk2aFjefOXMmCxcuZPny5ZQpU4aTJ0/Ss2dPnJ2dGTx4cJqdJz2YW1oRYZUD+9jnmIUHozjmyN4r4QghhMiWJv1+iWWHb73zcerP/kv3+/jfLgFwdWoTrC30p7bN3RPId3uuAfDbgFp45LDl0oMwahXJRZxGwcbS+KlwQY/DmbnzCrv/DU7xPjntrdg73Mfoc70XJjobv0//f7TT9fJX1dbwFCIbs4jTTtNTrLJYAfM3WVihGXEds29fj5BS/lmE6n+fmTCotBEVq+bJy2g6LD7Kg9AoXOwsqVE4F3svPyZGrb/IUml3J0Y3LUmd4jLCU4i3GZ2M6tmzJ02aNMHVVX+1kpcvX9KzZ880TUYdOXKE1q1b07x5c0Bbh+jXX3/l+PEElvHNhKxd8qJ5/AJbVRQR4aHYO7qYOiQhhBAi3b2KUVNq/M5k+3WoUgBzcxVjm5XC3tqCWLWG+fuC2HDqHvVK5iF/Djtm7LiS6P4lvkr6HK1TMHrpTW0r5+fG03DO3Akxar94pd2daFjajSENimGeyacVppnQe7Dvazi3GvKUgieXE+5nbg3qaP22Av+Dqp9A2Y9Apu+IVFiwYAGzZs3i0aNHVKhQgXnz5lGtWrUE+9atW5e//vrLoL1Zs2Zs27YNgB49erB8+XK97b6+vuzcmfz7WVqyiNVO01OsU5HYzUTMHHLTNucmNj5vA4Bq5yjt//PmWbM24F/XntB9qeH30JDIWHZcfIgFauK/XtsQTRTW/PswlIFL9xOGHWYoaHj9XvdV81K0rZyfHPZWGfUUhMhUjE5GKYqS4Aife/fu4eyctm+YNWvWZMmSJVy7do3ixYtz7tw5Dh06lGRNoejoaKKjX3/YCQsLS9OYjGFhaU2EpQv2cS9QhT9CcXCW0VFCCJEAY75QAISEhDB27Fg2bdrE8+fPKVSoEP7+/jRr1syg74wZMxgzZgxDhgzB398/HZ+FAAgOi6L6tL0JbutXtwgjfUsQHadJcISSpbkZwxoVZ1ij4rq2z3yKcOT6U7r8dIzZ7Spw9dFLFh+8kS6xbzx9L8V9/x5ZL/utevfyETw8Dzm9IPYV2LqAf7nX299OROUuAa4lobQflG3zul0dm2W/jIrMY+3atQwfPpxFixZRvXp1/P398fX15erVqwY3zQE2bdpETEyM7vGzZ8+oUKEC7dq10+vXpEkTli1bpnv89myQjGAZF6H9xSaL1ox6w7qB9Wkxdip/WH8FwI+zPqfP6O9NHFXyImPiKD1+V7L9iqnusdt6pNHH/zmuKYd2lGXd9twUUD3GtYIv09pXk++KIltJcTKqUqVKqFQqVCoVDRo0wMLi9a5qtZqbN2/qFblOC6NHjyYsLIySJUtibm6OWq3m66+/pkuXLonuM336dCZNmpSmcbwLaxd3NE9CsOMVkeFh2Dlm7TscQgiR1oz9QhETE0OjRo1wdXVlw4YNeHh4cPv2bVxcXAz6njhxgsWLF1O+fPkMeCbZS1SsmvIT/yRGrWFO+wr88s9tTicyouj4lw1wdXpdv8/YqXI1i+Tm5vTmuscD6xel3H/FzhMyp30FCudxYP6+IBqXdkOtKIzZlHBh8ZSo5pmTZT2rZt/i408DYX4V4/YZcw+sE/kiLYkokQbmzJlDnz596NmzJwCLFi1i27ZtLF26lNGjRxv0z5lTv37rmjVrsLOzM0hGWVtbkzdv3vQLPAWs1NpklNl7kIwyN1Ox8qu+nJ4ZQGWzIPpELafq6GqcmNHV1KEl6Oj1Z3T68Z9k+7XwUjH/YadUn+cTix18whurrl6eza7xVfhXUwj3Oj1pXa8mNpZmkpwS77UUf6ry8/MD4OzZs/j6+uLg8HoOs5WVFZ6enrRt2zZNg1u3bh2rVq1i9erVlClThrNnzzJ06FDy5ctH9+7dE9xnzJgxDB8+XPc4LCyMAgUKpGlcxrCwsibC0hn7uBAIf4Ti4CRvKkII8QZjv1AsXbqU58+fc+TIESwttV9qPT09DfqFh4fTpUsXfvzxR6ZOnZquzyG7ufs8UrfaHcDwdecS7Hd6XCNypsP0A0cbS25Ob8aJWy+4+zySFhXcDWpHAfzU/XUCpVO1gmkeR7YQF5OyRNTIm6BRg10ubc0n+awj0lFMTAynTp1izJgxujYzMzMaNmzI0aNHU3SMn3/+mY4dO2Jvb6/XfuDAAVxdXcmRIwf169dn6tSp5MqVK9HjpMesDJv/klHmti7vfKzMIIe9Fbb9VsHi6gCcsBnAwXGLqD3570zzvShOraHo2B2Jbi/m6sBPHxWi4JoGqF49h4eahDt2WKVdIfSPoVCkPnjWBkd3cCkAeyfD3WOJnsPX/CS+5ifh6EY4Cp1ixuLp3YSJrcskeI0TIqtLcTJqwoQJgPYDf4cOHTJkhbIvvviC0aNH07FjRwDKlSvH7du3mT59eqLJKGtra6OH02o0ibyZpBEr3eioSCIjwrBzkNFR6S29/6ZCiLSRmi8UW7dupUaNGgwYMIDffvuNPHny0LlzZ0aNGoW5+esPawMGDKB58+Y0bNhQklFpKCZOo5eISoiluYrArw2nTKYllUpFNa+cVPOS1WrTTfgT+LaoflujKVCoFtjn0q6Ql7cC2OeW5JPIUE+fPkWtVuPm5qbX7ubmxpUrideZi3f8+HEuXrzIzz//rNfepEkT2rRpg5eXF9evX+fLL7+kadOmHD16VO/68qb0mJVho9Emoyxs358VDW3cS3LS42Oq3F8JQB3zC0yZMYlxYyaaNjDg/L0QWs03rDH4fadKtKqQT/tgY29Yuj7hA0wIMXwPrNLTsN8n/43oPbMKLm2GZrMghydsGw4nl/KYXLjyTNf9V6uv4cLXLD3ThN/dB7H44yp6o4yFyOqMHm8enwSKiYnh8ePHBl/6CxZMuzuPkZGRmL1V0NLc3DzNEg1WVlaYmZnx4MED8uTJg5WVVbpl518qDtipXxL9/AFmFhk/9zy7UBSFmJgYnjx5gpmZGVZWUhBQiMwsNV8obty4wb59++jSpQvbt28nKCiI/v37Exsbq7txsmbNGk6fPs2JEydSFEdmqjeYmak1CsW/0r9z/MkHXgQcuUXX6gVpVTEftpYWlHLP+lNLspWoMLi8FYo1hkfn4dIWOLPSsN/by7Ln8MyI6IRIcz///DPlypUzqE0YfwMctDfBy5cvT5EiRThw4AANGjRI8FjpMSvDTokEwNLu/bqBXaXPfKL8j2ITEgTAuOjviIwag52Nab4bJTYlb8/wOhR1dYRXIYmvDtpyLuQuDoVqGn/iSl20P/FafActvsMV4Nl1mFdZr3svi53UCz5DjWnf8r+irvzySfVMM6JMiHdhdDIqMDCQXr16ceTIEb32+MLmarU6zYJr2bIlX3/9NQULFqRMmTKcOXOGOXPm0KtXrzQ5vpmZGV5eXjx8+JAHDx6kyTETo46LxSz8KSoUYp5HYWUtWe30ZGdnR8GCBQ2SmUKIrE+j0eDq6sqSJUswNzfH29ub+/fvM2vWLCZMmMDdu3cZMmQIu3fvTvEo3sxWbzAzehkVa1Cn6dYMbR2ncS1KmyIkkVpx0fDwHGwdBE+SH0UCQP/Ep5YIkdFy586Nubk5wcHBeu3BwcHJ1nuKiIhgzZo1TJ48OdnzFC5cmNy5cxMUFJRoMio1szKSY6e8AhVY2b0/I6Pi2Qw9RfS8/2H9TLvggd2M/2pDvp3sTmczdlxh0V/XDdpvzWgOUaFw8yAsb2m4Y60h0Cj5/3ZSLVeR16/F1R3wqzZB6mUWzHWbj/nztjdeYz6nYSk3vanoQmRFRiejevTogYWFBX/88Qfu7u7pmpWdN28e48aNo3///jx+/Jh8+fLRt29fxo8fn2bnsLKyomDBgsTFxaVpIi0hl1YspEzY31yyqkiJT39K13NlZ+bm5lhYWMgdAyGygNR8oXB3d8fS0lJvykSpUqV49OiRbtrf48ePqVz59Z1FtVrNwYMHmT9/PtHR0QbTLTJbvcHMRq1RDBJRN6al7zQ8kQ6iX4KFLUw1XBggSSOCwCFP+sQkRCpYWVnh7e3N3r17dXVtNRoNe/fuZeDAgUnuu379eqKjo+naNfkC2vfu3ePZs2e4u7unRdgpEqfWYEsUANb279fIqHjWg/4xHHE00RmGXtTWVkoHGo3CmbsvWLD/OvuuPNbbVtwmhBUtXcj7e2eYmMRBOv4KJTPw2leiKYy6DbOKgiYWgMbmp7hl3pn2V8ZRdfSVTFsIXoiUMDoZdfbsWU6dOkXJkiXTIx49jo6O+Pv7p/tS3CqVCktLS10h3PSSr0F/LFf8irfqLhcu/EO5qnXT9XxCCJHZpeYLRa1atVi9ejUajUY3+vHatWu4u7tjZWVFgwYNuHBBf+W0nj17UrJkSYO6UvHS4872+6Tp3IN6j4O+boqZmST8swSNRvslJqkEVMNJYOMM7hUgOgzyVwUre21BcjMpmisyp+HDh9O9e3eqVKlCtWrV8Pf3JyIiQrcYRrdu3fDw8GD69Ol6+/3888/4+fkZFCUPDw9n0qRJtG3blrx583L9+nVGjhxJ0aJF8fX1zbDnFREdi7NKO23c1uH9nfIc+cU91N8Uw1H16nWjf1n46glYpG2ZjSFrzvDb2YRmwSjcsvlvutzvieycrxJ8vBlsc6RpTClm6wLjn8LVnfBrB13zOusp2l8mDiC4gT9utROoUSVEJmd0Mqp06dI8ffo0PWJ577kXKceZnI2p9GIXsbunolTxkdE7Qohsz9gvFP369WP+/PkMGTKEQYMGERgYyLRp0xg8eDCgvZFRtmxZvXPY29uTK1cug3aRvGvBL7kWHK57fHN6M7l2ZQV3T8DPDZPu03AS/K9/4l/8JBElMrEOHTrw5MkTxo8fz6NHj6hYsSI7d+7U1SC8c+eOQbmGq1evcujQIf7880+D45mbm3P+/HmWL19OSEgI+fLlo3HjxkyZMiVDb1ZEhr8kfsyQ9XtUwPxtdvaOMOkR5Uev5bzNp683TM3DiR43qeqZNotTeI7epvvdjeccs0l65JxOo8lQYxBklpIfJZrAqFsw09Ngk9veoVzKUYkyZStmdFRCvBOjk1EzZ85k5MiRTJs2jXLlyhmMJnJyen/fNNOCh98k4pbupnLMCc4e2UXFWk1MHZIQQpiUsV8oChQowK5duxg2bBjly5fHw8ODIUOGMGrUKFM9hfda4+9ej4raObS2JKIyu6MLYNeXSfcp9AF0WAl2shKhyNoGDhyY6CjaAwcOGLSVKFECRVES7G9ra8uuXbvSMrxUiYzQLqChQYWZpa2Jo0l/56a3p8wYcy7ZfKJrqxrgRfiYZzhYG/1VFYD7Ia+oNWOfXps9r5JORH28WbtSqMoczFN33nRnm0NXT0qJieTq19UoqboLQJkNPtT6ZS4jOzaidUUPU0YpRIqplMTekRMR/4Xg7Q+j6VHAPC2EhYXh7OxMaGhopkmUnZrfDe+nv3HesjzlvjwoH+yFEGkuM773ZSXy+kFIZAwVJ+/WPfZwseXw6PomjEgkK/gSLExkZScLW+1ddUtZQEUkTt773t27voaXL52j1Po6RGKD3cTg5Hd4D6g1CqM3nGPWvz66thbRUylQpiY7Lj6ir09hutfwJFatIZeDtS5JpdYoRMepCQ6LJqe9FaGRsdSZtV93DBUaWpsdoaDqMcMtNyR8ctucMPIGZNXvYwms9vdjzhHUaTeEEu7y/7DIOKl57zM67bt///7kO4kkeX44gZgl2ygfe55TB37Du56fqUMSQgijqdVqAgIC2Lt3L48fP0aj0eht37dvXyJ7iqzgzUQUwL4RPon0FCZ15xjERsClLXB6+ev2Yr7QbBbkKGSy0IQQxouNeglAlMoGOxPHklHMzVTMal+RF1d+J8ca7Qp2f1h/BUFQk+9Z8peGxX/dMOqYn1usY5DFloQ39juqfW+0sn/HyDOBCSEo35VFFXZP19Tn+bc8WLSUqlY/smNIbXI7SE1MkTkZnYzy8ZEPo+8ql0cRTuZtQ5Xgddgemo6mTivMzDPJfGQhhEihIUOGEBAQQPPmzSlbtqyM8nxPKIqC15jtem0l3ByxtpD6QZmKRgOTEymoW6Q+dFmXsfEIIdKEJioCgGhV9hvFmKNkHZSaQ1Ed8de1HbHR1oOMU8y4qbhTzOw+AEvimnNKU4y5lguwUcWm/CTjX2SeOlBpQaVCNfwSaDQEHfiFogcHAZBP9ZwTsW3pMm0MXTp1p1m5jFsRUoiUStWE2L///pvFixdz48YN1q9fj4eHBytXrsTLy4sPPvggrWN8LxVtM46oHzZTWn2FE/vWU7VRh+R3EkKITGTNmjWsW7eOZs0ycJljka7Co+MoO0G/ZsrVqU0kEZWZvAqBmUmMdnIpqK19IoTIkuKis28yCkDVeBK8kYyKZ6HSUEx1X/f4U4ttBn0SZZcbPjsETu9xQsbMjKL1u4FPJ5iSW9e8ymo6/muv0n/VR9yY1kxWwhWZitFp4Y0bN+Lr64utrS2nT58mOlq79GhoaCjTpk1L8wDfVy5uBbnooU1AOR+diVqtSWYPIYTIXKysrChatKipwxBpJE6tMUhEHRldXxJRmUnsq4QTUQVrQNuftYVth17I+LiEEGlGHRMJQKxZ9kxGATAhBHIl8PnCzNKwLSkDTmjfF0def78TUW8yt4Rxz8D39ffyoRab+NHyW7p9NZO952+ZLjYh3mL0yKipU6eyaNEiunXrxpo1a3TttWrVYurUqWka3PuuxEdfEfH9BoprrnNs50qqN+9u6pCEECLFPv/8c+bOncv8+fNlil4Wp9EoFB27Q69ty4Ba5HN5/1dyyvSeBsG51fD3bMNtvtPhf/2ybuFdIYQB5b+RUdk6GaVSwaBTiW/XqGHyf6uBFm0EbZa8Xh1UUeQ90dwCagwA94oQoB293sj8NI3MT8Om6bzabMux6guoXLcVTjZGJviESENGJ6OuXr1KnTp1DNqdnZ0JCQlJi5iyDcec7pws1IUqt38mz8lviW3cGUtLeUMQQmQNhw4dYv/+/ezYsYMyZcoYvH9t2rTJRJEJY9V8awlsmZpnYk+uQkBziHiSeJ//lvcWQrxfNLGvAIgzz8bJqOSYmSf+HpjdE1Fv8qwFg07D70N49fAqttGPAbBVXlH3n17wD2gUFWd63sDbM6eJgxXZkdHT9PLmzUtQUJBB+6FDhyhcuHCaBJWdlG47ljDsKazc4fjvS0wdjhBCpJiLiwsffvghPj4+5M6dG2dnZ70fkfk9C4/Gc/Q2HoVF6douT5ZElEld3w8LqiWeiCpQHYZezNiYhBAZ579pempJRom0kKsI9PgD2zGB8NVjnpfqqrfZTKXgHeDFzLF9Cbx1x0RBiuzK6JFRffr0YciQISxduhSVSsWDBw84evQoI0aMYNy4cekR43vNzikXp4p+gnfQ93id/44I3+7Y2zuYOiwhhEjWsmXLTB2CMNLjsCiqTdsLwF9f1MVn1gG97f9O9sXWShJRJvPyEaz0M2zvvRfuHIUybcDZI8PDEkJkoP9GRkkySqQ5C2tydlgAmu+5tn0exU9O0G0aZbkGArQleB4U8iPf7S2QszD0OwKWMmVfpA+jk1GjR49Go9HQoEEDIiMjqVOnDtbW1owYMYJBgwalR4zvvXJtR/H4m1XkU57w94ZZ1O4+ydQhCSFEij158oSrV68CUKJECfLkyWPiiASAoiiERMbiYmdJdJyGkuN26m1/OxF1c3oz09b+mvjfaLrRd8HGyXRxZLS4GG1NqN+HGG6bEPJ6ykn+KhkalhDCROK0ySiNhSSjRDoxM6d4i6HQfAjPlnUg1x39xUvy3d6i/eX5Dfg6LzSdBdU/zfAwxfvP6GSUSqVi7NixfPHFFwQFBREeHk7p0qVxcJDRPKllZevAg4pDcT0zjnI3fuLZ0wHkyu1q6rCEECJJERERDBo0iBUrVqDRaFcENTc3p1u3bsybNw87OzsTR5h9/Xb2PkPWnE1R31LuTuwYUjt9A0pKXAxMfSOBOaOAdkU4p/xglkQ1geiXYO2Y/vGlp1PL4ffBCW/76rHUPhEiG1L9l4xSZGSUSG8qFbl6rdPevHoZwZG5H/MyWkNRswdUMbv2ut+OL7Q/vfdBfm/TxSveO0Yno+JZWVlx7tw5WrVqhb29fVrGlC2Vb96PO+d/pKD6DofWT+KDfgtMHZIQQiRp+PDh/PXXX/z+++/UqlUL0NYPHDx4MJ9//jkLFy40cYTZz70XkXwwc3+Sfcp5OHPhvrbw60/dqtCwtFtGhGbo/mlY2xXC7htu8y/3+vfqn0GxxuBZGyystCslTXJ5vX3Yv1l36lpCiajGX2tXQZJElHiPnD9/PsV9y5cvn46RZAFx0dp/ZWSUyCAqlYocTg40H7eZ4zefs+nsfVbHqil8fg4DLX573fGn+gBoKnTCrPUCbSF5Id6BSlEUJbU7Ozk5cfbs2UxduDwsLAxnZ2dCQ0Nxcsrcw/4vH1hLqQOfEqVY8rTnEfJ7Fjd1SEKILCoj3vty587Nhg0bqFu3rl77/v37ad++PU+eJLESWCaXla4dGo3Cb+fuM/vPa9x78SrJvtemNsXKwui1S9Le5n7aqWnGqjMSDn5j2N7hFyhcDw59B3ePQcdVYJOJi+hHh8P0txJofoug3EdgLqvqCtNJr/c+MzMzVCoViX3tiN+mUqlQq9Vpdl5TeNfX8J+5Xfnfi985Vqgv1Xsm8H4nRAa5+zyS2t/sZ77lXFqYH0u846cHIF+lDItLZE6pee9L9cgoINELikidUj7tuXp0HiWiL3B303jyD19j6pCEECJRkZGRuLkZjqpxdXUlMjLSBBFlT4W/3J5g+4bPalDFMycxcRouPwyjdD4nLM1NnIha2xUu/57wtn5Hwa003DsJPzVIuE9Ciaj4475pRsHEl/02lbgYUMfA02vwYz39bdmtTpbIdm7evGnqELIMlTpG+6+ljIwSplUgpx23ZjQnJq4pDcb9xEaribioIgw7LqnLU7Pc5NY8BfcK0GuXFD0XKfJOySiRxlQqrJpMgd/8qBa6k6vnj1GifHVTRyWEEAmqUaMGEyZMYMWKFdjYaD80v3r1ikmTJlGjRg0TR5c9/HH+gUHbJx94Ma5Fad1jKwszKhRwSZ8Anl3XJpdqDATz/z5ShN4DjRpyFNLvOyWPNhnzppqD4PoB6PEH2P4XY/4qrxNJQXvgr2+0o53eNvoO/D4ULm1KOLb4gujV+0HTGal4cka4ewLO/gJhDyDwT8PtOQtrC8EmpNV8SUSJ916hQoWS7yQAMNNop+mpZJqeyCSsLMzYO/1T4FPWnbzLtA2HqWN2nu+tXpeVya15qv3l4Tlt0fNW86ByN9MELLKMd0pG7dixAw+PLFqnIZPyqlSP8/vqUP7lQSK2j0Mpt8u0qxsJIUQi5s6di6+vL/nz56dChQoAnDt3DhsbG3bt2pXM3uJdhUXFMnD1Gb22PwZ9QFmPdJqeFrQXLm6EuqPBpSA8vgw//E+7bc+EhPf57DDkLQuRzw0TUUXqQ+OpSZ+zaEPtD2inti1toq0P1WGVNvnVbhk45oV/fkj8GMcWwv2T0OZHyOmlHXkVeg/K+On3iw4HayMWY4mL0Z43sef+psQSUaNugW2OlJ9TiCxq69atKe7bqlWrdIwk8zNTx2r/tbQ2cSRCGGpfpQDtq3TkYWhr6ixuRMTzhzQ1P05ls0DamB963XHrIO3PR0shVzFwz+a14ESCjK4Z9erVKxRF0a2SdPv2bTZv3kzp0qVp3LhxugT5LrJS3Y94D6+fJ88KHyxUGk7XW0lln+x9URZCGC+j3vsiIyNZtWoVV65cAaBUqVJ06dIFW9usPTw7s187omLVlBy3U/f4m4/K075KgfQ7YfgT+Lbo68cVOsG5X1N3rLY/a2sjpbXHVyBXEYh8BrNLpGyf2p/D37OT7jPgOOT573gxERB8CfZNgZsHUx6buZVhMm78i6RXCxTCBNKzZlRKSM0oODu9ARWjT3Km8nQqteqfDhEKkbYURcFrjLZkwDCL9Qyx2Jxwx+r9wLs7OLq/Hg0t3hsZUjOqdevWtGnThs8++4yQkBCqV6+OpaUlT58+Zc6cOfTr18/owIU+9yLlOe3mR+XHm3D8azyxNZtiaSkFTYUQmY+dnR19+vQxdRjZSnxB0TelayJKo9ZPREHqE1GQPokoANeS2n8d88LIm9rE0fMbsCKJGzrJJaIAFlRL2fl77tTe+bWwkRWGhHiLRqMxdQhZhplGm7g2t5KRUSJrUKlU3JrRnPn7Avn2z3ZsV1dnrdUUw/pSxxZqf9708RYo8lYdRZFtGH1L7vTp09SuXRuADRs24Obmxu3bt1mxYgXff/99mgd4//59unbtSq5cubC1taVcuXKcPHkyzc+T2RTvOI2X2FFMc5Njm9L+dRVCiNTYunUrsbGxut+T+hHp4+1E1I1pzdLvZDGRMDln0n36/q3916UgtF6gXcWuSSI1msq1S9v4EmOXE1wKQGEf7ZS+9FJnJEwI0da4KlQDrOwlESVEBlqwYAGenp7Y2NhQvXp1jh8/nmjfunXrolKpDH6aN2+u66MoCuPHj8fd3R1bW1saNmxIYGBgRjwVHYv4ZJQUgBZZzMD6xbg1ozm7pvfjSf+reEatpnTUUqKVJAZVrPTT1njcOxkenM2oUEUmYfTIqMjISBwdHQH4888/adOmDWZmZvzvf//j9u3baRrcixcvqFWrFvXq1WPHjh3kyZOHwMBAcuR4/+srOOR053SpAVS+PItSl+fy4nkPcuTMZeqwhBDZnJ+fH48ePcLV1RU/P79E+70PUy0yo+Jjd+g9vjKlCWZm6VhXcJq7/uNPdmtHHK300yac/vffaOg3V66r9N/Kdv/rB5e2wJ6JUHMglGmjTRJltFItYNyz1wXW4ykKqFTafzVq7fYXt7WjvnxGabdd2wWnV8CVP6DSx2CfR/v8rOy1I7CEEKkSERHBX3/9xZ07d4iJ0Z/COnjw4BQdY+3atQwfPpxFixZRvXp1/P398fX15erVq7i6uhr037Rpk965nj17RoUKFWjX7nWS/JtvvuH7779n+fLleHl5MW7cOHx9ffn33391C3WkNwtFe8NHRkaJrKyYmyO3ZjRHURS6/OTBo9AobjyNwJ5XXLL5xHCHv2e/Hq1csCb03K69Dov3mtE1o8qXL0/v3r358MMPKVu2LDt37qRGjRqcOnWK5s2b8+jRozQLbvTo0Rw+fJi///471cfI7HU/kqKOjebh9Erk19znb9eu1O6/IPmdhBCCrP3elxlkxtfvcNBTuvz0elW5QfWL8nnjFNZGSo3z62DTG1Mwv3oCFlbpdz4hhMllxHvfmTNnaNasGZGRkURERJAzZ06ePn2KnZ0drq6u3LiRSMH/t1SvXp2qVasyf/58QDsVsECBAgwaNIjRo0cnu7+/vz/jx4/n4cOH2NvboygK+fLl4/PPP2fEiBEAhIaG4ubmRkBAAB07dkxRXO/6Gt6eVJpCyn2Cmq2haLWmRu8vRGYWHaem5vR9PIuIwZ1nHLUZlGjfo+rSlK7eCOdbO+HpVe0I7CHnJUmVSaXmvc/oaXrjx49nxIgReHp6Ur16dd3y3X/++SeVKlUy9nBJ2rp1K1WqVKFdu3a4urpSqVIlfvzxxzQ9R2ZmbmnNS5+JAFQLXsOtaxdMG5AQQiQjJCQkVfsZM9Ui/jwDBgzA3d0da2trihcvzvbt23Xbp0+fTtWqVXF0dNSN4rp69WqqYsss5uy+pvd4YP2iifRMI1veKJw7IkgSUUKINDFs2DBatmzJixcvsLW15Z9//uH27dt4e3vz7bffpugYMTExnDp1ioYNG+razMzMaNiwIUePHk3RMX7++Wc6duyIvb09ADdv3uTRo0d6x3R2dqZ69eopPmZasFMiATCzTaeVUYUwIWsLc06Na8TN6c3YPq4jv/n9i2fUaipFLeLHOP2yAzXM/8X55FxtIgog5A5McoHN/eDBGXgapF2tV2RZRiejPvroI+7cucPJkyfZufP1Sj4NGjTgu+++S9Pgbty4wcKFCylWrBi7du2iX79+DB48mOXLlye6T3R0NGFhYXo/WVmpOu3419Yba1UcTzYnf5dHCCEyysyZM1m7dq3ucbt27ciZMyceHh6cO3cuxceJn2oxYcIETp8+TYUKFfD19eXx48cJ9o+JiaFRo0bcunWLDRs2cPXqVX788Uc8PDx0ff766y8GDBjAP//8w+7du4mNjaVx48ZEREQkeMys4OZTbexfNS/FrRnNsbZIx9pEUWGg0U4Voek34JAn/c4lhMhWzp49y+eff46ZmRnm5uZER0dToEABvvnmG7788ssUHePp06eo1Wrc3Nz02t3c3FI0S+P48eNcvHiR3r1769ri9zP2mGn93cMS7XuvpVXGTAsUwhRUKhU57K1oXdGDWzOac/zrDvyedwCeUauYHtuJFXGNWBbny151AoNdzq2GJXVhvjd846WtObWoNmg02h+RZRhdMwogb9685M2rrZUQFhbGvn37KFGiBCVLlkzT4DQaDVWqVGHatGkAVKpUiYsXL7Jo0SK6d++e4D7Tp09n0qRJaRqHSalUOPt9i3p1faq+OsSZg79TqU5LU0clhBAsWrSIVau0xaF3797Nnj172LlzJ+vWreOLL77gzz//TNFx5syZQ58+fejZs6fuuNu2bWPp0qUJTrVYunQpz58/58iRI7qVRj09PfX6vHmzBCAgIABXV1dOnTpFnTp1jH2qJrfq2G2eR2hrnbSqmC/9T7jx9Rc0Kn2c/ucTQmQblpaWmJlp74e7urpy584dSpUqhbOzM3fv3s2QGH7++WfKlStHtWopXC0zCWn93cNSiQUVWEgySmQjluZmbB34wX+PWgCw/cJDPll1mv/ys7Q1O0gb87+pbBZILBY4qSJfH+DReZj8Vl3pil0gdzHIVxncymrrVsoUv0zF6JFR7du3183NfvXqFVWqVKF9+/aUL1+ejRs3pmlw7u7ulC5dWq+tVKlS3LlzJ9F9xowZQ2hoqO4noy5q6cmjRGXOurUBwPHAOGJiYk0ckRBCaO8iFyhQAIA//viD9u3b07hxY0aOHMmJEydSdIzUTLXYunUrNWrUYMCAAbi5uVG2bFmmTZuWZMH00FBtge2cORMuoJ2ZR9UqisLYzRcByOdsg6tjBnxBCdz1+ncru/Q/nxAi26hUqZLuGuHj48P48eNZtWoVQ4cOpWzZsik6Ru7cuTE3Nyc4OFivPTg4WHfDPDERERGsWbOGTz7RL6Icv5+xx0zL7x6KomBJHABW1rKansjempVz59aM5rqf6ZOns9N7CaWiAygf/RPFo5azOK554gc4u0q7iMqKVjCrsHaK3/Ef4cm1xPcRGcroZNTBgwepXbs2AJs3b0ZRFEJCQvj++++ZOnVqmgZXq1Ytgxof165do1ChQonuY21tjZOTk97P+6B4x2mEYU9RzU2ObZht6nCEEIIcOXLoPnTv3LlTl1BSFCXFK+mlZqrFjRs32LBhA2q1mu3btzNu3Dhmz56d6DVIo9EwdOhQatWqlegXnenTp+Ps7Kz7iU+yZQZlJrxODC3v9e538ZN0aYt2uHu85nK9EUKkrWnTpuHurl2p8+uvvyZHjhz069ePJ0+esHjx4hQdw8rKCm9vb/bu3atr02g07N27V1fPNjHr168nOjqarl276rV7eXmRN29evWOGhYVx7NixJI+Zlt89YuPUWKm0108ra1lNT4g3WVmYMcWvLLdmNOfm9GZU8nJjelwXikWtoHLUIipFLWJ0bO+kD7J9BCyoChOdCV/SDGWFHyxrrv3sE//z8hGcWQURT40PUlG0P6agKPCzL/zUEE6vhFcv9LfHxWhXD46J1P6bCRg9TS80NFR3Z3nnzp20bdsWOzs7mjdvzhdffJGmwQ0bNoyaNWsybdo02rdvz/Hjx1myZAlLlixJ0/NkBY4583Km7BAqXZxG+avfE/ywC27umefLkhAi+2nTpg2dO3emWLFiPHv2jKZNtav+nDlzhqJF06+4tkajwdXVlSVLlmBubo63tzf3799n1qxZTJgwwaD/gAEDuHjxIocOHUr0mGPGjGH48OG6x2FhYZkiIRX0+CWRMa8/MBRzc0y/kz26AOvfmgJfJYHll4UQ4h1UqVJF97urq6vBtOqUGj58ON27d6dKlSpUq1YNf39/IiIidFO+u3XrhoeHB9OnT9fb7+eff8bPz49cuXLptatUKoYOHcrUqVMpVqwYXl5ejBs3jnz58uHn55eqGI0VHf2K+KUiLK1kZJQQiVGpVKztq00Sx6k1nLsXwqHAZ3y3x4k16vp6fa2IZZXV1+TkJUXMHuraHR4cTvjgs99YqVhlDhY2EPtfzdEKnaD1AjB7o27ntT9h4yeQuzjcP/m6PV9lKFAN7h7TFlxPTAt/KNkcHFy1jxUFYiNh+xfa0V0ATWdB8cb6+6nj4OdG4FIA7PNA0J7X2+6dgK0Dtb+7lYPgJBZC8/DWTmM8/V9dbtsc0OEX8Pwg8X3SiNHJqAIFCnD06FFy5szJzp07WbNmDQAvXrzAxiZtpw5UrVqVzZs3M2bMGCZPnoyXlxf+/v506dIlTc+TVVTwG87NK2vwirvBv7+OwG342uR3EkKIdPLdd9/h6enJ3bt3+eabb3BwcADg4cOH9O/fP5m9tVIz1cLd3R1LS0vMzV9/EChVqhSPHj0iJiYGK6vXq74NHDiQP/74g4MHD5I/f/5E47C2tsY6k92FjonT0HDOQd3jSa3KpN/JLm6EDb0M26W2ghAijd28eZO4uDiKFSum1x4YGIilpaVBDcDEdOjQgSdPnjB+/HgePXpExYoV2blzp26k7Z07d3S1qeJdvXqVQ4cOJVrTcOTIkURERPDpp58SEhLCBx98wM6dO9P8O05iYqKjdb9bZ9A5hcjqLMzN8C6UE+9CORnSUP99ZfafV5m3L4h2MRMB6FA5LzP/rU+sYs4adT1isOSCxouaZpdob/GX4cEV9etEFMC5X7U/QKRijZ3q9f+zeokogAentT/J+WOo9icpO77Q/iTkVTIrCiaViAK4f0r7ozveCyLvXsAuA5JRKkUxbhzZDz/8wJAhQ3BwcKBQoUKcPn0aMzMz5s2bx6ZNm9i/f396xZoqYWFhODs7Exoa+l5M2bt5Zj9ev/kBcK7xOirU9DVtQEKITCkrvfdVr16datWqMW/ePEA78qlgwYIMHDgwwQLmX375JatXr+bGjRu6Lxpz585l5syZPHjwANBOFRw0aBCbN2/mwIEDBl96kmPq1+9h6CtqTN+n13ZrRhJ1EVLryTX44X/aD1tvK9MG2i1L+3MKITKtjHjv8/HxoVevXgaLEf3yyy/89NNPHDhwIF3Om1He5TV89OAueZf8N518/AswM7qiihAihaLj1Fx6EMb+K4+Zty8IgI65b/Li+RMuKZ44E0Fps9sUUT3gM4s/UnWOg+pyWKKmhvm/bFNXo7n58VTHG6no3zTVS4QBh9VluKryZIFFdzxeXaWN+d+EYs8NjTsazHBUveK24kqI4kAdswuMslyT6Ll+LPkTfTq2Myq+1Lz3GZ2MAjh58iR3796lUaNGujvh27Ztw8XFhVq1ahl7uHRl6i8U6eH0vC5UfvYHQWZeFBx9XG8UgBBCQPq9923dupWmTZtiaWnJ1q1bk+zbqlWrFB1z7dq1dO/encWLF+umWqxbt44rV67g5uZmMNXi7t27lClThu7duzNo0CACAwPp1asXgwcPZuzYsQD079+f1atX89tvv1GixOvh1s7OztjaJj/1wdTXDs/R2/Qe35zeDNW7jFKKjQJLG+2/igZiX4G1A0x1New7+g68uKUdsv3mMHQhxHsvI977nJycOH36tMF07qCgIKpUqUJISEi6nDejvMtreOdWIAUDqhCrmGM5KZnRDkKIdKPRKAxac4Zt5x/qtRdR3cdN9YLi5o8IVVtTyuwO9kQxNq4XYPzntDKqm3xlsYqSZndYENeaB0ouCqseMsJyPQD1o7/lieJCJNao0f9MZoaGwqoHBCkeqTp3Uo6Mrk8+F+OmCqfmvc/oaXqgnetdpUoVFEVBURRUKhXNm6fDHVuRoKKdvyV03gGKam7y97pZ1O461tQhCSGyCT8/Px49eoSrq2uSNTRUKlWKi5gbO9WiQIEC7Nq1i2HDhlG+fHk8PDwYMmQIo0aN0vVZuHAhAHXr1tU717Jly+jRo0fKnqyJPAx9pff4/MTG75aI+rUzXN2WfD+ACSHaqXnuFVJ/PiGESIJKpeLly5cG7aGhoSm+bryvYmOitP+qLLE0cSxCZGdmZioWdK7Mgs4p659QEaGoWDUWZirMzVR8uvIUu/8Nplm5vGy/oF2gZ+Un1QgMLk2nP7wAqFciDydvvWB7dBzz1R9SMq8jNx5p3ytbV8xH6KtYnoXHsKSbN66ONkTFqomIjuPWs0huPY0gMiYORxtLyno4c+NJOP1WJTxFcFjD4sSqNZT1cCIkMha/Sh7YWJrm5mOqRkatWLGCWbNmERgYCEDx4sX54osv+Pjjj9M8wHdl6rvb6eXMpjlUOj+Jl4otEZ8eI69H4isMCiGyn/f1vS+jmOr1i4iO01s9b2O/mngXypH6A765Ml5iPGtDj9QNPxdCvF8y4r2vZcuW2Nra8uuvv+pq/6nVajp06EBERAQ7duxIl/NmlHd5Da9cOEHJjQ0JxQHniffTKUIhhEh7GTIyas6cOYwbN46BAwfqpuQdOnSIzz77jKdPnzJs2DBjDylSoWLrwQT9u5qicYFc+nU4eUdsNHVIQggh3kGsWqOXiLK3Mn+3RNTRBcn3qfQxtJ6f+nMIIYSRZs6cSZ06dShRogS1a9cG4O+//yYsLIx9+/Yls/f7LS5GWwMmTiXjooQQ7z+jk1Hz5s1j4cKFdOvWTdfWqlUrypQpw8SJEyUZlUFU5hZYtJqDZmMr/he+hxP7NlG1fhtThyWEyEYGDx5M0aJFGTx4sF77/PnzCQoKwt/f3zSBZVFfb7us9/jS5CbGH0RR4NB3sHeSfnutoXDrEFToCNX6pD5IIYR4R6VLl+b8+fPMnz+fc+fOYWtrS7du3Rg4cCA5c+Y0dXgmFfffNL04maQnhMgGjE5GPXz4kJo1axq016xZk4cPHyawh0gvnuXrcPrIR1R+tB73g6MJq9oAJ8cUTMkQQog0sHHjxgSLmNesWZMZM2ZIMspIAUdu6X6/NCmVK6Wu+giC9hi2N5pk2CaEECaSL18+pk2bZuowMh117H81o8wkGSWEeP8ZvV5o0aJFWbdunUH72rVrjV46W7y70l2/5bEqF/kJ5uxKwyXQhRAivTx79gxnZ8MEuJOTE0+fPjVBRFnX7+ce6H5f2KUy9tapWF8kcHfCiaiJoe8QmRBCpL2///6brl27UrNmTe7f19ZGWrlyJYcOHTJxZKalidVO01PLND0hRDZgdDJq0qRJjB8/niZNmjBlyhSmTJlCkyZNmDRpEpMnT06PGEUSbBxceFZ3BgA1g9fw76mDJo5ICJFdFC1alJ07dxq079ixg8KFC5sgoqxr8cHrut+blM1r/AECWmhHRcXLX037b+sU1I0SQogMtHHjRnx9fbG1teX06dNER2sTMKGhodl+tFT8yKg4lZWJIxFCiPRn9K3Xtm3bcvz4cebMmcOWLVsAKFWqFMePH6dSpUppHZ9IgVI+7Tl7+lcqhu7DctsQosv9g7WVtanDEkK854YPH87AgQN58uQJ9evXB2Dv3r3Mnj1bpugZ4cDVx1y8HwbAuBalUalUxh1g9wS49ffrx21+gvLt0jBCIYRIO1OnTmXRokV069aNNWvW6Npr1arF1KlTTRiZ6SnR4QDEmNmZOBIhhEh/RiWjYmNj6du3L+PGjeOXX35Jr5hEKnh1nUfoguoU09zg4Oqp1OkxxdQhCSHec7169SI6Opqvv/6aKVO07zmenp4Gi1yIxMWpNfRYdkL3uHFpt5TvfPl3WNtVv61CZyj3UcL9hRAiE7h69Sp16tQxaHd2diYkJCTjA8pElPiRUeZyU1kI8f4zapqepaUlGzduTK9YxDtwzpOfm5XHAFD15iJuXbtg4oiEENlBv379uHfvHsHBwYSFhXHjxg1JRBlhyd839B4XyJnCu+FbBxkmovKUhA8XgrEjq4QQIgPlzZuXoKAgg/ZDhw5l+ynemrgY7b9SwFwIkQ0YXTPKz89PNz1PZC4VWvTnsk0lbFUxvFzfj7i4OFOHJIR4z8XFxbFnzx42bdqEoigAPHjwgPDwcBNHlvlpNArf7Lyqe7xt8Acp23Fjbzi9Qr+tzIcw4FgaRieEEOmjT58+DBkyhGPHjqFSqXjw4AGrVq3i888/p1+/fqYOz7TitPWzNGZSM0oI8f4zumZUsWLFmDx5MocPH8bb2xt7e3u97YMHD06z4IRxVGZm5O60iMhldSgXe4GDa2ZQp+tXpg5LCPGeun37Nk2aNOHOnTtER0fTqFEjHB0dmTlzJtHR0SxatMjUIWZq2y8+1P3+XYcKlMlnuDKhgYkJ9OmyAYo1SsPIhBAi/YwePRqNRkODBg2IjIykTp06WFtb88UXX9C7d29Th2dSyn/JKMxlZJQQ4v1ndDLq559/xsXFhVOnTnHq1Cm9bSqVSpJRJpanUEnOlPuCShemUjVwLkFXWlK0ZAVThyWEeA8NGTKEKlWqcO7cOXLlyqVr//DDD+nTp48JI8v8zt0NYeDqM7rHfhU9kt8p7KFh24QQmZYnhMhSVCoVY8eO5YsvviAoKIjw8HBKly7N4sWL8fLy4tGjR6YO0WQUtXaanmIuI6OEEO8/o5NRN2/eTI84RBqq+OFw/g3cTumo08Ss/5SYUYewspI7LEKItPX3339z5MgRrKz0PzR7enpy//59E0WVNbRecFj3+6Ku3ilbQe/UMv3Hnx2SRJQQIsuIjo5m4sSJ7N69WzcSys/Pj2XLlvHhhx9ibm7OsGHDTB2mSan+GxmlSAFzIUQ2YHTNKJH5qczMcf34R8KxpbT6Cv+smmzqkIQQ7yGNRoNarTZov3fvHo6OjiaIKGtK0Qp6f46Dv2a+fjwxFPKWS7+ghBAijY0fP56FCxfi6enJzZs3adeuHZ9++infffcds2fP5ubNm4waNcrUYZrWfyOjkJFRQohswOhkVNu2bZk5c6ZB+zfffEO7du3SJCjx7nJ7FCWo0lgAqt/6gcALx00ckRDifdO4cWP8/f11j1UqFeHh4UyYMIFmzZqZLrBM7uqjl7rfe9T0xMwsmdFNkc/hyPevH1f/LJ0iE0KI9LN+/XpWrFjBhg0b+PPPP1Gr1cTFxXHu3Dk6duyIubm5qUM0PUlGCSGyEaOTUQcPHkzwS0bTpk05ePBgmgQl0kbFVgO5YPc/rFVxsPkzoqKiTB2SEOI98u2333L48GFKly5NVFQUnTt31k3RS+imhdDy9X99rZzYqkzyOxz8Vv9xU3lthRBZz7179/D29gagbNmyWFtbM2zYsJRNU84mVLpklEzTE0K8/4xORoWHhxvUBwGwtLQkLCwsTYISaUSlwqPbj4TiQDHNdY4v+8LUEQkh3iMFChTg3LlzjB07lmHDhlGpUiVmzJjBmTNncHV1NXV4mdLtZxG6351tU1jL7/iS179PDE3jiIQQImOo1Wq97xAWFhY4ODi80zEXLFiAp6cnNjY2VK9enePHk54JEBISwoABA3B3d8fa2prixYuzfft23faJEyeiUqn0fkqWLPlOMRrDTKNNRqksZWSUEOL9Z3QB83LlyrF27VrGjx+v175mzRr+396dx0VZ7X8A/zyzssim7IigV0VRQUVFNLObFC4tdrtd61Kilf5UMLq0WrfMuoldy7x5TctC7bZYWZqp0TVyuW6puOGGu+ACLsga68z5/TEyOALK4DDDzPN5v17Pa57lPGe+B2y+ceY854SHh1ssMLKMtv4dcHDwTHhseQZ35P0Huzfeg75DH7B1WERk56qrq9GtWzesXr0a8fHxiI+Pt3VIdmHo7A3G/e8mD7r1DUIA+mrDvsq5ZYIiIrICIQTGjRsHrdYw6qeiogKTJk2Cq6urSbnvv/++SfV9/fXXSElJwcKFCxEdHY25c+ciLi4O2dnZDX4hUlVVhXvuuQe+vr5Yvnw5goKCcObMGXh6epqU69GjB3755RfjsUpl9p9LzSbpDJ/3EkdGEZEMmP3p+tprr+FPf/oTTpw4gbvvvhsAkJGRga+++grffvutxQOk29fjngTsPrIOfa/8iKD1ybjUvT98fANsHRYR2TG1Ws1Hf82k1wuT486+TRgRcCKjbj+cXyQQkf1KSEgwOX788cdvq745c+ZgwoQJGD9+PABg4cKFWLNmDdLS0vDyyy/XK5+WloaCggJs3boVarVhZGpoaGi9ciqVCv7+/rcVW3PVjoxScGQUEcmA2Z1R999/P1auXImZM2di+fLlcHZ2RkREBH755RcMHTq0JWI0mjVrFqZNm4bk5GSTSXPp1sKfnI+z7+1Ge/057Fr8FNo9vxoKJRdTJKLmS0xMxDvvvINPPvnEqt8c26tV+84b99c+M6ThQtUVwNuNrK533/stEBURkXUsXrzYYnVVVVUhMzMT06ZNM55TKBSIjY3Ftm3bGrxn1apViImJQWJiIn744Qf4+Pjgr3/9K1566SWTydOPHTuGwMBAODk5ISYmBqmpqejQoYPFYr8Z42N6Ko6MIiLH16y/HkaNGoVRo0ZZOpab2rlzJz766CNERERY9X0dhZOrB/R/+gRV396HfuVbsPnb93DHo5xDioiab+fOncjIyMB///tf9OrVq9mPWsjFoQt18yqGB7rXL6CrbrwjCgA0ro1fIyKSkcuXL0On08HPz/Qz08/PD0eOHGnwnpMnT+LXX39FfHw81q5di+PHj2PKlCmorq7G9OnTAQDR0dFYsmQJwsLCcOHCBcyYMQNDhgzBgQMH4Obm1mC9lZWVqKysNB7fzhy6imuPZSvU7IwiIsdnF0NjSktLER8fj0WLFsHLy8vW4ditDj0HYX+3ZwEAUYf/ieMHd9o2ICKya56ennj44YcRFxeHwMBAeHh4mGzmsPQktM2ps6VdKDI81vjS8AYmw60oBt7ybvzmV/NbKCoiInnQ6/Xw9fXFxx9/jKioKIwZMwavvvoqFi5caCwzYsQIPPLII4iIiEBcXBzWrl2LwsJCfPPNN43Wm5qaapL7goODmx2jUlzrjOLIKCKSAbt4riIxMRGjRo1CbGws/vGPf9y0rCW/nXBEUWNexcF/bkCPikwolj+J4g6b4e5m3h+NRCRver0es2fPxtGjR1FVVYW7774bb7zxBpydmzfBdktMQmtundZwLL8EQCNzRf2zo+mxqy/g0R6ISQR6/dkK0RER2Q9vb28olUrk55t21Ofn5zc631NAQADUarXJI3ndu3dHXl4eqqqqGlwt3NPTE127dsXx48cbjWXatGlISUkxHhcXFze7Q0otaueMYmcUETm+Vj8yatmyZdi9ezdSU1ObVN6S3044IkmhRPsnl+AKPNFJ5ODgR09D6PW2DouI7Mjbb7+NV155BW3atEFQUBA++OADJCYmNru+6yehDQ8Px8KFC+Hi4oK0tLQGy9dOQrty5UoMHjwYoaGhGDp0KCIjI5tdZ0urqtHj+MVSAED3gBse9Si9BOhrTM+9cAyYuJ4dUUREDdBoNIiKikJGRt0iD3q9HhkZGYiJiWnwnsGDB+P48ePQX/f/vUePHkVAQECDHVGA4emMEydOICCg8YV/tFot3N3dTbbmUgpDLuDIKCKSg1bdGZWbm4vk5GR88cUXcHJyatI906ZNQ1FRkXHLzc1t4Sjtj4dvB1wduRA6ISGm9L/Y8u0cW4dERHbks88+w4cffoiff/4ZK1euxI8//ogvvvjC5H/wm6p2EtrY2FjjOXMmofXz80PPnj0xc+ZM6HS6ZtdZWVmJ4uJik82SDp4vQo1ewFmtRJDnDSPIts+v24/8K/ByjkXfm4jIEaWkpGDRokVYunQpDh8+jMmTJ6OsrMy4ut7YsWNNJjifPHkyCgoKkJycjKNHj2LNmjWYOXOmyZcpzz//PDZu3IjTp09j69ateOihh6BUKvHYY49ZpU0q42N6XE2PiByf2Z1R69evb4k4GpSZmYmLFy+ib9++UKlUUKlU2LhxIz744AOoVCrjHx7Xs+S3E46s84AR2Nv1GQBA/0OzcChzk40jIiJ7kZOTg5EjRxqPY2NjIUkSzp8/f5O7GnazSWjz8vIavOfkyZNYvnw5dDod1q5di9deew3vvfee8THu5tTZkqNqdXqBhz7cCgAor9ZBkiTTAid+rdt/aAHgxEeniYhuZcyYMXj33Xfx+uuvo3fv3ti7dy/S09ONn/05OTm4cOGCsXxwcDB+/vln7Ny5ExEREXjmmWeQnJyMl19+2Vjm7NmzeOyxxxAWFoa//OUvaNeuHbZv3w4fHx+rtEld2xmlbtqX8ERE9szsOaOGDx+O9u3bY/z48UhISGjRx+CGDRuGrKwsk3Pjx49Ht27d6i3DSubr+9h0ZL23E73KtsLjx6dREPI/tPW+yUpOREQAampq6o1WVavVqK6utsr7Xz8JrVKpRFRUFM6dO4fZs2cbV0QylyXn/LjegXNFWLr19M0LXdh32+9DRCRHSUlJSEpKavDahg0b6p2LiYnB9u3bG61v2bJllgqtWVS49piemiOjiMjxmd0Zde7cOfznP//B0qVLMWPGDNx999146qmnMHr06Eaft24uNzc39OzZ0+Scq6sr2rVrV+88mU9SKNFxwn9w/l+DECTysfuTsXB/fg1UKruY156IbEQIgXHjxkGrrZvToqKiApMmTYKrq6vx3Pfff3/LulpiEtrm1KnVak3aYwkXiytw37zNJueOvDW8fsGOdwKnNgF//LtF35+IiOyLGrWP6XFkFBE5PrMf0/P29sbf/vY37N27F7/99hu6du2KKVOmIDAwEM888wz27eM3vPakjac3qv60BJVCjb4V27El7SVbh0RErVxCQgJ8fX1NHmt7/PHHERgYaHKuKVpiEtrm1NkS9p0tMjnu08ETTuobRvQW5ho6ogDAL9xKkRERUWukufaYnoojo4hIBm5rCEzfvn3h7++Pdu3aYdasWUhLS8OHH36ImJgYLFy4ED169LBUnEYNDbml2xPaaxD2nXkTkbumYej5T7Dtxx6Iuf9JW4dFRK3U4sWLLVpfSkoKEhIS0K9fPwwYMABz586tNwltUFCQcVXVyZMn49///jeSk5MxdepUHDt2DDNnzsQzzzzT5DqtoaCs0uT4rQcbGNG7+f26/cA+LRwRERG1ZioY5sNVqLmaHhE5vmatplddXY3ly5dj5MiRCAkJwc8//4x///vfyM/Px/HjxxESEoJHHnnE0rFSC4q8bwp2BfzVsL/rZRzes/kWdxARWUZLTEJ7qzqt4eD5uhX5hnb1QY/ABhbU2PVp3b5b40uHExGR41Ne64xSqdQ2joSIqOVJQghhzg1Tp07FV199BSEEnnjiCTz99NP15m/Ky8tDYGBgs5b5trTi4mJ4eHigqKiIK+vdgr6mGofeG4Ge5TtxAd5QTtoAX/+Wm6CeiFoOP/tujyV+fqEvrwEAvDW6J54YGFK/QOYS4Mdkw77aFXjV/NUIiYgsibnj9jX3Z6jXC9TMaAeNpMPVSfvg5R/ackESEVlYcz77zB4ZdejQIcybNw/nz5/H3LlzG5xI3NvbG+vXrze3arIxhUqN0ElfI1cRhABcxqVPxqC8vNzWYRER2Z1qXd2XMSFtXRouVNsRBQDJnG+RiEjOqnU6aCTDyCilkosJEZHjM6szqrq6GiEhIRg4cOBNVx1SqVQYOnTobQdH1tfGox2Uf12GErigR81B7J3/BHQ6249wIyKyJ//65Zhx/47O3vUL/F5getzGp4UjIiKi1qymRmfc5wTmRCQHZnVGqdVqfPfddy0VC7USgZ0jcD72Q9QIBWJK12HLomdtHRIRkV1ZsPGEcV+hkOoXOLurbj9xhxUiIiKi1qymusq4zzmjiEgOzH5Mb/To0Vi5cmULhEKtSdgdD+FA3zcBAHfmLcXmZbNtHBERkX0o+r0aOr1hOsaH+gQ1XOjL6xb58AmzQlRERNSa1dTUdUapNRwZRUSOz+wHkrt06YI333wTW7ZsQVRUFFxdXU2uX7+0Ntm33g9Oxa6rOeh3+mPEHH4bu/7bHv3ufczWYRERtWpH8upW0evk7XqTkkRERAa6mhrjvqTgyCgicnxmd0Z9+umn8PT0RGZmJjIzM02uSZLEzigHEzX2HWT++xyiCtYgfEsyDnr5o0f/P9o6LCKiVquypm6evWp9AwvWFubW7Q99yQoRERFRa1dTXVl3oOAE5kTk+Mz+pDt16lRLxEGtlKRQIHLSYhx4fyR6lu9C4OoncNTpe3TtNcDWoRERtUpXyur+oKhpaAGI3Z/V7QdEWiEiIiJq7fQ6w8gonZCgVJg9kwoRkd3hJx3dkkqjRefE73BMHQYvqQRe3z2C00f32zosIqJW6Upp3bwfd3ZtYJW8HR/V7Xe51woRERFRa1dTU214lTgqiojkoVmfdmfPnsWqVauQk5ODqqoqk2tz5syxSGDUuji18YT/lNU4/e97EKo7jeov/4Tz439CYEgXW4dGRNSqnC+sAAD0CHTHwE7tTC9WFAMVRYb9oChAyXlBiIgIEDpDZ5QOShtHQkRkHWZ3RmVkZOCBBx5Ap06dcOTIEfTs2ROnT5+GEAJ9+/ZtiRiplXDz8oVu4mqc/ehetNefR86SB3Bxws/wDexg69CIiFqNtC2Gx9kHdGxb/+LJDXX7Q56zTkBERNTq1VRfGxnFzigikgmzH9ObNm0ann/+eWRlZcHJyQnfffcdcnNzMXToUDzyyCO3roDsmqdfMJye/BF5kg86iPMoWzQK+edzbB0WEVGro1U18AfFN0/U7XcbZb1giIioVdNzZBQRyYzZnVGHDx/G2LFjAQAqlQrl5eVo06YN3nzzTbzzzjsWD5BaH+/2nSGeWInL8EJHkYOKRSNw4dxpW4dFRGRzlTU64/6EIR1NL9ZUgoiIqCG6asPUJzqJnVFEJA9md0a5uroa54kKCAjAiRMnjNcuX75sucioVQvo1BM1CWtwUWqHEHEWNZ8Mx/kzx20dFhGRTZVUGFZDkiTAy0VjenHd63X7HYdaMSoiImrt6uaM4gTmRCQPZndGDRw4EJs3bwYAjBw5Es899xzefvttPPnkkxg4cKDFA6TWy79jD2DcWuRJPggWFyCWjMTZU9m2DouIyGYKfzd8WdNGq4JCIZlevHSkbv/x760YFRERtXb6GkP+qOHIKCKSCbM7o+bMmYPo6GgAwIwZMzBs2DB8/fXXCA0NxaeffmrxAKl18w3pBuVTP+G85I8gkQ/V0pE4dmCXrcMiIrKJc4UVUCokhLZzrX+xbSfDa0wSoOQ330REt2v+/PkIDQ2Fk5MToqOjsWPHjpuWLywsRGJiIgICAqDVatG1a1esXbv2tuq0FF0NR0YRkbyY/WnXqVMn476rqysWLlxo0YDI/vi074LLE35C7if3I1h/Fs7fPoCsksXoFRNn69CIiKxqaFcfHJwRh4KyqvoXj2cYXtt2qn+NiIjM8vXXXyMlJQULFy5EdHQ05s6di7i4OGRnZ8PX17de+aqqKtxzzz3w9fXF8uXLERQUhDNnzsDT07PZdVqS0Bnyhl5iZxQRyYPZI6NqVVVV4ezZs8jJyTHZSJ68AzvBMykDx9Td4CGVoUt6PHamf2HrsIiIrM5JrUSgp3PdibLLwMd/BArPGI6dvWwTGBGRA5kzZw4mTJiA8ePHIzw8HAsXLoSLiwvS0tIaLJ+WloaCggKsXLkSgwcPRmhoKIYOHYrIyMhm12lJ+tqRUeyMIiKZMLsz6ujRoxgyZAicnZ0REhKCjh07omPHjggNDUXHjh1vXQE5LLe2/gh+dh2yXAbCSapG322J2PzVPyGEsHVoRES2M/sPwPnddceBvW0WChGRI6iqqkJmZiZiY2ON5xQKBWJjY7Ft27YG71m1ahViYmKQmJgIPz8/9OzZEzNnzoROp2t2nQBQWVmJ4uJik605BDujiEhmzO6MGj9+PBQKBVavXo3MzEzs3r0bu3fvxp49e7B79+5bV2CG1NRU9O/fH25ubvD19cXo0aORnc0JslszJ1d3hKesRmbbUVBKAndkv40t854yrsBIRCR77kG2joCIyK5dvnwZOp0Ofn5+Juf9/PyQl5fX4D0nT57E8uXLodPpsHbtWrz22mt477338I9//KPZdQKGv1c8PDyMW3BwcLPapDc+pscJzIlIHszuet+7dy8yMzPRrVu3lojHxMaNG5GYmIj+/fujpqYGr7zyCu69914cOnQIrq4NTA5LrYJSpUbfpM+R+fnfEXVyPu4o+A773z2J9hOWoa2Pv63DIyKyLlcfoOxS3bFKa7tYiIhkSq/Xw9fXFx9//DGUSiWioqJw7tw5zJ49G9OnT292vdOmTUNKSorxuLi4uFkdUkJXOzJK3exYiIjsidkjo8LDw3H58uWWiKWe9PR0jBs3Dj169EBkZCSWLFmCnJwcZGZmWuX9qfkkhQJRY2fiwB3z8bvQIqJqD8o+vAvHsqyzIgkR2RdzVi9asmQJJEky2ZycnEzKlJaWIikpCe3bt4ezs7Nx7g+ryz9o2hH12NfWj4GIyMF4e3tDqVQiPz/f5Hx+fj78/Rv+4jMgIABdu3aFUlk38qh79+7Iy8tDVVVVs+oEAK1WC3d3d5OtWa51RnECcyKSC7M7o9555x28+OKL2LBhA65cuWKRZ6SbqqioCADQtm3bRstY6rltsoyesY/j8pgfkSf5IFhcQNDy+7Dlu3mcR4qIjGpXL5o+fTp2796NyMhIxMXF4eLFi43e4+7ujgsXLhi3M2fOmFxPSUlBeno6Pv/8cxw+fBjPPvsskpKSsGrVqpZujqkFg+r2p50FwoZb9/2JiByQRqNBVFQUMjIyjOf0ej0yMjIQExPT4D2DBw/G8ePHodfrjeeOHj2KgIAAaDSaZtVpSfprnVFCwc4oIpIHszujYmNjsX37dgwbNgy+vr7w8vKCl5cXPD094eXVcisE6fV6PPvssxg8eDB69uzZaDlLPbdNltMhPBouif/DIae+cJEqMTjr7/jt/UdRWlJk69CIqBVozupFkiTB39/fuN04x8fWrVuRkJCAu+66C6GhoZg4cSIiIyNvOuLK4ipLTY+1btZ7byIiB5eSkoJFixZh6dKlOHz4MCZPnoyysjKMHz8eADB27FhMmzbNWH7y5MkoKChAcnIyjh49ijVr1mDmzJlITExscp0tqnZklIKP6RGRPJjd9b5+/fqWiOOWEhMTceDAAWzevPmm5Sz13DZZlrt3ALq/sA67Pv87+pxciIHF6Tj9/mCcffATdIscaOvwiMhGalcvuv4PhqasXlRaWoqQkBDo9Xr07dsXM2fORI8ePYzXBw0ahFWrVuHJJ59EYGAgNmzYgKNHj+L9999vsL7KykpUVlYajy0yqrb0ukc9+jx++/UREZHRmDFjcOnSJbz++uvIy8tD7969kZ6ebvxyIicnBwpF3ffuwcHB+Pnnn/G3v/0NERERCAoKQnJyMl566aUm19mSBB/TIyKZMfvTbujQoS0Rx00lJSVh9erV2LRpE9q3b3/TslqtFlotJ4dtjSSlCv0SZiF7+51olz4ZofpcVH4/Cv/L/D9EP/4GNBqNrUMkIiu72epFR44cafCesLAwpKWlISIiAkVFRXj33XcxaNAgHDx40Jgj5s2bh4kTJ6J9+/ZQqVRQKBRYtGgR7rzzzgbrTE1NxYwZMyzbuHPXzW94/zzL1k1EREhKSkJSUlKD1zZs2FDvXExMDLZv397sOluUrgYAH9MjIvlo0qfd/v370bNnTygUCuzfv/+mZSMiIiwSGAAIITB16lSsWLECGzZsQMeOHS1WN9lO2MCRKPrDFmQtmYBeZVsxJGc+jrzzCzSPfIxO3XrbOjwiauViYmJM5u8YNGgQunfvjo8++ghvvfUWAENn1Pbt27Fq1SqEhIRg06ZNSExMRGBgIGJjY+vV2SKjar+fULevMPupeCIikhN9FQB2RhGRfDTp0653797Iy8uDr68vevfuDUmSGpyAWpIk6HQ6iwWXmJiIL7/8Ej/88APc3NyQl5cHAPDw8ICzs7PF3oesz8OnPXo9vxZ7flyAzrvfQjddNiq+isWmDk+j/2Ovw9nFxdYhEpEVNHf1ouup1Wr06dMHx48fBwCUl5fjlVdewYoVKzBq1CgAhi9K9u7di3fffbfBziiOqiUiIpuqHRnFx/SISCaa9FXtqVOn4OPjY9w/efIkTp06VW87efKkRYNbsGABioqKcNdddyEgIMC4ff01l8Z2CJKEPg9MQeWELTjgHAUnqRp35i7ApdlR2LP+e1tHR0RWYInVi3Q6HbKyshAQEAAAqK6uRnV1tclcIQCgVCpNVlGymk5/tP57EhGRfdHXPqbHCcyJSB6a1PUeEhLS4H5La2j0FTke76BOaPfCL9iX/imCdvwDHcR5dNg4Hjt3Lka7B99GpzDLPfpJRK1PSkoKEhIS0K9fPwwYMABz586ttyJSUFAQUlNTAQBvvvkmBg4ciM6dO6OwsBCzZ8/GmTNn8PTTTwMA3N3dMXToULzwwgtwdnZGSEgINm7ciM8++wxz5syxTqOunq7bHz7LOu9JRET2S2+YwJyP6RGRXJj9aXflyhW0a9cOAJCbm4tFixahvLwcDzzwAIYMGWLxAEkeJIUCkSMnoGzww9j55cvom/cN+v++CdVf3oWtbe/HH/48A35BobYOk4hagLkrIl29ehUTJkxAXl4evLy8EBUVha1btyI8PNxYZtmyZZg2bRri4+NRUFCAkJAQvP3225g0aZJ1GvWvyLp9zw7WeU8iIrJb0rXV9ISSI6OISB4k0cThR1lZWbj//vuRm5uLLl26YNmyZRg+fDjKysqgUChQVlaG5cuXY/To0S0csnmKi4vh4eGBoqIiuLu72zocaqKzh3eg8MdX0fP3HQCA34UWu/0eRqf7X0BgcCcbR0fU+vGz7/bc9s/vDY/r9ossFxgRUQti7rh9zf0Zbp8/AQMvfYPtQeMwcMK/WjBCIiLLa85nX5OX93nxxRfRq1cvbNq0CXfddRfuu+8+jBo1CkVFRbh69Sr+7//+D7Nm8VEEsoz23Qeg54vrcHTEMhxVd4OLVIk7Ln4J70/6Y/vcv+JU9j5bh0hEREREZBnXHtOT+JgeEclEkz/tdu7ciV9//RURERGIjIzExx9/jClTphgfnZg6dSoGDhzYYoGSPHWNHgHRPw6HNy2HYuu/EFZ1AAML10D/5VrscYpCdeQTiBz2KLRaJ1uHSkRUn1eorSMgIiJ7cG0Cc4mP6RGRTDR5ZFRBQYFxme02bdrA1dUVXl5exuteXl4oKSmxfIQke5JCge53/QVhr2zBsfuWY59LDBSSQJ/KXRiwIxklqWHY/OEUHNy1EXqdDVbKIiK63vVPv9+RYrs4iIjIbkjXRkZByZFRRCQPZn3aSZJ002Oiltal3z1Av3tw8cxhnFm3AJ3O/gBvFOKOi18Aq7/AudW+OO17D1x6jEBY/7vh4uJq65CJSG4uH6vb7zHaZmEQEZH9kK6NjFKoODKKiOTBrM6ocePGQavVAgAqKiowadIkuLoa/tivrKy0fHREjfAN6Q7fpz9ATdVs7N/0DfT7l6Nr0TYESRcRdPEL4OIX+P1XLfY6RaCs/RB4ht+NP/QcAKdr/36JiFpM5XWjhLWcAJiIiG6ttjMKCo1tAyEispImd0YlJCSYHD/++OP1yowdO/b2IyIyg0qjRUTsE0DsE6j4vQR7//c9xOEf0aFwJ9pJhehduRM4sRM4MQdlq7TI0oSh2Ls3NKED4du1P9p36AylsslPqxIR3VrFVcOrT3eAI4iJiKgJah/T48goIpKLJndGLV68uCXjILptTi5u6B2XAMQlQOj1OJu9C+f3pMMldxNCyw+ijfQ7elXvBy7sBy58BmwDioQrzqpDUezeGTrvbnDy7QyPwD/AP7gL3Nw4ooGImuH3AsNrG1/bxkFERHZDITiBORHJC2fII4ckKRRo330A2ncfAAAQeh0uHN+PCwc3Qpe7E75FWQiqyYWHVAaPmoNAwUGg4AfgaF0dl+CJy0o/lGm8UeXkA30bPyjd/aHxDIRruyB4+AWjnU8QNBr+TwMRXafskuHV1du2cRARkd1QcM4oIpIZdkaRLEgKJQK69kFA1z7Gc7qqCpw9sR+XT+5F1fkDcC48BreK8/DR5cEVFfBBIXx0hUB5NlAO4Gr9enVCwmXJHYUKL5Qr3VGp9kS11hN6Jy8Il3ZQubaD2t0bzu4+0Lp7w9nNC65tPOHq6gqVSmm19hORFe390vDqypFRRETUNLUjoxRKzhlFRPLAziiSLaXGyWT0lJEQKCm8iMu5x1B28TQqCy9AX3wBUmk+tBWX4FJ1BR41V+AlCqGUBLxRBG99EaAHUA3g91u/d7VQoghOKJNcUKFwQaXCBVVKF1Sr2qBG5Qq90glCpQVUWkCpBdTOkNROUKidoFA7Q6lxhlJj2JfUWijVWihUGihVaqjU115VGijVGqjUGqhUGqg0GqjVWqjVKq6ESdRShADyDxj2yxvowSYiImqA8TE9jowiIplgZxTRjSQJbl5+cPPyA3BHo8X0NTW4euUCSq+cQ/nVPFQUX0Z16WXoS69AKi+AorIQmsqrcKopgquuGG6iBG1QDgBQSzp4oAweKDN0YukB1ACwwqKUeiGhCkrooEQNlKiRDPt6KK5tSuglBQQU0EsK6KCEkAznhaS4ds1QBpICekkFPRSAZLgurnutvQ5F3TEUKgjJUB4Kw2a4pjRM9iwZJpSXJCUgAZCUhjmga69DMnSmKQzvL12LA5AgKepepdq6JAmSsZxhH9euG84byhnuua7ctboM1yQAhrLi+nuMdUqGOBUKCBgeE5VQ9z6GmAEJEiSFBIHa95fqriskSFBAkgBReyxJkCDBuY0X3NtxlI1dqCqt2y8+Z7s4iIjIrvi5KoEiwMfD1dahEBFZBTujiJpJoVLByy8YXn7BTb9Jr0dVeTHKSopQXnIVFWVFqCwtRHV5Map/L4auogRSVQlQXQHUVAA1lYCuEoqaCih0lVDoK6HUVUKlr4RKVEGlr4JGVBm6lYQOKtRACcOrSuiglnT145YEtKiBoferEeKGV7Kp39qNRvTUpbYOg5ri2Lq6fQ3/oCAioqbxcVEARYCfp5utQyEisgp2RhFZk0IBjasnNK6e8PIPafn3EwJCV43q6irUXNuqq6ugq6lGTXUV9DVV0NdUQ+hroNfVQK/TGV71umvndBAm+zUQOh2E0EHoaq5dM2yo3Rc64No1CD1Qe03ojPsQ1za9DpJeBwl6SEIHIQQAAUnoDY87Cf21dugh4dqxEAAMr1JtWQhI1+7FdcdSQ8fQX3ftWh3X13ddnYZxTrXnrrsOvWHQVu2r0BvLKlBXTgG98VdRe85QH657Lxjfw1AO9coJBeePsBtBfev273nLdnEQEcnA/PnzMXv2bOTl5SEyMhLz5s3DgAEDGiy7ZMkSjB8/3uScVqtFRUWF8XjcuHFYutT0y5+4uDikp6dbPvgbKVSAQm14JSKSAX7aETkySYKk0kCj0kDjbOtgqLkG2joAajqvUOCNIltHQUTk8L7++mukpKRg4cKFiI6Oxty5cxEXF4fs7Gz4+jb8aLu7uzuys7ONxw3NoTl8+HAsXrzYeKzVai0ffEMmZFjnfYiIWgmFrQMgIiIiIiIyx5w5czBhwgSMHz8e4eHhWLhwIVxcXJCWltboPZIkwd/f37j5+fnVK6PVak3KeHl5tWQziIhki51RRERERERkN6qqqpCZmYnY2FjjOYVCgdjYWGzbtq3R+0pLSxESEoLg4GA8+OCDOHjwYL0yGzZsgK+vL8LCwjB58mRcuXKlRdpARCR37IwiIiIiIiK7cfnyZeh0unojm/z8/JCXl9fgPWFhYUhLS8MPP/yAzz//HHq9HoMGDcLZs2eNZYYPH47PPvsMGRkZeOedd7Bx40aMGDECOl39BWFqVVZWori42GQjIqJb45xRRERERETk0GJiYhATE2M8HjRoELp3746PPvoIb71lWHDi0UcfNV7v1asXIiIi8Ic//AEbNmzAsGHDGqw3NTUVM2bMaNngiYgcEEdGERERERGR3fD29oZSqUR+fr7J+fz8fPj7+zepDrVajT59+uD48eONlunUqRO8vb1vWmbatGkoKioybrm5uU1rBBGRzDn8yCjDUvHgkFkikpXaz7zaz0AyD3MHEcmRveQOjUaDqKgoZGRkYPTo0QAAvV6PjIwMJCUlNakOnU6HrKwsjBw5stEyZ8+exZUrVxAQENBoGa1Wa7LiHvMHEclRc/KHw3dGlZSUAACCg4NtHAkRkfWVlJTAw8PD1mHYHeYOIpIze8gdKSkpSEhIQL9+/TBgwADMnTsXZWVlGD9+PABg7NixCAoKQmpqKgDgzTffxMCBA9G5c2cUFhZi9uzZOHPmDJ5++mkAhsnNZ8yYgYcffhj+/v44ceIEXnzxRXTu3BlxcXFNjov5g4jkzJz84fCdUYGBgcjNzYWbmxskSWryfcXFxQgODkZubi7c3d1bMELbYjsdj1zaynbenBACJSUlCAwMbMHoHFdzcwfAf5uOhu10LGznzdlT7hgzZgwuXbqE119/HXl5eejduzfS09ONk5rn5ORAoaibkeTq1auYMGEC8vLy4OXlhaioKGzduhXh4eEAAKVSif3792Pp0qUoLCxEYGAg7r33Xrz11lsmI59uhX973Bzb6VjYTsdyO+1sTv6QRGsfh2sjxcXF8PDwQFFRkcP/g2M7HYtc2sp2Umsll98Z2+lY2E7HIpd2OhK5/M7YTsfCdjoWa7eTE5gTEREREREREZHVsDOKiIiIiIiIiIishp1RjdBqtZg+fbpZz4jbI7bT8cilrWwntVZy+Z2xnY6F7XQscmmnI5HL74ztdCxsp2Oxdjs5ZxQREREREREREVkNR0YREREREREREZHVsDOKiIiIiIiIiIishp1RRERERERERERkNeyMasT8+fMRGhoKJycnREdHY8eOHbYOqVGbNm3C/fffj8DAQEiShJUrV5pcF0Lg9ddfR0BAAJydnREbG4tjx46ZlCkoKEB8fDzc3d3h6emJp556CqWlpSZl9u/fjyFDhsDJyQnBwcH45z//2dJNM5Gamor+/fvDzc0Nvr6+GD16NLKzs03KVFRUIDExEe3atUObNm3w8MMPIz8/36RMTk4ORo0aBRcXF/j6+uKFF15ATU2NSZkNGzagb9++0Gq16Ny5M5YsWdLSzTNasGABIiIi4O7uDnd3d8TExOCnn34yXneENjZk1qxZkCQJzz77rPGcI7T1jTfegCRJJlu3bt2M1x2hjVTHnnIHII/8IZfcAcgzfzhq7gCYP+TGnvKHHHIHIJ/8IcfcAThu/rCr3CGonmXLlgmNRiPS0tLEwYMHxYQJE4Snp6fIz8+3dWgNWrt2rXj11VfF999/LwCIFStWmFyfNWuW8PDwECtXrhT79u0TDzzwgOjYsaMoLy83lhk+fLiIjIwU27dvF//73/9E586dxWOPPWa8XlRUJPz8/ER8fLw4cOCA+Oqrr4Szs7P46KOPrNVMERcXJxYvXiwOHDgg9u7dK0aOHCk6dOggSktLjWUmTZokgoODRUZGhti1a5cYOHCgGDRokPF6TU2N6Nmzp4iNjRV79uwRa9euFd7e3mLatGnGMidPnhQuLi4iJSVFHDp0SMybN08olUqRnp5ulXauWrVKrFmzRhw9elRkZ2eLV155RajVanHgwAGHaeONduzYIUJDQ0VERIRITk42nneEtk6fPl306NFDXLhwwbhdunTJodpIBvaWO4SQR/6QS+4QQn75w5FzhxDMH3Jib/lDDrlDCPnkD7nlDiEcO3/YU+5gZ1QDBgwYIBITE43HOp1OBAYGitTUVBtG1TQ3JgS9Xi/8/f3F7NmzjecKCwuFVqsVX331lRBCiEOHDgkAYufOncYyP/30k5AkSZw7d04IIcSHH34ovLy8RGVlpbHMSy+9JMLCwlq4RY27ePGiACA2btwohDC0S61Wi2+//dZY5vDhwwKA2LZtmxDCkDwVCoXIy8szllmwYIFwd3c3tu3FF18UPXr0MHmvMWPGiLi4uJZuUqO8vLzEJ5984pBtLCkpEV26dBHr1q0TQ4cONSYER2nr9OnTRWRkZIPXHKWNZGDPuUMI+eQPOeUOIRw3fzh67hCC+UNO7Dl/yCV3CCGv/OGouUMIx88f9pQ7+JjeDaqqqpCZmYnY2FjjOYVCgdjYWGzbts2GkTXPqVOnkJeXZ9IeDw8PREdHG9uzbds2eHp6ol+/fsYysbGxUCgU+O2334xl7rzzTmg0GmOZuLg4ZGdn4+rVq1ZqjamioiIAQNu2bQEAmZmZqK6uNmlrt27d0KFDB5O29urVC35+fsYycXFxKC4uxsGDB41lrq+jtowtfv86nQ7Lli1DWVkZYmJiHLKNiYmJGDVqVL14HKmtx44dQ2BgIDp16oT4+Hjk5OQAcKw2yp2j5Q7AcfOHHHIH4Pj5Qw65A2D+kANHyx+OmjsAeeQPR88dgDzyh73kDnZG3eDy5cvQ6XQmP3wA8PPzQ15eno2iar7amG/Wnry8PPj6+ppcV6lUaNu2rUmZhuq4/j2sSa/X49lnn8XgwYPRs2dPYxwajQaenp4mZW9s663a0ViZ4uJilJeXt0Rz6snKykKbNm2g1WoxadIkrFixAuHh4Q7VRgBYtmwZdu/ejdTU1HrXHKWt0dHRWLJkCdLT07FgwQKcOnUKQ4YMQUlJicO0kRwvdwCOmT8cPXcA8sgfcsgdAPOHXDha/nDE3AE4fv6QQ+4A5JE/7Cl3qMxtHFFrkJiYiAMHDmDz5s22DqVFhIWFYe/evSgqKsLy5cuRkJCAjRs32josi8rNzUVycjLWrVsHJycnW4fTYkaMGGHcj4iIQHR0NEJCQvDNN9/A2dnZhpERyY+j5w7A8fOHXHIHwPxB1Jo4ev5w9NwByCd/2FPu4MioG3h7e0OpVNabUT4/Px/+/v42iqr5amO+WXv8/f1x8eJFk+s1NTUoKCgwKdNQHde/h7UkJSVh9erVWL9+Pdq3b2887+/vj6qqKhQWFpqUv7Gtt2pHY2Xc3d2t9h+wRqNB586dERUVhdTUVERGRuJf//qXQ7UxMzMTFy9eRN++faFSqaBSqbBx40Z88MEHUKlU8PPzc5i2Xs/T0xNdu3bF8ePHHer3KXeOljsAx8sfcsgdgOPnD7nmDoD5w1E5Wv5wtNwByCN/OHruAOSbP1pz7mBn1A00Gg2ioqKQkZFhPKfX65GRkYGYmBgbRtY8HTt2hL+/v0l7iouL8dtvvxnbExMTg8LCQmRmZhrL/Prrr9Dr9YiOjjaW2bRpE6qrq41l1q1bh7CwMHh5eVmlLUIIJCUlYcWKFfj111/RsWNHk+tRUVFQq9Umbc3OzkZOTo5JW7OyskwS4Lp16+Du7o7w8HBjmevrqC1jy9+/Xq9HZWWlQ7Vx2LBhyMrKwt69e41bv379EB8fb9x3lLZer7S0FCdOnEBAQIBD/T7lztFyB+A4+UPOuQNwvPwh19wBMH84KkfLH46SOwB55w9Hyx2AfPNHq84dZk13LhPLli0TWq1WLFmyRBw6dEhMnDhReHp6mswo35qUlJSIPXv2iD179ggAYs6cOWLPnj3izJkzQgjD8qqenp7ihx9+EPv37xcPPvhgg8ur9unTR/z2229i8+bNokuXLibLqxYWFgo/Pz/xxBNPiAMHDohly5YJFxcXqy6vOnnyZOHh4SE2bNhgslTl77//biwzadIk0aFDB/Hrr7+KXbt2iZiYGBETE2O8XrtU5b333iv27t0r0tPThY+PT4NLVb7wwgvi8OHDYv78+VZdjvPll18WGzduFKdOnRL79+8XL7/8spAkSfz3v/91mDY25voVLYRwjLY+99xzYsOGDeLUqVNiy5YtIjY2Vnh7e4uLFy86TBvJwN5yhxDyyB9yyR1CyDd/OGLuEIL5Q07sLX/IIXcIIZ/8IdfcIYRj5g97yh3sjGrEvHnzRIcOHYRGoxEDBgwQ27dvt3VIjVq/fr0AUG9LSEgQQhiWWH3ttdeEn5+f0Gq1YtiwYSI7O9ukjitXrojHHntMtGnTRri7u4vx48eLkpISkzL79u0Td9xxh9BqtSIoKEjMmjXLWk0UQogG2whALF682FimvLxcTJkyRXh5eQkXFxfx0EMPiQsXLpjUc/r0aTFixAjh7OwsvL29xXPPPSeqq6tNyqxfv1707t1baDQa0alTJ5P3aGlPPvmkCAkJERqNRvj4+Ihhw4YZk4EQjtHGxtyYEByhrWPGjBEBAQFCo9GIoKAgMWbMGHH8+HHjdUdoI9Wxp9whhDzyh1xyhxDyzR+OmDuEYP6QG3vKH3LIHULIJ3/INXcI4Zj5w55yhySEEOaNpSIiIiIiIiIiImoezhlFRERERERERERWw84oIiIiIiIiIiKyGnZGERERERERERGR1bAzioiIiIiIiIiIrIadUUREREREREREZDXsjCIiIiIiIiIiIqthZxQREREREREREVkNO6OIiIiIiIiIiMhq2BlF1ApJkoSVK1faOgwiIrIjzB1ERGQu5g6yFXZGEd1g3LhxkCSp3jZ8+HBbh0ZERK0UcwcREZmLuYPkTGXrAIhao+HDh2Px4sUm57RarY2iISIie8DcQURE5mLuILniyCiiBmi1Wvj7+5tsXl5eAAxDWRcsWIARI0bA2dkZnTp1wvLly03uz8rKwt133w1nZ2e0a9cOEydORGlpqUmZtLQ09OjRA1qtFgEBAUhKSjK5fvnyZTz00ENwcXFBly5dsGrVqpZtNBER3RbmDiIiMhdzB8kVO6OImuG1117Dww8/jH379iE+Ph6PPvooDh8+DAAoKytDXFwcvLy8sHPnTnz77bf45ZdfTD70FyxYgMTEREycOBFZWVlYtWoVOnfubPIeM2bMwF/+8hfs378fI0eORHx8PAoKCqzaTiIishzmDiIiMhdzBzksQUQmEhIShFKpFK6uribb22+/LYQQAoCYNGmSyT3R0dFi8uTJQgghPv74Y+Hl5SVKS0uN19esWSMUCoXIy8sTQggRGBgoXn311UZjACD+/ve/G49LS0sFAPHTTz9ZrJ1ERGQ5zB1ERGQu5g6SM84ZRdSAP/7xj1iwYIHJubZt2xr3Y2JiTK7FxMRg7969AIDDhw8jMjISrq6uxuuDBw+GXq9HdnY2JEnC+fPnMWzYsJvGEBERYdx3dXWFu7s7Ll682NwmERFRC2PuICIiczF3kFyxM4qoAa6urvWGr1qKs7Nzk8qp1WqTY0mSoNfrWyIkIiKyAOYOIiIyF3MHyRXnjCJqhu3bt9c77t69OwCge/fu2LdvH8rKyozXt2zZAoVCgbCwMLi5uSE0NBQZGRlWjZmIiGyLuYOIiMzF3EGOiiOjiBpQWVmJvLw8k3MqlQre3t4AgG+//Rb9+vXDHXfcgS+++AI7duzAp59+CgCIj4/H9OnTkZCQgDfeeAOXLl3C1KlT8cQTT8DPzw8A8MYbb2DSpEnw9fXFiBEjUFJSgi1btmDq1KnWbSgREVkMcwcREZmLuYPkip1RRA1IT09HQECAybmwsDAcOXIEgGHFiWXLlmHKlCkICAjAV199hfDwcACAi4sLfv75ZyQnJ6N///5wcXHBww8/jDlz5hjrSkhIQEVFBd5//308//zz8Pb2xp///GfrNZCIiCyOuYOIiMzF3EFyJQkhhK2DILInkiRhxYoVGD16tK1DISIiO8HcQURE5mLuIEfGOaOIiIiIiIiIiMhq2BlFRERERERERERWw8f0iIiIiIiIiIjIajgyioiIiIiIiIiIrIadUUREREREREREZDXsjCIiIiIiIiIiIqthZxQREREREREREVkNO6OIiIiIiIiIiMhq2BlFRERERERERERWw84oIiIiIiIiIiKyGnZGERERERERERGR1bAzioiIiIiIiIiIrOb/AYDmZFjko5yoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set-up a 1x2 figure for binary cross-entropy, precision & recall\n",
    "fig, axs=plt.subplots(1,3, figsize=(12,3))\n",
    "\n",
    "# Add the main title\n",
    "fig.suptitle('Classifier training curves', size='large')\n",
    "\n",
    "axs[0].set_title('Binary cross-entropy')\n",
    "axs[0].plot(training_results.history['loss'], label='Training')\n",
    "axs[0].plot(training_results.history['val_loss'], label='Validation')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Binary cross-entropy')\n",
    "axs[0].legend(loc='upper left')\n",
    "\n",
    "axs[1].set_title('Precision')\n",
    "axs[1].plot(training_results.history['precision'])\n",
    "axs[1].plot(training_results.history['val_precision'])\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Precision')\n",
    "\n",
    "axs[2].set_title('Recall')\n",
    "axs[2].plot(training_results.history['recall'])\n",
    "axs[2].plot(training_results.history['val_recall'])\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Recall')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.659\n",
      "Recall: 0.685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=nn_model.predict(testing_features_df)\n",
    "calls=list(np.where(np.array(predictions) > 0.5, 1, 0))\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision=precision_score(testing_labels_df['efs'], calls)\n",
    "recall=recall_score(testing_labels_df['efs'], calls)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm=confusion_matrix(testing_labels_df['efs'], calls, normalize='true')\n",
    "cm_disp=ConfusionMatrixDisplay(confusion_matrix=cm)#, display_labels=['0', 'EFS 1'])\n",
    "_=cm_disp.plot()\n",
    "\n",
    "plt.title('Test set gradient boosting classifier performance')\n",
    "plt.xlabel('Predicted EFS')\n",
    "plt.ylabel('True EFS')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
