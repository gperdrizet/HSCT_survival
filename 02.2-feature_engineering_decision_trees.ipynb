{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival data feature engineering\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "dictionary_file='./data/raw/data_dictionary.csv'\n",
    "training_file='./data/raw/train.csv'\n",
    "testing_file='./data/raw/test.csv'\n",
    "\n",
    "standard_scaler_file='./models/02.1-standard_scaler.pkl'\n",
    "training_features_df_file='./data/processed/02.1-linear-logistic_regression_training_features_df.parquet'\n",
    "training_labels_df_file='./data/processed/02.1-linear-logistic_regression_training_labels_df.parquet'\n",
    "testing_features_df_file='./data/processed/02.1-linear-logistic_regression_testing_features_df.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (28800, 57)\n",
      "Testing features: (3, 57)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "dictionary_df=pd.read_csv(dictionary_file)\n",
    "training_df=pd.read_csv(training_file)\n",
    "testing_df=pd.read_csv(testing_file)\n",
    "\n",
    "# Save the ID and drop\n",
    "training_ids=training_df['ID']\n",
    "testing_ids=testing_df['ID']\n",
    "training_df.drop('ID', axis=1, inplace=True)\n",
    "testing_df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# Remove the labels from the training dataframe\n",
    "training_labels_df=training_df[['efs', 'efs_time']].copy()\n",
    "training_df.drop(['efs', 'efs_time'], axis=1, inplace=True)\n",
    "\n",
    "print(f'Training features: {training_df.shape}')\n",
    "print(f'Testing features: {testing_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training numerical features: (28800, 22)\n",
      "Training categorical features: (28800, 35)\n",
      "Testing numerical features: (3, 22)\n",
      "Testing categorical features: (3, 35)\n"
     ]
    }
   ],
   "source": [
    "# Get lists of categorical and numerical column names\n",
    "categorical_feature_names=dictionary_df['variable'][dictionary_df['type'] == 'Categorical']\n",
    "numerical_feature_names=dictionary_df['variable'][dictionary_df['type'] == 'Numerical']\n",
    "\n",
    "# Remove the feature column from the column names lists\n",
    "categorical_feature_names=categorical_feature_names[categorical_feature_names != 'efs']\n",
    "numerical_feature_names=numerical_feature_names[numerical_feature_names != 'efs_time']\n",
    "\n",
    "# Split the training and testing dataframes\n",
    "training_categorical_df=training_df[categorical_feature_names].copy()\n",
    "training_numerical_df=training_df[numerical_feature_names].copy()\n",
    "testing_categorical_df=testing_df[categorical_feature_names].copy()\n",
    "testing_numerical_df=testing_df[numerical_feature_names].copy()\n",
    "\n",
    "print(f'Training numerical features: {training_numerical_df.shape}')\n",
    "print(f'Training categorical features: {training_categorical_df.shape}')\n",
    "print(f'Testing numerical features: {testing_numerical_df.shape}')\n",
    "print(f'Testing categorical features: {testing_categorical_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle missing data\n",
    "\n",
    "### 3.1. Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training categorical features: (28800, 35)\n",
      "Testing categorical features: (3, 35)\n"
     ]
    }
   ],
   "source": [
    "training_categorical_df.fillna('Missing', inplace=True)\n",
    "testing_categorical_df.fillna('Missing', inplace=True)\n",
    "\n",
    "print(f'Training categorical features: {training_categorical_df.shape}')\n",
    "print(f'Testing categorical features: {testing_categorical_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training numerical features: (28800, 22)\n",
      "Testing numerical features: (3, 22)\n"
     ]
    }
   ],
   "source": [
    "# Use K-nearest neighbor imputation to fill in missing data\n",
    "imputer=KNNImputer(n_neighbors=3, weights='uniform')\n",
    "imputer.fit(training_numerical_df)\n",
    "\n",
    "training_numerical_data=imputer.transform(training_numerical_df)\n",
    "testing_numerical_data=imputer.transform(testing_numerical_df)\n",
    "\n",
    "# Save the imputer for later\n",
    "with open('./models/02-KNN_imputer.pkl', 'wb') as output_file:\n",
    "    pickle.dump(imputer, output_file)\n",
    "\n",
    "# Re-build dataframes\n",
    "training_numerical_df=pd.DataFrame(training_numerical_data, columns=training_numerical_df.columns)\n",
    "testing_numerical_df=pd.DataFrame(testing_numerical_data, columns=testing_numerical_df.columns)\n",
    "\n",
    "print(f'Training numerical features: {training_numerical_df.shape}')\n",
    "print(f'Testing numerical features: {testing_numerical_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. One-hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training categorical features: (28800, 156)\n",
      "Testing categorical features: (3, 156)\n"
     ]
    }
   ],
   "source": [
    "# Encode the features\n",
    "encoder=OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoder.fit(training_categorical_df)\n",
    "\n",
    "training_categorical_data=encoder.transform(training_categorical_df)\n",
    "testing_categorical_data=encoder.transform(testing_categorical_df)\n",
    "\n",
    "# Save the one-hot encoder for later\n",
    "with open('./models/02-one_hot_encoder.pkl', 'wb') as output_file:\n",
    "    pickle.dump(encoder, output_file)\n",
    "\n",
    "# Rebuild the dataframes\n",
    "feature_names=encoder.get_feature_names_out()\n",
    "training_categorical_df=pd.DataFrame(training_categorical_data, columns=feature_names)\n",
    "testing_categorical_df=pd.DataFrame(testing_categorical_data, columns=feature_names)\n",
    "\n",
    "print(f'Training categorical features: {training_categorical_df.shape}')\n",
    "print(f'Testing categorical features: {testing_categorical_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Re-combine numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (28800, 178)\n",
      "Testing features: (3, 178)\n"
     ]
    }
   ],
   "source": [
    "training_features_df=pd.concat(\n",
    "    [\n",
    "        training_numerical_df.reset_index(drop=True), \n",
    "        training_categorical_df.reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "testing_features_df=pd.concat(\n",
    "    [\n",
    "        testing_numerical_df.reset_index(drop=True), \n",
    "        testing_categorical_df.reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f'Training features: {training_features_df.shape}')\n",
    "print(f'Testing features: {testing_features_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if needed\n",
    "Path('./data/processed').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add back ID column\n",
    "training_features_df['ID']=training_ids\n",
    "testing_features_df['ID']=testing_ids\n",
    "\n",
    "training_features_df.to_parquet('./data/processed/training_features_df.parquet', index=False)\n",
    "training_labels_df.to_parquet('./data/processed/training_labels_df.parquet', index=False)\n",
    "testing_features_df.to_parquet('./data/processed/testing_features_df.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
