{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSCT survival gradient boosting decision tree model\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "retrain_models=True\n",
    "baseline_model_file='./models/05.1-gradient_boosting_baseline.pkl'\n",
    "tuned_model_file='./models/05.2-gradient_boosting_tuned.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features=pd.read_parquet('./data/encoded/training_features_df.parquet')\n",
    "training_labels=pd.read_parquet('./data/encoded/training_labels_df.parquet')\n",
    "\n",
    "# Take the log of the labels\n",
    "training_labels['efs_time']=np.log(training_labels['efs_time'])\n",
    "\n",
    "# Take the square root of the features\n",
    "training_features=training_features\n",
    "\n",
    "# Remove id column from training features\n",
    "training_features.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "plt.title('EFS time distribution')\n",
    "plt.hist(training_labels['efs_time'], density=True, bins=30, color='black')\n",
    "plt.xlabel('EFS time')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "print(f'Training features: {training_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, features: pd.DataFrame, labels: pd.Series) -> list[float]:\n",
    "    '''Reusable helper function to run cross-validation on a model. Takes model,\n",
    "    Pandas data frame of features and Pandas data series of labels. Returns \n",
    "    list of cross-validation fold accuracy scores as percents.'''\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cross_validation=KFold(n_splits=7, shuffle=True, random_state=315)\n",
    "\n",
    "    # Run the cross-validation, collecting the scores\n",
    "    scores=cross_val_score(\n",
    "        model,\n",
    "        features,\n",
    "        labels,\n",
    "        cv=cross_validation,\n",
    "        n_jobs=-1,\n",
    "        scoring='neg_root_mean_squared_error'\n",
    "    )\n",
    "\n",
    "    # Print mean and standard deviation of the scores\n",
    "    print(f'Cross validation RMSE {-scores.mean():.2f} +/- {scores.std():.2f}')\n",
    "\n",
    "    # Return the scores\n",
    "    return scores\n",
    "\n",
    "# Instantiate default elastic net model\n",
    "baseline_model=GradientBoostingRegressor(random_state=315)\n",
    "\n",
    "# Run cross-validation to estimate out-of-sample performance\n",
    "baseline_scores=cross_val(baseline_model, training_features, training_labels['efs_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit and evaluate baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load model as desired\n",
    "if retrain_models == True:\n",
    "    baseline_model.fit(training_features, training_labels['efs_time'])\n",
    "\n",
    "    with open(baseline_model_file, 'wb') as output_file:\n",
    "        pickle.dump(baseline_model, output_file)\n",
    "\n",
    "elif retrain_models == False:\n",
    "    with open(baseline_model_file, 'rb') as input_file:\n",
    "        baseline_model=pickle.load(input_file)\n",
    "\n",
    "# Make predictions for the whole test set\n",
    "predicted_efs_time=baseline_model.predict(training_features)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,3, figsize=(10,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Baseline gradient regression model performance')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "axs[0].scatter(training_labels['efs_time'], predicted_efs_time, color='black', s=0.2)\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "\n",
    "axs[1].set_title('EFS residual as a function of fitted value')\n",
    "axs[1].scatter(predicted_efs_time, training_labels['efs_time'] - predicted_efs_time, color='black', s=0.2)\n",
    "axs[1].set_xlabel('EFS time')\n",
    "axs[1].set_ylabel('true - predicted EFS time')\n",
    "\n",
    "axs[2].set_title('Normal quantile plot')\n",
    "stats.probplot(training_labels['efs_time'] - predicted_efs_time, plot=axs[2])\n",
    "axs[2].get_lines()[0].set_markeredgecolor('black')\n",
    "axs[2].get_lines()[0].set_markerfacecolor('black')\n",
    "axs[2].set_xlabel('Normal quantiles')\n",
    "axs[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load model as desired\n",
    "if retrain_models == True:\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model=GradientBoostingRegressor(random_state=315)\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cross_validation=KFold(n_splits=7, shuffle=True, random_state=315)\n",
    "\n",
    "    # Define the hyperparameter search space\n",
    "    distributions={\n",
    "        'learning_rate': stats.uniform(loc=0.00001, scale=0.00999),\n",
    "        'n_estimators': list(range(10, 500)),\n",
    "        'max_depth': list(range(5, 10)),\n",
    "        'min_samples_split': list(range(2, 100)),\n",
    "        'min_samples_leaf': list(range(2, 100)),\n",
    "        'subsample': stats.uniform(loc=0.5, scale=0.5)\n",
    "    }\n",
    "\n",
    "    # Set-up the search\n",
    "    search=RandomizedSearchCV(\n",
    "        model,\n",
    "        distributions,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        cv=cross_validation,\n",
    "        n_iter=100,\n",
    "        random_state=315,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    results=search.fit(training_features, training_labels['efs_time'])\n",
    "    print(f'Best hyperparameters: {results.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit and evaluate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load model as desired\n",
    "if retrain_models == True:\n",
    "    \n",
    "    # Instantiate the model with the tuned hyperparameters\n",
    "    tuned_model=GradientBoostingRegressor(**results.best_params_, random_state=315)\n",
    "    tuned_model.fit(training_features, training_labels['efs_time'])\n",
    "\n",
    "    with open(tuned_model_file, 'wb') as output_file:\n",
    "        pickle.dump(tuned_model, output_file)\n",
    "\n",
    "elif retrain_models == False:\n",
    "    with open(tuned_model_file, 'rb') as input_file:\n",
    "        tuned_model=pickle.load(input_file)\n",
    "\n",
    "# Run cross-validation to estimate out-of-sample performance\n",
    "tuned_scores=cross_val(model, training_features, training_labels['efs_time'])\n",
    "\n",
    "# Make predictions on the training set\n",
    "predicted_efs_time=tuned_model.predict(training_features)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs=plt.subplots(1,3, figsize=(10,4))\n",
    "axs=axs.flatten()\n",
    "\n",
    "fig.suptitle('Tuned gradient boosting regression model performance')\n",
    "\n",
    "axs[0].set_title('Actual vs predicted EFS time')\n",
    "axs[0].scatter(training_labels['efs_time'], predicted_efs_time, color='black', s=0.2)\n",
    "axs[0].set_xlabel('True EFS time')\n",
    "axs[0].set_ylabel('Predicted EFS time')\n",
    "\n",
    "axs[1].set_title('EFS residual as a function of fitted value')\n",
    "axs[1].scatter(predicted_efs_time, training_labels['efs_time'] - predicted_efs_time, color='black', s=0.2)\n",
    "axs[1].set_xlabel('EFS time')\n",
    "axs[1].set_ylabel('true - predicted EFS time')\n",
    "\n",
    "axs[2].set_title('Normal quantile plot')\n",
    "stats.probplot(training_labels['efs_time'] - predicted_efs_time, plot=axs[2])\n",
    "axs[2].get_lines()[0].set_markeredgecolor('black')\n",
    "axs[2].get_lines()[0].set_markerfacecolor('black')\n",
    "axs[2].set_xlabel('Normal quantiles')\n",
    "axs[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features_df=pd.read_parquet('./data/encoded/testing_features_df.parquet')\n",
    "ids=testing_features_df['ID']\n",
    "testing_features_df.drop('ID', axis=1, inplace=True)\n",
    "predicted_efs_time=tuned_model.predict(testing_features_df)\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(predicted_efs_time.reshape(-1, 1))\n",
    "predicted_efs_time=scaler.transform(predicted_efs_time.reshape(-1, 1))\n",
    "\n",
    "predictions_df=pd.DataFrame.from_dict({'ID': ids, 'prediction': predicted_efs_time.flatten()})\n",
    "predictions_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
